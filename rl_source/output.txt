WARNING:tensorflow:From alumni_env_continual_learning.py:37: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From alumni_env_continual_learning.py:39: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-05-12 14:14:08.743183: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-05-12 14:14:08.748160: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-05-12 14:14:08.751635: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-05-12 14:14:08.751747: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: vumacs
2020-05-12 14:14:08.751800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: vumacs
2020-05-12 14:14:08.751910: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.64.0
2020-05-12 14:14:08.751974: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0
2020-05-12 14:14:08.752023: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.64.0
2020-05-12 14:14:08.770871: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2020-05-12 14:14:08.771814: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e3a030 executing computations on platform Host. Devices:
2020-05-12 14:14:08.771930: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-05-12 14:14:08.773460: I tensorflow/core/common_runtime/direct_session.cc:296] Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device

Using TensorFlow backend.
Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.86it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 200.43it/s]Retaining 94.49086969978335% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 58.70it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 208.70it/s]Retaining 96.27444892890406% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 59.79it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 213.66it/s]Retaining 96.29629629629629% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 38.90it/s]Dask Apply:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:00<00:00, 52.95it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 191.59it/s]Retaining 99.59349593495935% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 48.40it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 216.94it/s]Retaining 99.93222636394442% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.17it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 211.49it/s]Retaining 99.9647266313933% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 89.27it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 226.46it/s]Retaining 99.9622641509434% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 88.45it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 234.15it/s]Retaining 99.96244836650395% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  20%|â–ˆâ–ˆ        | 8/40 [00:00<00:00, 79.36it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 231.59it/s]Retaining 99.96236356793376% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 88.31it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 236.10it/s]Retaining 99.9623352165725% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 89.76it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 226.32it/s]Retaining 99.96249062265566% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 69.96it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 224.25it/s]Retaining 99.9626307922272% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 87.69it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 227.41it/s]Retaining 99.96292176492399% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 69.37it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 217.64it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 59.15it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 207.03it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 45.65it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 197.01it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 48.95it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 207.46it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.92it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 211.49it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.48it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 203.99it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 58.74it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 78.06it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 196.40it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 48.45it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 200.84it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 45.86it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 206.71it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.35it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 200.26it/s]Retaining 100.0% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.19it/s]Dask Apply:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:00<00:00, 65.84it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 194.36it/s]Retaining 99.96824388694824% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 59.73it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 209.62it/s]Retaining 99.96828417380273% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 53.96it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 203.15it/s]Retaining 99.9680817108203% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.64it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 212.67it/s]Retaining 99.96951219512195% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:   8%|â–Š         | 3/40 [00:00<00:01, 29.60it/s]Dask Apply:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:00<00:00, 40.77it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 193.32it/s]Retaining 98.38187702265373% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.81it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 224.92it/s]Retaining 96.69711876317639% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  20%|â–ˆâ–ˆ        | 8/40 [00:00<00:00, 79.92it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 225.10it/s]Retaining 95.95125786163523% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.39it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 207.97it/s]Retaining 95.35066981875492% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.54it/s]Dask Apply:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:00<00:00, 53.69it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 194.03it/s]Retaining 71.95914577530176% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.72it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 210.66it/s]Retaining 69.04687985097796% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.11it/s]Dask Apply:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:00<00:00, 65.94it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 196.87it/s]Retaining 69.84126984126983% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 56.52it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 198.41it/s]Retaining 67.38586616635398% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.10it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 217.42it/s]Retaining 68.99356150457471% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 89.86it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 230.08it/s]Retaining 70.54673721340389% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:00<00:00, 97.93it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 230.71it/s]Retaining 75.16981132075472% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  20%|â–ˆâ–ˆ        | 8/40 [00:00<00:00, 78.66it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 224.40it/s]Retaining 79.34660157716861% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.54it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 225.42it/s]Retaining 80.7677832141513% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 88.21it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 208.28it/s]Retaining 83.91713747645952% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.13it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 217.94it/s]Retaining 83.30832708177044% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  20%|â–ˆâ–ˆ        | 8/40 [00:00<00:00, 79.41it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 233.85it/s]Retaining 81.83856502242152% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 87.61it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 229.19it/s]Retaining 81.90582128290693% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  20%|â–ˆâ–ˆ        | 8/40 [00:00<00:00, 78.04it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 233.17it/s]Retaining 79.9118619170033% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.20it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 217.99it/s]Retaining 78.90835579514825% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 86.95it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 220.62it/s]Retaining 74.87844408427877% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 58.32it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 206.53it/s]Retaining 70.78760490639122% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.53it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 208.20it/s]Retaining 66.02129719264279% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.48it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 201.76it/s]Retaining 67.30830927173564% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 59.06it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 217.05it/s]Retaining 64.86917677089981% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.51it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 200.16it/s]Retaining 66.1151765828826% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:   8%|â–Š         | 3/40 [00:00<00:01, 29.11it/s]Dask Apply:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:00<00:00, 40.11it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 182.03it/s]Retaining 66.94214876033058% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.10it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 210.95it/s]Retaining 66.12646965363838% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  15%|â–ˆâ–Œ        | 6/40 [00:00<00:00, 55.44it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 200.76it/s]Retaining 70.3080342966021% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.62it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 203.81it/s]Retaining 71.83634633682207% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.71it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 214.17it/s]Retaining 72.74178104053622% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  10%|â–ˆ         | 4/40 [00:00<00:00, 39.43it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 204.98it/s]Retaining 75.03048780487805% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  12%|â–ˆâ–Ž        | 5/40 [00:00<00:00, 49.54it/s]Dask Apply:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:00<00:00, 66.49it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 197.83it/s]Retaining 79.8705501618123% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  18%|â–ˆâ–Š        | 7/40 [00:00<00:00, 68.85it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 224.99it/s]Retaining 78.1447645818693% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:00<00:00, 88.61it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 239.71it/s]Retaining 79.63836477987421% of the data

Dask Apply:   0%|          | 0/40 [00:00<?, ?it/s]Dask Apply:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:00<00:00, 107.06it/s]Dask Apply: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 239.51it/s]
WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-05-12 14:14:57.923400: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.

WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/keras/callbacks.py:856: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.

Retaining 79.55082742316785% of the data
Train on 2737 samples, validate on 316 samples
Epoch 1/5000
 - 1s - loss: 0.0483 - val_loss: 0.1053
Epoch 2/5000
 - 0s - loss: 0.0483 - val_loss: 0.1053
Epoch 3/5000
 - 0s - loss: 0.0483 - val_loss: 0.1053
Epoch 4/5000
 - 0s - loss: 0.0483 - val_loss: 0.1053
Epoch 5/5000
 - 0s - loss: 0.0483 - val_loss: 0.1053
Epoch 6/5000
 - 0s - loss: 0.0483 - val_loss: 0.1053
Train on 2009 samples, validate on 316 samples
Epoch 1/5000
 - 0s - loss: 0.0941 - val_loss: 0.0307
Epoch 2/5000
 - 0s - loss: 0.0232 - val_loss: 0.0074
Epoch 3/5000
 - 0s - loss: 0.0138 - val_loss: 0.0087
Epoch 4/5000
 - 0s - loss: 0.0113 - val_loss: 0.0067
Epoch 5/5000
 - 0s - loss: 0.0091 - val_loss: 0.0062
Epoch 6/5000
 - 0s - loss: 0.0078 - val_loss: 0.0067
Epoch 7/5000
 - 0s - loss: 0.0077 - val_loss: 0.0055
Epoch 8/5000
 - 0s - loss: 0.0073 - val_loss: 0.0055
Epoch 9/5000
 - 0s - loss: 0.0072 - val_loss: 0.0046
Epoch 10/5000
 - 0s - loss: 0.0071 - val_loss: 0.0042
Epoch 11/5000
 - 0s - loss: 0.0070 - val_loss: 0.0041
Epoch 12/5000
 - 0s - loss: 0.0069 - val_loss: 0.0038
Epoch 13/5000
 - 0s - loss: 0.0069 - val_loss: 0.0039
Epoch 14/5000
 - 0s - loss: 0.0068 - val_loss: 0.0037
Epoch 15/5000
 - 0s - loss: 0.0091 - val_loss: 0.0019
Epoch 16/5000
 - 0s - loss: 0.0062 - val_loss: 0.0020
Epoch 17/5000
 - 0s - loss: 0.0061 - val_loss: 0.0020
Epoch 18/5000
 - 0s - loss: 0.0060 - val_loss: 0.0019
Epoch 19/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 20/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 21/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 22/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 23/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 24/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 25/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 26/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 27/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 28/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 29/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 30/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 31/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 32/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 33/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 34/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 35/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 36/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 37/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 38/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 39/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 40/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 41/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 42/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 43/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 44/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
Epoch 45/5000
 - 0s - loss: 0.0058 - val_loss: 0.0019
WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Train on 2915 samples, validate on 316 samples
Epoch 1/5000
 - 2s - loss: 0.6501 - val_loss: 0.6606
Epoch 2/5000
 - 1s - loss: 0.6030 - val_loss: 0.6586
Epoch 3/5000
 - 1s - loss: 0.5906 - val_loss: 0.6519
Epoch 4/5000
 - 1s - loss: 0.5764 - val_loss: 0.6318
Epoch 5/5000
 - 1s - loss: 0.5342 - val_loss: 0.5628
Epoch 6/5000
 - 1s - loss: 0.4269 - val_loss: 0.5042
Epoch 7/5000
 - 1s - loss: 0.3562 - val_loss: 0.4893
Epoch 8/5000
 - 1s - loss: 0.3347 - val_loss: 0.4835
Epoch 9/5000
 - 1s - loss: 0.3261 - val_loss: 0.4810
Epoch 10/5000
 - 1s - loss: 0.3198 - val_loss: 0.4785
Epoch 11/5000
 - 1s - loss: 0.3146 - val_loss: 0.4754
Epoch 12/5000
 - 1s - loss: 0.3103 - val_loss: 0.4733
Epoch 13/5000
 - 1s - loss: 0.3068 - val_loss: 0.4709
Epoch 14/5000
 - 1s - loss: 0.3039 - val_loss: 0.4688
Epoch 15/5000
 - 1s - loss: 0.3014 - val_loss: 0.4670
Epoch 16/5000
 - 1s - loss: 0.2995 - val_loss: 0.4663
Epoch 17/5000
 - 1s - loss: 0.2980 - val_loss: 0.4652
Epoch 18/5000
 - 1s - loss: 0.2968 - val_loss: 0.4643
Epoch 19/5000
 - 1s - loss: 0.2956 - val_loss: 0.4641
Epoch 20/5000
 - 1s - loss: 0.2945 - val_loss: 0.4637
Epoch 21/5000
 - 1s - loss: 0.2934 - val_loss: 0.4628
Epoch 22/5000
 - 1s - loss: 0.2924 - val_loss: 0.4621
Epoch 23/5000
 - 1s - loss: 0.2913 - val_loss: 0.4619
Epoch 24/5000
 - 1s - loss: 0.2905 - val_loss: 0.4613
Epoch 25/5000
 - 1s - loss: 0.2898 - val_loss: 0.4618
Epoch 26/5000
 - 1s - loss: 0.2893 - val_loss: 0.4612
Epoch 27/5000
 - 1s - loss: 0.2884 - val_loss: 0.4608
Epoch 28/5000
 - 1s - loss: 0.2879 - val_loss: 0.4600
Epoch 29/5000
 - 1s - loss: 0.2874 - val_loss: 0.4597
Epoch 30/5000
 - 1s - loss: 0.2870 - val_loss: 0.4593
Epoch 31/5000
 - 1s - loss: 0.2865 - val_loss: 0.4587
Epoch 32/5000
 - 1s - loss: 0.2862 - val_loss: 0.4580
Epoch 33/5000
 - 1s - loss: 0.2859 - val_loss: 0.4578
Epoch 34/5000
 - 1s - loss: 0.2859 - val_loss: 0.4568
Epoch 35/5000
 - 1s - loss: 0.2852 - val_loss: 0.4566
Epoch 36/5000
 - 1s - loss: 0.2847 - val_loss: 0.4560
Epoch 37/5000
 - 1s - loss: 0.2840 - val_loss: 0.4552
Epoch 38/5000
 - 1s - loss: 0.2838 - val_loss: 0.4556
Epoch 39/5000
 - 1s - loss: 0.2838 - val_loss: 0.4554
Epoch 40/5000
 - 1s - loss: 0.2709 - val_loss: 0.4488
Epoch 41/5000
 - 1s - loss: 0.2695 - val_loss: 0.4456
Epoch 42/5000
 - 1s - loss: 0.2690 - val_loss: 0.4444
Epoch 43/5000
 - 1s - loss: 0.2688 - val_loss: 0.4438
Epoch 44/5000
 - 1s - loss: 0.2686 - val_loss: 0.4435
Epoch 45/5000
 - 1s - loss: 0.2684 - val_loss: 0.4434
Epoch 46/5000
 - 1s - loss: 0.2683 - val_loss: 0.4432
Epoch 47/5000
 - 1s - loss: 0.2682 - val_loss: 0.4430
Epoch 48/5000
 - 1s - loss: 0.2680 - val_loss: 0.4429
Epoch 49/5000
 - 1s - loss: 0.2679 - val_loss: 0.4428
Epoch 50/5000
 - 1s - loss: 0.2677 - val_loss: 0.4428
Epoch 51/5000
 - 1s - loss: 0.2676 - val_loss: 0.4427
Epoch 52/5000
 - 1s - loss: 0.2675 - val_loss: 0.4427
Epoch 53/5000
 - 1s - loss: 0.2664 - val_loss: 0.4428
Epoch 54/5000
 - 1s - loss: 0.2664 - val_loss: 0.4428
Epoch 55/5000
 - 1s - loss: 0.2664 - val_loss: 0.4428
Epoch 56/5000
 - 1s - loss: 0.2663 - val_loss: 0.4428
Epoch 57/5000
 - 1s - loss: 0.2662 - val_loss: 0.4428
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: [33mWARN: Box bound precision lowered by casting to float32[0m
  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))
WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.flatten instead.
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8bb5634320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8bb5634320>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8ba87d7c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8ba87d7c18>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.

WARNING:tensorflow:From /data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

setting environment to train mode..... 

Training Started... 

---------------------------------------
| approxkl           | 6.3692705e-06  |
| clipfrac           | 0.0            |
| explained_variance | 0.00153        |
| fps                | 29             |
| n_updates          | 1              |
| policy_entropy     | 1.4182982      |
| policy_loss        | -3.8769795e-05 |
| serial_timesteps   | 128            |
| time_elapsed       | 1.12e-05       |
| total_timesteps    | 128            |
| value_loss         | 5735.4233      |
---------------------------------------
---------------------------------------
| approxkl           | 1.8332435e-06  |
| clipfrac           | 0.0            |
| explained_variance | 0.000547       |
| fps                | 37             |
| n_updates          | 2              |
| policy_entropy     | 1.4171113      |
| policy_loss        | -0.00013996975 |
| serial_timesteps   | 256            |
| time_elapsed       | 4.33           |
| total_timesteps    | 256            |
| value_loss         | 4198.6445      |
---------------------------------------
-------------------------------------
| approxkl           | 8.780715e-05 |
| clipfrac           | 0.0          |
| explained_variance | 0.00115      |
| fps                | 38           |
| n_updates          | 3            |
| policy_entropy     | 1.4162124    |
| policy_loss        | -0.001858911 |
| serial_timesteps   | 384          |
| time_elapsed       | 7.73         |
| total_timesteps    | 384          |
| value_loss         | 2030.2968    |
-------------------------------------
--------------------------------------
| approxkl           | 9.758199e-05  |
| clipfrac           | 0.0           |
| explained_variance | 0.00243       |
| fps                | 46            |
| n_updates          | 4             |
| policy_entropy     | 1.4153963     |
| policy_loss        | -0.0011412997 |
| serial_timesteps   | 512           |
| time_elapsed       | 11            |
| total_timesteps    | 512           |
| value_loss         | 1210.0121     |
--------------------------------------
--------------------------------------
| approxkl           | 5.8779704e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.00445       |
| fps                | 44            |
| n_updates          | 5             |
| policy_entropy     | 1.4147862     |
| policy_loss        | -0.0018001501 |
| serial_timesteps   | 640           |
| time_elapsed       | 13.8          |
| total_timesteps    | 640           |
| value_loss         | 125.34774     |
--------------------------------------
--------------------------------------
| approxkl           | 7.671842e-05  |
| clipfrac           | 0.0           |
| explained_variance | 0.00278       |
| fps                | 36            |
| n_updates          | 6             |
| policy_entropy     | 1.4144169     |
| policy_loss        | -0.0028105953 |
| serial_timesteps   | 768           |
| time_elapsed       | 16.7          |
| total_timesteps    | 768           |
| value_loss         | 3083.892      |
--------------------------------------
--------------------------------------
| approxkl           | 2.627676e-05  |
| clipfrac           | 0.0           |
| explained_variance | 0.00123       |
| fps                | 41            |
| n_updates          | 7             |
| policy_entropy     | 1.4144375     |
| policy_loss        | -0.0009076528 |
| serial_timesteps   | 896           |
| time_elapsed       | 20.2          |
| total_timesteps    | 896           |
| value_loss         | 11592.019     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00014154548 |
| clipfrac           | 0.0           |
| explained_variance | 0.00541       |
| fps                | 38            |
| n_updates          | 8             |
| policy_entropy     | 1.4147965     |
| policy_loss        | -0.0025056321 |
| serial_timesteps   | 1024          |
| time_elapsed       | 23.3          |
| total_timesteps    | 1024          |
| value_loss         | 3684.8025     |
--------------------------------------
--------------------------------------
| approxkl           | 6.9387906e-06 |
| clipfrac           | 0.0           |
| explained_variance | 0.0137        |
| fps                | 40            |
| n_updates          | 9             |
| policy_entropy     | 1.414954      |
| policy_loss        | 0.00024520454 |
| serial_timesteps   | 1152          |
| time_elapsed       | 26.7          |
| total_timesteps    | 1152          |
| value_loss         | 23.066433     |
--------------------------------------
--------------------------------------
| approxkl           | 3.4863344e-05 |
| clipfrac           | 0.0           |
| explained_variance | -0.0173       |
| fps                | 41            |
| n_updates          | 10            |
| policy_entropy     | 1.4140756     |
| policy_loss        | 0.00019133091 |
| serial_timesteps   | 1280          |
| time_elapsed       | 29.8          |
| total_timesteps    | 1280          |
| value_loss         | 50.092106     |
--------------------------------------
--------------------------------------
| approxkl           | 2.2614957e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.00088       |
| fps                | 42            |
| n_updates          | 11            |
| policy_entropy     | 1.4127277     |
| policy_loss        | -0.0009568011 |
| serial_timesteps   | 1408          |
| time_elapsed       | 32.9          |
| total_timesteps    | 1408          |
| value_loss         | 273.52512     |
--------------------------------------
--------------------------------------
| approxkl           | 4.4436598e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.00629       |
| fps                | 42            |
| n_updates          | 12            |
| policy_entropy     | 1.412065      |
| policy_loss        | -0.0012327804 |
| serial_timesteps   | 1536          |
| time_elapsed       | 35.9          |
| total_timesteps    | 1536          |
| value_loss         | 581.17737     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00056256755  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.19e+03       |
| explained_variance | 0.0237         |
| fps                | 44             |
| n_updates          | 13             |
| policy_entropy     | 1.4121655      |
| policy_loss        | -0.00045212766 |
| serial_timesteps   | 1664           |
| time_elapsed       | 38.9           |
| total_timesteps    | 1664           |
| value_loss         | 87.035385      |
---------------------------------------
--------------------------------------
| approxkl           | 6.9274997e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.0394        |
| fps                | 42            |
| n_updates          | 14            |
| policy_entropy     | 1.4125222     |
| policy_loss        | 0.00064406067 |
| serial_timesteps   | 1792          |
| time_elapsed       | 41.8          |
| total_timesteps    | 1792          |
| value_loss         | 14.494101     |
--------------------------------------
---------------------------------------
| approxkl           | 9.235524e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.19e+03       |
| explained_variance | -0.064         |
| fps                | 47             |
| n_updates          | 15             |
| policy_entropy     | 1.4128883      |
| policy_loss        | -0.00067996676 |
| serial_timesteps   | 1920           |
| time_elapsed       | 44.9           |
| total_timesteps    | 1920           |
| value_loss         | 12.105663      |
---------------------------------------
An average of 0.0 episodes completed
Best mean reward: -inf - Latest 5 sample mean reward per episode: 2186.75
Saving new best model
--------------------------------------
| approxkl           | 0.0004297159  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.0278        |
| fps                | 45            |
| n_updates          | 16            |
| policy_entropy     | 1.414942      |
| policy_loss        | -0.0005840155 |
| serial_timesteps   | 2048          |
| time_elapsed       | 47.6          |
| total_timesteps    | 2048          |
| value_loss         | 69.410324     |
--------------------------------------
--------------------------------------
| approxkl           | 1.4610162e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.00681       |
| fps                | 44            |
| n_updates          | 17            |
| policy_entropy     | 1.4154143     |
| policy_loss        | 6.900926e-05  |
| serial_timesteps   | 2176          |
| time_elapsed       | 50.4          |
| total_timesteps    | 2176          |
| value_loss         | 994.0929      |
--------------------------------------
---------------------------------------
| approxkl           | 3.3318418e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.19e+03       |
| explained_variance | -0.107         |
| fps                | 50             |
| n_updates          | 18             |
| policy_entropy     | 1.415419       |
| policy_loss        | -0.00011782418 |
| serial_timesteps   | 2304           |
| time_elapsed       | 53.3           |
| total_timesteps    | 2304           |
| value_loss         | 12.692631      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00017115663 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | -0.0102       |
| fps                | 43            |
| n_updates          | 19            |
| policy_entropy     | 1.4150114     |
| policy_loss        | -0.0010012249 |
| serial_timesteps   | 2432          |
| time_elapsed       | 55.8          |
| total_timesteps    | 2432          |
| value_loss         | 12.7173       |
--------------------------------------
--------------------------------------
| approxkl           | 0.00013465768 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | -0.00095      |
| fps                | 44            |
| n_updates          | 20            |
| policy_entropy     | 1.4157212     |
| policy_loss        | -0.0012736577 |
| serial_timesteps   | 2560          |
| time_elapsed       | 58.7          |
| total_timesteps    | 2560          |
| value_loss         | 6210.765      |
--------------------------------------
--------------------------------------
| approxkl           | 3.8098658e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.0104        |
| fps                | 39            |
| n_updates          | 21            |
| policy_entropy     | 1.4160659     |
| policy_loss        | 0.00013487996 |
| serial_timesteps   | 2688          |
| time_elapsed       | 61.6          |
| total_timesteps    | 2688          |
| value_loss         | 2607.4734     |
--------------------------------------
--------------------------------------
| approxkl           | 3.35385e-05   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.00917       |
| fps                | 41            |
| n_updates          | 22            |
| policy_entropy     | 1.4159367     |
| policy_loss        | -0.0019586054 |
| serial_timesteps   | 2816          |
| time_elapsed       | 64.8          |
| total_timesteps    | 2816          |
| value_loss         | 1194.3282     |
--------------------------------------
--------------------------------------
| approxkl           | 1.4047997e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.0196        |
| fps                | 43            |
| n_updates          | 23            |
| policy_entropy     | 1.4158705     |
| policy_loss        | -0.0010390119 |
| serial_timesteps   | 2944          |
| time_elapsed       | 67.9          |
| total_timesteps    | 2944          |
| value_loss         | 453.19293     |
--------------------------------------
An average of 0.0 episodes completed
Best mean reward: 2186.75 - Latest 5 sample mean reward per episode: 2186.75
--------------------------------------
| approxkl           | 1.1117161e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.19e+03      |
| explained_variance | 0.022         |
| fps                | 45            |
| n_updates          | 24            |
| policy_entropy     | 1.4157879     |
| policy_loss        | 0.00045203778 |
| serial_timesteps   | 3072          |
| time_elapsed       | 70.9          |
| total_timesteps    | 3072          |
| value_loss         | 428.2139      |
--------------------------------------
---------------------------------------
| approxkl           | 1.8832503e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.84e+03       |
| explained_variance | 0.00576        |
| fps                | 42             |
| n_updates          | 25             |
| policy_entropy     | 1.4158676      |
| policy_loss        | -0.00018410769 |
| serial_timesteps   | 3200           |
| time_elapsed       | 73.7           |
| total_timesteps    | 3200           |
| value_loss         | 4804.2593      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00021481517 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | 0.00392       |
| fps                | 39            |
| n_updates          | 26            |
| policy_entropy     | 1.4169567     |
| policy_loss        | 0.0006987677  |
| serial_timesteps   | 3328          |
| time_elapsed       | 76.7          |
| total_timesteps    | 3328          |
| value_loss         | 16242.546     |
--------------------------------------
--------------------------------------
| approxkl           | 1.7028523e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | 0.0122        |
| fps                | 42            |
| n_updates          | 27            |
| policy_entropy     | 1.418199      |
| policy_loss        | 3.0509429e-05 |
| serial_timesteps   | 3456          |
| time_elapsed       | 79.9          |
| total_timesteps    | 3456          |
| value_loss         | 1282.4673     |
--------------------------------------
--------------------------------------
| approxkl           | 4.4151584e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | -0.256        |
| fps                | 46            |
| n_updates          | 28            |
| policy_entropy     | 1.4185452     |
| policy_loss        | -0.0002115583 |
| serial_timesteps   | 3584          |
| time_elapsed       | 82.9          |
| total_timesteps    | 3584          |
| value_loss         | 18.40335      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00013835968 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | 0.00929       |
| fps                | 46            |
| n_updates          | 29            |
| policy_entropy     | 1.4188828     |
| policy_loss        | -0.0016157804 |
| serial_timesteps   | 3712          |
| time_elapsed       | 85.7          |
| total_timesteps    | 3712          |
| value_loss         | 17.792086     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0004893248 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.84e+03     |
| explained_variance | 0.0244       |
| fps                | 46           |
| n_updates          | 30           |
| policy_entropy     | 1.4201006    |
| policy_loss        | 0.0013527975 |
| serial_timesteps   | 3840         |
| time_elapsed       | 88.4         |
| total_timesteps    | 3840         |
| value_loss         | 199.44736    |
-------------------------------------
---------------------------------------
| approxkl           | 3.531287e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.84e+03       |
| explained_variance | 0.0277         |
| fps                | 45             |
| n_updates          | 31             |
| policy_entropy     | 1.4205844      |
| policy_loss        | -0.00087347045 |
| serial_timesteps   | 3968           |
| time_elapsed       | 91.2           |
| total_timesteps    | 3968           |
| value_loss         | 80.41391       |
---------------------------------------
An average of 1.0 episodes completed
Best mean reward: 2186.75 - Latest 5 sample mean reward per episode: 1836.81
--------------------------------------
| approxkl           | 2.1513553e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | 0.0263        |
| fps                | 49            |
| n_updates          | 32            |
| policy_entropy     | 1.4202328     |
| policy_loss        | 0.00014108943 |
| serial_timesteps   | 4096          |
| time_elapsed       | 94            |
| total_timesteps    | 4096          |
| value_loss         | 52.21978      |
--------------------------------------
---------------------------------------
| approxkl           | 6.865879e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.84e+03       |
| explained_variance | -0.00833       |
| fps                | 44             |
| n_updates          | 33             |
| policy_entropy     | 1.4199305      |
| policy_loss        | -0.00018918491 |
| serial_timesteps   | 4224           |
| time_elapsed       | 96.6           |
| total_timesteps    | 4224           |
| value_loss         | 125.74245      |
---------------------------------------
---------------------------------------
| approxkl           | 9.492974e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.84e+03       |
| explained_variance | -0.384         |
| fps                | 43             |
| n_updates          | 34             |
| policy_entropy     | 1.4206095      |
| policy_loss        | -0.00028799882 |
| serial_timesteps   | 4352           |
| time_elapsed       | 99.5           |
| total_timesteps    | 4352           |
| value_loss         | 8.121748       |
---------------------------------------
--------------------------------------
| approxkl           | 3.6436402e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | 0.0477        |
| fps                | 42            |
| n_updates          | 35            |
| policy_entropy     | 1.423436      |
| policy_loss        | -0.0009020767 |
| serial_timesteps   | 4480          |
| time_elapsed       | 102           |
| total_timesteps    | 4480          |
| value_loss         | 292.28366     |
--------------------------------------
--------------------------------------
| approxkl           | 1.612142e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.84e+03      |
| explained_variance | 0.0149        |
| fps                | 44            |
| n_updates          | 36            |
| policy_entropy     | 1.4245201     |
| policy_loss        | 0.00027841819 |
| serial_timesteps   | 4608          |
| time_elapsed       | 105           |
| total_timesteps    | 4608          |
| value_loss         | 793.74677     |
--------------------------------------
---------------------------------------
| approxkl           | 4.5455928e-07  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.15e+03       |
| explained_variance | -0.125         |
| fps                | 43             |
| n_updates          | 37             |
| policy_entropy     | 1.4249079      |
| policy_loss        | -3.5138102e-05 |
| serial_timesteps   | 4736           |
| time_elapsed       | 108            |
| total_timesteps    | 4736           |
| value_loss         | 23.426945      |
---------------------------------------
--------------------------------------
| approxkl           | 4.852705e-07  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.15e+03      |
| explained_variance | -0.0264       |
| fps                | 48            |
| n_updates          | 38            |
| policy_entropy     | 1.4254345     |
| policy_loss        | -9.938842e-06 |
| serial_timesteps   | 4864          |
| time_elapsed       | 111           |
| total_timesteps    | 4864          |
| value_loss         | 144.13373     |
--------------------------------------
--------------------------------------
| approxkl           | 3.8174454e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.15e+03      |
| explained_variance | 0.0168        |
| fps                | 40            |
| n_updates          | 39            |
| policy_entropy     | 1.4253781     |
| policy_loss        | -9.914581e-05 |
| serial_timesteps   | 4992          |
| time_elapsed       | 114           |
| total_timesteps    | 4992          |
| value_loss         | 4528.302      |
--------------------------------------
An average of 2.0 episodes completed
Best mean reward: 2186.75 - Latest 5 sample mean reward per episode: 2152.19
---------------------------------------
| approxkl           | 5.578107e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.15e+03       |
| explained_variance | -0.0059        |
| fps                | 40             |
| n_updates          | 40             |
| policy_entropy     | 1.4253676      |
| policy_loss        | -0.00088727777 |
| serial_timesteps   | 5120           |
| time_elapsed       | 117            |
| total_timesteps    | 5120           |
| value_loss         | 7336.076       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00095882226 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.15e+03      |
| explained_variance | 0.00334       |
| fps                | 44            |
| n_updates          | 41            |
| policy_entropy     | 1.4259754     |
| policy_loss        | -0.0020946632 |
| serial_timesteps   | 5248          |
| time_elapsed       | 120           |
| total_timesteps    | 5248          |
| value_loss         | 2278.376      |
--------------------------------------
--------------------------------------
| approxkl           | 2.8189173e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.15e+03      |
| explained_variance | 0.0112        |
| fps                | 46            |
| n_updates          | 42            |
| policy_entropy     | 1.4260907     |
| policy_loss        | 0.0013437328  |
| serial_timesteps   | 5376          |
| time_elapsed       | 123           |
| total_timesteps    | 5376          |
| value_loss         | 78.26978      |
--------------------------------------
---------------------------------------
| approxkl           | 5.121786e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.15e+03       |
| explained_variance | 0.0191         |
| fps                | 44             |
| n_updates          | 43             |
| policy_entropy     | 1.4263654      |
| policy_loss        | -0.00064464076 |
| serial_timesteps   | 5504           |
| time_elapsed       | 126            |
| total_timesteps    | 5504           |
| value_loss         | 742.9415       |
---------------------------------------
-------------------------------------
| approxkl           | 6.829382e-06 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.15e+03     |
| explained_variance | 0.00729      |
| fps                | 38           |
| n_updates          | 44           |
| policy_entropy     | 1.4264708    |
| policy_loss        | -0.000612766 |
| serial_timesteps   | 5632         |
| time_elapsed       | 129          |
| total_timesteps    | 5632         |
| value_loss         | 2027.4374    |
-------------------------------------
---------------------------------------
| approxkl           | 2.969756e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.15e+03       |
| explained_variance | 0.00294        |
| fps                | 43             |
| n_updates          | 45             |
| policy_entropy     | 1.4265145      |
| policy_loss        | -0.00074120355 |
| serial_timesteps   | 5760           |
| time_elapsed       | 132            |
| total_timesteps    | 5760           |
| value_loss         | 2947.3594      |
---------------------------------------
---------------------------------------
| approxkl           | 4.290911e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.15e+03       |
| explained_variance | 0.0125         |
| fps                | 42             |
| n_updates          | 46             |
| policy_entropy     | 1.4266236      |
| policy_loss        | -3.5275705e-05 |
| serial_timesteps   | 5888           |
| time_elapsed       | 135            |
| total_timesteps    | 5888           |
| value_loss         | 1039.7612      |
---------------------------------------
An average of 2.0 episodes completed
Best mean reward: 2186.75 - Latest 5 sample mean reward per episode: 2152.19
--------------------------------------
| approxkl           | 3.5232973e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.15e+03      |
| explained_variance | -0.595        |
| fps                | 46            |
| n_updates          | 47            |
| policy_entropy     | 1.4272299     |
| policy_loss        | 0.00030089542 |
| serial_timesteps   | 6016          |
| time_elapsed       | 138           |
| total_timesteps    | 6016          |
| value_loss         | 8.614333      |
--------------------------------------
--------------------------------------
| approxkl           | 1.9089734e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.15e+03      |
| explained_variance | 0.0543        |
| fps                | 45            |
| n_updates          | 48            |
| policy_entropy     | 1.4268626     |
| policy_loss        | 0.00026053574 |
| serial_timesteps   | 6144          |
| time_elapsed       | 141           |
| total_timesteps    | 6144          |
| value_loss         | 13.595291     |
--------------------------------------
---------------------------------------
| approxkl           | 9.507849e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.42e+03       |
| explained_variance | 0.0718         |
| fps                | 42             |
| n_updates          | 49             |
| policy_entropy     | 1.4290603      |
| policy_loss        | -0.00046019512 |
| serial_timesteps   | 6272           |
| time_elapsed       | 144            |
| total_timesteps    | 6272           |
| value_loss         | 32.345234      |
---------------------------------------
---------------------------------------
| approxkl           | 1.6619007e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.42e+03       |
| explained_variance | 0.0136         |
| fps                | 43             |
| n_updates          | 50             |
| policy_entropy     | 1.4301606      |
| policy_loss        | -0.00019131217 |
| serial_timesteps   | 6400           |
| time_elapsed       | 147            |
| total_timesteps    | 6400           |
| value_loss         | 1220.0767      |
---------------------------------------
---------------------------------------
| approxkl           | 9.5135634e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.42e+03       |
| explained_variance | 0.0622         |
| fps                | 45             |
| n_updates          | 51             |
| policy_entropy     | 1.4297677      |
| policy_loss        | -0.00036885287 |
| serial_timesteps   | 6528           |
| time_elapsed       | 150            |
| total_timesteps    | 6528           |
| value_loss         | 81.80329       |
---------------------------------------
--------------------------------------
| approxkl           | 5.988356e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.42e+03      |
| explained_variance | -0.0857       |
| fps                | 42            |
| n_updates          | 52            |
| policy_entropy     | 1.4295706     |
| policy_loss        | 0.00046051398 |
| serial_timesteps   | 6656          |
| time_elapsed       | 152           |
| total_timesteps    | 6656          |
| value_loss         | 9.411956      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00011927957 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.42e+03      |
| explained_variance | -0.0871       |
| fps                | 43            |
| n_updates          | 53            |
| policy_entropy     | 1.4298396     |
| policy_loss        | -0.0011795993 |
| serial_timesteps   | 6784          |
| time_elapsed       | 155           |
| total_timesteps    | 6784          |
| value_loss         | 11.248524     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0009401053 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.42e+03     |
| explained_variance | 0.0409       |
| fps                | 41           |
| n_updates          | 54           |
| policy_entropy     | 1.4319261    |
| policy_loss        | -0.00387543  |
| serial_timesteps   | 6912         |
| time_elapsed       | 158          |
| total_timesteps    | 6912         |
| value_loss         | 644.64685    |
-------------------------------------
An average of 3.0 episodes completed
Best mean reward: 2186.75 - Latest 5 sample mean reward per episode: 2422.62
Saving new best model
--------------------------------------
| approxkl           | 2.1489614e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.42e+03      |
| explained_variance | 0.00984       |
| fps                | 42            |
| n_updates          | 55            |
| policy_entropy     | 1.4327099     |
| policy_loss        | 0.0011581131  |
| serial_timesteps   | 7040          |
| time_elapsed       | 161           |
| total_timesteps    | 7040          |
| value_loss         | 104.73487     |
--------------------------------------
-------------------------------------
| approxkl           | 6.714916e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.42e+03     |
| explained_variance | -0.0187      |
| fps                | 43           |
| n_updates          | 56           |
| policy_entropy     | 1.4328218    |
| policy_loss        | -0.001435331 |
| serial_timesteps   | 7168         |
| time_elapsed       | 164          |
| total_timesteps    | 7168         |
| value_loss         | 138.29901    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00034825323 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.42e+03      |
| explained_variance | -0.0141       |
| fps                | 38            |
| n_updates          | 57            |
| policy_entropy     | 1.4327036     |
| policy_loss        | -0.0024286602 |
| serial_timesteps   | 7296          |
| time_elapsed       | 167           |
| total_timesteps    | 7296          |
| value_loss         | 1584.343      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0003071054 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.42e+03     |
| explained_variance | 0.0184       |
| fps                | 37           |
| n_updates          | 58           |
| policy_entropy     | 1.4326177    |
| policy_loss        | -0.003965999 |
| serial_timesteps   | 7424         |
| time_elapsed       | 171          |
| total_timesteps    | 7424         |
| value_loss         | 1353.8379    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00027049478 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.42e+03      |
| explained_variance | -0.0062       |
| fps                | 41            |
| n_updates          | 59            |
| policy_entropy     | 1.4325581     |
| policy_loss        | -0.0016168559 |
| serial_timesteps   | 7552          |
| time_elapsed       | 174           |
| total_timesteps    | 7552          |
| value_loss         | 6325.303      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0014138828 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.42e+03     |
| explained_variance | 0.0238       |
| fps                | 45           |
| n_updates          | 60           |
| policy_entropy     | 1.4326727    |
| policy_loss        | -0.006097053 |
| serial_timesteps   | 7680         |
| time_elapsed       | 177          |
| total_timesteps    | 7680         |
| value_loss         | 1650.3623    |
-------------------------------------
--------------------------------------
| approxkl           | 5.567864e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.00874       |
| fps                | 45            |
| n_updates          | 61            |
| policy_entropy     | 1.4325227     |
| policy_loss        | -0.0016261009 |
| serial_timesteps   | 7808          |
| time_elapsed       | 180           |
| total_timesteps    | 7808          |
| value_loss         | 825.92035     |
--------------------------------------
--------------------------------------
| approxkl           | 1.7330056e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.0136        |
| fps                | 44            |
| n_updates          | 62            |
| policy_entropy     | 1.4323378     |
| policy_loss        | 0.0004757844  |
| serial_timesteps   | 7936          |
| time_elapsed       | 183           |
| total_timesteps    | 7936          |
| value_loss         | 1611.5057     |
--------------------------------------
An average of 4.0 episodes completed
Best mean reward: 2422.62 - Latest 5 sample mean reward per episode: 2041.27
--------------------------------------
| approxkl           | 6.0360417e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.0103        |
| fps                | 40            |
| n_updates          | 63            |
| policy_entropy     | 1.4324949     |
| policy_loss        | 0.0006039707  |
| serial_timesteps   | 8064          |
| time_elapsed       | 186           |
| total_timesteps    | 8064          |
| value_loss         | 7671.152      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00010866518 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.00728       |
| fps                | 45            |
| n_updates          | 64            |
| policy_entropy     | 1.4336048     |
| policy_loss        | 0.0005747905  |
| serial_timesteps   | 8192          |
| time_elapsed       | 189           |
| total_timesteps    | 8192          |
| value_loss         | 12112.736     |
--------------------------------------
------------------------------------
| approxkl           | 0.000315593 |
| clipfrac           | 0.0         |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.04e+03    |
| explained_variance | 0.0512      |
| fps                | 39          |
| n_updates          | 65          |
| policy_entropy     | 1.4343785   |
| policy_loss        | 0.007168502 |
| serial_timesteps   | 8320        |
| time_elapsed       | 192         |
| total_timesteps    | 8320        |
| value_loss         | 461.44244   |
------------------------------------
--------------------------------------
| approxkl           | 8.4824555e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.00608       |
| fps                | 49            |
| n_updates          | 66            |
| policy_entropy     | 1.4348563     |
| policy_loss        | -0.0010053156 |
| serial_timesteps   | 8448          |
| time_elapsed       | 195           |
| total_timesteps    | 8448          |
| value_loss         | 30.075735     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0011309212  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.135         |
| fps                | 43            |
| n_updates          | 67            |
| policy_entropy     | 1.4372088     |
| policy_loss        | -0.0008186289 |
| serial_timesteps   | 8576          |
| time_elapsed       | 197           |
| total_timesteps    | 8576          |
| value_loss         | 16.332558     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00046648947 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.102         |
| fps                | 47            |
| n_updates          | 68            |
| policy_entropy     | 1.4408673     |
| policy_loss        | -0.00562564   |
| serial_timesteps   | 8704          |
| time_elapsed       | 200           |
| total_timesteps    | 8704          |
| value_loss         | 171.4965      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016909032 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.0964        |
| fps                | 47            |
| n_updates          | 69            |
| policy_entropy     | 1.4422586     |
| policy_loss        | 0.0023511196  |
| serial_timesteps   | 8832          |
| time_elapsed       | 203           |
| total_timesteps    | 8832          |
| value_loss         | 117.18635     |
--------------------------------------
--------------------------------------
| approxkl           | 2.7834745e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | 0.101         |
| fps                | 44            |
| n_updates          | 70            |
| policy_entropy     | 1.442261      |
| policy_loss        | 0.0003828935  |
| serial_timesteps   | 8960          |
| time_elapsed       | 206           |
| total_timesteps    | 8960          |
| value_loss         | 72.78514      |
--------------------------------------
An average of 4.0 episodes completed
Best mean reward: 2422.62 - Latest 5 sample mean reward per episode: 2041.27
---------------------------------------
| approxkl           | 6.7757e-08     |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.04e+03       |
| explained_variance | 0.414          |
| fps                | 46             |
| n_updates          | 71             |
| policy_entropy     | 1.4422169      |
| policy_loss        | -1.6522128e-05 |
| serial_timesteps   | 9088           |
| time_elapsed       | 209            |
| total_timesteps    | 9088           |
| value_loss         | 15.157994      |
---------------------------------------
--------------------------------------
| approxkl           | 8.163542e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.04e+03      |
| explained_variance | -0.333        |
| fps                | 49            |
| n_updates          | 72            |
| policy_entropy     | 1.4418873     |
| policy_loss        | 0.00023412006 |
| serial_timesteps   | 9216          |
| time_elapsed       | 211           |
| total_timesteps    | 9216          |
| value_loss         | 18.028782     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00017148953  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.11e+03       |
| explained_variance | 0.0664         |
| fps                | 45             |
| n_updates          | 73             |
| policy_entropy     | 1.4398472      |
| policy_loss        | -0.00014784059 |
| serial_timesteps   | 9344           |
| time_elapsed       | 214            |
| total_timesteps    | 9344           |
| value_loss         | 655.86774      |
---------------------------------------
--------------------------------------
| approxkl           | 8.919042e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.11e+03      |
| explained_variance | 0.0423        |
| fps                | 43            |
| n_updates          | 74            |
| policy_entropy     | 1.4389409     |
| policy_loss        | -0.0004480451 |
| serial_timesteps   | 9472          |
| time_elapsed       | 217           |
| total_timesteps    | 9472          |
| value_loss         | 620.90137     |
--------------------------------------
---------------------------------------
| approxkl           | 4.181024e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.11e+03       |
| explained_variance | 0.136          |
| fps                | 51             |
| n_updates          | 75             |
| policy_entropy     | 1.4387424      |
| policy_loss        | -0.00046228536 |
| serial_timesteps   | 9600           |
| time_elapsed       | 220            |
| total_timesteps    | 9600           |
| value_loss         | 18.015388      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0011576464 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.11e+03     |
| explained_variance | 0.0895       |
| fps                | 52           |
| n_updates          | 76           |
| policy_entropy     | 1.4376972    |
| policy_loss        | 0.005784359  |
| serial_timesteps   | 9728         |
| time_elapsed       | 222          |
| total_timesteps    | 9728         |
| value_loss         | 115.79049    |
-------------------------------------
--------------------------------------
| approxkl           | 2.4934556e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.11e+03      |
| explained_variance | 0.0197        |
| fps                | 41            |
| n_updates          | 77            |
| policy_entropy     | 1.4376446     |
| policy_loss        | 2.6941183e-05 |
| serial_timesteps   | 9856          |
| time_elapsed       | 225           |
| total_timesteps    | 9856          |
| value_loss         | 6606.9736     |
--------------------------------------
---------------------------------------
| approxkl           | 1.9169049e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.11e+03       |
| explained_variance | -0.00506       |
| fps                | 43             |
| n_updates          | 78             |
| policy_entropy     | 1.4393854      |
| policy_loss        | -2.7578208e-05 |
| serial_timesteps   | 9984           |
| time_elapsed       | 228            |
| total_timesteps    | 9984           |
| value_loss         | 5952.287       |
---------------------------------------
An average of 5.0 episodes completed
Best mean reward: 2422.62 - Latest 5 sample mean reward per episode: 2098.85
-------------------------------------
| approxkl           | 8.845406e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.11e+03     |
| explained_variance | 0.0112       |
| fps                | 39           |
| n_updates          | 79           |
| policy_entropy     | 1.4381647    |
| policy_loss        | 0.0007289548 |
| serial_timesteps   | 10112        |
| time_elapsed       | 231          |
| total_timesteps    | 10112        |
| value_loss         | 2020.8054    |
-------------------------------------
--------------------------------------
| approxkl           | 2.7273204e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.11e+03      |
| explained_variance | 0.0592        |
| fps                | 49            |
| n_updates          | 80            |
| policy_entropy     | 1.437513      |
| policy_loss        | -0.000262618  |
| serial_timesteps   | 10240         |
| time_elapsed       | 234           |
| total_timesteps    | 10240         |
| value_loss         | 62.26904      |
--------------------------------------
---------------------------------------
| approxkl           | 7.515384e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.11e+03       |
| explained_variance | 0.0427         |
| fps                | 44             |
| n_updates          | 81             |
| policy_entropy     | 1.4372306      |
| policy_loss        | -7.5090444e-05 |
| serial_timesteps   | 10368          |
| time_elapsed       | 236            |
| total_timesteps    | 10368          |
| value_loss         | 2084.5918      |
---------------------------------------
--------------------------------------
| approxkl           | 1.3712893e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.11e+03      |
| explained_variance | 0.0201        |
| fps                | 42            |
| n_updates          | 82            |
| policy_entropy     | 1.4371805     |
| policy_loss        | 3.846863e-05  |
| serial_timesteps   | 10496         |
| time_elapsed       | 239           |
| total_timesteps    | 10496         |
| value_loss         | 9111.265      |
--------------------------------------
--------------------------------------
| approxkl           | 1.8360111e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.11e+03      |
| explained_variance | 0.0173        |
| fps                | 50            |
| n_updates          | 83            |
| policy_entropy     | 1.4382788     |
| policy_loss        | 1.9234954e-05 |
| serial_timesteps   | 10624         |
| time_elapsed       | 242           |
| total_timesteps    | 10624         |
| value_loss         | 10470.34      |
--------------------------------------
--------------------------------------
| approxkl           | 7.447609e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.11e+03      |
| explained_variance | 0.0434        |
| fps                | 51            |
| n_updates          | 84            |
| policy_entropy     | 1.4398799     |
| policy_loss        | 0.00036915147 |
| serial_timesteps   | 10752         |
| time_elapsed       | 245           |
| total_timesteps    | 10752         |
| value_loss         | 871.0122      |
--------------------------------------
---------------------------------------
| approxkl           | 0.0003271256   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.58e+03       |
| explained_variance | -2.13          |
| fps                | 50             |
| n_updates          | 85             |
| policy_entropy     | 1.4399985      |
| policy_loss        | -0.00082362455 |
| serial_timesteps   | 10880          |
| time_elapsed       | 247            |
| total_timesteps    | 10880          |
| value_loss         | 9.349239       |
---------------------------------------
An average of 6.0 episodes completed
Best mean reward: 2422.62 - Latest 5 sample mean reward per episode: 2874.81
Saving new best model
-------------------------------------
| approxkl           | 0.0010119779 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.58e+03     |
| explained_variance | 0.238        |
| fps                | 49           |
| n_updates          | 86           |
| policy_entropy     | 1.4390893    |
| policy_loss        | -0.003649346 |
| serial_timesteps   | 11008        |
| time_elapsed       | 250          |
| total_timesteps    | 11008        |
| value_loss         | 16.065393    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00032278802 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | 0.121         |
| fps                | 45            |
| n_updates          | 87            |
| policy_entropy     | 1.4411956     |
| policy_loss        | -0.0014236225 |
| serial_timesteps   | 11136         |
| time_elapsed       | 252           |
| total_timesteps    | 11136         |
| value_loss         | 166.50719     |
--------------------------------------
--------------------------------------
| approxkl           | 5.5072855e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | 0.181         |
| fps                | 39            |
| n_updates          | 88            |
| policy_entropy     | 1.4424841     |
| policy_loss        | 1.1546188e-05 |
| serial_timesteps   | 11264         |
| time_elapsed       | 255           |
| total_timesteps    | 11264         |
| value_loss         | 96.53459      |
--------------------------------------
---------------------------------------
| approxkl           | 8.415031e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.58e+03       |
| explained_variance | 0.101          |
| fps                | 45             |
| n_updates          | 89             |
| policy_entropy     | 1.4428688      |
| policy_loss        | -0.00045890454 |
| serial_timesteps   | 11392          |
| time_elapsed       | 259            |
| total_timesteps    | 11392          |
| value_loss         | 76.68943       |
---------------------------------------
--------------------------------------
| approxkl           | 5.5737673e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | 0.483         |
| fps                | 43            |
| n_updates          | 90            |
| policy_entropy     | 1.4429682     |
| policy_loss        | 0.00026871148 |
| serial_timesteps   | 11520         |
| time_elapsed       | 261           |
| total_timesteps    | 11520         |
| value_loss         | 13.379876     |
--------------------------------------
--------------------------------------
| approxkl           | 5.0899166e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | -1.31         |
| fps                | 45            |
| n_updates          | 91            |
| policy_entropy     | 1.4428952     |
| policy_loss        | 0.00010302197 |
| serial_timesteps   | 11648         |
| time_elapsed       | 264           |
| total_timesteps    | 11648         |
| value_loss         | 22.064745     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0002571684   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.58e+03       |
| explained_variance | 0.0721         |
| fps                | 41             |
| n_updates          | 92             |
| policy_entropy     | 1.4410405      |
| policy_loss        | -9.2363916e-07 |
| serial_timesteps   | 11776          |
| time_elapsed       | 267            |
| total_timesteps    | 11776          |
| value_loss         | 652.5108       |
---------------------------------------
--------------------------------------
| approxkl           | 5.7567077e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | 0.0701        |
| fps                | 48            |
| n_updates          | 93            |
| policy_entropy     | 1.4401258     |
| policy_loss        | -8.064695e-05 |
| serial_timesteps   | 11904         |
| time_elapsed       | 270           |
| total_timesteps    | 11904         |
| value_loss         | 494.992       |
--------------------------------------
An average of 6.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2874.81
--------------------------------------
| approxkl           | 0.0001433478  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | -0.188        |
| fps                | 47            |
| n_updates          | 94            |
| policy_entropy     | 1.4399807     |
| policy_loss        | -0.0020850878 |
| serial_timesteps   | 12032         |
| time_elapsed       | 273           |
| total_timesteps    | 12032         |
| value_loss         | 9.833732      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00024907527 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | 0.112         |
| fps                | 46            |
| n_updates          | 95            |
| policy_entropy     | 1.4401622     |
| policy_loss        | 0.0025443742  |
| serial_timesteps   | 12160         |
| time_elapsed       | 276           |
| total_timesteps    | 12160         |
| value_loss         | 509.07776     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00012332232 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.58e+03      |
| explained_variance | 0.0369        |
| fps                | 42            |
| n_updates          | 96            |
| policy_entropy     | 1.4401022     |
| policy_loss        | 0.00020639319 |
| serial_timesteps   | 12288         |
| time_elapsed       | 278           |
| total_timesteps    | 12288         |
| value_loss         | 6246.9014     |
--------------------------------------
--------------------------------------
| approxkl           | 7.354767e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | 0.00515       |
| fps                | 48            |
| n_updates          | 97            |
| policy_entropy     | 1.4393051     |
| policy_loss        | 1.3055629e-05 |
| serial_timesteps   | 12416         |
| time_elapsed       | 281           |
| total_timesteps    | 12416         |
| value_loss         | 4560.0513     |
--------------------------------------
--------------------------------------
| approxkl           | 2.073459e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | 0.014         |
| fps                | 46            |
| n_updates          | 98            |
| policy_entropy     | 1.4390326     |
| policy_loss        | 0.00031840382 |
| serial_timesteps   | 12544         |
| time_elapsed       | 284           |
| total_timesteps    | 12544         |
| value_loss         | 1914.962      |
--------------------------------------
--------------------------------------
| approxkl           | 5.4475197e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | 0.191         |
| fps                | 48            |
| n_updates          | 99            |
| policy_entropy     | 1.4389446     |
| policy_loss        | 5.0842995e-05 |
| serial_timesteps   | 12672         |
| time_elapsed       | 287           |
| total_timesteps    | 12672         |
| value_loss         | 57.08098      |
--------------------------------------
-------------------------------------
| approxkl           | 8.184739e-06 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.51e+03     |
| explained_variance | 0.0507       |
| fps                | 43           |
| n_updates          | 100          |
| policy_entropy     | 1.4386618    |
| policy_loss        | 0.0008756971 |
| serial_timesteps   | 12800        |
| time_elapsed       | 289          |
| total_timesteps    | 12800        |
| value_loss         | 2644.6394    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00023948416  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.51e+03       |
| explained_variance | 0.0248         |
| fps                | 42             |
| n_updates          | 101            |
| policy_entropy     | 1.4388187      |
| policy_loss        | -0.00053623854 |
| serial_timesteps   | 12928          |
| time_elapsed       | 292            |
| total_timesteps    | 12928          |
| value_loss         | 10284.876      |
---------------------------------------
An average of 7.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2722.39
----------------------------------------
| approxkl           | 6.25413e-05     |
| clipfrac           | 0.0             |
| ep_len_mean        | 1.54e+03        |
| ep_reward_mean     | 2.51e+03        |
| explained_variance | 0.0196          |
| fps                | 46              |
| n_updates          | 102             |
| policy_entropy     | 1.4377211       |
| policy_loss        | -0.000111245376 |
| serial_timesteps   | 13056           |
| time_elapsed       | 295             |
| total_timesteps    | 13056           |
| value_loss         | 8747.652        |
----------------------------------------
--------------------------------------
| approxkl           | 7.510204e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | 0.0159        |
| fps                | 45            |
| n_updates          | 103           |
| policy_entropy     | 1.4375871     |
| policy_loss        | -0.0007988807 |
| serial_timesteps   | 13184         |
| time_elapsed       | 298           |
| total_timesteps    | 13184         |
| value_loss         | 846.72296     |
--------------------------------------
-------------------------------------
| approxkl           | 5.006243e-06 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.51e+03     |
| explained_variance | -2.49        |
| fps                | 43           |
| n_updates          | 104          |
| policy_entropy     | 1.4376869    |
| policy_loss        | 6.404705e-05 |
| serial_timesteps   | 13312        |
| time_elapsed       | 301          |
| total_timesteps    | 13312        |
| value_loss         | 19.475136    |
-------------------------------------
--------------------------------------
| approxkl           | 8.534768e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | -0.0435       |
| fps                | 43            |
| n_updates          | 105           |
| policy_entropy     | 1.4387528     |
| policy_loss        | -0.0014296946 |
| serial_timesteps   | 13440         |
| time_elapsed       | 304           |
| total_timesteps    | 13440         |
| value_loss         | 19.437017     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00071883417 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | 0.181         |
| fps                | 47            |
| n_updates          | 106           |
| policy_entropy     | 1.4406599     |
| policy_loss        | -0.0005885293 |
| serial_timesteps   | 13568         |
| time_elapsed       | 307           |
| total_timesteps    | 13568         |
| value_loss         | 198.05135     |
--------------------------------------
--------------------------------------
| approxkl           | 1.5935153e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.51e+03      |
| explained_variance | -0.0103       |
| fps                | 42            |
| n_updates          | 107           |
| policy_entropy     | 1.4415656     |
| policy_loss        | 0.0011374382  |
| serial_timesteps   | 13696         |
| time_elapsed       | 309           |
| total_timesteps    | 13696         |
| value_loss         | 340.25305     |
--------------------------------------
---------------------------------------
| approxkl           | 5.4593747e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.51e+03       |
| explained_variance | 0.114          |
| fps                | 47             |
| n_updates          | 108            |
| policy_entropy     | 1.4416317      |
| policy_loss        | -0.00072489365 |
| serial_timesteps   | 13824          |
| time_elapsed       | 312            |
| total_timesteps    | 13824          |
| value_loss         | 199.36375      |
---------------------------------------
--------------------------------------
| approxkl           | 3.2306816e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | 0.343         |
| fps                | 45            |
| n_updates          | 109           |
| policy_entropy     | 1.4415615     |
| policy_loss        | -0.0007651298 |
| serial_timesteps   | 13952         |
| time_elapsed       | 315           |
| total_timesteps    | 13952         |
| value_loss         | 6.6455584     |
--------------------------------------
An average of 8.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2732.50
--------------------------------------
| approxkl           | 0.00068663794 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | -0.832        |
| fps                | 50            |
| n_updates          | 110           |
| policy_entropy     | 1.4407483     |
| policy_loss        | -0.0022066105 |
| serial_timesteps   | 14080         |
| time_elapsed       | 318           |
| total_timesteps    | 14080         |
| value_loss         | 13.784501     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0008072906  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | 0.117         |
| fps                | 44            |
| n_updates          | 111           |
| policy_entropy     | 1.4400812     |
| policy_loss        | -0.0020660264 |
| serial_timesteps   | 14208         |
| time_elapsed       | 320           |
| total_timesteps    | 14208         |
| value_loss         | 767.0583      |
--------------------------------------
--------------------------------------
| approxkl           | 4.4161523e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | 0.119         |
| fps                | 49            |
| n_updates          | 112           |
| policy_entropy     | 1.4398748     |
| policy_loss        | 0.00014370005 |
| serial_timesteps   | 14336         |
| time_elapsed       | 323           |
| total_timesteps    | 14336         |
| value_loss         | 155.63724     |
--------------------------------------
--------------------------------------
| approxkl           | 1.0135699e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | -3.28         |
| fps                | 44            |
| n_updates          | 113           |
| policy_entropy     | 1.4397011     |
| policy_loss        | 3.3449614e-06 |
| serial_timesteps   | 14464         |
| time_elapsed       | 326           |
| total_timesteps    | 14464         |
| value_loss         | 17.543758     |
--------------------------------------
--------------------------------------
| approxkl           | 6.8950125e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | 0.0793        |
| fps                | 45            |
| n_updates          | 114           |
| policy_entropy     | 1.4389685     |
| policy_loss        | -0.0011918416 |
| serial_timesteps   | 14592         |
| time_elapsed       | 329           |
| total_timesteps    | 14592         |
| value_loss         | 1131.751      |
--------------------------------------
---------------------------------------
| approxkl           | 3.6060142e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.59e+03       |
| explained_variance | 0.0535         |
| fps                | 49             |
| n_updates          | 115            |
| policy_entropy     | 1.438637       |
| policy_loss        | 0.000119114295 |
| serial_timesteps   | 14720          |
| time_elapsed       | 332            |
| total_timesteps    | 14720          |
| value_loss         | 5985.112       |
---------------------------------------
-------------------------------------
| approxkl           | 7.238449e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.59e+03     |
| explained_variance | 0.00384      |
| fps                | 45           |
| n_updates          | 116          |
| policy_entropy     | 1.4395111    |
| policy_loss        | 0.0008003056 |
| serial_timesteps   | 14848        |
| time_elapsed       | 334          |
| total_timesteps    | 14848        |
| value_loss         | 4047.7847    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00023548031 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.59e+03      |
| explained_variance | 0.0553        |
| fps                | 44            |
| n_updates          | 117           |
| policy_entropy     | 1.4408417     |
| policy_loss        | 0.0015939719  |
| serial_timesteps   | 14976         |
| time_elapsed       | 337           |
| total_timesteps    | 14976         |
| value_loss         | 1525.3403     |
--------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8ba83dfe80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8ba83dfe80>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8ba82fdeb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8ba82fdeb8>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2785 samples, validate on 316 samples
Epoch 7/5000
 - 1s - loss: 0.0125 - val_loss: 0.0338
Epoch 8/5000
 - 0s - loss: 0.0151 - val_loss: 0.0355
Epoch 9/5000
 - 0s - loss: 0.0141 - val_loss: 0.0263
Epoch 10/5000
 - 0s - loss: 0.0147 - val_loss: 0.0227
Epoch 11/5000
 - 0s - loss: 0.0145 - val_loss: 0.0224
Epoch 12/5000
 - 0s - loss: 0.0123 - val_loss: 0.0200
Epoch 13/5000
 - 0s - loss: 0.0090 - val_loss: 0.0164
Epoch 14/5000
 - 0s - loss: 0.0064 - val_loss: 0.0136
Epoch 15/5000
 - 0s - loss: 0.0053 - val_loss: 0.0120
Epoch 16/5000
 - 0s - loss: 0.0049 - val_loss: 0.0107
Epoch 17/5000
 - 0s - loss: 0.0047 - val_loss: 0.0105
Epoch 18/5000
 - 0s - loss: 0.0047 - val_loss: 0.0103
Epoch 19/5000
 - 0s - loss: 0.0046 - val_loss: 0.0098
Epoch 20/5000
 - 0s - loss: 0.0045 - val_loss: 0.0102
Epoch 21/5000
 - 0s - loss: 0.0045 - val_loss: 0.0102
Epoch 22/5000
 - 0s - loss: 0.0044 - val_loss: 0.0097
Epoch 23/5000
 - 0s - loss: 0.0044 - val_loss: 0.0092
Epoch 24/5000
 - 0s - loss: 0.0043 - val_loss: 0.0089
Epoch 25/5000
 - 0s - loss: 0.0043 - val_loss: 0.0086
Epoch 26/5000
 - 0s - loss: 0.0043 - val_loss: 0.0084
Epoch 27/5000
 - 0s - loss: 0.0042 - val_loss: 0.0082
Epoch 28/5000
 - 0s - loss: 0.0042 - val_loss: 0.0081
Epoch 29/5000
 - 0s - loss: 0.0042 - val_loss: 0.0080
Epoch 30/5000
 - 0s - loss: 0.0042 - val_loss: 0.0079
Epoch 31/5000
 - 0s - loss: 0.0042 - val_loss: 0.0078
Epoch 32/5000
 - 0s - loss: 0.0042 - val_loss: 0.0078
Epoch 33/5000
 - 0s - loss: 0.0041 - val_loss: 0.0078
Epoch 34/5000
 - 0s - loss: 0.0041 - val_loss: 0.0077
Epoch 35/5000
 - 0s - loss: 0.0041 - val_loss: 0.0079
Epoch 36/5000
 - 0s - loss: 0.0040 - val_loss: 0.0080
Epoch 37/5000
 - 0s - loss: 0.0040 - val_loss: 0.0081
Epoch 38/5000
 - 0s - loss: 0.0040 - val_loss: 0.0082
Epoch 39/5000
 - 0s - loss: 0.0040 - val_loss: 0.0082
Train on 1908 samples, validate on 316 samples
Epoch 46/5000
 - 1s - loss: 0.0532 - val_loss: 0.0021
Epoch 47/5000
 - 0s - loss: 0.0205 - val_loss: 0.0017
Epoch 48/5000
 - 0s - loss: 0.0149 - val_loss: 0.0015
Epoch 49/5000
 - 0s - loss: 0.0116 - val_loss: 0.0014
Epoch 50/5000
 - 0s - loss: 0.0103 - val_loss: 0.0014
Epoch 51/5000
 - 0s - loss: 0.0097 - val_loss: 0.0015
Epoch 52/5000
 - 0s - loss: 0.0110 - val_loss: 0.0021
Epoch 53/5000
 - 0s - loss: 0.0080 - val_loss: 0.0021
Epoch 54/5000
 - 0s - loss: 0.0072 - val_loss: 0.0019
Train on 2905 samples, validate on 316 samples
Epoch 58/5000
 - 2s - loss: 0.6574 - val_loss: 0.6365
Epoch 59/5000
 - 1s - loss: 0.6163 - val_loss: 0.6351
Epoch 60/5000
 - 1s - loss: 0.5589 - val_loss: 0.6307
Epoch 61/5000
 - 1s - loss: 0.4543 - val_loss: 0.6578
Epoch 62/5000
 - 1s - loss: 0.4055 - val_loss: 0.6869
Epoch 63/5000
 - 1s - loss: 0.3746 - val_loss: 0.6909
Epoch 64/5000
 - 1s - loss: 0.3719 - val_loss: 0.6944
Epoch 65/5000
 - 1s - loss: 0.3703 - val_loss: 0.6973
setting environment to train mode..... 

Training Started... 

An average of 9.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2757.87
---------------------------------------
| approxkl           | 4.77296e-06    |
| clipfrac           | 0.0            |
| explained_variance | 0.185          |
| fps                | 22             |
| n_updates          | 1              |
| policy_entropy     | 1.4413334      |
| policy_loss        | -0.00023262936 |
| serial_timesteps   | 128            |
| time_elapsed       | 1.19e-05       |
| total_timesteps    | 128            |
| value_loss         | 38.052116      |
---------------------------------------
--------------------------------------
| approxkl           | 1.0636575e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.178         |
| fps                | 39            |
| n_updates          | 2             |
| policy_entropy     | 1.4414165     |
| policy_loss        | 1.1951895e-05 |
| serial_timesteps   | 256           |
| time_elapsed       | 5.8           |
| total_timesteps    | 256           |
| value_loss         | 16.11348      |
--------------------------------------
--------------------------------------
| approxkl           | 4.3007822e-07 |
| clipfrac           | 0.0           |
| explained_variance | 0.276         |
| fps                | 40            |
| n_updates          | 3             |
| policy_entropy     | 1.4414867     |
| policy_loss        | 4.5175548e-05 |
| serial_timesteps   | 384           |
| time_elapsed       | 9.07          |
| total_timesteps    | 384           |
| value_loss         | 364.10275     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00034897495 |
| clipfrac           | 0.0           |
| explained_variance | 0.0453        |
| fps                | 40            |
| n_updates          | 4             |
| policy_entropy     | 1.44088       |
| policy_loss        | -0.001465449  |
| serial_timesteps   | 512           |
| time_elapsed       | 12.2          |
| total_timesteps    | 512           |
| value_loss         | 1866.516      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0003348526  |
| clipfrac           | 0.0           |
| explained_variance | 0.125         |
| fps                | 41            |
| n_updates          | 5             |
| policy_entropy     | 1.4393227     |
| policy_loss        | -0.0011230547 |
| serial_timesteps   | 640           |
| time_elapsed       | 15.4          |
| total_timesteps    | 640           |
| value_loss         | 957.7649      |
--------------------------------------
--------------------------------------
| approxkl           | 5.0594448e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.168         |
| fps                | 36            |
| n_updates          | 6             |
| policy_entropy     | 1.439024      |
| policy_loss        | 0.0009729933  |
| serial_timesteps   | 768           |
| time_elapsed       | 18.5          |
| total_timesteps    | 768           |
| value_loss         | 37.80188      |
--------------------------------------
---------------------------------------
| approxkl           | 1.1117668e-05  |
| clipfrac           | 0.0            |
| explained_variance | 0.426          |
| fps                | 41             |
| n_updates          | 7              |
| policy_entropy     | 1.4391156      |
| policy_loss        | -0.00018157403 |
| serial_timesteps   | 896            |
| time_elapsed       | 21.9           |
| total_timesteps    | 896            |
| value_loss         | 20.158175      |
---------------------------------------
--------------------------------------
| approxkl           | 1.8072453e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.485         |
| fps                | 36            |
| n_updates          | 8             |
| policy_entropy     | 1.4400228     |
| policy_loss        | 0.00025768217 |
| serial_timesteps   | 1024          |
| time_elapsed       | 25            |
| total_timesteps    | 1024          |
| value_loss         | 23.139284     |
--------------------------------------
An average of 9.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2757.87
--------------------------------------
| approxkl           | 7.900171e-05  |
| clipfrac           | 0.0           |
| explained_variance | 0.332         |
| fps                | 36            |
| n_updates          | 9             |
| policy_entropy     | 1.4405253     |
| policy_loss        | 0.00036133267 |
| serial_timesteps   | 1152          |
| time_elapsed       | 28.5          |
| total_timesteps    | 1152          |
| value_loss         | 24.87147      |
--------------------------------------
---------------------------------------
| approxkl           | 3.0342844e-06  |
| clipfrac           | 0.0            |
| explained_variance | 0.313          |
| fps                | 36             |
| n_updates          | 10             |
| policy_entropy     | 1.4404434      |
| policy_loss        | -0.00014578516 |
| serial_timesteps   | 1280           |
| time_elapsed       | 32             |
| total_timesteps    | 1280           |
| value_loss         | 24.335358      |
---------------------------------------
---------------------------------------
| approxkl           | 5.767063e-06   |
| clipfrac           | 0.0            |
| explained_variance | 0.361          |
| fps                | 38             |
| n_updates          | 11             |
| policy_entropy     | 1.4401398      |
| policy_loss        | -0.00031532138 |
| serial_timesteps   | 1408           |
| time_elapsed       | 35.5           |
| total_timesteps    | 1408           |
| value_loss         | 25.333408      |
---------------------------------------
--------------------------------------
| approxkl           | 6.649665e-05  |
| clipfrac           | 0.0           |
| explained_variance | 0.406         |
| fps                | 38            |
| n_updates          | 12            |
| policy_entropy     | 1.4398311     |
| policy_loss        | -0.0010432391 |
| serial_timesteps   | 1536          |
| time_elapsed       | 38.9          |
| total_timesteps    | 1536          |
| value_loss         | 20.092054     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0001174108   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.11e+03       |
| explained_variance | 0.058          |
| fps                | 34             |
| n_updates          | 13             |
| policy_entropy     | 1.4401064      |
| policy_loss        | -0.00053917104 |
| serial_timesteps   | 1664           |
| time_elapsed       | 42.2           |
| total_timesteps    | 1664           |
| value_loss         | 25.448694      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00040458402 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.357         |
| fps                | 41            |
| n_updates          | 14            |
| policy_entropy     | 1.4417337     |
| policy_loss        | 0.0014395118  |
| serial_timesteps   | 1792          |
| time_elapsed       | 45.9          |
| total_timesteps    | 1792          |
| value_loss         | 180.68137     |
--------------------------------------
--------------------------------------
| approxkl           | 9.70326e-05   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.37          |
| fps                | 40            |
| n_updates          | 15            |
| policy_entropy     | 1.4422388     |
| policy_loss        | -0.0009705464 |
| serial_timesteps   | 1920          |
| time_elapsed       | 49            |
| total_timesteps    | 1920          |
| value_loss         | 13.831738     |
--------------------------------------
An average of 10.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2484.89
-------------------------------------
| approxkl           | 0.001382347  |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.11e+03     |
| explained_variance | 0.189        |
| fps                | 38           |
| n_updates          | 16           |
| policy_entropy     | 1.4428232    |
| policy_loss        | -0.011844336 |
| serial_timesteps   | 2048         |
| time_elapsed       | 52.1         |
| total_timesteps    | 2048         |
| value_loss         | 11.782583    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0020869407 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.11e+03     |
| explained_variance | 0.44         |
| fps                | 37           |
| n_updates          | 17           |
| policy_entropy     | 1.4425179    |
| policy_loss        | 0.010188712  |
| serial_timesteps   | 2176         |
| time_elapsed       | 55.5         |
| total_timesteps    | 2176         |
| value_loss         | 7.6623144    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00015927515  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.11e+03       |
| explained_variance | 0.269          |
| fps                | 43             |
| n_updates          | 18             |
| policy_entropy     | 1.4416896      |
| policy_loss        | -0.00026118208 |
| serial_timesteps   | 2304           |
| time_elapsed       | 58.9           |
| total_timesteps    | 2304           |
| value_loss         | 31.464508      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0002912366  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.211         |
| fps                | 39            |
| n_updates          | 19            |
| policy_entropy     | 1.442789      |
| policy_loss        | -0.0024076132 |
| serial_timesteps   | 2432          |
| time_elapsed       | 61.8          |
| total_timesteps    | 2432          |
| value_loss         | 54.863358     |
--------------------------------------
--------------------------------------
| approxkl           | 4.61022e-05   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.412         |
| fps                | 38            |
| n_updates          | 20            |
| policy_entropy     | 1.4427631     |
| policy_loss        | 0.00079734274 |
| serial_timesteps   | 2560          |
| time_elapsed       | 65.1          |
| total_timesteps    | 2560          |
| value_loss         | 11.318977     |
--------------------------------------
--------------------------------------
| approxkl           | 5.2017763e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.344         |
| fps                | 37            |
| n_updates          | 21            |
| policy_entropy     | 1.4426332     |
| policy_loss        | 3.020314e-05  |
| serial_timesteps   | 2688          |
| time_elapsed       | 68.5          |
| total_timesteps    | 2688          |
| value_loss         | 25.18288      |
--------------------------------------
-------------------------------------
| approxkl           | 2.051774e-06 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.11e+03     |
| explained_variance | 0.134        |
| fps                | 34           |
| n_updates          | 22           |
| policy_entropy     | 1.4425627    |
| policy_loss        | 8.127722e-05 |
| serial_timesteps   | 2816         |
| time_elapsed       | 71.9         |
| total_timesteps    | 2816         |
| value_loss         | 430.53174    |
-------------------------------------
--------------------------------------
| approxkl           | 5.869611e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.0276        |
| fps                | 35            |
| n_updates          | 23            |
| policy_entropy     | 1.4430448     |
| policy_loss        | 0.00073687907 |
| serial_timesteps   | 2944          |
| time_elapsed       | 75.5          |
| total_timesteps    | 2944          |
| value_loss         | 2382.412      |
--------------------------------------
An average of 10.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2484.89
------------------------------------
| approxkl           | 0.001451714 |
| clipfrac           | 0.005859375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 1.11e+03    |
| explained_variance | 0.118       |
| fps                | 38          |
| n_updates          | 24          |
| policy_entropy     | 1.4429125   |
| policy_loss        | 0.001183471 |
| serial_timesteps   | 3072        |
| time_elapsed       | 79.1        |
| total_timesteps    | 3072        |
| value_loss         | 642.3899    |
------------------------------------
--------------------------------------
| approxkl           | 2.9931876e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.42          |
| fps                | 38            |
| n_updates          | 25            |
| policy_entropy     | 1.4429001     |
| policy_loss        | 0.00028763933 |
| serial_timesteps   | 3200          |
| time_elapsed       | 82.4          |
| total_timesteps    | 3200          |
| value_loss         | 20.38948      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016786144 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.504         |
| fps                | 36            |
| n_updates          | 26            |
| policy_entropy     | 1.443384      |
| policy_loss        | 0.0006472628  |
| serial_timesteps   | 3328          |
| time_elapsed       | 85.8          |
| total_timesteps    | 3328          |
| value_loss         | 40.275124     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00030767283 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.438         |
| fps                | 39            |
| n_updates          | 27            |
| policy_entropy     | 1.4423938     |
| policy_loss        | -0.0017620829 |
| serial_timesteps   | 3456          |
| time_elapsed       | 89.3          |
| total_timesteps    | 3456          |
| value_loss         | 38.25007      |
--------------------------------------
--------------------------------------
| approxkl           | 1.4927405e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.313         |
| fps                | 38            |
| n_updates          | 28            |
| policy_entropy     | 1.4418929     |
| policy_loss        | 0.00018572272 |
| serial_timesteps   | 3584          |
| time_elapsed       | 92.5          |
| total_timesteps    | 3584          |
| value_loss         | 20.61143      |
--------------------------------------
--------------------------------------
| approxkl           | 3.9384147e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.399         |
| fps                | 38            |
| n_updates          | 29            |
| policy_entropy     | 1.4416441     |
| policy_loss        | -0.0014112918 |
| serial_timesteps   | 3712          |
| time_elapsed       | 95.9          |
| total_timesteps    | 3712          |
| value_loss         | 17.61921      |
--------------------------------------
--------------------------------------
| approxkl           | 5.9452163e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.415         |
| fps                | 38            |
| n_updates          | 30            |
| policy_entropy     | 1.4414126     |
| policy_loss        | 0.00015044061 |
| serial_timesteps   | 3840          |
| time_elapsed       | 99.2          |
| total_timesteps    | 3840          |
| value_loss         | 31.051744     |
--------------------------------------
---------------------------------------
| approxkl           | 3.6393635e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.11e+03       |
| explained_variance | 0.473          |
| fps                | 40             |
| n_updates          | 31             |
| policy_entropy     | 1.4414928      |
| policy_loss        | -7.7007106e-05 |
| serial_timesteps   | 3968           |
| time_elapsed       | 103            |
| total_timesteps    | 3968           |
| value_loss         | 19.433165      |
---------------------------------------
An average of 11.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1633.20
--------------------------------------
| approxkl           | 0.00047827992 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | -1.13         |
| fps                | 35            |
| n_updates          | 32            |
| policy_entropy     | 1.4415814     |
| policy_loss        | -0.0018163519 |
| serial_timesteps   | 4096          |
| time_elapsed       | 106           |
| total_timesteps    | 4096          |
| value_loss         | 30.140148     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0009974746 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.11e+03     |
| explained_variance | 0.356        |
| fps                | 39           |
| n_updates          | 33           |
| policy_entropy     | 1.4417119    |
| policy_loss        | 0.0032552097 |
| serial_timesteps   | 4224         |
| time_elapsed       | 109          |
| total_timesteps    | 4224         |
| value_loss         | 163.70992    |
-------------------------------------
--------------------------------------
| approxkl           | 2.1523208e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.0379        |
| fps                | 38            |
| n_updates          | 34            |
| policy_entropy     | 1.4414018     |
| policy_loss        | 0.00016387668 |
| serial_timesteps   | 4352          |
| time_elapsed       | 113           |
| total_timesteps    | 4352          |
| value_loss         | 19.718746     |
--------------------------------------
---------------------------------------
| approxkl           | 3.548047e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.11e+03       |
| explained_variance | -0.371         |
| fps                | 38             |
| n_updates          | 35             |
| policy_entropy     | 1.4411069      |
| policy_loss        | -0.00021948502 |
| serial_timesteps   | 4480           |
| time_elapsed       | 116            |
| total_timesteps    | 4480           |
| value_loss         | 11.789558      |
---------------------------------------
--------------------------------------
| approxkl           | 7.9464946e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.11e+03      |
| explained_variance | 0.619         |
| fps                | 38            |
| n_updates          | 36            |
| policy_entropy     | 1.4411049     |
| policy_loss        | 0.00084352307 |
| serial_timesteps   | 4608          |
| time_elapsed       | 119           |
| total_timesteps    | 4608          |
| value_loss         | 12.484803     |
--------------------------------------
---------------------------------------
| approxkl           | 1.8420168e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 710            |
| explained_variance | 0.384          |
| fps                | 39             |
| n_updates          | 37             |
| policy_entropy     | 1.4407849      |
| policy_loss        | -5.3319265e-05 |
| serial_timesteps   | 4736           |
| time_elapsed       | 123            |
| total_timesteps    | 4736           |
| value_loss         | 6.3415184      |
---------------------------------------
--------------------------------------
| approxkl           | 2.8343486e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.294         |
| fps                | 38            |
| n_updates          | 38            |
| policy_entropy     | 1.4405936     |
| policy_loss        | -4.213152e-05 |
| serial_timesteps   | 4864          |
| time_elapsed       | 126           |
| total_timesteps    | 4864          |
| value_loss         | 81.48293      |
--------------------------------------
--------------------------------------
| approxkl           | 8.376812e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | -0.101        |
| fps                | 36            |
| n_updates          | 39            |
| policy_entropy     | 1.4405473     |
| policy_loss        | -4.922354e-05 |
| serial_timesteps   | 4992          |
| time_elapsed       | 129           |
| total_timesteps    | 4992          |
| value_loss         | 36.677994     |
--------------------------------------
An average of 12.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1211.33
---------------------------------------
| approxkl           | 1.8941151e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 710            |
| explained_variance | 0.359          |
| fps                | 39             |
| n_updates          | 40             |
| policy_entropy     | 1.4402307      |
| policy_loss        | -0.00013173732 |
| serial_timesteps   | 5120           |
| time_elapsed       | 133            |
| total_timesteps    | 5120           |
| value_loss         | 27.404121      |
---------------------------------------
--------------------------------------
| approxkl           | 8.010154e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.133         |
| fps                | 38            |
| n_updates          | 41            |
| policy_entropy     | 1.4401121     |
| policy_loss        | 0.00010160962 |
| serial_timesteps   | 5248          |
| time_elapsed       | 136           |
| total_timesteps    | 5248          |
| value_loss         | 476.01108     |
--------------------------------------
---------------------------------------
| approxkl           | 2.361305e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 710            |
| explained_variance | 0.0879         |
| fps                | 37             |
| n_updates          | 42             |
| policy_entropy     | 1.4413142      |
| policy_loss        | -0.00023505685 |
| serial_timesteps   | 5376           |
| time_elapsed       | 139            |
| total_timesteps    | 5376           |
| value_loss         | 2177.6372      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00012766391 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.137         |
| fps                | 40            |
| n_updates          | 43            |
| policy_entropy     | 1.4429501     |
| policy_loss        | 0.0015307333  |
| serial_timesteps   | 5504          |
| time_elapsed       | 143           |
| total_timesteps    | 5504          |
| value_loss         | 426.23734     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00049129996 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.37          |
| fps                | 36            |
| n_updates          | 44            |
| policy_entropy     | 1.4431052     |
| policy_loss        | -0.0041599665 |
| serial_timesteps   | 5632          |
| time_elapsed       | 146           |
| total_timesteps    | 5632          |
| value_loss         | 13.901788     |
--------------------------------------
--------------------------------------
| approxkl           | 5.661656e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.209         |
| fps                | 37            |
| n_updates          | 45            |
| policy_entropy     | 1.4427919     |
| policy_loss        | 0.00028049445 |
| serial_timesteps   | 5760          |
| time_elapsed       | 149           |
| total_timesteps    | 5760          |
| value_loss         | 36.828907     |
--------------------------------------
--------------------------------------
| approxkl           | 4.2093075e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.435         |
| fps                | 39            |
| n_updates          | 46            |
| policy_entropy     | 1.4424812     |
| policy_loss        | -3.339292e-05 |
| serial_timesteps   | 5888          |
| time_elapsed       | 153           |
| total_timesteps    | 5888          |
| value_loss         | 29.827555     |
--------------------------------------
--------------------------------------
| approxkl           | 3.0005024e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 710           |
| explained_variance | 0.263         |
| fps                | 37            |
| n_updates          | 47            |
| policy_entropy     | 1.4424539     |
| policy_loss        | 1.9375235e-05 |
| serial_timesteps   | 6016          |
| time_elapsed       | 156           |
| total_timesteps    | 6016          |
| value_loss         | 32.639847     |
--------------------------------------
An average of 12.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1211.33
---------------------------------------
| approxkl           | 9.537069e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 710            |
| explained_variance | 0.44           |
| fps                | 41             |
| n_updates          | 48             |
| policy_entropy     | 1.4427332      |
| policy_loss        | -0.00027832587 |
| serial_timesteps   | 6144           |
| time_elapsed       | 159            |
| total_timesteps    | 6144           |
| value_loss         | 17.304506      |
---------------------------------------
---------------------------------------
| approxkl           | 1.5487569e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 812            |
| explained_variance | 0.0607         |
| fps                | 37             |
| n_updates          | 49             |
| policy_entropy     | 1.4434907      |
| policy_loss        | -0.00011152966 |
| serial_timesteps   | 6272           |
| time_elapsed       | 162            |
| total_timesteps    | 6272           |
| value_loss         | 27.295725      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00012279634 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | 0.446         |
| fps                | 34            |
| n_updates          | 50            |
| policy_entropy     | 1.4440542     |
| policy_loss        | -0.0017924313 |
| serial_timesteps   | 6400          |
| time_elapsed       | 166           |
| total_timesteps    | 6400          |
| value_loss         | 14.473621     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00013047071 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | -0.516        |
| fps                | 35            |
| n_updates          | 51            |
| policy_entropy     | 1.4443834     |
| policy_loss        | 6.164203e-05  |
| serial_timesteps   | 6528          |
| time_elapsed       | 169           |
| total_timesteps    | 6528          |
| value_loss         | 31.266989     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00038351858 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | 0.268         |
| fps                | 41            |
| n_updates          | 52            |
| policy_entropy     | 1.4452232     |
| policy_loss        | 8.331845e-06  |
| serial_timesteps   | 6656          |
| time_elapsed       | 173           |
| total_timesteps    | 6656          |
| value_loss         | 173.78178     |
--------------------------------------
---------------------------------------
| approxkl           | 2.8259556e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 812            |
| explained_variance | 0.426          |
| fps                | 39             |
| n_updates          | 53             |
| policy_entropy     | 1.4455508      |
| policy_loss        | -0.00030060252 |
| serial_timesteps   | 6784           |
| time_elapsed       | 176            |
| total_timesteps    | 6784           |
| value_loss         | 20.439997      |
---------------------------------------
-------------------------------------
| approxkl           | 5.849963e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 812          |
| explained_variance | -0.111       |
| fps                | 36           |
| n_updates          | 54           |
| policy_entropy     | 1.4458731    |
| policy_loss        | 0.0002864817 |
| serial_timesteps   | 6912         |
| time_elapsed       | 179          |
| total_timesteps    | 6912         |
| value_loss         | 13.059336    |
-------------------------------------
An average of 13.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 778.47
--------------------------------------
| approxkl           | 1.3661014e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | 0.138         |
| fps                | 39            |
| n_updates          | 55            |
| policy_entropy     | 1.4461566     |
| policy_loss        | 0.00014632469 |
| serial_timesteps   | 7040          |
| time_elapsed       | 183           |
| total_timesteps    | 7040          |
| value_loss         | 16.70741      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00010241023 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | -0.799        |
| fps                | 38            |
| n_updates          | 56            |
| policy_entropy     | 1.4464881     |
| policy_loss        | -0.0025454708 |
| serial_timesteps   | 7168          |
| time_elapsed       | 186           |
| total_timesteps    | 7168          |
| value_loss         | 136.23784     |
--------------------------------------
-------------------------------------
| approxkl           | 8.457154e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 812          |
| explained_variance | 0.303        |
| fps                | 35           |
| n_updates          | 57           |
| policy_entropy     | 1.4466643    |
| policy_loss        | 0.0022740825 |
| serial_timesteps   | 7296         |
| time_elapsed       | 189          |
| total_timesteps    | 7296         |
| value_loss         | 86.962166    |
-------------------------------------
--------------------------------------
| approxkl           | 5.305672e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | 0.0858        |
| fps                | 37            |
| n_updates          | 58            |
| policy_entropy     | 1.4464588     |
| policy_loss        | 0.00011123507 |
| serial_timesteps   | 7424          |
| time_elapsed       | 193           |
| total_timesteps    | 7424          |
| value_loss         | 31.753593     |
--------------------------------------
--------------------------------------
| approxkl           | 5.6996356e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 812           |
| explained_variance | 0.391         |
| fps                | 37            |
| n_updates          | 59            |
| policy_entropy     | 1.4463017     |
| policy_loss        | 3.3270073e-05 |
| serial_timesteps   | 7552          |
| time_elapsed       | 196           |
| total_timesteps    | 7552          |
| value_loss         | 35.729103     |
--------------------------------------
---------------------------------------
| approxkl           | 8.357481e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 812            |
| explained_variance | -0.0558        |
| fps                | 37             |
| n_updates          | 60             |
| policy_entropy     | 1.4462968      |
| policy_loss        | -0.00078375416 |
| serial_timesteps   | 7680           |
| time_elapsed       | 200            |
| total_timesteps    | 7680           |
| value_loss         | 531.7372       |
---------------------------------------
-------------------------------------
| approxkl           | 0.0011140722 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 772          |
| explained_variance | -0.0332      |
| fps                | 36           |
| n_updates          | 61           |
| policy_entropy     | 1.4471952    |
| policy_loss        | 0.0047374098 |
| serial_timesteps   | 7808         |
| time_elapsed       | 203          |
| total_timesteps    | 7808         |
| value_loss         | 1736.1793    |
-------------------------------------
---------------------------------------
| approxkl           | 1.23066875e-05 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 772            |
| explained_variance | 0.00772        |
| fps                | 39             |
| n_updates          | 62             |
| policy_entropy     | 1.4470432      |
| policy_loss        | -0.00022289029 |
| serial_timesteps   | 7936           |
| time_elapsed       | 207            |
| total_timesteps    | 7936           |
| value_loss         | 189.79288      |
---------------------------------------
An average of 14.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 772.49
--------------------------------------
| approxkl           | 0.00033505715 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 772           |
| explained_variance | 0.0303        |
| fps                | 40            |
| n_updates          | 63            |
| policy_entropy     | 1.4472536     |
| policy_loss        | -0.0023460537 |
| serial_timesteps   | 8064          |
| time_elapsed       | 210           |
| total_timesteps    | 8064          |
| value_loss         | 17.40887      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00030917473 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 772           |
| explained_variance | 0.466         |
| fps                | 36            |
| n_updates          | 64            |
| policy_entropy     | 1.4485044     |
| policy_loss        | 0.00060285686 |
| serial_timesteps   | 8192          |
| time_elapsed       | 213           |
| total_timesteps    | 8192          |
| value_loss         | 26.651905     |
--------------------------------------
--------------------------------------
| approxkl           | 1.9955325e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 772           |
| explained_variance | 0.524         |
| fps                | 36            |
| n_updates          | 65            |
| policy_entropy     | 1.4503975     |
| policy_loss        | 0.00017030141 |
| serial_timesteps   | 8320          |
| time_elapsed       | 217           |
| total_timesteps    | 8320          |
| value_loss         | 24.847054     |
--------------------------------------
--------------------------------------
| approxkl           | 2.2142312e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 772           |
| explained_variance | 0.257         |
| fps                | 40            |
| n_updates          | 66            |
| policy_entropy     | 1.4513685     |
| policy_loss        | -8.604454e-05 |
| serial_timesteps   | 8448          |
| time_elapsed       | 220           |
| total_timesteps    | 8448          |
| value_loss         | 26.817743     |
--------------------------------------
--------------------------------------
| approxkl           | 5.9013855e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 772           |
| explained_variance | 0.361         |
| fps                | 39            |
| n_updates          | 67            |
| policy_entropy     | 1.4514104     |
| policy_loss        | -9.021722e-06 |
| serial_timesteps   | 8576          |
| time_elapsed       | 223           |
| total_timesteps    | 8576          |
| value_loss         | 27.39629      |
--------------------------------------
---------------------------------------
| approxkl           | 1.696847e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 772            |
| explained_variance | -0.173         |
| fps                | 38             |
| n_updates          | 68             |
| policy_entropy     | 1.4512517      |
| policy_loss        | -9.0778805e-05 |
| serial_timesteps   | 8704           |
| time_elapsed       | 227            |
| total_timesteps    | 8704           |
| value_loss         | 15.376059      |
---------------------------------------
---------------------------------------
| approxkl           | 3.5571757e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 772            |
| explained_variance | 0.412          |
| fps                | 39             |
| n_updates          | 69             |
| policy_entropy     | 1.4511627      |
| policy_loss        | -0.00010490732 |
| serial_timesteps   | 8832           |
| time_elapsed       | 230            |
| total_timesteps    | 8832           |
| value_loss         | 12.071331      |
---------------------------------------
---------------------------------------
| approxkl           | 1.21904395e-05 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 772            |
| explained_variance | -0.569         |
| fps                | 41             |
| n_updates          | 70             |
| policy_entropy     | 1.4509397      |
| policy_loss        | -0.00082589313 |
| serial_timesteps   | 8960           |
| time_elapsed       | 233            |
| total_timesteps    | 8960           |
| value_loss         | 19.92804       |
---------------------------------------
An average of 14.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 772.49
---------------------------------------
| approxkl           | 7.311631e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 772            |
| explained_variance | 0.431          |
| fps                | 40             |
| n_updates          | 71             |
| policy_entropy     | 1.4507942      |
| policy_loss        | -3.0876952e-05 |
| serial_timesteps   | 9088           |
| time_elapsed       | 236            |
| total_timesteps    | 9088           |
| value_loss         | 68.56503       |
---------------------------------------
--------------------------------------
| approxkl           | 5.082623e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 772           |
| explained_variance | 0.038         |
| fps                | 37            |
| n_updates          | 72            |
| policy_entropy     | 1.4510062     |
| policy_loss        | -0.0005003257 |
| serial_timesteps   | 9216          |
| time_elapsed       | 239           |
| total_timesteps    | 9216          |
| value_loss         | 13.654394     |
--------------------------------------
---------------------------------------
| approxkl           | 9.722305e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 741            |
| explained_variance | -0.615         |
| fps                | 35             |
| n_updates          | 73             |
| policy_entropy     | 1.4517372      |
| policy_loss        | -0.00024971523 |
| serial_timesteps   | 9344           |
| time_elapsed       | 243            |
| total_timesteps    | 9344           |
| value_loss         | 6.7357893      |
---------------------------------------
-------------------------------------
| approxkl           | 6.271527e-06 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 741          |
| explained_variance | 0.0122       |
| fps                | 37           |
| n_updates          | 74           |
| policy_entropy     | 1.4520628    |
| policy_loss        | 0.000288722  |
| serial_timesteps   | 9472         |
| time_elapsed       | 246          |
| total_timesteps    | 9472         |
| value_loss         | 14.389585    |
-------------------------------------
--------------------------------------
| approxkl           | 3.7095277e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 741           |
| explained_variance | -0.0555       |
| fps                | 37            |
| n_updates          | 75            |
| policy_entropy     | 1.452134      |
| policy_loss        | -0.0005756512 |
| serial_timesteps   | 9600          |
| time_elapsed       | 250           |
| total_timesteps    | 9600          |
| value_loss         | 35.42501      |
--------------------------------------
--------------------------------------
| approxkl           | 2.6417685e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 741           |
| explained_variance | 0.0969        |
| fps                | 34            |
| n_updates          | 76            |
| policy_entropy     | 1.4522493     |
| policy_loss        | -0.0010982763 |
| serial_timesteps   | 9728          |
| time_elapsed       | 253           |
| total_timesteps    | 9728          |
| value_loss         | 112.279915    |
--------------------------------------
---------------------------------------
| approxkl           | 4.3607248e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 741            |
| explained_variance | 0.13           |
| fps                | 36             |
| n_updates          | 77             |
| policy_entropy     | 1.4521892      |
| policy_loss        | -6.8336376e-05 |
| serial_timesteps   | 9856           |
| time_elapsed       | 257            |
| total_timesteps    | 9856           |
| value_loss         | 44.590004      |
---------------------------------------
---------------------------------------
| approxkl           | 2.8751729e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 741            |
| explained_variance | 0.45           |
| fps                | 38             |
| n_updates          | 78             |
| policy_entropy     | 1.4520551      |
| policy_loss        | -0.00018547359 |
| serial_timesteps   | 9984           |
| time_elapsed       | 260            |
| total_timesteps    | 9984           |
| value_loss         | 78.75885       |
---------------------------------------
An average of 15.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 667.00
--------------------------------------
| approxkl           | 4.4689416e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 741           |
| explained_variance | 0.0861        |
| fps                | 40            |
| n_updates          | 79            |
| policy_entropy     | 1.451957      |
| policy_loss        | -0.0006404432 |
| serial_timesteps   | 10112         |
| time_elapsed       | 264           |
| total_timesteps    | 10112         |
| value_loss         | 326.67258     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0017558461 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 741          |
| explained_variance | 0.102        |
| fps                | 35           |
| n_updates          | 80           |
| policy_entropy     | 1.4512419    |
| policy_loss        | -0.007316479 |
| serial_timesteps   | 10240        |
| time_elapsed       | 267          |
| total_timesteps    | 10240        |
| value_loss         | 2011.2289    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0033389546  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 741           |
| explained_variance | -0.00416      |
| fps                | 39            |
| n_updates          | 81            |
| policy_entropy     | 1.4525574     |
| policy_loss        | -0.0018634046 |
| serial_timesteps   | 10368         |
| time_elapsed       | 271           |
| total_timesteps    | 10368         |
| value_loss         | 136.7034      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011546755 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 741          |
| explained_variance | 0.156        |
| fps                | 38           |
| n_updates          | 82           |
| policy_entropy     | 1.4528611    |
| policy_loss        | -0.003660156 |
| serial_timesteps   | 10496        |
| time_elapsed       | 274          |
| total_timesteps    | 10496        |
| value_loss         | 18.870506    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0007266454 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 741          |
| explained_variance | -0.234       |
| fps                | 38           |
| n_updates          | 83           |
| policy_entropy     | 1.451139     |
| policy_loss        | 0.0047272337 |
| serial_timesteps   | 10624        |
| time_elapsed       | 277          |
| total_timesteps    | 10624        |
| value_loss         | 53.619358    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0012133002   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 741            |
| explained_variance | 0.361          |
| fps                | 41             |
| n_updates          | 84             |
| policy_entropy     | 1.4516077      |
| policy_loss        | -0.00045166595 |
| serial_timesteps   | 10752          |
| time_elapsed       | 280            |
| total_timesteps    | 10752          |
| value_loss         | 29.98077       |
---------------------------------------
---------------------------------------
| approxkl           | 4.766007e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 782            |
| explained_variance | 0.344          |
| fps                | 38             |
| n_updates          | 85             |
| policy_entropy     | 1.4520315      |
| policy_loss        | -0.00024199742 |
| serial_timesteps   | 10880          |
| time_elapsed       | 284            |
| total_timesteps    | 10880          |
| value_loss         | 27.058485      |
---------------------------------------
--------------------------------------
| approxkl           | 3.703321e-07  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 782           |
| explained_variance | 0.445         |
| fps                | 39            |
| n_updates          | 86            |
| policy_entropy     | 1.452042      |
| policy_loss        | 2.8285081e-05 |
| serial_timesteps   | 11008         |
| time_elapsed       | 287           |
| total_timesteps    | 11008         |
| value_loss         | 25.576012     |
--------------------------------------
An average of 16.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 650.66
-------------------------------------
| approxkl           | 9.900475e-07 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 782          |
| explained_variance | -0.0349      |
| fps                | 40           |
| n_updates          | 87           |
| policy_entropy     | 1.4518304    |
| policy_loss        | 7.461547e-05 |
| serial_timesteps   | 11136        |
| time_elapsed       | 290          |
| total_timesteps    | 11136        |
| value_loss         | 22.301348    |
-------------------------------------
---------------------------------------
| approxkl           | 2.7095724e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 782            |
| explained_variance | 0.453          |
| fps                | 38             |
| n_updates          | 88             |
| policy_entropy     | 1.4518093      |
| policy_loss        | -0.00081956293 |
| serial_timesteps   | 11264          |
| time_elapsed       | 293            |
| total_timesteps    | 11264          |
| value_loss         | 21.665157      |
---------------------------------------
--------------------------------------
| approxkl           | 5.229877e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 782           |
| explained_variance | 0.496         |
| fps                | 36            |
| n_updates          | 89            |
| policy_entropy     | 1.4517003     |
| policy_loss        | 0.00018556335 |
| serial_timesteps   | 11392         |
| time_elapsed       | 297           |
| total_timesteps    | 11392         |
| value_loss         | 29.342903     |
--------------------------------------
----------------------------------------
| approxkl           | 6.463036e-06    |
| clipfrac           | 0.0             |
| ep_len_mean        | 1.54e+03        |
| ep_reward_mean     | 782             |
| explained_variance | 0.295           |
| fps                | 37              |
| n_updates          | 90              |
| policy_entropy     | 1.451702        |
| policy_loss        | -0.000113156624 |
| serial_timesteps   | 11520           |
| time_elapsed       | 300             |
| total_timesteps    | 11520           |
| value_loss         | 114.48621       |
----------------------------------------
--------------------------------------
| approxkl           | 0.00019898356 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 782           |
| explained_variance | 0.227         |
| fps                | 39            |
| n_updates          | 91            |
| policy_entropy     | 1.4517392     |
| policy_loss        | -0.0024074377 |
| serial_timesteps   | 11648         |
| time_elapsed       | 304           |
| total_timesteps    | 11648         |
| value_loss         | 18.934305     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0009929759 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 782          |
| explained_variance | 0.14         |
| fps                | 35           |
| n_updates          | 92           |
| policy_entropy     | 1.452356     |
| policy_loss        | 0.0011496565 |
| serial_timesteps   | 11776        |
| time_elapsed       | 307          |
| total_timesteps    | 11776        |
| value_loss         | 9.449599     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0001246873  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 782           |
| explained_variance | -0.84         |
| fps                | 41            |
| n_updates          | 93            |
| policy_entropy     | 1.4529245     |
| policy_loss        | -0.0017798318 |
| serial_timesteps   | 11904         |
| time_elapsed       | 310           |
| total_timesteps    | 11904         |
| value_loss         | 18.644093     |
--------------------------------------
An average of 16.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 650.66
--------------------------------------
| approxkl           | 0.0004917565  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 782           |
| explained_variance | -0.0031       |
| fps                | 37            |
| n_updates          | 94            |
| policy_entropy     | 1.4538757     |
| policy_loss        | -0.0013465174 |
| serial_timesteps   | 12032         |
| time_elapsed       | 313           |
| total_timesteps    | 12032         |
| value_loss         | 8.328         |
--------------------------------------
--------------------------------------
| approxkl           | 2.0949454e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 782           |
| explained_variance | 0.097         |
| fps                | 38            |
| n_updates          | 95            |
| policy_entropy     | 1.4547375     |
| policy_loss        | 0.0007269252  |
| serial_timesteps   | 12160         |
| time_elapsed       | 317           |
| total_timesteps    | 12160         |
| value_loss         | 107.8936      |
--------------------------------------
---------------------------------------
| approxkl           | 1.35482205e-05 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 782            |
| explained_variance | 0.342          |
| fps                | 36             |
| n_updates          | 96             |
| policy_entropy     | 1.4549974      |
| policy_loss        | -0.00049330585 |
| serial_timesteps   | 12288          |
| time_elapsed       | 320            |
| total_timesteps    | 12288          |
| value_loss         | 37.33256       |
---------------------------------------
--------------------------------------
| approxkl           | 2.8533483e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.33          |
| fps                | 37            |
| n_updates          | 97            |
| policy_entropy     | 1.4550004     |
| policy_loss        | -0.0007456831 |
| serial_timesteps   | 12416         |
| time_elapsed       | 324           |
| total_timesteps    | 12416         |
| value_loss         | 137.31409     |
--------------------------------------
--------------------------------------
| approxkl           | 5.419573e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.0312        |
| fps                | 38            |
| n_updates          | 98            |
| policy_entropy     | 1.4552149     |
| policy_loss        | -0.0007846273 |
| serial_timesteps   | 12544         |
| time_elapsed       | 327           |
| total_timesteps    | 12544         |
| value_loss         | 653.9497      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00046708854 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.0813        |
| fps                | 41            |
| n_updates          | 99            |
| policy_entropy     | 1.4566411     |
| policy_loss        | -0.0005597187 |
| serial_timesteps   | 12672         |
| time_elapsed       | 330           |
| total_timesteps    | 12672         |
| value_loss         | 2170.5933     |
--------------------------------------
---------------------------------------
| approxkl           | 9.396356e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 706            |
| explained_variance | 0.102          |
| fps                | 39             |
| n_updates          | 100            |
| policy_entropy     | 1.4577739      |
| policy_loss        | -0.00039622118 |
| serial_timesteps   | 12800          |
| time_elapsed       | 334            |
| total_timesteps    | 12800          |
| value_loss         | 55.169327      |
---------------------------------------
--------------------------------------
| approxkl           | 1.2211743e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | -0.0504       |
| fps                | 34            |
| n_updates          | 101           |
| policy_entropy     | 1.4581455     |
| policy_loss        | 0.00019289297 |
| serial_timesteps   | 12928         |
| time_elapsed       | 337           |
| total_timesteps    | 12928         |
| value_loss         | 13.230274     |
--------------------------------------
An average of 17.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 704.28
--------------------------------------
| approxkl           | 0.00013500685 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.08          |
| fps                | 38            |
| n_updates          | 102           |
| policy_entropy     | 1.4596182     |
| policy_loss        | -0.0008207471 |
| serial_timesteps   | 13056         |
| time_elapsed       | 340           |
| total_timesteps    | 13056         |
| value_loss         | 21.746836     |
--------------------------------------
--------------------------------------
| approxkl           | 1.8090816e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.386         |
| fps                | 38            |
| n_updates          | 103           |
| policy_entropy     | 1.4599593     |
| policy_loss        | 0.0003371121  |
| serial_timesteps   | 13184         |
| time_elapsed       | 344           |
| total_timesteps    | 13184         |
| value_loss         | 33.29998      |
--------------------------------------
---------------------------------------
| approxkl           | 5.6935323e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 706            |
| explained_variance | 0.325          |
| fps                | 39             |
| n_updates          | 104            |
| policy_entropy     | 1.4601574      |
| policy_loss        | -0.00013571733 |
| serial_timesteps   | 13312          |
| time_elapsed       | 347            |
| total_timesteps    | 13312          |
| value_loss         | 26.874104      |
---------------------------------------
--------------------------------------
| approxkl           | 4.8342154e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.486         |
| fps                | 36            |
| n_updates          | 105           |
| policy_entropy     | 1.4605515     |
| policy_loss        | -0.0005669575 |
| serial_timesteps   | 13440         |
| time_elapsed       | 350           |
| total_timesteps    | 13440         |
| value_loss         | 15.935688     |
--------------------------------------
--------------------------------------
| approxkl           | 1.9811077e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.235         |
| fps                | 40            |
| n_updates          | 106           |
| policy_entropy     | 1.4612938     |
| policy_loss        | 0.00014052994 |
| serial_timesteps   | 13568         |
| time_elapsed       | 354           |
| total_timesteps    | 13568         |
| value_loss         | 19.83191      |
--------------------------------------
--------------------------------------
| approxkl           | 8.733579e-07  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.477         |
| fps                | 36            |
| n_updates          | 107           |
| policy_entropy     | 1.4617376     |
| policy_loss        | 0.00013284665 |
| serial_timesteps   | 13696         |
| time_elapsed       | 357           |
| total_timesteps    | 13696         |
| value_loss         | 31.051403     |
--------------------------------------
--------------------------------------
| approxkl           | 1.6808862e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 706           |
| explained_variance | 0.424         |
| fps                | 41            |
| n_updates          | 108           |
| policy_entropy     | 1.4616324     |
| policy_loss        | -2.562732e-05 |
| serial_timesteps   | 13824         |
| time_elapsed       | 361           |
| total_timesteps    | 13824         |
| value_loss         | 72.2474       |
--------------------------------------
--------------------------------------
| approxkl           | 2.7006686e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 759           |
| explained_variance | 0.282         |
| fps                | 37            |
| n_updates          | 109           |
| policy_entropy     | 1.4618927     |
| policy_loss        | 6.368745e-05  |
| serial_timesteps   | 13952         |
| time_elapsed       | 364           |
| total_timesteps    | 13952         |
| value_loss         | 97.37548      |
--------------------------------------
An average of 18.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 716.35
---------------------------------------
| approxkl           | 2.3950714e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 759            |
| explained_variance | 0.348          |
| fps                | 40             |
| n_updates          | 110            |
| policy_entropy     | 1.4621174      |
| policy_loss        | -0.00016678253 |
| serial_timesteps   | 14080          |
| time_elapsed       | 367            |
| total_timesteps    | 14080          |
| value_loss         | 11.362393      |
---------------------------------------
---------------------------------------
| approxkl           | 0.00013021876  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 759            |
| explained_variance | 0.38           |
| fps                | 38             |
| n_updates          | 111            |
| policy_entropy     | 1.4627883      |
| policy_loss        | -0.00055625837 |
| serial_timesteps   | 14208          |
| time_elapsed       | 370            |
| total_timesteps    | 14208          |
| value_loss         | 6.34068        |
---------------------------------------
--------------------------------------
| approxkl           | 0.00013907284 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 759           |
| explained_variance | -0.87         |
| fps                | 38            |
| n_updates          | 112           |
| policy_entropy     | 1.4638077     |
| policy_loss        | 0.00014444231 |
| serial_timesteps   | 14336         |
| time_elapsed       | 373           |
| total_timesteps    | 14336         |
| value_loss         | 33.065548     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018267786 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 759           |
| explained_variance | -0.726        |
| fps                | 36            |
| n_updates          | 113           |
| policy_entropy     | 1.4671891     |
| policy_loss        | 0.0030695638  |
| serial_timesteps   | 14464         |
| time_elapsed       | 377           |
| total_timesteps    | 14464         |
| value_loss         | 8.115329      |
--------------------------------------
-------------------------------------
| approxkl           | 4.898298e-07 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 759          |
| explained_variance | 0.114        |
| fps                | 41           |
| n_updates          | 114          |
| policy_entropy     | 1.4684999    |
| policy_loss        | 5.003868e-05 |
| serial_timesteps   | 14592        |
| time_elapsed       | 380          |
| total_timesteps    | 14592        |
| value_loss         | 95.99722     |
-------------------------------------
---------------------------------------
| approxkl           | 3.3607063e-07  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 759            |
| explained_variance | 0.333          |
| fps                | 43             |
| n_updates          | 115            |
| policy_entropy     | 1.4688079      |
| policy_loss        | -7.0466194e-06 |
| serial_timesteps   | 14720          |
| time_elapsed       | 383            |
| total_timesteps    | 14720          |
| value_loss         | 35.382793      |
---------------------------------------
--------------------------------------
| approxkl           | 3.2032e-06    |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 759           |
| explained_variance | 0.357         |
| fps                | 39            |
| n_updates          | 116           |
| policy_entropy     | 1.4689761     |
| policy_loss        | 4.2034546e-05 |
| serial_timesteps   | 14848         |
| time_elapsed       | 386           |
| total_timesteps    | 14848         |
| value_loss         | 213.55173     |
--------------------------------------
-------------------------------------
| approxkl           | 7.943174e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 759          |
| explained_variance | 0.0898       |
| fps                | 41           |
| n_updates          | 117          |
| policy_entropy     | 1.4690325    |
| policy_loss        | 0.0013392442 |
| serial_timesteps   | 14976        |
| time_elapsed       | 390          |
| total_timesteps    | 14976        |
| value_loss         | 967.9728     |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b9790a048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b9790a048>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b9790a1d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b9790a1d0>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2782 samples, validate on 312 samples
Epoch 40/5000
 - 1s - loss: 0.0783 - val_loss: 0.2194
Epoch 41/5000
 - 0s - loss: 0.0783 - val_loss: 0.2194
Epoch 42/5000
 - 0s - loss: 0.0783 - val_loss: 0.2194
Epoch 43/5000
 - 0s - loss: 0.0783 - val_loss: 0.2194
Epoch 44/5000
 - 0s - loss: 0.0783 - val_loss: 0.2194
Epoch 45/5000
 - 0s - loss: 0.0783 - val_loss: 0.2194
Train on 1932 samples, validate on 312 samples
Epoch 55/5000
 - 1s - loss: 0.0436 - val_loss: 0.0016
Epoch 56/5000
 - 0s - loss: 0.0272 - val_loss: 0.0012
Epoch 57/5000
 - 0s - loss: 0.0231 - val_loss: 8.2528e-04
Epoch 58/5000
 - 0s - loss: 0.0201 - val_loss: 6.4301e-04
Epoch 59/5000
 - 0s - loss: 0.0162 - val_loss: 5.6410e-04
Epoch 60/5000
 - 0s - loss: 0.0128 - val_loss: 5.2720e-04
Epoch 61/5000
 - 0s - loss: 0.0097 - val_loss: 4.8364e-04
Epoch 62/5000
 - 0s - loss: 0.0078 - val_loss: 8.4610e-04
Epoch 63/5000
 - 0s - loss: 0.0079 - val_loss: 0.0011
Epoch 64/5000
 - 0s - loss: 0.0062 - val_loss: 7.4802e-04
Epoch 65/5000
 - 0s - loss: 0.0056 - val_loss: 5.1200e-04
Epoch 66/5000
 - 0s - loss: 0.0054 - val_loss: 3.9760e-04
Epoch 67/5000
 - 0s - loss: 0.0052 - val_loss: 3.4758e-04
Epoch 68/5000
 - 0s - loss: 0.0051 - val_loss: 3.3052e-04
Epoch 69/5000
 - 0s - loss: 0.0050 - val_loss: 3.2958e-04
Epoch 70/5000
 - 0s - loss: 0.0050 - val_loss: 3.2867e-04
Epoch 71/5000
 - 0s - loss: 0.0050 - val_loss: 3.2781e-04
Epoch 72/5000
 - 0s - loss: 0.0049 - val_loss: 3.2702e-04
Epoch 73/5000
 - 0s - loss: 0.0049 - val_loss: 3.2694e-04
Epoch 74/5000
 - 0s - loss: 0.0049 - val_loss: 3.2686e-04
Epoch 75/5000
 - 0s - loss: 0.0049 - val_loss: 3.2678e-04
Epoch 76/5000
 - 0s - loss: 0.0049 - val_loss: 3.2670e-04
Epoch 77/5000
 - 0s - loss: 0.0049 - val_loss: 3.2670e-04
Epoch 78/5000
 - 0s - loss: 0.0049 - val_loss: 3.2669e-04
Epoch 79/5000
 - 0s - loss: 0.0049 - val_loss: 3.2668e-04
Epoch 80/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 81/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 82/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 83/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 84/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 85/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 86/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 87/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 88/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 89/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 90/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Epoch 91/5000
 - 0s - loss: 0.0049 - val_loss: 3.2667e-04
Train on 2901 samples, validate on 312 samples
Epoch 66/5000
 - 2s - loss: 0.6671 - val_loss: 0.5431
Epoch 67/5000
 - 1s - loss: 0.6381 - val_loss: 0.4956
Epoch 68/5000
 - 1s - loss: 0.6200 - val_loss: 0.4825
Epoch 69/5000
 - 1s - loss: 0.5731 - val_loss: 0.4517
Epoch 70/5000
 - 1s - loss: 0.4849 - val_loss: 0.4741
Epoch 71/5000
 - 1s - loss: 0.4474 - val_loss: 0.4967
Epoch 72/5000
 - 1s - loss: 0.4244 - val_loss: 0.4806
Epoch 73/5000
 - 1s - loss: 0.4229 - val_loss: 0.4745
Epoch 74/5000
 - 1s - loss: 0.4221 - val_loss: 0.4729
setting environment to train mode..... 

Training Started... 

An average of 19.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 560.00
--------------------------------------
| approxkl           | 0.00013551558 |
| clipfrac           | 0.0           |
| explained_variance | -0.0396       |
| fps                | 19            |
| n_updates          | 1             |
| policy_entropy     | 1.4693604     |
| policy_loss        | -0.0005632901 |
| serial_timesteps   | 128           |
| time_elapsed       | 1.31e-05      |
| total_timesteps    | 128           |
| value_loss         | 285.7046      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0005212012 |
| clipfrac           | 0.0          |
| explained_variance | 0.0278       |
| fps                | 40           |
| n_updates          | 2            |
| policy_entropy     | 1.4691447    |
| policy_loss        | -0.005596815 |
| serial_timesteps   | 256          |
| time_elapsed       | 6.56         |
| total_timesteps    | 256          |
| value_loss         | 9901.779     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0019740437  |
| clipfrac           | 0.015625      |
| explained_variance | -0.00987      |
| fps                | 34            |
| n_updates          | 3             |
| policy_entropy     | 1.469703      |
| policy_loss        | -0.0038969147 |
| serial_timesteps   | 384           |
| time_elapsed       | 9.72          |
| total_timesteps    | 384           |
| value_loss         | 371.549       |
--------------------------------------
-------------------------------------
| approxkl           | 0.0004747668 |
| clipfrac           | 0.0          |
| explained_variance | -0.146       |
| fps                | 32           |
| n_updates          | 4            |
| policy_entropy     | 1.4708067    |
| policy_loss        | 3.433856e-05 |
| serial_timesteps   | 512          |
| time_elapsed       | 13.4         |
| total_timesteps    | 512          |
| value_loss         | 69.35501     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0028402961  |
| clipfrac           | 0.02734375    |
| explained_variance | 0.263         |
| fps                | 38            |
| n_updates          | 5             |
| policy_entropy     | 1.4721191     |
| policy_loss        | -0.0031537684 |
| serial_timesteps   | 640           |
| time_elapsed       | 17.4          |
| total_timesteps    | 640           |
| value_loss         | 72.687515     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00017051795  |
| clipfrac           | 0.0            |
| explained_variance | 0.235          |
| fps                | 42             |
| n_updates          | 6              |
| policy_entropy     | 1.4716328      |
| policy_loss        | -0.00039001822 |
| serial_timesteps   | 768            |
| time_elapsed       | 20.7           |
| total_timesteps    | 768            |
| value_loss         | 34.081947      |
---------------------------------------
--------------------------------------
| approxkl           | 3.3674348e-07 |
| clipfrac           | 0.0           |
| explained_variance | 0.397         |
| fps                | 39            |
| n_updates          | 7             |
| policy_entropy     | 1.4708531     |
| policy_loss        | 9.1509544e-05 |
| serial_timesteps   | 896           |
| time_elapsed       | 23.7          |
| total_timesteps    | 896           |
| value_loss         | 25.516571     |
--------------------------------------
---------------------------------------
| approxkl           | 7.0205842e-06  |
| clipfrac           | 0.0            |
| explained_variance | 0.32           |
| fps                | 38             |
| n_updates          | 8              |
| policy_entropy     | 1.4706186      |
| policy_loss        | -0.00023124914 |
| serial_timesteps   | 1024           |
| time_elapsed       | 26.9           |
| total_timesteps    | 1024           |
| value_loss         | 24.664778      |
---------------------------------------
An average of 19.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 560.00
--------------------------------------
| approxkl           | 0.00037932285 |
| clipfrac           | 0.0           |
| explained_variance | -0.35         |
| fps                | 39            |
| n_updates          | 9             |
| policy_entropy     | 1.470356      |
| policy_loss        | -0.0015419221 |
| serial_timesteps   | 1152          |
| time_elapsed       | 30.2          |
| total_timesteps    | 1152          |
| value_loss         | 51.967854     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00067224563 |
| clipfrac           | 0.001953125   |
| explained_variance | 0.51          |
| fps                | 35            |
| n_updates          | 10            |
| policy_entropy     | 1.4698263     |
| policy_loss        | -0.003033397  |
| serial_timesteps   | 1280          |
| time_elapsed       | 33.4          |
| total_timesteps    | 1280          |
| value_loss         | 13.954281     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00012109434 |
| clipfrac           | 0.0           |
| explained_variance | 0.428         |
| fps                | 39            |
| n_updates          | 11            |
| policy_entropy     | 1.4696248     |
| policy_loss        | 0.00033419393 |
| serial_timesteps   | 1408          |
| time_elapsed       | 37.1          |
| total_timesteps    | 1408          |
| value_loss         | 59.178177     |
--------------------------------------
---------------------------------------
| approxkl           | 4.376504e-07   |
| clipfrac           | 0.0            |
| explained_variance | 0.31           |
| fps                | 35             |
| n_updates          | 12             |
| policy_entropy     | 1.4693449      |
| policy_loss        | -3.1896634e-06 |
| serial_timesteps   | 1536           |
| time_elapsed       | 40.3           |
| total_timesteps    | 1536           |
| value_loss         | 97.56592       |
---------------------------------------
--------------------------------------
| approxkl           | 9.924486e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.658        |
| fps                | 36            |
| n_updates          | 13            |
| policy_entropy     | 1.4693321     |
| policy_loss        | -0.0005922143 |
| serial_timesteps   | 1664          |
| time_elapsed       | 43.9          |
| total_timesteps    | 1664          |
| value_loss         | 30.607536     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018458875 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.174         |
| fps                | 44            |
| n_updates          | 14            |
| policy_entropy     | 1.469322      |
| policy_loss        | -0.0040429337 |
| serial_timesteps   | 1792          |
| time_elapsed       | 47.4          |
| total_timesteps    | 1792          |
| value_loss         | 66.79934      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00012746768 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.636        |
| fps                | 35            |
| n_updates          | 15            |
| policy_entropy     | 1.4692667     |
| policy_loss        | -0.0026054676 |
| serial_timesteps   | 1920          |
| time_elapsed       | 50.3          |
| total_timesteps    | 1920          |
| value_loss         | 57.159565     |
--------------------------------------
---------------------------------------
| approxkl           | 3.1583026e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.4e+03        |
| explained_variance | -2.63          |
| fps                | 40             |
| n_updates          | 16             |
| policy_entropy     | 1.4694881      |
| policy_loss        | -0.00048037514 |
| serial_timesteps   | 2048           |
| time_elapsed       | 53.9           |
| total_timesteps    | 2048           |
| value_loss         | 44.725563      |
---------------------------------------
An average of 20.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 723.04
--------------------------------------
| approxkl           | 4.4594857e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.978        |
| fps                | 43            |
| n_updates          | 17            |
| policy_entropy     | 1.4700174     |
| policy_loss        | 0.00069555524 |
| serial_timesteps   | 2176          |
| time_elapsed       | 57.1          |
| total_timesteps    | 2176          |
| value_loss         | 26.617496     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00014481149 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.169         |
| fps                | 35            |
| n_updates          | 18            |
| policy_entropy     | 1.4702958     |
| policy_loss        | -0.0032107416 |
| serial_timesteps   | 2304          |
| time_elapsed       | 60.1          |
| total_timesteps    | 2304          |
| value_loss         | 68.288795     |
--------------------------------------
--------------------------------------
| approxkl           | 9.031661e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.421         |
| fps                | 34            |
| n_updates          | 19            |
| policy_entropy     | 1.4704013     |
| policy_loss        | -8.700823e-05 |
| serial_timesteps   | 2432          |
| time_elapsed       | 63.6          |
| total_timesteps    | 2432          |
| value_loss         | 58.60853      |
--------------------------------------
-------------------------------------
| approxkl           | 3.604335e-06 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.4e+03      |
| explained_variance | 0.083        |
| fps                | 35           |
| n_updates          | 20           |
| policy_entropy     | 1.4706709    |
| policy_loss        | 8.418952e-05 |
| serial_timesteps   | 2560         |
| time_elapsed       | 67.3         |
| total_timesteps    | 2560         |
| value_loss         | 724.97614    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00022789265 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.0384        |
| fps                | 36            |
| n_updates          | 21            |
| policy_entropy     | 1.4701737     |
| policy_loss        | 0.0018483507  |
| serial_timesteps   | 2688          |
| time_elapsed       | 70.9          |
| total_timesteps    | 2688          |
| value_loss         | 8980.955      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0022119423  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.0332        |
| fps                | 37            |
| n_updates          | 22            |
| policy_entropy     | 1.46962       |
| policy_loss        | -0.0009368344 |
| serial_timesteps   | 2816          |
| time_elapsed       | 74.4          |
| total_timesteps    | 2816          |
| value_loss         | 61.17043      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017783997 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.603        |
| fps                | 34            |
| n_updates          | 23            |
| policy_entropy     | 1.46947       |
| policy_loss        | -0.0023543863 |
| serial_timesteps   | 2944          |
| time_elapsed       | 77.8          |
| total_timesteps    | 2944          |
| value_loss         | 13.088818     |
--------------------------------------
An average of 20.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 723.04
-------------------------------------
| approxkl           | 0.002120191  |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.4e+03      |
| explained_variance | -0.197       |
| fps                | 39           |
| n_updates          | 24           |
| policy_entropy     | 1.4685341    |
| policy_loss        | -0.008381433 |
| serial_timesteps   | 3072         |
| time_elapsed       | 81.5         |
| total_timesteps    | 3072         |
| value_loss         | 109.09309    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0031292862 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | -0.345       |
| fps                | 38           |
| n_updates          | 25           |
| policy_entropy     | 1.4634764    |
| policy_loss        | 0.011912421  |
| serial_timesteps   | 3200         |
| time_elapsed       | 84.8         |
| total_timesteps    | 3200         |
| value_loss         | 36.149628    |
-------------------------------------
--------------------------------------
| approxkl           | 3.5524703e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | 0.211         |
| fps                | 34            |
| n_updates          | 26            |
| policy_entropy     | 1.461608      |
| policy_loss        | 0.00010333001 |
| serial_timesteps   | 3328          |
| time_elapsed       | 88.1          |
| total_timesteps    | 3328          |
| value_loss         | 26.329327     |
--------------------------------------
---------------------------------------
| approxkl           | 5.418604e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.58e+03       |
| explained_variance | -0.628         |
| fps                | 37             |
| n_updates          | 27             |
| policy_entropy     | 1.4612545      |
| policy_loss        | -8.7603694e-05 |
| serial_timesteps   | 3456           |
| time_elapsed       | 91.8           |
| total_timesteps    | 3456           |
| value_loss         | 10.41888       |
---------------------------------------
--------------------------------------
| approxkl           | 1.1269212e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.293        |
| fps                | 34            |
| n_updates          | 28            |
| policy_entropy     | 1.4612097     |
| policy_loss        | -0.0001365887 |
| serial_timesteps   | 3584          |
| time_elapsed       | 95.2          |
| total_timesteps    | 3584          |
| value_loss         | 176.89832     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00055767683 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.136        |
| fps                | 37            |
| n_updates          | 29            |
| policy_entropy     | 1.4595962     |
| policy_loss        | -0.004254678  |
| serial_timesteps   | 3712          |
| time_elapsed       | 99            |
| total_timesteps    | 3712          |
| value_loss         | 207.32956     |
--------------------------------------
--------------------------------------
| approxkl           | 5.3664888e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.349        |
| fps                | 43            |
| n_updates          | 30            |
| policy_entropy     | 1.4587749     |
| policy_loss        | 6.450317e-05  |
| serial_timesteps   | 3840          |
| time_elapsed       | 102           |
| total_timesteps    | 3840          |
| value_loss         | 514.79407     |
--------------------------------------
---------------------------------------
| approxkl           | 2.304877e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.58e+03       |
| explained_variance | 0.213          |
| fps                | 36             |
| n_updates          | 31             |
| policy_entropy     | 1.4588377      |
| policy_loss        | -1.6525155e-05 |
| serial_timesteps   | 3968           |
| time_elapsed       | 105            |
| total_timesteps    | 3968           |
| value_loss         | 93.8056        |
---------------------------------------
An average of 21.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 868.41
--------------------------------------
| approxkl           | 1.6203758e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.303        |
| fps                | 35            |
| n_updates          | 32            |
| policy_entropy     | 1.4589725     |
| policy_loss        | -0.0008219406 |
| serial_timesteps   | 4096          |
| time_elapsed       | 109           |
| total_timesteps    | 4096          |
| value_loss         | 144.7737      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0003250977 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | -0.391       |
| fps                | 46           |
| n_updates          | 33           |
| policy_entropy     | 1.4595       |
| policy_loss        | 0.0008645863 |
| serial_timesteps   | 4224         |
| time_elapsed       | 113          |
| total_timesteps    | 4224         |
| value_loss         | 171.10179    |
-------------------------------------
-------------------------------------
| approxkl           | 0.004101035  |
| clipfrac           | 0.044921875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | 0.226        |
| fps                | 37           |
| n_updates          | 34           |
| policy_entropy     | 1.4601457    |
| policy_loss        | -0.013670891 |
| serial_timesteps   | 4352         |
| time_elapsed       | 115          |
| total_timesteps    | 4352         |
| value_loss         | 169.25449    |
-------------------------------------
-------------------------------------
| approxkl           | 0.001033111  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | 0.132        |
| fps                | 34           |
| n_updates          | 35           |
| policy_entropy     | 1.4604223    |
| policy_loss        | 0.0014064005 |
| serial_timesteps   | 4480         |
| time_elapsed       | 119          |
| total_timesteps    | 4480         |
| value_loss         | 216.39023    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00027074144 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.269        |
| fps                | 39            |
| n_updates          | 36            |
| policy_entropy     | 1.459513      |
| policy_loss        | -0.0019701652 |
| serial_timesteps   | 4608          |
| time_elapsed       | 122           |
| total_timesteps    | 4608          |
| value_loss         | 386.51703     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0011792289   |
| clipfrac           | 0.005859375    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.56e+03       |
| explained_variance | -0.199         |
| fps                | 36             |
| n_updates          | 37             |
| policy_entropy     | 1.4614493      |
| policy_loss        | -0.00046143157 |
| serial_timesteps   | 4736           |
| time_elapsed       | 126            |
| total_timesteps    | 4736           |
| value_loss         | 193.29161      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00038538908 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.267        |
| fps                | 39            |
| n_updates          | 38            |
| policy_entropy     | 1.4625882     |
| policy_loss        | 0.0021731611  |
| serial_timesteps   | 4864          |
| time_elapsed       | 129           |
| total_timesteps    | 4864          |
| value_loss         | 45.874634     |
--------------------------------------
--------------------------------------
| approxkl           | 3.145686e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.0136        |
| fps                | 39            |
| n_updates          | 39            |
| policy_entropy     | 1.4628004     |
| policy_loss        | 0.00011011516 |
| serial_timesteps   | 4992          |
| time_elapsed       | 132           |
| total_timesteps    | 4992          |
| value_loss         | 1728.8022     |
--------------------------------------
An average of 22.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1137.90
--------------------------------------
| approxkl           | 1.9476971e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.0128        |
| fps                | 37            |
| n_updates          | 40            |
| policy_entropy     | 1.4630531     |
| policy_loss        | -0.0009375359 |
| serial_timesteps   | 5120          |
| time_elapsed       | 136           |
| total_timesteps    | 5120          |
| value_loss         | 5364.0645     |
--------------------------------------
-------------------------------------
| approxkl           | 8.126072e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.56e+03     |
| explained_variance | -0.112       |
| fps                | 36           |
| n_updates          | 41           |
| policy_entropy     | 1.4627886    |
| policy_loss        | 0.0003942257 |
| serial_timesteps   | 5248         |
| time_elapsed       | 139          |
| total_timesteps    | 5248         |
| value_loss         | 20.4736      |
-------------------------------------
--------------------------------------
| approxkl           | 0.0002316111  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.25         |
| fps                | 37            |
| n_updates          | 42            |
| policy_entropy     | 1.4621571     |
| policy_loss        | -0.0026245234 |
| serial_timesteps   | 5376          |
| time_elapsed       | 143           |
| total_timesteps    | 5376          |
| value_loss         | 6.6800723     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0015042876  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.134        |
| fps                | 39            |
| n_updates          | 43            |
| policy_entropy     | 1.4612424     |
| policy_loss        | -0.0063110543 |
| serial_timesteps   | 5504          |
| time_elapsed       | 146           |
| total_timesteps    | 5504          |
| value_loss         | 150.83162     |
--------------------------------------
--------------------------------------
| approxkl           | 3.9131264e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.301         |
| fps                | 36            |
| n_updates          | 44            |
| policy_entropy     | 1.4611549     |
| policy_loss        | 0.001008185   |
| serial_timesteps   | 5632          |
| time_elapsed       | 149           |
| total_timesteps    | 5632          |
| value_loss         | 8.53993       |
--------------------------------------
--------------------------------------
| approxkl           | 0.00024966508 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.153        |
| fps                | 40            |
| n_updates          | 45            |
| policy_entropy     | 1.4611709     |
| policy_loss        | 0.0025648705  |
| serial_timesteps   | 5760          |
| time_elapsed       | 153           |
| total_timesteps    | 5760          |
| value_loss         | 83.600586     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0016566459  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.159         |
| fps                | 35            |
| n_updates          | 46            |
| policy_entropy     | 1.4605042     |
| policy_loss        | -0.0077835014 |
| serial_timesteps   | 5888          |
| time_elapsed       | 156           |
| total_timesteps    | 5888          |
| value_loss         | 12.385002     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00085927703 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.0534       |
| fps                | 39            |
| n_updates          | 47            |
| policy_entropy     | 1.4611357     |
| policy_loss        | -0.0030441473 |
| serial_timesteps   | 6016          |
| time_elapsed       | 160           |
| total_timesteps    | 6016          |
| value_loss         | 115.11904     |
--------------------------------------
An average of 22.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1137.90
--------------------------------------
| approxkl           | 0.00021410832 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.0774       |
| fps                | 36            |
| n_updates          | 48            |
| policy_entropy     | 1.4611821     |
| policy_loss        | 0.0017682492  |
| serial_timesteps   | 6144          |
| time_elapsed       | 163           |
| total_timesteps    | 6144          |
| value_loss         | 311.39273     |
--------------------------------------
------------------------------------
| approxkl           | 0.00383172  |
| clipfrac           | 0.056640625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 1.75e+03    |
| explained_variance | 0.000401    |
| fps                | 36          |
| n_updates          | 49          |
| policy_entropy     | 1.4613786   |
| policy_loss        | 0.00620424  |
| serial_timesteps   | 6272        |
| time_elapsed       | 166         |
| total_timesteps    | 6272        |
| value_loss         | 106.59006   |
------------------------------------
--------------------------------------
| approxkl           | 0.0006525803  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | -0.0581       |
| fps                | 38            |
| n_updates          | 50            |
| policy_entropy     | 1.4614122     |
| policy_loss        | -0.0031979939 |
| serial_timesteps   | 6400          |
| time_elapsed       | 170           |
| total_timesteps    | 6400          |
| value_loss         | 175.60455     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0017277276 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.75e+03     |
| explained_variance | 0.0575       |
| fps                | 36           |
| n_updates          | 51           |
| policy_entropy     | 1.4617606    |
| policy_loss        | 0.0013993665 |
| serial_timesteps   | 6528         |
| time_elapsed       | 173          |
| total_timesteps    | 6528         |
| value_loss         | 328.02744    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016419382 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.75e+03     |
| explained_variance | -0.00436     |
| fps                | 36           |
| n_updates          | 52           |
| policy_entropy     | 1.4637247    |
| policy_loss        | -0.008981367 |
| serial_timesteps   | 6656         |
| time_elapsed       | 177          |
| total_timesteps    | 6656         |
| value_loss         | 102.11697    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0025155263  |
| clipfrac           | 0.0234375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | 0.363         |
| fps                | 39            |
| n_updates          | 53            |
| policy_entropy     | 1.464964      |
| policy_loss        | -0.0081484765 |
| serial_timesteps   | 6784          |
| time_elapsed       | 180           |
| total_timesteps    | 6784          |
| value_loss         | 34.152054     |
--------------------------------------
-------------------------------------
| approxkl           | 0.001660411  |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.75e+03     |
| explained_variance | -0.0379      |
| fps                | 38           |
| n_updates          | 54           |
| policy_entropy     | 1.4635943    |
| policy_loss        | -0.005708702 |
| serial_timesteps   | 6912         |
| time_elapsed       | 183          |
| total_timesteps    | 6912         |
| value_loss         | 292.09537    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0024913473 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.75e+03     |
| explained_variance | -0.028       |
| fps                | 38           |
| n_updates          | 55           |
| policy_entropy     | 1.4617469    |
| policy_loss        | 0.0032996917 |
| serial_timesteps   | 7040         |
| time_elapsed       | 187          |
| total_timesteps    | 7040         |
| value_loss         | 281.16266    |
-------------------------------------
An average of 23.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1363.02
--------------------------------------
| approxkl           | 3.4057113e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | -0.114        |
| fps                | 36            |
| n_updates          | 56            |
| policy_entropy     | 1.463071      |
| policy_loss        | -7.13887e-05  |
| serial_timesteps   | 7168          |
| time_elapsed       | 190           |
| total_timesteps    | 7168          |
| value_loss         | 117.920105    |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016880459 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | -0.133        |
| fps                | 37            |
| n_updates          | 57            |
| policy_entropy     | 1.4639521     |
| policy_loss        | 0.00049167685 |
| serial_timesteps   | 7296          |
| time_elapsed       | 194           |
| total_timesteps    | 7296          |
| value_loss         | 211.04816     |
--------------------------------------
--------------------------------------
| approxkl           | 3.676919e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | -1.13e-05     |
| fps                | 37            |
| n_updates          | 58            |
| policy_entropy     | 1.465438      |
| policy_loss        | 0.00024316437 |
| serial_timesteps   | 7424          |
| time_elapsed       | 197           |
| total_timesteps    | 7424          |
| value_loss         | 4864.1426     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00021105782 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | 0.00361       |
| fps                | 39            |
| n_updates          | 59            |
| policy_entropy     | 1.4656564     |
| policy_loss        | 0.00063531613 |
| serial_timesteps   | 7552          |
| time_elapsed       | 200           |
| total_timesteps    | 7552          |
| value_loss         | 3214.7551     |
--------------------------------------
--------------------------------------
| approxkl           | 8.800668e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.75e+03      |
| explained_variance | -0.0577       |
| fps                | 36            |
| n_updates          | 60            |
| policy_entropy     | 1.4642581     |
| policy_loss        | 0.00032265368 |
| serial_timesteps   | 7680          |
| time_elapsed       | 204           |
| total_timesteps    | 7680          |
| value_loss         | 9.803816      |
--------------------------------------
---------------------------------------
| approxkl           | 3.2886743e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.95e+03       |
| explained_variance | -0.0165        |
| fps                | 34             |
| n_updates          | 61             |
| policy_entropy     | 1.4635324      |
| policy_loss        | -0.00033911638 |
| serial_timesteps   | 7808           |
| time_elapsed       | 207            |
| total_timesteps    | 7808           |
| value_loss         | 23.371944      |
---------------------------------------
---------------------------------------
| approxkl           | 0.000112591006 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.95e+03       |
| explained_variance | -0.00491       |
| fps                | 39             |
| n_updates          | 62             |
| policy_entropy     | 1.4636496      |
| policy_loss        | -0.0010187225  |
| serial_timesteps   | 7936           |
| time_elapsed       | 211            |
| total_timesteps    | 7936           |
| value_loss         | 297.48804      |
---------------------------------------
An average of 24.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1948.57
--------------------------------------
| approxkl           | 6.8278685e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.95e+03      |
| explained_variance | 0.0823        |
| fps                | 37            |
| n_updates          | 63            |
| policy_entropy     | 1.4637799     |
| policy_loss        | 0.00035525765 |
| serial_timesteps   | 8064          |
| time_elapsed       | 214           |
| total_timesteps    | 8064          |
| value_loss         | 7.1584835     |
--------------------------------------
---------------------------------------
| approxkl           | 1.7120408e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.95e+03       |
| explained_variance | -0.0395        |
| fps                | 33             |
| n_updates          | 64             |
| policy_entropy     | 1.4639653      |
| policy_loss        | -0.00045210432 |
| serial_timesteps   | 8192           |
| time_elapsed       | 218            |
| total_timesteps    | 8192           |
| value_loss         | 39.15188       |
---------------------------------------
---------------------------------------
| approxkl           | 0.00024023175  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.95e+03       |
| explained_variance | 0.0491         |
| fps                | 37             |
| n_updates          | 65             |
| policy_entropy     | 1.4640694      |
| policy_loss        | -0.00015917548 |
| serial_timesteps   | 8320           |
| time_elapsed       | 221            |
| total_timesteps    | 8320           |
| value_loss         | 12.800233      |
---------------------------------------
--------------------------------------
| approxkl           | 4.1653657e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.95e+03      |
| explained_variance | -0.0294       |
| fps                | 42            |
| n_updates          | 66            |
| policy_entropy     | 1.4630262     |
| policy_loss        | -0.0010468967 |
| serial_timesteps   | 8448          |
| time_elapsed       | 225           |
| total_timesteps    | 8448          |
| value_loss         | 95.690994     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0007666429  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.95e+03      |
| explained_variance | 0.0055        |
| fps                | 35            |
| n_updates          | 67            |
| policy_entropy     | 1.462492      |
| policy_loss        | -0.0053145206 |
| serial_timesteps   | 8576          |
| time_elapsed       | 228           |
| total_timesteps    | 8576          |
| value_loss         | 435.4343      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008486432  |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.95e+03     |
| explained_variance | -0.00553     |
| fps                | 36           |
| n_updates          | 68           |
| policy_entropy     | 1.461894     |
| policy_loss        | 0.0050217886 |
| serial_timesteps   | 8704         |
| time_elapsed       | 231          |
| total_timesteps    | 8704         |
| value_loss         | 335.94452    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0031079038 |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.95e+03     |
| explained_variance | 0.00196      |
| fps                | 35           |
| n_updates          | 69           |
| policy_entropy     | 1.4614294    |
| policy_loss        | 0.010869475  |
| serial_timesteps   | 8832         |
| time_elapsed       | 235          |
| total_timesteps    | 8832         |
| value_loss         | 338.04034    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0015788894 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.95e+03     |
| explained_variance | 0.0175       |
| fps                | 37           |
| n_updates          | 70           |
| policy_entropy     | 1.4603586    |
| policy_loss        | 0.0017123377 |
| serial_timesteps   | 8960         |
| time_elapsed       | 238          |
| total_timesteps    | 8960         |
| value_loss         | 465.1167     |
-------------------------------------
An average of 24.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1948.57
--------------------------------------
| approxkl           | 0.00090604014 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.95e+03      |
| explained_variance | 0.00887       |
| fps                | 37            |
| n_updates          | 71            |
| policy_entropy     | 1.4586847     |
| policy_loss        | -0.008173814  |
| serial_timesteps   | 9088          |
| time_elapsed       | 242           |
| total_timesteps    | 9088          |
| value_loss         | 156.56387     |
--------------------------------------
--------------------------------------
| approxkl           | 0.010065898   |
| clipfrac           | 0.12890625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.95e+03      |
| explained_variance | 0.0357        |
| fps                | 38            |
| n_updates          | 72            |
| policy_entropy     | 1.4569533     |
| policy_loss        | -0.0049400534 |
| serial_timesteps   | 9216          |
| time_elapsed       | 245           |
| total_timesteps    | 9216          |
| value_loss         | 65.42015      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006952005  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | 0.00596       |
| fps                | 38            |
| n_updates          | 73            |
| policy_entropy     | 1.4557264     |
| policy_loss        | -0.0072560348 |
| serial_timesteps   | 9344          |
| time_elapsed       | 248           |
| total_timesteps    | 9344          |
| value_loss         | 203.99716     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0004280812 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.93e+03     |
| explained_variance | 0.0181       |
| fps                | 38           |
| n_updates          | 74           |
| policy_entropy     | 1.4552408    |
| policy_loss        | 0.0016393859 |
| serial_timesteps   | 9472         |
| time_elapsed       | 252          |
| total_timesteps    | 9472         |
| value_loss         | 338.45404    |
-------------------------------------
---------------------------------------
| approxkl           | 0.000111407906 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.93e+03       |
| explained_variance | 0.00602        |
| fps                | 41             |
| n_updates          | 75             |
| policy_entropy     | 1.4548815      |
| policy_loss        | 0.00027165108  |
| serial_timesteps   | 9600           |
| time_elapsed       | 255            |
| total_timesteps    | 9600           |
| value_loss         | 42.953312      |
---------------------------------------
-------------------------------------
| approxkl           | 3.996285e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.93e+03     |
| explained_variance | 0.0082       |
| fps                | 38           |
| n_updates          | 76           |
| policy_entropy     | 1.4545109    |
| policy_loss        | -0.001154025 |
| serial_timesteps   | 9728         |
| time_elapsed       | 258          |
| total_timesteps    | 9728         |
| value_loss         | 118.4023     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0023527786 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.93e+03     |
| explained_variance | -4.57e-05    |
| fps                | 34           |
| n_updates          | 77           |
| policy_entropy     | 1.4542699    |
| policy_loss        | -0.011697568 |
| serial_timesteps   | 9856         |
| time_elapsed       | 261          |
| total_timesteps    | 9856         |
| value_loss         | 6237.824     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0012669661  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | 0.00111       |
| fps                | 37            |
| n_updates          | 78            |
| policy_entropy     | 1.4543269     |
| policy_loss        | -0.0021910043 |
| serial_timesteps   | 9984          |
| time_elapsed       | 265           |
| total_timesteps    | 9984          |
| value_loss         | 1620.2415     |
--------------------------------------
An average of 25.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2035.84
--------------------------------------
| approxkl           | 2.4398003e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | -0.0345       |
| fps                | 36            |
| n_updates          | 79            |
| policy_entropy     | 1.454172      |
| policy_loss        | 0.00041636068 |
| serial_timesteps   | 10112         |
| time_elapsed       | 269           |
| total_timesteps    | 10112         |
| value_loss         | 5.9040413     |
--------------------------------------
--------------------------------------
| approxkl           | 2.8500679e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | -0.00937      |
| fps                | 38            |
| n_updates          | 80            |
| policy_entropy     | 1.4539139     |
| policy_loss        | -0.0013706621 |
| serial_timesteps   | 10240         |
| time_elapsed       | 272           |
| total_timesteps    | 10240         |
| value_loss         | 47.58235      |
--------------------------------------
--------------------------------------
| approxkl           | 9.231922e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | 0.00934       |
| fps                | 38            |
| n_updates          | 81            |
| policy_entropy     | 1.4538354     |
| policy_loss        | -0.0011636656 |
| serial_timesteps   | 10368         |
| time_elapsed       | 275           |
| total_timesteps    | 10368         |
| value_loss         | 20.117802     |
--------------------------------------
-------------------------------------
| approxkl           | 6.404011e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.93e+03     |
| explained_variance | 0.0331       |
| fps                | 35           |
| n_updates          | 82           |
| policy_entropy     | 1.4535834    |
| policy_loss        | 0.0010845165 |
| serial_timesteps   | 10496        |
| time_elapsed       | 279          |
| total_timesteps    | 10496        |
| value_loss         | 34.475918    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00079045695 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | 0.0373        |
| fps                | 34            |
| n_updates          | 83            |
| policy_entropy     | 1.4532235     |
| policy_loss        | -0.0046183774 |
| serial_timesteps   | 10624         |
| time_elapsed       | 282           |
| total_timesteps    | 10624         |
| value_loss         | 4.951985      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00020149726 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.93e+03      |
| explained_variance | -0.0313       |
| fps                | 36            |
| n_updates          | 84            |
| policy_entropy     | 1.4520524     |
| policy_loss        | 0.003656088   |
| serial_timesteps   | 10752         |
| time_elapsed       | 286           |
| total_timesteps    | 10752         |
| value_loss         | 19.384876     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006466954  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -0.0126       |
| fps                | 36            |
| n_updates          | 85            |
| policy_entropy     | 1.4517812     |
| policy_loss        | -0.0021415432 |
| serial_timesteps   | 10880         |
| time_elapsed       | 290           |
| total_timesteps    | 10880         |
| value_loss         | 55.46299      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00040251453 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | 0.00589       |
| fps                | 36            |
| n_updates          | 86            |
| policy_entropy     | 1.4518332     |
| policy_loss        | -0.0068002813 |
| serial_timesteps   | 11008         |
| time_elapsed       | 293           |
| total_timesteps    | 11008         |
| value_loss         | 176.91321     |
--------------------------------------
An average of 26.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2139.61
--------------------------------------
| approxkl           | 8.549445e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | 0.00756       |
| fps                | 39            |
| n_updates          | 87            |
| policy_entropy     | 1.4519366     |
| policy_loss        | 7.9588615e-05 |
| serial_timesteps   | 11136         |
| time_elapsed       | 297           |
| total_timesteps    | 11136         |
| value_loss         | 150.26523     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018618046 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -0.0115       |
| fps                | 38            |
| n_updates          | 88            |
| policy_entropy     | 1.4532745     |
| policy_loss        | 0.0022096196  |
| serial_timesteps   | 11264         |
| time_elapsed       | 300           |
| total_timesteps    | 11264         |
| value_loss         | 34.67108      |
--------------------------------------
--------------------------------------
| approxkl           | 9.0526766e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -0.00806      |
| fps                | 38            |
| n_updates          | 89            |
| policy_entropy     | 1.45383       |
| policy_loss        | -0.0007096847 |
| serial_timesteps   | 11392         |
| time_elapsed       | 303           |
| total_timesteps    | 11392         |
| value_loss         | 191.52486     |
--------------------------------------
---------------------------------------
| approxkl           | 3.4809214e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.98e+03       |
| explained_variance | -0.000117      |
| fps                | 39             |
| n_updates          | 90             |
| policy_entropy     | 1.4539063      |
| policy_loss        | -0.00068010646 |
| serial_timesteps   | 11520          |
| time_elapsed       | 306            |
| total_timesteps    | 11520          |
| value_loss         | 273.47177      |
---------------------------------------
--------------------------------------
| approxkl           | 2.0912936e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -0.00889      |
| fps                | 39            |
| n_updates          | 91            |
| policy_entropy     | 1.4550222     |
| policy_loss        | -0.000172231  |
| serial_timesteps   | 11648         |
| time_elapsed       | 310           |
| total_timesteps    | 11648         |
| value_loss         | 179.4024      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0004642603 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.98e+03     |
| explained_variance | -0.00169     |
| fps                | 39           |
| n_updates          | 92           |
| policy_entropy     | 1.4579083    |
| policy_loss        | 0.0069754478 |
| serial_timesteps   | 11776        |
| time_elapsed       | 313          |
| total_timesteps    | 11776        |
| value_loss         | 137.8275     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00042726097 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | 0.00188       |
| fps                | 41            |
| n_updates          | 93            |
| policy_entropy     | 1.4587674     |
| policy_loss        | 0.0014671979  |
| serial_timesteps   | 11904         |
| time_elapsed       | 316           |
| total_timesteps    | 11904         |
| value_loss         | 384.46558     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016970368 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -0.0181       |
| fps                | 38            |
| n_updates          | 94            |
| policy_entropy     | 1.4579321     |
| policy_loss        | 0.00017908751 |
| serial_timesteps   | 12032         |
| time_elapsed       | 319           |
| total_timesteps    | 12032         |
| value_loss         | 134.21507     |
--------------------------------------
An average of 26.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2139.61
--------------------------------------
| approxkl           | 4.614907e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -8.57e-05     |
| fps                | 31            |
| n_updates          | 95            |
| policy_entropy     | 1.4571272     |
| policy_loss        | -0.0005447704 |
| serial_timesteps   | 12160         |
| time_elapsed       | 323           |
| total_timesteps    | 12160         |
| value_loss         | 137.76993     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0007711601  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.98e+03      |
| explained_variance | -0.000299     |
| fps                | 34            |
| n_updates          | 96            |
| policy_entropy     | 1.456471      |
| policy_loss        | -0.0036382156 |
| serial_timesteps   | 12288         |
| time_elapsed       | 327           |
| total_timesteps    | 12288         |
| value_loss         | 8713.818      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0028051352 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.09e+03     |
| explained_variance | -0.00182     |
| fps                | 38           |
| n_updates          | 97           |
| policy_entropy     | 1.4565392    |
| policy_loss        | 0.0021126668 |
| serial_timesteps   | 12416        |
| time_elapsed       | 330          |
| total_timesteps    | 12416        |
| value_loss         | 492.54047    |
-------------------------------------
--------------------------------------
| approxkl           | 1.2325757e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.09e+03      |
| explained_variance | -0.00917      |
| fps                | 35            |
| n_updates          | 98            |
| policy_entropy     | 1.4567544     |
| policy_loss        | 0.00045602466 |
| serial_timesteps   | 12544         |
| time_elapsed       | 334           |
| total_timesteps    | 12544         |
| value_loss         | 20.915789     |
--------------------------------------
------------------------------------
| approxkl           | 0.013824748 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.09e+03    |
| explained_variance | -0.00982    |
| fps                | 41          |
| n_updates          | 99          |
| policy_entropy     | 1.4572021   |
| policy_loss        | -0.01969206 |
| serial_timesteps   | 12672       |
| time_elapsed       | 337         |
| total_timesteps    | 12672       |
| value_loss         | 2.9802978   |
------------------------------------
---------------------------------------
| approxkl           | 1.0649397e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.09e+03       |
| explained_variance | 0.00268        |
| fps                | 40             |
| n_updates          | 100            |
| policy_entropy     | 1.458163       |
| policy_loss        | -0.00032464752 |
| serial_timesteps   | 12800          |
| time_elapsed       | 340            |
| total_timesteps    | 12800          |
| value_loss         | 57.998703      |
---------------------------------------
---------------------------------------
| approxkl           | 5.447172e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.09e+03       |
| explained_variance | 0.02           |
| fps                | 40             |
| n_updates          | 101            |
| policy_entropy     | 1.4583598      |
| policy_loss        | -0.00059912005 |
| serial_timesteps   | 12928          |
| time_elapsed       | 343            |
| total_timesteps    | 12928          |
| value_loss         | 20.578789      |
---------------------------------------
An average of 27.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2415.76
-------------------------------------
| approxkl           | 2.61099e-05  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.09e+03     |
| explained_variance | 0.0297       |
| fps                | 36           |
| n_updates          | 102          |
| policy_entropy     | 1.4579332    |
| policy_loss        | 0.0002646274 |
| serial_timesteps   | 13056        |
| time_elapsed       | 347          |
| total_timesteps    | 13056        |
| value_loss         | 9.932903     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00032040363 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.09e+03      |
| explained_variance | -0.00515      |
| fps                | 39            |
| n_updates          | 103           |
| policy_entropy     | 1.4573805     |
| policy_loss        | -0.0030395403 |
| serial_timesteps   | 13184         |
| time_elapsed       | 350           |
| total_timesteps    | 13184         |
| value_loss         | 43.156254     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0044771717 |
| clipfrac           | 0.048828125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.09e+03     |
| explained_variance | 0.00378      |
| fps                | 35           |
| n_updates          | 104          |
| policy_entropy     | 1.4575039    |
| policy_loss        | -0.015653733 |
| serial_timesteps   | 13312        |
| time_elapsed       | 353          |
| total_timesteps    | 13312        |
| value_loss         | 14.983069    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0009996018  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.09e+03      |
| explained_variance | 0.00141       |
| fps                | 36            |
| n_updates          | 105           |
| policy_entropy     | 1.4579172     |
| policy_loss        | -0.0018796783 |
| serial_timesteps   | 13440         |
| time_elapsed       | 357           |
| total_timesteps    | 13440         |
| value_loss         | 409.68307     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0047922316 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.09e+03     |
| explained_variance | 0.000826     |
| fps                | 41           |
| n_updates          | 106          |
| policy_entropy     | 1.4597645    |
| policy_loss        | -0.004274112 |
| serial_timesteps   | 13568        |
| time_elapsed       | 360          |
| total_timesteps    | 13568        |
| value_loss         | 133.79659    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00046142642 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.09e+03      |
| explained_variance | -0.00577      |
| fps                | 33            |
| n_updates          | 107           |
| policy_entropy     | 1.4607209     |
| policy_loss        | 0.0027616573  |
| serial_timesteps   | 13696         |
| time_elapsed       | 364           |
| total_timesteps    | 13696         |
| value_loss         | 208.43272     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00051978196 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.09e+03      |
| explained_variance | -5.19e-05     |
| fps                | 41            |
| n_updates          | 108           |
| policy_entropy     | 1.460461      |
| policy_loss        | -0.0012104276 |
| serial_timesteps   | 13824         |
| time_elapsed       | 367           |
| total_timesteps    | 13824         |
| value_loss         | 476.08603     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0010641583  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | 0.00395       |
| fps                | 36            |
| n_updates          | 109           |
| policy_entropy     | 1.4600643     |
| policy_loss        | -0.0006021906 |
| serial_timesteps   | 13952         |
| time_elapsed       | 370           |
| total_timesteps    | 13952         |
| value_loss         | 49.97775      |
--------------------------------------
An average of 28.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2242.11
-------------------------------------
| approxkl           | 0.0061070174 |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.02e+03     |
| explained_variance | -0.00841     |
| fps                | 38           |
| n_updates          | 110          |
| policy_entropy     | 1.4601295    |
| policy_loss        | -0.021035273 |
| serial_timesteps   | 14080        |
| time_elapsed       | 374          |
| total_timesteps    | 14080        |
| value_loss         | 22.258549    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0014928054  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | 0.00864       |
| fps                | 38            |
| n_updates          | 111           |
| policy_entropy     | 1.4606348     |
| policy_loss        | -0.0039012409 |
| serial_timesteps   | 14208         |
| time_elapsed       | 377           |
| total_timesteps    | 14208         |
| value_loss         | 155.91768     |
--------------------------------------
--------------------------------------
| approxkl           | 3.757225e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | -0.00204      |
| fps                | 34            |
| n_updates          | 112           |
| policy_entropy     | 1.4605027     |
| policy_loss        | -0.0005302625 |
| serial_timesteps   | 14336         |
| time_elapsed       | 381           |
| total_timesteps    | 14336         |
| value_loss         | 154.09451     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0047901236 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.02e+03     |
| explained_variance | -0.0105      |
| fps                | 37           |
| n_updates          | 113          |
| policy_entropy     | 1.460456     |
| policy_loss        | 0.0034601255 |
| serial_timesteps   | 14464        |
| time_elapsed       | 384          |
| total_timesteps    | 14464        |
| value_loss         | 63.964027    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00014806018 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | 0.000488      |
| fps                | 35            |
| n_updates          | 114           |
| policy_entropy     | 1.459632      |
| policy_loss        | 0.0026559324  |
| serial_timesteps   | 14592         |
| time_elapsed       | 388           |
| total_timesteps    | 14592         |
| value_loss         | 170.12894     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0031632287 |
| clipfrac           | 0.017578125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.02e+03     |
| explained_variance | 0.000441     |
| fps                | 34           |
| n_updates          | 115          |
| policy_entropy     | 1.4589765    |
| policy_loss        | -0.012561578 |
| serial_timesteps   | 14720        |
| time_elapsed       | 391          |
| total_timesteps    | 14720        |
| value_loss         | 8344.594     |
-------------------------------------
------------------------------------
| approxkl           | 0.005699035 |
| clipfrac           | 0.064453125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.02e+03    |
| explained_variance | -0.00184    |
| fps                | 40          |
| n_updates          | 116         |
| policy_entropy     | 1.4591331   |
| policy_loss        | 0.005547112 |
| serial_timesteps   | 14848       |
| time_elapsed       | 395         |
| total_timesteps    | 14848       |
| value_loss         | 160.50421   |
------------------------------------
--------------------------------------
| approxkl           | 0.00055903476 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | -0.0108       |
| fps                | 37            |
| n_updates          | 117           |
| policy_entropy     | 1.4592365     |
| policy_loss        | -0.004290451  |
| serial_timesteps   | 14976         |
| time_elapsed       | 398           |
| total_timesteps    | 14976         |
| value_loss         | 6.2253404     |
--------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b8f6ef9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b8f6ef9b0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b8f677e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b8f677e48>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2871 samples, validate on 314 samples
Epoch 46/5000
 - 1s - loss: 0.0135 - val_loss: 0.0471
Epoch 47/5000
 - 0s - loss: 0.0187 - val_loss: 0.0320
Epoch 48/5000
 - 0s - loss: 0.0163 - val_loss: 0.0235
Epoch 49/5000
 - 0s - loss: 0.0119 - val_loss: 0.0179
Epoch 50/5000
 - 0s - loss: 0.0083 - val_loss: 0.0150
Epoch 51/5000
 - 0s - loss: 0.0076 - val_loss: 0.0122
Epoch 52/5000
 - 0s - loss: 0.0068 - val_loss: 0.0112
Epoch 53/5000
 - 0s - loss: 0.0068 - val_loss: 0.0117
Epoch 54/5000
 - 0s - loss: 0.0066 - val_loss: 0.0113
Epoch 55/5000
 - 0s - loss: 0.0072 - val_loss: 0.0054
Epoch 56/5000
 - 0s - loss: 0.0053 - val_loss: 0.0052
Epoch 57/5000
 - 0s - loss: 0.0051 - val_loss: 0.0051
Epoch 58/5000
 - 0s - loss: 0.0049 - val_loss: 0.0050
Epoch 59/5000
 - 0s - loss: 0.0047 - val_loss: 0.0049
Epoch 60/5000
 - 0s - loss: 0.0046 - val_loss: 0.0048
Epoch 61/5000
 - 0s - loss: 0.0046 - val_loss: 0.0048
Epoch 62/5000
 - 0s - loss: 0.0046 - val_loss: 0.0047
Epoch 63/5000
 - 0s - loss: 0.0045 - val_loss: 0.0047
Epoch 64/5000
 - 0s - loss: 0.0044 - val_loss: 0.0047
Epoch 65/5000
 - 0s - loss: 0.0044 - val_loss: 0.0047
Epoch 66/5000
 - 0s - loss: 0.0043 - val_loss: 0.0047
Epoch 67/5000
 - 0s - loss: 0.0043 - val_loss: 0.0047
Epoch 68/5000
 - 0s - loss: 0.0043 - val_loss: 0.0047
Train on 1841 samples, validate on 314 samples
Epoch 92/5000
 - 1s - loss: 0.0165 - val_loss: 7.8531e-04
Epoch 93/5000
 - 0s - loss: 0.0081 - val_loss: 7.3986e-04
Epoch 94/5000
 - 0s - loss: 0.0061 - val_loss: 6.8453e-04
Epoch 95/5000
 - 0s - loss: 0.0057 - val_loss: 6.8481e-04
Epoch 96/5000
 - 0s - loss: 0.0056 - val_loss: 7.0568e-04
Epoch 97/5000
 - 0s - loss: 0.0049 - val_loss: 6.8165e-04
Epoch 98/5000
 - 0s - loss: 0.0047 - val_loss: 6.7191e-04
Epoch 99/5000
 - 0s - loss: 0.0046 - val_loss: 6.7160e-04
Epoch 100/5000
 - 0s - loss: 0.0046 - val_loss: 6.7336e-04
Epoch 101/5000
 - 0s - loss: 0.0045 - val_loss: 6.7353e-04
Epoch 102/5000
 - 0s - loss: 0.0045 - val_loss: 6.7373e-04
Epoch 103/5000
 - 0s - loss: 0.0045 - val_loss: 6.7392e-04
Epoch 104/5000
 - 0s - loss: 0.0045 - val_loss: 6.7403e-04
Train on 2884 samples, validate on 314 samples
Epoch 75/5000
 - 2s - loss: 0.6832 - val_loss: 0.6589
Epoch 76/5000
 - 1s - loss: 0.6581 - val_loss: 0.6051
Epoch 77/5000
 - 1s - loss: 0.6416 - val_loss: 0.5713
Epoch 78/5000
 - 1s - loss: 0.6381 - val_loss: 0.5609
Epoch 79/5000
 - 1s - loss: 0.6327 - val_loss: 0.5496
Epoch 80/5000
 - 1s - loss: 0.6223 - val_loss: 0.5313
Epoch 81/5000
 - 1s - loss: 0.5950 - val_loss: 0.4999
Epoch 82/5000
 - 1s - loss: 0.5456 - val_loss: 0.4948
Epoch 83/5000
 - 1s - loss: 0.5064 - val_loss: 0.4932
Epoch 84/5000
 - 1s - loss: 0.4905 - val_loss: 0.4959
Epoch 85/5000
 - 1s - loss: 0.4830 - val_loss: 0.4962
Epoch 86/5000
 - 1s - loss: 0.4606 - val_loss: 0.4936
Epoch 87/5000
 - 1s - loss: 0.4589 - val_loss: 0.4925
Epoch 88/5000
 - 1s - loss: 0.4580 - val_loss: 0.4921
Epoch 89/5000
 - 1s - loss: 0.4574 - val_loss: 0.4920
Epoch 90/5000
 - 1s - loss: 0.4568 - val_loss: 0.4919
Epoch 91/5000
 - 1s - loss: 0.4564 - val_loss: 0.4919
Epoch 92/5000
 - 1s - loss: 0.4543 - val_loss: 0.4919
Epoch 93/5000
 - 1s - loss: 0.4542 - val_loss: 0.4920
Epoch 94/5000
 - 1s - loss: 0.4542 - val_loss: 0.4920
Epoch 95/5000
 - 1s - loss: 0.4541 - val_loss: 0.4921
Epoch 96/5000
 - 1s - loss: 0.4539 - val_loss: 0.4921
setting environment to train mode..... 

Training Started... 

An average of 29.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1432.20
-------------------------------------
| approxkl           | 0.0014243757 |
| clipfrac           | 0.00390625   |
| explained_variance | 0.00241      |
| fps                | 15           |
| n_updates          | 1            |
| policy_entropy     | 1.459183     |
| policy_loss        | -0.003220232 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.22e-05     |
| total_timesteps    | 128          |
| value_loss         | 189.8358     |
-------------------------------------
---------------------------------------
| approxkl           | 9.302928e-05   |
| clipfrac           | 0.0            |
| explained_variance | 0.00495        |
| fps                | 42             |
| n_updates          | 2              |
| policy_entropy     | 1.4591937      |
| policy_loss        | -0.00072225847 |
| serial_timesteps   | 256            |
| time_elapsed       | 8.27           |
| total_timesteps    | 256            |
| value_loss         | 129.21725      |
---------------------------------------
--------------------------------------
| approxkl           | 8.31526e-05   |
| clipfrac           | 0.0           |
| explained_variance | 0.00199       |
| fps                | 41            |
| n_updates          | 3             |
| policy_entropy     | 1.4593152     |
| policy_loss        | -0.0013000955 |
| serial_timesteps   | 384           |
| time_elapsed       | 11.3          |
| total_timesteps    | 384           |
| value_loss         | 102.53035     |
--------------------------------------
---------------------------------------
| approxkl           | 2.720467e-05   |
| clipfrac           | 0.0            |
| explained_variance | 0.00539        |
| fps                | 37             |
| n_updates          | 4              |
| policy_entropy     | 1.459326       |
| policy_loss        | -2.4757988e-05 |
| serial_timesteps   | 512            |
| time_elapsed       | 14.3           |
| total_timesteps    | 512            |
| value_loss         | 429.92703      |
---------------------------------------
--------------------------------------
| approxkl           | 2.7177766e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.00142       |
| fps                | 41            |
| n_updates          | 5             |
| policy_entropy     | 1.4587051     |
| policy_loss        | -0.0005797399 |
| serial_timesteps   | 640           |
| time_elapsed       | 17.8          |
| total_timesteps    | 640           |
| value_loss         | 374.45297     |
--------------------------------------
--------------------------------------
| approxkl           | 5.648808e-06  |
| clipfrac           | 0.0           |
| explained_variance | 0.00333       |
| fps                | 42            |
| n_updates          | 6             |
| policy_entropy     | 1.4584304     |
| policy_loss        | -6.295246e-05 |
| serial_timesteps   | 768           |
| time_elapsed       | 20.8          |
| total_timesteps    | 768           |
| value_loss         | 539.7193      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0015904836 |
| clipfrac           | 0.009765625  |
| explained_variance | 0.00128      |
| fps                | 40           |
| n_updates          | 7            |
| policy_entropy     | 1.4586172    |
| policy_loss        | 0.0020957692 |
| serial_timesteps   | 896          |
| time_elapsed       | 23.9         |
| total_timesteps    | 896          |
| value_loss         | 256.885      |
-------------------------------------
---------------------------------------
| approxkl           | 4.1412266e-05  |
| clipfrac           | 0.0            |
| explained_variance | -0.00103       |
| fps                | 50             |
| n_updates          | 8              |
| policy_entropy     | 1.4584627      |
| policy_loss        | -0.00055453205 |
| serial_timesteps   | 1024           |
| time_elapsed       | 27             |
| total_timesteps    | 1024           |
| value_loss         | 154.61385      |
---------------------------------------
An average of 29.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1432.20
---------------------------------------
| approxkl           | 4.0115247e-06  |
| clipfrac           | 0.0            |
| explained_variance | 0.00088        |
| fps                | 39             |
| n_updates          | 9              |
| policy_entropy     | 1.4584059      |
| policy_loss        | 0.000100921025 |
| serial_timesteps   | 1152           |
| time_elapsed       | 29.6           |
| total_timesteps    | 1152           |
| value_loss         | 1219.1667      |
---------------------------------------
---------------------------------------
| approxkl           | 5.4460015e-06  |
| clipfrac           | 0.0            |
| explained_variance | -0.00131       |
| fps                | 39             |
| n_updates          | 10             |
| policy_entropy     | 1.4583249      |
| policy_loss        | -0.00020713074 |
| serial_timesteps   | 1280           |
| time_elapsed       | 32.8           |
| total_timesteps    | 1280           |
| value_loss         | 242.85704      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00012532464 |
| clipfrac           | 0.0           |
| explained_variance | -0.00243      |
| fps                | 38            |
| n_updates          | 11            |
| policy_entropy     | 1.4581958     |
| policy_loss        | -0.0015450411 |
| serial_timesteps   | 1408          |
| time_elapsed       | 36.1          |
| total_timesteps    | 1408          |
| value_loss         | 169.08612     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00015366777 |
| clipfrac           | 0.0           |
| explained_variance | -0.00288      |
| fps                | 35            |
| n_updates          | 12            |
| policy_entropy     | 1.4579816     |
| policy_loss        | -0.0013988102 |
| serial_timesteps   | 1536          |
| time_elapsed       | 39.4          |
| total_timesteps    | 1536          |
| value_loss         | 273.28467     |
--------------------------------------
-------------------------------------
| approxkl           | 0.006241016  |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.6e+03      |
| explained_variance | -0.00204     |
| fps                | 48           |
| n_updates          | 13           |
| policy_entropy     | 1.4579554    |
| policy_loss        | -0.019216057 |
| serial_timesteps   | 1664         |
| time_elapsed       | 43           |
| total_timesteps    | 1664         |
| value_loss         | 56.75034     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00081382727 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.6e+03       |
| explained_variance | 0.00192       |
| fps                | 43            |
| n_updates          | 14            |
| policy_entropy     | 1.4580457     |
| policy_loss        | -0.0007295314 |
| serial_timesteps   | 1792          |
| time_elapsed       | 45.7          |
| total_timesteps    | 1792          |
| value_loss         | 341.94977     |
--------------------------------------
---------------------------------------
| approxkl           | 3.490825e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.6e+03        |
| explained_variance | 0.00432        |
| fps                | 44             |
| n_updates          | 15             |
| policy_entropy     | 1.4580204      |
| policy_loss        | -1.8382503e-05 |
| serial_timesteps   | 1920           |
| time_elapsed       | 48.6           |
| total_timesteps    | 1920           |
| value_loss         | 97.6903        |
---------------------------------------
-------------------------------------
| approxkl           | 0.0015323542 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.6e+03      |
| explained_variance | 0.000598     |
| fps                | 35           |
| n_updates          | 16           |
| policy_entropy     | 1.4573083    |
| policy_loss        | 0.00936036   |
| serial_timesteps   | 2048         |
| time_elapsed       | 51.5         |
| total_timesteps    | 2048         |
| value_loss         | 2478.9727    |
-------------------------------------
An average of 30.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1384.54
-------------------------------------
| approxkl           | 0.0053454596 |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.6e+03      |
| explained_variance | -0.00842     |
| fps                | 41           |
| n_updates          | 17           |
| policy_entropy     | 1.4574901    |
| policy_loss        | -0.008578697 |
| serial_timesteps   | 2176         |
| time_elapsed       | 55.1         |
| total_timesteps    | 2176         |
| value_loss         | 32.370613    |
-------------------------------------
---------------------------------------
| approxkl           | 3.2324838e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.6e+03        |
| explained_variance | 7.13e-05       |
| fps                | 38             |
| n_updates          | 18             |
| policy_entropy     | 1.4576205      |
| policy_loss        | -0.00015462749 |
| serial_timesteps   | 2304           |
| time_elapsed       | 58.2           |
| total_timesteps    | 2304           |
| value_loss         | 126.34503      |
---------------------------------------
--------------------------------------
| approxkl           | 3.8065537e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.6e+03       |
| explained_variance | 0.00365       |
| fps                | 44            |
| n_updates          | 19            |
| policy_entropy     | 1.4577088     |
| policy_loss        | 1.8048217e-05 |
| serial_timesteps   | 2432          |
| time_elapsed       | 61.5          |
| total_timesteps    | 2432          |
| value_loss         | 799.8737      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00043372327 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.6e+03       |
| explained_variance | 0.000654      |
| fps                | 42            |
| n_updates          | 20            |
| policy_entropy     | 1.4574685     |
| policy_loss        | 0.00054914824 |
| serial_timesteps   | 2560          |
| time_elapsed       | 64.4          |
| total_timesteps    | 2560          |
| value_loss         | 549.25037     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00022273586 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.6e+03       |
| explained_variance | 0.00601       |
| fps                | 44            |
| n_updates          | 21            |
| policy_entropy     | 1.4573474     |
| policy_loss        | -0.002527606  |
| serial_timesteps   | 2688          |
| time_elapsed       | 67.4          |
| total_timesteps    | 2688          |
| value_loss         | 69.69928      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00023130694 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.6e+03       |
| explained_variance | 0.00101       |
| fps                | 44            |
| n_updates          | 22            |
| policy_entropy     | 1.4575386     |
| policy_loss        | -0.0007438198 |
| serial_timesteps   | 2816          |
| time_elapsed       | 70.3          |
| total_timesteps    | 2816          |
| value_loss         | 550.7037      |
--------------------------------------
--------------------------------------
| approxkl           | 6.4917303e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.6e+03       |
| explained_variance | 0.00422       |
| fps                | 40            |
| n_updates          | 23            |
| policy_entropy     | 1.4576236     |
| policy_loss        | 0.00016003847 |
| serial_timesteps   | 2944          |
| time_elapsed       | 73.1          |
| total_timesteps    | 2944          |
| value_loss         | 632.07745     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0021181086 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.6e+03      |
| explained_variance | 0.00761      |
| fps                | 40           |
| n_updates          | 24           |
| policy_entropy     | 1.4583492    |
| policy_loss        | 0.0054532206 |
| serial_timesteps   | 3072         |
| time_elapsed       | 76.3         |
| total_timesteps    | 3072         |
| value_loss         | 471.399      |
-------------------------------------
An average of 30.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1384.54
--------------------------------------
| approxkl           | 0.00073173374 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | 0.00646       |
| fps                | 41            |
| n_updates          | 25            |
| policy_entropy     | 1.4587188     |
| policy_loss        | -0.000861599  |
| serial_timesteps   | 3200          |
| time_elapsed       | 79.5          |
| total_timesteps    | 3200          |
| value_loss         | 74.09322      |
--------------------------------------
---------------------------------------
| approxkl           | 0.00017431394  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.02e+03       |
| explained_variance | 0.00245        |
| fps                | 39             |
| n_updates          | 26             |
| policy_entropy     | 1.45887        |
| policy_loss        | -0.00078270223 |
| serial_timesteps   | 3328           |
| time_elapsed       | 82.6           |
| total_timesteps    | 3328           |
| value_loss         | 377.98474      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00027869263 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | -0.00678      |
| fps                | 43            |
| n_updates          | 27            |
| policy_entropy     | 1.4589782     |
| policy_loss        | -0.0045251064 |
| serial_timesteps   | 3456          |
| time_elapsed       | 85.8          |
| total_timesteps    | 3456          |
| value_loss         | 24.835133     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00013552562  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.02e+03       |
| explained_variance | 0.00241        |
| fps                | 40             |
| n_updates          | 28             |
| policy_entropy     | 1.4589833      |
| policy_loss        | -0.00064427615 |
| serial_timesteps   | 3584           |
| time_elapsed       | 88.8           |
| total_timesteps    | 3584           |
| value_loss         | 2065.9585      |
---------------------------------------
---------------------------------------
| approxkl           | 2.9117805e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.02e+03       |
| explained_variance | 0.00302        |
| fps                | 42             |
| n_updates          | 29             |
| policy_entropy     | 1.45902        |
| policy_loss        | -7.8919344e-05 |
| serial_timesteps   | 3712           |
| time_elapsed       | 91.9           |
| total_timesteps    | 3712           |
| value_loss         | 177.28333      |
---------------------------------------
--------------------------------------
| approxkl           | 0.002953707   |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | -0.00267      |
| fps                | 48            |
| n_updates          | 30            |
| policy_entropy     | 1.4590894     |
| policy_loss        | -0.0033783908 |
| serial_timesteps   | 3840          |
| time_elapsed       | 94.9          |
| total_timesteps    | 3840          |
| value_loss         | 119.4687      |
--------------------------------------
--------------------------------------
| approxkl           | 6.270472e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | 0.00425       |
| fps                | 43            |
| n_updates          | 31            |
| policy_entropy     | 1.459105      |
| policy_loss        | -0.0003961816 |
| serial_timesteps   | 3968          |
| time_elapsed       | 97.6          |
| total_timesteps    | 3968          |
| value_loss         | 280.1982      |
--------------------------------------
An average of 31.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1419.54
---------------------------------------
| approxkl           | 4.2107895e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.02e+03       |
| explained_variance | 0.00282        |
| fps                | 42             |
| n_updates          | 32             |
| policy_entropy     | 1.4589982      |
| policy_loss        | -0.00050900294 |
| serial_timesteps   | 4096           |
| time_elapsed       | 101            |
| total_timesteps    | 4096           |
| value_loss         | 35.24337       |
---------------------------------------
---------------------------------------
| approxkl           | 9.92259e-05    |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.02e+03       |
| explained_variance | 0.00424        |
| fps                | 39             |
| n_updates          | 33             |
| policy_entropy     | 1.4583429      |
| policy_loss        | -0.00054896343 |
| serial_timesteps   | 4224           |
| time_elapsed       | 104            |
| total_timesteps    | 4224           |
| value_loss         | 600.0261       |
---------------------------------------
-------------------------------------
| approxkl           | 0.0015170019 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.02e+03     |
| explained_variance | -0.0091      |
| fps                | 40           |
| n_updates          | 34           |
| policy_entropy     | 1.4579062    |
| policy_loss        | -0.000674048 |
| serial_timesteps   | 4352         |
| time_elapsed       | 107          |
| total_timesteps    | 4352         |
| value_loss         | 269.29837    |
-------------------------------------
--------------------------------------
| approxkl           | 6.5880544e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.02e+03      |
| explained_variance | 0.00244       |
| fps                | 41            |
| n_updates          | 35            |
| policy_entropy     | 1.4578313     |
| policy_loss        | -0.0018692014 |
| serial_timesteps   | 4480          |
| time_elapsed       | 110           |
| total_timesteps    | 4480          |
| value_loss         | 2966.3928     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0004661646 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.02e+03     |
| explained_variance | -0.00115     |
| fps                | 43           |
| n_updates          | 36           |
| policy_entropy     | 1.4581926    |
| policy_loss        | 0.0010328101 |
| serial_timesteps   | 4608         |
| time_elapsed       | 113          |
| total_timesteps    | 4608         |
| value_loss         | 110.67498    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0008843406  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.14e+03      |
| explained_variance | -0.00975      |
| fps                | 42            |
| n_updates          | 37            |
| policy_entropy     | 1.4594598     |
| policy_loss        | 0.00022893888 |
| serial_timesteps   | 4736          |
| time_elapsed       | 116           |
| total_timesteps    | 4736          |
| value_loss         | 247.54037     |
--------------------------------------
--------------------------------------
| approxkl           | 7.0841597e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.14e+03      |
| explained_variance | 0.00183       |
| fps                | 42            |
| n_updates          | 38            |
| policy_entropy     | 1.4601427     |
| policy_loss        | 0.00039850717 |
| serial_timesteps   | 4864          |
| time_elapsed       | 119           |
| total_timesteps    | 4864          |
| value_loss         | 2081.0974     |
--------------------------------------
---------------------------------------
| approxkl           | 1.9175637e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.14e+03       |
| explained_variance | 4.72e-05       |
| fps                | 43             |
| n_updates          | 39             |
| policy_entropy     | 1.4602823      |
| policy_loss        | -0.00034823222 |
| serial_timesteps   | 4992           |
| time_elapsed       | 122            |
| total_timesteps    | 4992           |
| value_loss         | 200.40038      |
---------------------------------------
An average of 32.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1311.75
-------------------------------------
| approxkl           | 3.577898e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.14e+03     |
| explained_variance | 0.0125       |
| fps                | 42           |
| n_updates          | 40           |
| policy_entropy     | 1.4604293    |
| policy_loss        | 0.000801987  |
| serial_timesteps   | 5120         |
| time_elapsed       | 125          |
| total_timesteps    | 5120         |
| value_loss         | 32.406418    |
-------------------------------------
--------------------------------------
| approxkl           | 8.597798e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.14e+03      |
| explained_variance | 0.00227       |
| fps                | 42            |
| n_updates          | 41            |
| policy_entropy     | 1.4606199     |
| policy_loss        | -0.0001285096 |
| serial_timesteps   | 5248          |
| time_elapsed       | 128           |
| total_timesteps    | 5248          |
| value_loss         | 699.18243     |
--------------------------------------
---------------------------------------
| approxkl           | 1.2491719e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.14e+03       |
| explained_variance | 0.00558        |
| fps                | 43             |
| n_updates          | 42             |
| policy_entropy     | 1.4606885      |
| policy_loss        | -1.7776852e-05 |
| serial_timesteps   | 5376           |
| time_elapsed       | 131            |
| total_timesteps    | 5376           |
| value_loss         | 527.2311       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0005694992  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.14e+03      |
| explained_variance | 0.00367       |
| fps                | 40            |
| n_updates          | 43            |
| policy_entropy     | 1.4612488     |
| policy_loss        | -0.0020714581 |
| serial_timesteps   | 5504          |
| time_elapsed       | 134           |
| total_timesteps    | 5504          |
| value_loss         | 568.1861      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0002666963 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.14e+03     |
| explained_variance | 0.00047      |
| fps                | 42           |
| n_updates          | 44           |
| policy_entropy     | 1.4618022    |
| policy_loss        | 0.0023742542 |
| serial_timesteps   | 5632         |
| time_elapsed       | 137          |
| total_timesteps    | 5632         |
| value_loss         | 110.48478    |
-------------------------------------
--------------------------------------
| approxkl           | 1.2173815e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.14e+03      |
| explained_variance | 0.00159       |
| fps                | 43            |
| n_updates          | 45            |
| policy_entropy     | 1.4619192     |
| policy_loss        | 8.1390084e-05 |
| serial_timesteps   | 5760          |
| time_elapsed       | 140           |
| total_timesteps    | 5760          |
| value_loss         | 356.93533     |
--------------------------------------
---------------------------------------
| approxkl           | 1.5153262e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.14e+03       |
| explained_variance | 0.00147        |
| fps                | 45             |
| n_updates          | 46             |
| policy_entropy     | 1.4619093      |
| policy_loss        | -2.0931475e-05 |
| serial_timesteps   | 5888           |
| time_elapsed       | 143            |
| total_timesteps    | 5888           |
| value_loss         | 250.79535      |
---------------------------------------
---------------------------------------
| approxkl           | 3.354706e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.14e+03       |
| explained_variance | 0.000718       |
| fps                | 41             |
| n_updates          | 47             |
| policy_entropy     | 1.4617978      |
| policy_loss        | -0.00020160014 |
| serial_timesteps   | 6016           |
| time_elapsed       | 146            |
| total_timesteps    | 6016           |
| value_loss         | 1531.6174      |
---------------------------------------
An average of 32.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1311.75
--------------------------------------
| approxkl           | 6.865587e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.14e+03      |
| explained_variance | 0.00278       |
| fps                | 39            |
| n_updates          | 48            |
| policy_entropy     | 1.4616063     |
| policy_loss        | 0.00014466431 |
| serial_timesteps   | 6144          |
| time_elapsed       | 149           |
| total_timesteps    | 6144          |
| value_loss         | 89.2093       |
--------------------------------------
--------------------------------------
| approxkl           | 0.0015603931  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | 0.00159       |
| fps                | 42            |
| n_updates          | 49            |
| policy_entropy     | 1.461503      |
| policy_loss        | -0.0057538785 |
| serial_timesteps   | 6272          |
| time_elapsed       | 152           |
| total_timesteps    | 6272          |
| value_loss         | 175.74995     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0007508563 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.22e+03     |
| explained_variance | -0.00549     |
| fps                | 41           |
| n_updates          | 50           |
| policy_entropy     | 1.4611474    |
| policy_loss        | 0.0024497479 |
| serial_timesteps   | 6400         |
| time_elapsed       | 155          |
| total_timesteps    | 6400         |
| value_loss         | 220.78549    |
-------------------------------------
--------------------------------------
| approxkl           | 4.8525297e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | 0.000646      |
| fps                | 40            |
| n_updates          | 51            |
| policy_entropy     | 1.4610691     |
| policy_loss        | 9.2818984e-05 |
| serial_timesteps   | 6528          |
| time_elapsed       | 158           |
| total_timesteps    | 6528          |
| value_loss         | 275.39526     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0025637583 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.22e+03     |
| explained_variance | 0.00541      |
| fps                | 38           |
| n_updates          | 52           |
| policy_entropy     | 1.4617009    |
| policy_loss        | -0.013986331 |
| serial_timesteps   | 6656         |
| time_elapsed       | 162          |
| total_timesteps    | 6656         |
| value_loss         | 331.58502    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0016018089  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | 0.00264       |
| fps                | 40            |
| n_updates          | 53            |
| policy_entropy     | 1.4620818     |
| policy_loss        | -0.0039532855 |
| serial_timesteps   | 6784          |
| time_elapsed       | 165           |
| total_timesteps    | 6784          |
| value_loss         | 467.60495     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0008395242  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | 0.00192       |
| fps                | 41            |
| n_updates          | 54            |
| policy_entropy     | 1.4622903     |
| policy_loss        | -0.0031530783 |
| serial_timesteps   | 6912          |
| time_elapsed       | 168           |
| total_timesteps    | 6912          |
| value_loss         | 1546.2072     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00085180363 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | -0.00673      |
| fps                | 39            |
| n_updates          | 55            |
| policy_entropy     | 1.4616973     |
| policy_loss        | -0.003790206  |
| serial_timesteps   | 7040          |
| time_elapsed       | 171           |
| total_timesteps    | 7040          |
| value_loss         | 300.69907     |
--------------------------------------
An average of 33.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1514.84
--------------------------------------
| approxkl           | 0.003024608   |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | -0.00865      |
| fps                | 42            |
| n_updates          | 56            |
| policy_entropy     | 1.4610375     |
| policy_loss        | 0.00070390396 |
| serial_timesteps   | 7168          |
| time_elapsed       | 175           |
| total_timesteps    | 7168          |
| value_loss         | 198.5571      |
--------------------------------------
---------------------------------------
| approxkl           | 2.1211817e-07  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.22e+03       |
| explained_variance | 0.000542       |
| fps                | 45             |
| n_updates          | 57             |
| policy_entropy     | 1.4603215      |
| policy_loss        | -1.4513498e-05 |
| serial_timesteps   | 7296           |
| time_elapsed       | 178            |
| total_timesteps    | 7296           |
| value_loss         | 2411.9993      |
---------------------------------------
--------------------------------------
| approxkl           | 1.2955081e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | 0.00279       |
| fps                | 37            |
| n_updates          | 58            |
| policy_entropy     | 1.4599705     |
| policy_loss        | -3.120862e-05 |
| serial_timesteps   | 7424          |
| time_elapsed       | 180           |
| total_timesteps    | 7424          |
| value_loss         | 202.13535     |
--------------------------------------
--------------------------------------
| approxkl           | 1.7997874e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.22e+03      |
| explained_variance | -0.00186      |
| fps                | 42            |
| n_updates          | 59            |
| policy_entropy     | 1.4597791     |
| policy_loss        | 1.4881371e-05 |
| serial_timesteps   | 7552          |
| time_elapsed       | 184           |
| total_timesteps    | 7552          |
| value_loss         | 48.6603       |
--------------------------------------
---------------------------------------
| approxkl           | 2.155885e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.22e+03       |
| explained_variance | 0.0036         |
| fps                | 39             |
| n_updates          | 60             |
| policy_entropy     | 1.4597547      |
| policy_loss        | -0.00010026008 |
| serial_timesteps   | 7680           |
| time_elapsed       | 187            |
| total_timesteps    | 7680           |
| value_loss         | 836.161        |
---------------------------------------
---------------------------------------
| approxkl           | 1.6482597e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.33e+03       |
| explained_variance | 0.00256        |
| fps                | 38             |
| n_updates          | 61             |
| policy_entropy     | 1.4597483      |
| policy_loss        | -2.6472844e-07 |
| serial_timesteps   | 7808           |
| time_elapsed       | 190            |
| total_timesteps    | 7808           |
| value_loss         | 323.90576      |
---------------------------------------
--------------------------------------
| approxkl           | 6.0740035e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.00355       |
| fps                | 39            |
| n_updates          | 62            |
| policy_entropy     | 1.4596686     |
| policy_loss        | 2.8493989e-05 |
| serial_timesteps   | 7936          |
| time_elapsed       | 193           |
| total_timesteps    | 7936          |
| value_loss         | 543.1492      |
--------------------------------------
-------------------------------------
| approxkl           | 1.611532e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.33e+03     |
| explained_variance | 0.00208      |
| fps                | 41           |
| n_updates          | 63           |
| policy_entropy     | 1.4597591    |
| policy_loss        | 6.379472e-05 |
| serial_timesteps   | 8064         |
| time_elapsed       | 197          |
| total_timesteps    | 8064         |
| value_loss         | 323.80115    |
-------------------------------------
An average of 34.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2326.37
--------------------------------------
| approxkl           | 1.4341545e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.00149       |
| fps                | 42            |
| n_updates          | 64            |
| policy_entropy     | 1.4597925     |
| policy_loss        | 8.2247425e-07 |
| serial_timesteps   | 8192          |
| time_elapsed       | 200           |
| total_timesteps    | 8192          |
| value_loss         | 84.521484     |
--------------------------------------
--------------------------------------
| approxkl           | 6.744073e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.000698      |
| fps                | 39            |
| n_updates          | 65            |
| policy_entropy     | 1.459932      |
| policy_loss        | -0.0006130866 |
| serial_timesteps   | 8320          |
| time_elapsed       | 203           |
| total_timesteps    | 8320          |
| value_loss         | 1407.9735     |
--------------------------------------
---------------------------------------
| approxkl           | 1.0803929e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.33e+03       |
| explained_variance | 0.00183        |
| fps                | 42             |
| n_updates          | 66             |
| policy_entropy     | 1.4599733      |
| policy_loss        | -0.00028112956 |
| serial_timesteps   | 8448           |
| time_elapsed       | 206            |
| total_timesteps    | 8448           |
| value_loss         | 370.9976       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00017879784 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.00205       |
| fps                | 41            |
| n_updates          | 67            |
| policy_entropy     | 1.4598739     |
| policy_loss        | -0.0006686095 |
| serial_timesteps   | 8576          |
| time_elapsed       | 209           |
| total_timesteps    | 8576          |
| value_loss         | 147.90076     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00012725516 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.000967      |
| fps                | 41            |
| n_updates          | 68            |
| policy_entropy     | 1.4599857     |
| policy_loss        | 9.9194935e-05 |
| serial_timesteps   | 8704          |
| time_elapsed       | 212           |
| total_timesteps    | 8704          |
| value_loss         | 87.618065     |
--------------------------------------
------------------------------------
| approxkl           | 0.000992589 |
| clipfrac           | 0.00390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.33e+03    |
| explained_variance | -0.00138    |
| fps                | 40          |
| n_updates          | 69          |
| policy_entropy     | 1.4595048   |
| policy_loss        | 0.007934553 |
| serial_timesteps   | 8832        |
| time_elapsed       | 215         |
| total_timesteps    | 8832        |
| value_loss         | 113.184006  |
------------------------------------
--------------------------------------
| approxkl           | 1.9339966e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.00186       |
| fps                | 36            |
| n_updates          | 70            |
| policy_entropy     | 1.4590927     |
| policy_loss        | 3.6407495e-05 |
| serial_timesteps   | 8960          |
| time_elapsed       | 218           |
| total_timesteps    | 8960          |
| value_loss         | 364.8199      |
--------------------------------------
An average of 34.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2326.37
--------------------------------------
| approxkl           | 0.0014948391  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.00315       |
| fps                | 41            |
| n_updates          | 71            |
| policy_entropy     | 1.4590114     |
| policy_loss        | -0.0032720598 |
| serial_timesteps   | 9088          |
| time_elapsed       | 222           |
| total_timesteps    | 9088          |
| value_loss         | 72.810555     |
--------------------------------------
--------------------------------------
| approxkl           | 5.0957315e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.33e+03      |
| explained_variance | 0.000832      |
| fps                | 42            |
| n_updates          | 72            |
| policy_entropy     | 1.4588355     |
| policy_loss        | 1.4436198e-05 |
| serial_timesteps   | 9216          |
| time_elapsed       | 225           |
| total_timesteps    | 9216          |
| value_loss         | 2765.7812     |
--------------------------------------
---------------------------------------
| approxkl           | 0.002434743    |
| clipfrac           | 0.015625       |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.39e+03       |
| explained_variance | 0.00205        |
| fps                | 36             |
| n_updates          | 73             |
| policy_entropy     | 1.4582304      |
| policy_loss        | -0.00046280038 |
| serial_timesteps   | 9344           |
| time_elapsed       | 228            |
| total_timesteps    | 9344           |
| value_loss         | 486.79214      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00024673887 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.00242       |
| fps                | 39            |
| n_updates          | 74            |
| policy_entropy     | 1.4578683     |
| policy_loss        | -0.0036876244 |
| serial_timesteps   | 9472          |
| time_elapsed       | 231           |
| total_timesteps    | 9472          |
| value_loss         | 276.17358     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011792507 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.39e+03     |
| explained_variance | 0.00333      |
| fps                | 41           |
| n_updates          | 75           |
| policy_entropy     | 1.4577594    |
| policy_loss        | 0.0027793336 |
| serial_timesteps   | 9600         |
| time_elapsed       | 235          |
| total_timesteps    | 9600         |
| value_loss         | 181.7418     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00085442205 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.000277      |
| fps                | 39            |
| n_updates          | 76            |
| policy_entropy     | 1.4587916     |
| policy_loss        | -0.0020649615 |
| serial_timesteps   | 9728          |
| time_elapsed       | 238           |
| total_timesteps    | 9728          |
| value_loss         | 1309.844      |
--------------------------------------
---------------------------------------
| approxkl           | 0.00013330308  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.39e+03       |
| explained_variance | 0.00175        |
| fps                | 47             |
| n_updates          | 77             |
| policy_entropy     | 1.4592551      |
| policy_loss        | -0.00055774045 |
| serial_timesteps   | 9856           |
| time_elapsed       | 241            |
| total_timesteps    | 9856           |
| value_loss         | 202.05145      |
---------------------------------------
--------------------------------------
| approxkl           | 3.37152e-05   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | -2.99e-05     |
| fps                | 44            |
| n_updates          | 78            |
| policy_entropy     | 1.4591326     |
| policy_loss        | 0.00033659767 |
| serial_timesteps   | 9984          |
| time_elapsed       | 244           |
| total_timesteps    | 9984          |
| value_loss         | 412.64355     |
--------------------------------------
An average of 35.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2543.97
---------------------------------------
| approxkl           | 4.905849e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.39e+03       |
| explained_variance | 0.00199        |
| fps                | 42             |
| n_updates          | 79             |
| policy_entropy     | 1.4590186      |
| policy_loss        | -0.00010834867 |
| serial_timesteps   | 10112          |
| time_elapsed       | 247            |
| total_timesteps    | 10112          |
| value_loss         | 351.36133      |
---------------------------------------
--------------------------------------
| approxkl           | 3.8968557e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.00279       |
| fps                | 42            |
| n_updates          | 80            |
| policy_entropy     | 1.4589742     |
| policy_loss        | 1.2248638e-05 |
| serial_timesteps   | 10240         |
| time_elapsed       | 250           |
| total_timesteps    | 10240         |
| value_loss         | 444.62        |
--------------------------------------
---------------------------------------
| approxkl           | 0.00041059882  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.39e+03       |
| explained_variance | 0.00196        |
| fps                | 43             |
| n_updates          | 81             |
| policy_entropy     | 1.4589512      |
| policy_loss        | -0.00026194064 |
| serial_timesteps   | 10368          |
| time_elapsed       | 253            |
| total_timesteps    | 10368          |
| value_loss         | 445.38754      |
---------------------------------------
--------------------------------------
| approxkl           | 1.8320341e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.000939      |
| fps                | 40            |
| n_updates          | 82            |
| policy_entropy     | 1.458925      |
| policy_loss        | 0.00014459644 |
| serial_timesteps   | 10496         |
| time_elapsed       | 255           |
| total_timesteps    | 10496         |
| value_loss         | 284.86838     |
--------------------------------------
-------------------------------------
| approxkl           | 0.006523867  |
| clipfrac           | 0.08984375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.39e+03     |
| explained_variance | 0.000276     |
| fps                | 46           |
| n_updates          | 83           |
| policy_entropy     | 1.4583551    |
| policy_loss        | -0.021167666 |
| serial_timesteps   | 10624        |
| time_elapsed       | 259          |
| total_timesteps    | 10624        |
| value_loss         | 40.67747     |
-------------------------------------
-------------------------------------
| approxkl           | 0.001309696  |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.39e+03     |
| explained_variance | 0.000643     |
| fps                | 41           |
| n_updates          | 84           |
| policy_entropy     | 1.4579736    |
| policy_loss        | -0.002744792 |
| serial_timesteps   | 10752        |
| time_elapsed       | 261          |
| total_timesteps    | 10752        |
| value_loss         | 1577.894     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00084618974 |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.41e+03      |
| explained_variance | -0.000503     |
| fps                | 40            |
| n_updates          | 85            |
| policy_entropy     | 1.4582952     |
| policy_loss        | -0.00276481   |
| serial_timesteps   | 10880         |
| time_elapsed       | 264           |
| total_timesteps    | 10880         |
| value_loss         | 69.859146     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0022200893 |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.41e+03     |
| explained_variance | -0.000763    |
| fps                | 40           |
| n_updates          | 86           |
| policy_entropy     | 1.4600273    |
| policy_loss        | -0.004712482 |
| serial_timesteps   | 11008        |
| time_elapsed       | 268          |
| total_timesteps    | 11008        |
| value_loss         | 88.37376     |
-------------------------------------
An average of 36.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2567.17
-------------------------------------
| approxkl           | 0.0029892086 |
| clipfrac           | 0.0234375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.41e+03     |
| explained_variance | -0.00084     |
| fps                | 46           |
| n_updates          | 87           |
| policy_entropy     | 1.46179      |
| policy_loss        | -0.008679784 |
| serial_timesteps   | 11136        |
| time_elapsed       | 271          |
| total_timesteps    | 11136        |
| value_loss         | 105.198235   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00875434   |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.41e+03     |
| explained_variance | -0.00176     |
| fps                | 44           |
| n_updates          | 88           |
| policy_entropy     | 1.4623765    |
| policy_loss        | -0.018211143 |
| serial_timesteps   | 11264        |
| time_elapsed       | 274          |
| total_timesteps    | 11264        |
| value_loss         | 86.60357     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0005527022  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.41e+03      |
| explained_variance | 0.00116       |
| fps                | 39            |
| n_updates          | 89            |
| policy_entropy     | 1.4625592     |
| policy_loss        | -0.0004532137 |
| serial_timesteps   | 11392         |
| time_elapsed       | 276           |
| total_timesteps    | 11392         |
| value_loss         | 665.16125     |
--------------------------------------
---------------------------------------
| approxkl           | 1.155728e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.41e+03       |
| explained_variance | 0.000347       |
| fps                | 41             |
| n_updates          | 90             |
| policy_entropy     | 1.462602       |
| policy_loss        | -0.00046185066 |
| serial_timesteps   | 11520          |
| time_elapsed       | 280            |
| total_timesteps    | 11520          |
| value_loss         | 194.43326      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0020440558  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.41e+03      |
| explained_variance | 0.000764      |
| fps                | 36            |
| n_updates          | 91            |
| policy_entropy     | 1.4627109     |
| policy_loss        | 0.00056538056 |
| serial_timesteps   | 11648         |
| time_elapsed       | 283           |
| total_timesteps    | 11648         |
| value_loss         | 3337.044      |
--------------------------------------
---------------------------------------
| approxkl           | 0.00016898992  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.41e+03       |
| explained_variance | 0.00135        |
| fps                | 42             |
| n_updates          | 92             |
| policy_entropy     | 1.4628701      |
| policy_loss        | -1.8455787e-05 |
| serial_timesteps   | 11776          |
| time_elapsed       | 286            |
| total_timesteps    | 11776          |
| value_loss         | 63.259834      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0012683552 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.41e+03     |
| explained_variance | -0.00452     |
| fps                | 41           |
| n_updates          | 93           |
| policy_entropy     | 1.4632093    |
| policy_loss        | -0.009791562 |
| serial_timesteps   | 11904        |
| time_elapsed       | 289          |
| total_timesteps    | 11904        |
| value_loss         | 125.61494    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0030494425 |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.41e+03     |
| explained_variance | 0.00199      |
| fps                | 40           |
| n_updates          | 94           |
| policy_entropy     | 1.4623885    |
| policy_loss        | -0.00235694  |
| serial_timesteps   | 12032        |
| time_elapsed       | 292          |
| total_timesteps    | 12032        |
| value_loss         | 1044.2184    |
-------------------------------------
An average of 36.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2567.17
--------------------------------------
| approxkl           | 0.0004294469  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.41e+03      |
| explained_variance | 0.000437      |
| fps                | 37            |
| n_updates          | 95            |
| policy_entropy     | 1.4625894     |
| policy_loss        | -0.0003628577 |
| serial_timesteps   | 12160         |
| time_elapsed       | 296           |
| total_timesteps    | 12160         |
| value_loss         | 373.54132     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0018692011 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.41e+03     |
| explained_variance | 0.000283     |
| fps                | 40           |
| n_updates          | 96           |
| policy_entropy     | 1.4632192    |
| policy_loss        | -0.011149003 |
| serial_timesteps   | 12288        |
| time_elapsed       | 299          |
| total_timesteps    | 12288        |
| value_loss         | 70.87284     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0019383571 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.39e+03     |
| explained_variance | 0.000251     |
| fps                | 41           |
| n_updates          | 97           |
| policy_entropy     | 1.4639045    |
| policy_loss        | -0.007237384 |
| serial_timesteps   | 12416        |
| time_elapsed       | 302          |
| total_timesteps    | 12416        |
| value_loss         | 616.50586    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00071504095 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.00366       |
| fps                | 42            |
| n_updates          | 98            |
| policy_entropy     | 1.4643435     |
| policy_loss        | 0.0017333197  |
| serial_timesteps   | 12544         |
| time_elapsed       | 305           |
| total_timesteps    | 12544         |
| value_loss         | 515.16235     |
--------------------------------------
--------------------------------------
| approxkl           | 5.8152673e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.00324       |
| fps                | 43            |
| n_updates          | 99            |
| policy_entropy     | 1.4644971     |
| policy_loss        | 0.0005642045  |
| serial_timesteps   | 12672         |
| time_elapsed       | 308           |
| total_timesteps    | 12672         |
| value_loss         | 737.2463      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0023879684  |
| clipfrac           | 0.015625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.00745       |
| fps                | 41            |
| n_updates          | 100           |
| policy_entropy     | 1.466076      |
| policy_loss        | -0.0023676897 |
| serial_timesteps   | 12800         |
| time_elapsed       | 311           |
| total_timesteps    | 12800         |
| value_loss         | 34.929638     |
--------------------------------------
-------------------------------------
| approxkl           | 9.561391e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.39e+03     |
| explained_variance | 0.00135      |
| fps                | 42           |
| n_updates          | 101          |
| policy_entropy     | 1.4670649    |
| policy_loss        | 0.0008757055 |
| serial_timesteps   | 12928        |
| time_elapsed       | 314          |
| total_timesteps    | 12928        |
| value_loss         | 329.53452    |
-------------------------------------
---------------------------------------
| approxkl           | 4.207111e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.39e+03       |
| explained_variance | -0.00616       |
| fps                | 46             |
| n_updates          | 102            |
| policy_entropy     | 1.467243       |
| policy_loss        | -8.5882144e-05 |
| serial_timesteps   | 13056          |
| time_elapsed       | 317            |
| total_timesteps    | 13056          |
| value_loss         | 50.738636      |
---------------------------------------
An average of 37.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2546.53
--------------------------------------
| approxkl           | 5.452573e-07  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.000842      |
| fps                | 42            |
| n_updates          | 103           |
| policy_entropy     | 1.467304      |
| policy_loss        | 1.1205673e-05 |
| serial_timesteps   | 13184         |
| time_elapsed       | 320           |
| total_timesteps    | 13184         |
| value_loss         | 2385.7844     |
--------------------------------------
---------------------------------------
| approxkl           | 2.721204e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.39e+03       |
| explained_variance | 0.00169        |
| fps                | 42             |
| n_updates          | 104            |
| policy_entropy     | 1.4673921      |
| policy_loss        | -0.00054926414 |
| serial_timesteps   | 13312          |
| time_elapsed       | 323            |
| total_timesteps    | 13312          |
| value_loss         | 172.15971      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00096596347 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | -0.000743     |
| fps                | 41            |
| n_updates          | 105           |
| policy_entropy     | 1.4674128     |
| policy_loss        | -0.0051376848 |
| serial_timesteps   | 13440         |
| time_elapsed       | 326           |
| total_timesteps    | 13440         |
| value_loss         | 86.24571      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0013230827  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | -0.00113      |
| fps                | 43            |
| n_updates          | 106           |
| policy_entropy     | 1.4670751     |
| policy_loss        | -0.0056826407 |
| serial_timesteps   | 13568         |
| time_elapsed       | 329           |
| total_timesteps    | 13568         |
| value_loss         | 135.2312      |
--------------------------------------
--------------------------------------
| approxkl           | 7.3008455e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | -0.00113      |
| fps                | 42            |
| n_updates          | 107           |
| policy_entropy     | 1.4669137     |
| policy_loss        | 0.0003228396  |
| serial_timesteps   | 13696         |
| time_elapsed       | 332           |
| total_timesteps    | 13696         |
| value_loss         | 92.82571      |
--------------------------------------
--------------------------------------
| approxkl           | 2.7899234e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.39e+03      |
| explained_variance | 0.00104       |
| fps                | 40            |
| n_updates          | 108           |
| policy_entropy     | 1.4670013     |
| policy_loss        | 0.0008025612  |
| serial_timesteps   | 13824         |
| time_elapsed       | 335           |
| total_timesteps    | 13824         |
| value_loss         | 580.89276     |
--------------------------------------
-------------------------------------
| approxkl           | 5.608769e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.38e+03     |
| explained_variance | 0.000472     |
| fps                | 38           |
| n_updates          | 109          |
| policy_entropy     | 1.4671825    |
| policy_loss        | 0.0005526602 |
| serial_timesteps   | 13952        |
| time_elapsed       | 338          |
| total_timesteps    | 13952        |
| value_loss         | 341.63593    |
-------------------------------------
An average of 38.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2517.30
--------------------------------------
| approxkl           | 8.4852456e-07 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.38e+03      |
| explained_variance | 0.00114       |
| fps                | 42            |
| n_updates          | 110           |
| policy_entropy     | 1.46722       |
| policy_loss        | 6.228755e-05  |
| serial_timesteps   | 14080         |
| time_elapsed       | 342           |
| total_timesteps    | 14080         |
| value_loss         | 3023.5583     |
--------------------------------------
---------------------------------------
| approxkl           | 2.0642688e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.38e+03       |
| explained_variance | -0.00284       |
| fps                | 40             |
| n_updates          | 111            |
| policy_entropy     | 1.467187       |
| policy_loss        | -0.00011211971 |
| serial_timesteps   | 14208          |
| time_elapsed       | 345            |
| total_timesteps    | 14208          |
| value_loss         | 79.90581       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0015965257  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.38e+03      |
| explained_variance | -0.00203      |
| fps                | 41            |
| n_updates          | 112           |
| policy_entropy     | 1.4668769     |
| policy_loss        | -0.0062603294 |
| serial_timesteps   | 14336         |
| time_elapsed       | 348           |
| total_timesteps    | 14336         |
| value_loss         | 22.59521      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0002653459 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.38e+03     |
| explained_variance | 0.000634     |
| fps                | 42           |
| n_updates          | 113          |
| policy_entropy     | 1.4666367    |
| policy_loss        | 0.0004931531 |
| serial_timesteps   | 14464        |
| time_elapsed       | 351          |
| total_timesteps    | 14464        |
| value_loss         | 2283.693     |
-------------------------------------
---------------------------------------
| approxkl           | 0.00013019954  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.38e+03       |
| explained_variance | 8.37e-05       |
| fps                | 42             |
| n_updates          | 114            |
| policy_entropy     | 1.4671121      |
| policy_loss        | -0.00011325907 |
| serial_timesteps   | 14592          |
| time_elapsed       | 354            |
| total_timesteps    | 14592          |
| value_loss         | 209.88646      |
---------------------------------------
---------------------------------------
| approxkl           | 1.2460399e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.38e+03       |
| explained_variance | 0.00504        |
| fps                | 43             |
| n_updates          | 115            |
| policy_entropy     | 1.4675832      |
| policy_loss        | -0.00015573308 |
| serial_timesteps   | 14720          |
| time_elapsed       | 357            |
| total_timesteps    | 14720          |
| value_loss         | 60.407635      |
---------------------------------------
--------------------------------------
| approxkl           | 3.9700317e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.38e+03      |
| explained_variance | 0.000951      |
| fps                | 40            |
| n_updates          | 116           |
| policy_entropy     | 1.4678074     |
| policy_loss        | -8.169672e-05 |
| serial_timesteps   | 14848         |
| time_elapsed       | 360           |
| total_timesteps    | 14848         |
| value_loss         | 647.1909      |
--------------------------------------
--------------------------------------
| approxkl           | 5.3594636e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.38e+03      |
| explained_variance | 0.00192       |
| fps                | 37            |
| n_updates          | 117           |
| policy_entropy     | 1.4678924     |
| policy_loss        | 9.082374e-06  |
| serial_timesteps   | 14976         |
| time_elapsed       | 363           |
| total_timesteps    | 14976         |
| value_loss         | 595.193       |
--------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b87d3d470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b87d3d470>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b87c4e940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b87c4e940>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2642 samples, validate on 307 samples
Epoch 69/5000
 - 2s - loss: 0.0159 - val_loss: 0.0419
Epoch 70/5000
 - 0s - loss: 0.0198 - val_loss: 0.0327
Epoch 71/5000
 - 0s - loss: 0.0148 - val_loss: 0.0191
Epoch 72/5000
 - 0s - loss: 0.0095 - val_loss: 0.0148
Epoch 73/5000
 - 0s - loss: 0.0068 - val_loss: 0.0112
Epoch 74/5000
 - 0s - loss: 0.0050 - val_loss: 0.0090
Epoch 75/5000
 - 0s - loss: 0.0046 - val_loss: 0.0081
Epoch 76/5000
 - 0s - loss: 0.0043 - val_loss: 0.0077
Epoch 77/5000
 - 0s - loss: 0.0041 - val_loss: 0.0072
Epoch 78/5000
 - 0s - loss: 0.0040 - val_loss: 0.0069
Epoch 79/5000
 - 0s - loss: 0.0039 - val_loss: 0.0067
Epoch 80/5000
 - 0s - loss: 0.0039 - val_loss: 0.0065
Epoch 81/5000
 - 0s - loss: 0.0039 - val_loss: 0.0063
Epoch 82/5000
 - 0s - loss: 0.0038 - val_loss: 0.0061
Epoch 83/5000
 - 0s - loss: 0.0038 - val_loss: 0.0060
Epoch 84/5000
 - 0s - loss: 0.0038 - val_loss: 0.0059
Epoch 85/5000
 - 0s - loss: 0.0038 - val_loss: 0.0058
Epoch 86/5000
 - 0s - loss: 0.0037 - val_loss: 0.0057
Epoch 87/5000
 - 0s - loss: 0.0037 - val_loss: 0.0056
Epoch 88/5000
 - 0s - loss: 0.0037 - val_loss: 0.0056
Epoch 89/5000
 - 0s - loss: 0.0037 - val_loss: 0.0055
Epoch 90/5000
 - 0s - loss: 0.0038 - val_loss: 0.0044
Epoch 91/5000
 - 0s - loss: 0.0037 - val_loss: 0.0043
Epoch 92/5000
 - 0s - loss: 0.0037 - val_loss: 0.0042
Epoch 93/5000
 - 0s - loss: 0.0036 - val_loss: 0.0042
Epoch 94/5000
 - 0s - loss: 0.0036 - val_loss: 0.0041
Epoch 95/5000
 - 0s - loss: 0.0035 - val_loss: 0.0041
Epoch 96/5000
 - 0s - loss: 0.0033 - val_loss: 0.0040
Epoch 97/5000
 - 0s - loss: 0.0033 - val_loss: 0.0038
Epoch 98/5000
 - 0s - loss: 0.0032 - val_loss: 0.0038
Epoch 99/5000
 - 0s - loss: 0.0032 - val_loss: 0.0037
Epoch 100/5000
 - 0s - loss: 0.0032 - val_loss: 0.0037
Epoch 101/5000
 - 0s - loss: 0.0032 - val_loss: 0.0037
Epoch 102/5000
 - 0s - loss: 0.0032 - val_loss: 0.0037
Epoch 103/5000
 - 0s - loss: 0.0032 - val_loss: 0.0037
Epoch 104/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 105/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 106/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 107/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 108/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 109/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 110/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 111/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 112/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 113/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 114/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 115/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 116/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 117/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Epoch 118/5000
 - 0s - loss: 0.0032 - val_loss: 0.0036
Train on 1729 samples, validate on 307 samples
Epoch 105/5000
 - 1s - loss: 0.0179 - val_loss: 0.0013
Epoch 106/5000
 - 0s - loss: 0.0107 - val_loss: 9.0277e-04
Epoch 107/5000
 - 0s - loss: 0.0090 - val_loss: 8.3897e-04
Epoch 108/5000
 - 0s - loss: 0.0064 - val_loss: 8.5225e-04
Epoch 109/5000
 - 0s - loss: 0.0046 - val_loss: 7.3070e-04
Epoch 110/5000
 - 0s - loss: 0.0044 - val_loss: 7.2439e-04
Epoch 111/5000
 - 0s - loss: 0.0044 - val_loss: 7.2419e-04
Epoch 112/5000
 - 0s - loss: 0.0044 - val_loss: 7.2525e-04
Epoch 113/5000
 - 0s - loss: 0.0042 - val_loss: 7.2524e-04
Epoch 114/5000
 - 0s - loss: 0.0042 - val_loss: 7.2533e-04
Epoch 115/5000
 - 0s - loss: 0.0042 - val_loss: 7.2545e-04
Epoch 116/5000
 - 0s - loss: 0.0042 - val_loss: 7.2559e-04
Train on 2644 samples, validate on 307 samples
Epoch 97/5000
 - 3s - loss: 0.6698 - val_loss: 0.6273
Epoch 98/5000
 - 1s - loss: 0.6318 - val_loss: 0.5782
Epoch 99/5000
 - 1s - loss: 0.6267 - val_loss: 0.5699
Epoch 100/5000
 - 1s - loss: 0.6207 - val_loss: 0.5667
Epoch 101/5000
 - 1s - loss: 0.6111 - val_loss: 0.5640
Epoch 102/5000
 - 1s - loss: 0.5962 - val_loss: 0.5640
Epoch 103/5000
 - 1s - loss: 0.5719 - val_loss: 0.5716
Epoch 104/5000
 - 1s - loss: 0.5363 - val_loss: 0.5725
Epoch 105/5000
 - 1s - loss: 0.5314 - val_loss: 0.5735
Epoch 106/5000
 - 1s - loss: 0.5274 - val_loss: 0.5747
Epoch 107/5000
 - 1s - loss: 0.5237 - val_loss: 0.5759
setting environment to train mode..... 

Training Started... 

An average of 39.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2073.99
--------------------------------------
| approxkl           | 0.00034241175 |
| clipfrac           | 0.0           |
| explained_variance | 0.00438       |
| fps                | 13            |
| n_updates          | 1             |
| policy_entropy     | 1.4681599     |
| policy_loss        | 0.00027630432 |
| serial_timesteps   | 128           |
| time_elapsed       | 1.14e-05      |
| total_timesteps    | 128           |
| value_loss         | 65.57182      |
--------------------------------------
--------------------------------------
| approxkl           | 3.6145695e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.00376       |
| fps                | 34            |
| n_updates          | 2             |
| policy_entropy     | 1.4681311     |
| policy_loss        | 0.00023550028 |
| serial_timesteps   | 256           |
| time_elapsed       | 9.62          |
| total_timesteps    | 256           |
| value_loss         | 83.5361       |
--------------------------------------
---------------------------------------
| approxkl           | 7.152698e-05   |
| clipfrac           | 0.0            |
| explained_variance | 0.00338        |
| fps                | 36             |
| n_updates          | 3              |
| policy_entropy     | 1.4683199      |
| policy_loss        | -0.00044092606 |
| serial_timesteps   | 384            |
| time_elapsed       | 13.3           |
| total_timesteps    | 384            |
| value_loss         | 40.578835      |
---------------------------------------
--------------------------------------
| approxkl           | 5.5535835e-05 |
| clipfrac           | 0.0           |
| explained_variance | 0.00644       |
| fps                | 33            |
| n_updates          | 4             |
| policy_entropy     | 1.4683683     |
| policy_loss        | -0.0004268632 |
| serial_timesteps   | 512           |
| time_elapsed       | 16.9          |
| total_timesteps    | 512           |
| value_loss         | 41.95972      |
--------------------------------------
-------------------------------------
| approxkl           | 7.801959e-05 |
| clipfrac           | 0.0          |
| explained_variance | -0.000169    |
| fps                | 33           |
| n_updates          | 5            |
| policy_entropy     | 1.4685639    |
| policy_loss        | 0.0006237137 |
| serial_timesteps   | 640          |
| time_elapsed       | 20.7         |
| total_timesteps    | 640          |
| value_loss         | 46.44103     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0003417217 |
| clipfrac           | 0.0          |
| explained_variance | 0.00121      |
| fps                | 32           |
| n_updates          | 6            |
| policy_entropy     | 1.4687455    |
| policy_loss        | 0.0013017177 |
| serial_timesteps   | 768          |
| time_elapsed       | 24.6         |
| total_timesteps    | 768          |
| value_loss         | 106.81966    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0005617182  |
| clipfrac           | 0.0           |
| explained_variance | 0.00136       |
| fps                | 36            |
| n_updates          | 7             |
| policy_entropy     | 1.4677519     |
| policy_loss        | -0.0041664517 |
| serial_timesteps   | 896           |
| time_elapsed       | 28.5          |
| total_timesteps    | 896           |
| value_loss         | 144.14157     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00024877448 |
| clipfrac           | 0.0           |
| explained_variance | 0.00282       |
| fps                | 33            |
| n_updates          | 8             |
| policy_entropy     | 1.4671624     |
| policy_loss        | -0.0015602158 |
| serial_timesteps   | 1024          |
| time_elapsed       | 32            |
| total_timesteps    | 1024          |
| value_loss         | 50.532032     |
--------------------------------------
An average of 39.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2073.99
--------------------------------------
| approxkl           | 0.00045843993 |
| clipfrac           | 0.0           |
| explained_variance | -0.00649      |
| fps                | 30            |
| n_updates          | 9             |
| policy_entropy     | 1.4671        |
| policy_loss        | -0.0035413976 |
| serial_timesteps   | 1152          |
| time_elapsed       | 35.8          |
| total_timesteps    | 1152          |
| value_loss         | 19.842003     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00082760106 |
| clipfrac           | 0.0           |
| explained_variance | 0.000526      |
| fps                | 36            |
| n_updates          | 10            |
| policy_entropy     | 1.4675273     |
| policy_loss        | -0.0015046082 |
| serial_timesteps   | 1280          |
| time_elapsed       | 40            |
| total_timesteps    | 1280          |
| value_loss         | 48.77073      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0010936614  |
| clipfrac           | 0.00390625    |
| explained_variance | -0.000772     |
| fps                | 34            |
| n_updates          | 11            |
| policy_entropy     | 1.4680601     |
| policy_loss        | -0.0049354755 |
| serial_timesteps   | 1408          |
| time_elapsed       | 43.5          |
| total_timesteps    | 1408          |
| value_loss         | 62.156445     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0011139652  |
| clipfrac           | 0.005859375   |
| explained_variance | 0.00231       |
| fps                | 34            |
| n_updates          | 12            |
| policy_entropy     | 1.4694681     |
| policy_loss        | -0.0030098485 |
| serial_timesteps   | 1536          |
| time_elapsed       | 47.1          |
| total_timesteps    | 1536          |
| value_loss         | 36.36165      |
--------------------------------------
--------------------------------------
| approxkl           | 0.000266271   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.00116       |
| fps                | 37            |
| n_updates          | 13            |
| policy_entropy     | 1.4696928     |
| policy_loss        | -0.0009521743 |
| serial_timesteps   | 1664          |
| time_elapsed       | 50.8          |
| total_timesteps    | 1664          |
| value_loss         | 154.57552     |
--------------------------------------
--------------------------------------
| approxkl           | 7.422001e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.00133       |
| fps                | 35            |
| n_updates          | 14            |
| policy_entropy     | 1.4696479     |
| policy_loss        | 0.00010842999 |
| serial_timesteps   | 1792          |
| time_elapsed       | 54.2          |
| total_timesteps    | 1792          |
| value_loss         | 96.90884      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0008594701  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | -0.00284      |
| fps                | 35            |
| n_updates          | 15            |
| policy_entropy     | 1.4707106     |
| policy_loss        | -0.0034546491 |
| serial_timesteps   | 1920          |
| time_elapsed       | 57.8          |
| total_timesteps    | 1920          |
| value_loss         | 135.92026     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0046660784  |
| clipfrac           | 0.0546875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.000111      |
| fps                | 37            |
| n_updates          | 16            |
| policy_entropy     | 1.4709861     |
| policy_loss        | -0.0042744735 |
| serial_timesteps   | 2048          |
| time_elapsed       | 61.5          |
| total_timesteps    | 2048          |
| value_loss         | 153.143       |
--------------------------------------
An average of 40.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1728.23
---------------------------------------
| approxkl           | 2.4179722e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 955            |
| explained_variance | -0.000687      |
| fps                | 33             |
| n_updates          | 17             |
| policy_entropy     | 1.4711291      |
| policy_loss        | -0.00051678193 |
| serial_timesteps   | 2176           |
| time_elapsed       | 64.9           |
| total_timesteps    | 2176           |
| value_loss         | 178.87776      |
---------------------------------------
---------------------------------------
| approxkl           | 7.851631e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 955            |
| explained_variance | 0.0016         |
| fps                | 31             |
| n_updates          | 18             |
| policy_entropy     | 1.4713653      |
| policy_loss        | -0.00014150573 |
| serial_timesteps   | 2304           |
| time_elapsed       | 68.8           |
| total_timesteps    | 2304           |
| value_loss         | 38.79951       |
---------------------------------------
--------------------------------------
| approxkl           | 5.9637164e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.003         |
| fps                | 32            |
| n_updates          | 19            |
| policy_entropy     | 1.4713401     |
| policy_loss        | 0.00013554236 |
| serial_timesteps   | 2432          |
| time_elapsed       | 72.8          |
| total_timesteps    | 2432          |
| value_loss         | 69.266396     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00055713585 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.00232       |
| fps                | 36            |
| n_updates          | 20            |
| policy_entropy     | 1.4714804     |
| policy_loss        | -0.0024893286 |
| serial_timesteps   | 2560          |
| time_elapsed       | 76.7          |
| total_timesteps    | 2560          |
| value_loss         | 46.053837     |
--------------------------------------
------------------------------------
| approxkl           | 0.000742459 |
| clipfrac           | 0.0         |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 955         |
| explained_variance | 0.0109      |
| fps                | 33          |
| n_updates          | 21          |
| policy_entropy     | 1.471945    |
| policy_loss        | 0.003245957 |
| serial_timesteps   | 2688        |
| time_elapsed       | 80.3        |
| total_timesteps    | 2688        |
| value_loss         | 26.74575    |
------------------------------------
--------------------------------------
| approxkl           | 0.00040724562 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.000361      |
| fps                | 31            |
| n_updates          | 22            |
| policy_entropy     | 1.4721574     |
| policy_loss        | -0.0007267154 |
| serial_timesteps   | 2816          |
| time_elapsed       | 84            |
| total_timesteps    | 2816          |
| value_loss         | 35.752728     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0008141336  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 955           |
| explained_variance | 0.00219       |
| fps                | 36            |
| n_updates          | 23            |
| policy_entropy     | 1.4712199     |
| policy_loss        | -0.0020538715 |
| serial_timesteps   | 2944          |
| time_elapsed       | 88.1          |
| total_timesteps    | 2944          |
| value_loss         | 83.09434      |
--------------------------------------
---------------------------------------
| approxkl           | 6.0410646e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 955            |
| explained_variance | 0.00199        |
| fps                | 30             |
| n_updates          | 24             |
| policy_entropy     | 1.4707435      |
| policy_loss        | -0.00078050536 |
| serial_timesteps   | 3072           |
| time_elapsed       | 91.6           |
| total_timesteps    | 3072           |
| value_loss         | 257.61926      |
---------------------------------------
An average of 41.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1504.19
--------------------------------------
| approxkl           | 4.291361e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.000933      |
| fps                | 36            |
| n_updates          | 25            |
| policy_entropy     | 1.4705051     |
| policy_loss        | -0.0007951978 |
| serial_timesteps   | 3200          |
| time_elapsed       | 95.8          |
| total_timesteps    | 3200          |
| value_loss         | 156.61766     |
--------------------------------------
--------------------------------------
| approxkl           | 6.6212406e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.00448      |
| fps                | 34            |
| n_updates          | 26            |
| policy_entropy     | 1.4703908     |
| policy_loss        | 0.00038847572 |
| serial_timesteps   | 3328          |
| time_elapsed       | 99.3          |
| total_timesteps    | 3328          |
| value_loss         | 22.018774     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0003623049 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.2e+03      |
| explained_variance | -0.00337     |
| fps                | 33           |
| n_updates          | 27           |
| policy_entropy     | 1.4705564    |
| policy_loss        | 0.0014706713 |
| serial_timesteps   | 3456         |
| time_elapsed       | 103          |
| total_timesteps    | 3456         |
| value_loss         | 96.59908     |
-------------------------------------
--------------------------------------
| approxkl           | 1.6018862e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.00274      |
| fps                | 35            |
| n_updates          | 28            |
| policy_entropy     | 1.4705857     |
| policy_loss        | 2.5016547e-05 |
| serial_timesteps   | 3584          |
| time_elapsed       | 107           |
| total_timesteps    | 3584          |
| value_loss         | 69.3586       |
--------------------------------------
--------------------------------------
| approxkl           | 0.00062786054 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.000766      |
| fps                | 31            |
| n_updates          | 29            |
| policy_entropy     | 1.472193      |
| policy_loss        | 0.0016388263  |
| serial_timesteps   | 3712          |
| time_elapsed       | 110           |
| total_timesteps    | 3712          |
| value_loss         | 28.39236      |
--------------------------------------
---------------------------------------
| approxkl           | 2.1185839e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.2e+03        |
| explained_variance | -0.00248       |
| fps                | 34             |
| n_updates          | 30             |
| policy_entropy     | 1.4766086      |
| policy_loss        | -0.00018616568 |
| serial_timesteps   | 3840           |
| time_elapsed       | 114            |
| total_timesteps    | 3840           |
| value_loss         | 77.21457       |
---------------------------------------
---------------------------------------
| approxkl           | 2.083897e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.2e+03        |
| explained_variance | 0.00273        |
| fps                | 34             |
| n_updates          | 31             |
| policy_entropy     | 1.4780036      |
| policy_loss        | -0.00011331134 |
| serial_timesteps   | 3968           |
| time_elapsed       | 118            |
| total_timesteps    | 3968           |
| value_loss         | 201.0203       |
---------------------------------------
--------------------------------------
| approxkl           | 6.546652e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.00115      |
| fps                | 32            |
| n_updates          | 32            |
| policy_entropy     | 1.4780353     |
| policy_loss        | 2.4371315e-05 |
| serial_timesteps   | 4096          |
| time_elapsed       | 122           |
| total_timesteps    | 4096          |
| value_loss         | 107.89253     |
--------------------------------------
An average of 41.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1504.19
-------------------------------------
| approxkl           | 0.0013772303 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.2e+03      |
| explained_variance | -0.00648     |
| fps                | 36           |
| n_updates          | 33           |
| policy_entropy     | 1.4764401    |
| policy_loss        | 0.0022979756 |
| serial_timesteps   | 4224         |
| time_elapsed       | 126          |
| total_timesteps    | 4224         |
| value_loss         | 91.10088     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0009617419 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.2e+03      |
| explained_variance | -0.00204     |
| fps                | 36           |
| n_updates          | 34           |
| policy_entropy     | 1.4754719    |
| policy_loss        | -0.002134617 |
| serial_timesteps   | 4352         |
| time_elapsed       | 129          |
| total_timesteps    | 4352         |
| value_loss         | 42.79723     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00022772423 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.000303     |
| fps                | 35            |
| n_updates          | 35            |
| policy_entropy     | 1.475423      |
| policy_loss        | 0.00068882946 |
| serial_timesteps   | 4480          |
| time_elapsed       | 133           |
| total_timesteps    | 4480          |
| value_loss         | 36.602455     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0001221346  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.00318       |
| fps                | 36            |
| n_updates          | 36            |
| policy_entropy     | 1.4750674     |
| policy_loss        | 0.00066941045 |
| serial_timesteps   | 4608          |
| time_elapsed       | 136           |
| total_timesteps    | 4608          |
| value_loss         | 37.42831      |
--------------------------------------
---------------------------------------
| approxkl           | 3.4811088e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.28e+03       |
| explained_variance | 0.00108        |
| fps                | 35             |
| n_updates          | 37             |
| policy_entropy     | 1.4749259      |
| policy_loss        | -0.00044806686 |
| serial_timesteps   | 4736           |
| time_elapsed       | 140            |
| total_timesteps    | 4736           |
| value_loss         | 78.437096      |
---------------------------------------
--------------------------------------
| approxkl           | 0.001451556   |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | 0.00382       |
| fps                | 34            |
| n_updates          | 38            |
| policy_entropy     | 1.4744205     |
| policy_loss        | -0.0014602022 |
| serial_timesteps   | 4864          |
| time_elapsed       | 144           |
| total_timesteps    | 4864          |
| value_loss         | 29.50843      |
--------------------------------------
--------------------------------------
| approxkl           | 3.5318728e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | -0.000159     |
| fps                | 32            |
| n_updates          | 39            |
| policy_entropy     | 1.4713123     |
| policy_loss        | 0.0005179533  |
| serial_timesteps   | 4992          |
| time_elapsed       | 147           |
| total_timesteps    | 4992          |
| value_loss         | 29.628572     |
--------------------------------------
An average of 42.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1341.97
---------------------------------------
| approxkl           | 2.7672959e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.28e+03       |
| explained_variance | -0.000265      |
| fps                | 33             |
| n_updates          | 40             |
| policy_entropy     | 1.4699904      |
| policy_loss        | -3.1477713e-05 |
| serial_timesteps   | 5120           |
| time_elapsed       | 151            |
| total_timesteps    | 5120           |
| value_loss         | 48.73965       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0006890103  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | 0.000804      |
| fps                | 32            |
| n_updates          | 41            |
| policy_entropy     | 1.4694531     |
| policy_loss        | -0.0043109674 |
| serial_timesteps   | 5248          |
| time_elapsed       | 155           |
| total_timesteps    | 5248          |
| value_loss         | 251.96164     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00011664206  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.28e+03       |
| explained_variance | 0.000801       |
| fps                | 35             |
| n_updates          | 42             |
| policy_entropy     | 1.4692925      |
| policy_loss        | -0.00083332555 |
| serial_timesteps   | 5376           |
| time_elapsed       | 159            |
| total_timesteps    | 5376           |
| value_loss         | 38.95586       |
---------------------------------------
---------------------------------------
| approxkl           | 0.0007443868   |
| clipfrac           | 0.00390625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.28e+03       |
| explained_variance | -0.00226       |
| fps                | 31             |
| n_updates          | 43             |
| policy_entropy     | 1.4703543      |
| policy_loss        | -0.00056895113 |
| serial_timesteps   | 5504           |
| time_elapsed       | 163            |
| total_timesteps    | 5504           |
| value_loss         | 51.48228       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0007526621  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | -0.00327      |
| fps                | 31            |
| n_updates          | 44            |
| policy_entropy     | 1.4738345     |
| policy_loss        | -0.0006762005 |
| serial_timesteps   | 5632          |
| time_elapsed       | 167           |
| total_timesteps    | 5632          |
| value_loss         | 38.790474     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0015241675  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | -0.00265      |
| fps                | 35            |
| n_updates          | 45            |
| policy_entropy     | 1.4756526     |
| policy_loss        | -0.0061709597 |
| serial_timesteps   | 5760          |
| time_elapsed       | 171           |
| total_timesteps    | 5760          |
| value_loss         | 104.488304    |
--------------------------------------
----------------------------------------
| approxkl           | 2.1329663e-05   |
| clipfrac           | 0.0             |
| ep_len_mean        | 1.54e+03        |
| ep_reward_mean     | 1.28e+03        |
| explained_variance | 0.000537        |
| fps                | 37              |
| n_updates          | 46              |
| policy_entropy     | 1.4763645       |
| policy_loss        | -0.000113186135 |
| serial_timesteps   | 5888            |
| time_elapsed       | 174             |
| total_timesteps    | 5888            |
| value_loss         | 48.424126       |
----------------------------------------
--------------------------------------
| approxkl           | 0.00014218068 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | -0.00102      |
| fps                | 33            |
| n_updates          | 47            |
| policy_entropy     | 1.4768641     |
| policy_loss        | 0.0005011561  |
| serial_timesteps   | 6016          |
| time_elapsed       | 178           |
| total_timesteps    | 6016          |
| value_loss         | 178.15063     |
--------------------------------------
An average of 42.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1341.97
--------------------------------------
| approxkl           | 0.0003975921  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.28e+03      |
| explained_variance | 0.00041       |
| fps                | 36            |
| n_updates          | 48            |
| policy_entropy     | 1.4770875     |
| policy_loss        | -0.0028898353 |
| serial_timesteps   | 6144          |
| time_elapsed       | 182           |
| total_timesteps    | 6144          |
| value_loss         | 198.5635      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0067377863 |
| clipfrac           | 0.095703125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.25e+03     |
| explained_variance | -0.000143    |
| fps                | 35           |
| n_updates          | 49           |
| policy_entropy     | 1.4767123    |
| policy_loss        | -0.010179259 |
| serial_timesteps   | 6272         |
| time_elapsed       | 185          |
| total_timesteps    | 6272         |
| value_loss         | 132.4359     |
-------------------------------------
---------------------------------------
| approxkl           | 3.0268684e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.25e+03       |
| explained_variance | 0.00112        |
| fps                | 33             |
| n_updates          | 50             |
| policy_entropy     | 1.4765214      |
| policy_loss        | -0.00011460134 |
| serial_timesteps   | 6400           |
| time_elapsed       | 189            |
| total_timesteps    | 6400           |
| value_loss         | 120.95808      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0018864048 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.25e+03     |
| explained_variance | -0.00355     |
| fps                | 35           |
| n_updates          | 51           |
| policy_entropy     | 1.4765756    |
| policy_loss        | -0.006510751 |
| serial_timesteps   | 6528         |
| time_elapsed       | 193          |
| total_timesteps    | 6528         |
| value_loss         | 41.784946    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0063594887  |
| clipfrac           | 0.080078125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | 0.00177       |
| fps                | 33            |
| n_updates          | 52            |
| policy_entropy     | 1.4756604     |
| policy_loss        | -0.0056336625 |
| serial_timesteps   | 6656          |
| time_elapsed       | 196           |
| total_timesteps    | 6656          |
| value_loss         | 27.527721     |
--------------------------------------
---------------------------------------
| approxkl           | 5.2364067e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.25e+03       |
| explained_variance | 0.00219        |
| fps                | 35             |
| n_updates          | 53             |
| policy_entropy     | 1.4747281      |
| policy_loss        | -0.00014981424 |
| serial_timesteps   | 6784           |
| time_elapsed       | 200            |
| total_timesteps    | 6784           |
| value_loss         | 54.36922       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00022883652 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | 0.00446       |
| fps                | 36            |
| n_updates          | 54            |
| policy_entropy     | 1.4748768     |
| policy_loss        | 0.0014977771  |
| serial_timesteps   | 6912          |
| time_elapsed       | 204           |
| total_timesteps    | 6912          |
| value_loss         | 42.422012     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0034314017  |
| clipfrac           | 0.04296875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | 0.00157       |
| fps                | 33            |
| n_updates          | 55            |
| policy_entropy     | 1.4748684     |
| policy_loss        | -0.0076918597 |
| serial_timesteps   | 7040          |
| time_elapsed       | 207           |
| total_timesteps    | 7040          |
| value_loss         | 31.118063     |
--------------------------------------
An average of 43.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1110.26
-------------------------------------
| approxkl           | 0.009631126  |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.25e+03     |
| explained_variance | 0.00513      |
| fps                | 34           |
| n_updates          | 56           |
| policy_entropy     | 1.4744697    |
| policy_loss        | 0.0029922354 |
| serial_timesteps   | 7168         |
| time_elapsed       | 211          |
| total_timesteps    | 7168         |
| value_loss         | 48.02041     |
-------------------------------------
--------------------------------------
| approxkl           | 1.709019e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | 0.00118       |
| fps                | 34            |
| n_updates          | 57            |
| policy_entropy     | 1.4742423     |
| policy_loss        | 0.00014249608 |
| serial_timesteps   | 7296          |
| time_elapsed       | 215           |
| total_timesteps    | 7296          |
| value_loss         | 47.78573      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00048023593 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | 0.0018        |
| fps                | 32            |
| n_updates          | 58            |
| policy_entropy     | 1.4738486     |
| policy_loss        | -0.0013032113 |
| serial_timesteps   | 7424          |
| time_elapsed       | 219           |
| total_timesteps    | 7424          |
| value_loss         | 117.66687     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0050963433  |
| clipfrac           | 0.072265625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | 0.00225       |
| fps                | 33            |
| n_updates          | 59            |
| policy_entropy     | 1.4738412     |
| policy_loss        | -0.0051858313 |
| serial_timesteps   | 7552          |
| time_elapsed       | 222           |
| total_timesteps    | 7552          |
| value_loss         | 99.629875     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00037767997 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.25e+03      |
| explained_variance | -0.0052       |
| fps                | 34            |
| n_updates          | 60            |
| policy_entropy     | 1.4729923     |
| policy_loss        | 0.0025432091  |
| serial_timesteps   | 7680          |
| time_elapsed       | 226           |
| total_timesteps    | 7680          |
| value_loss         | 54.22047      |
--------------------------------------
--------------------------------------
| approxkl           | 3.0247425e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.000607     |
| fps                | 35            |
| n_updates          | 61            |
| policy_entropy     | 1.4728099     |
| policy_loss        | 0.00014032121 |
| serial_timesteps   | 7808          |
| time_elapsed       | 230           |
| total_timesteps    | 7808          |
| value_loss         | 161.99469     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0013307973  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.0195       |
| fps                | 37            |
| n_updates          | 62            |
| policy_entropy     | 1.4738208     |
| policy_loss        | -0.0050808415 |
| serial_timesteps   | 7936          |
| time_elapsed       | 234           |
| total_timesteps    | 7936          |
| value_loss         | 28.816072     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00035002996 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.000607     |
| fps                | 36            |
| n_updates          | 63            |
| policy_entropy     | 1.4743091     |
| policy_loss        | -0.0015653025 |
| serial_timesteps   | 8064          |
| time_elapsed       | 237           |
| total_timesteps    | 8064          |
| value_loss         | 18.442446     |
--------------------------------------
An average of 44.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1177.22
--------------------------------------
| approxkl           | 0.0013050572  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.00074      |
| fps                | 31            |
| n_updates          | 64            |
| policy_entropy     | 1.4743843     |
| policy_loss        | -0.0035582941 |
| serial_timesteps   | 8192          |
| time_elapsed       | 241           |
| total_timesteps    | 8192          |
| value_loss         | 73.59547      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00014337443 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.000389      |
| fps                | 33            |
| n_updates          | 65            |
| policy_entropy     | 1.4743834     |
| policy_loss        | -0.001069678  |
| serial_timesteps   | 8320          |
| time_elapsed       | 245           |
| total_timesteps    | 8320          |
| value_loss         | 202.15059     |
--------------------------------------
--------------------------------------
| approxkl           | 0.001034513   |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.00185      |
| fps                | 36            |
| n_updates          | 66            |
| policy_entropy     | 1.4738424     |
| policy_loss        | -0.0027643994 |
| serial_timesteps   | 8448          |
| time_elapsed       | 249           |
| total_timesteps    | 8448          |
| value_loss         | 72.415054     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0018804072   |
| clipfrac           | 0.00390625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.18e+03       |
| explained_variance | -0.00164       |
| fps                | 34             |
| n_updates          | 67             |
| policy_entropy     | 1.4737064      |
| policy_loss        | -0.00034444104 |
| serial_timesteps   | 8576           |
| time_elapsed       | 252            |
| total_timesteps    | 8576           |
| value_loss         | 174.32692      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0008435083 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.18e+03     |
| explained_variance | -0.00618     |
| fps                | 36           |
| n_updates          | 68           |
| policy_entropy     | 1.4735421    |
| policy_loss        | -0.003222176 |
| serial_timesteps   | 8704         |
| time_elapsed       | 256          |
| total_timesteps    | 8704         |
| value_loss         | 50.07643     |
-------------------------------------
------------------------------------
| approxkl           | 0.001351662 |
| clipfrac           | 0.017578125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 1.18e+03    |
| explained_variance | 0.00419     |
| fps                | 35          |
| n_updates          | 69          |
| policy_entropy     | 1.4730067   |
| policy_loss        | -0.00579449 |
| serial_timesteps   | 8832        |
| time_elapsed       | 259         |
| total_timesteps    | 8832        |
| value_loss         | 27.596401   |
------------------------------------
--------------------------------------
| approxkl           | 0.0009916249  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.00237       |
| fps                | 35            |
| n_updates          | 70            |
| policy_entropy     | 1.4722058     |
| policy_loss        | -0.0008781359 |
| serial_timesteps   | 8960          |
| time_elapsed       | 263           |
| total_timesteps    | 8960          |
| value_loss         | 65.64772      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0029266165 |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.18e+03     |
| explained_variance | 0.00695      |
| fps                | 36           |
| n_updates          | 71           |
| policy_entropy     | 1.4718634    |
| policy_loss        | -0.003967708 |
| serial_timesteps   | 9088         |
| time_elapsed       | 267          |
| total_timesteps    | 9088         |
| value_loss         | 45.46707     |
-------------------------------------
An average of 44.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1177.22
--------------------------------------
| approxkl           | 0.012526712   |
| clipfrac           | 0.19335938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.00419       |
| fps                | 33            |
| n_updates          | 72            |
| policy_entropy     | 1.4704396     |
| policy_loss        | -0.0017500443 |
| serial_timesteps   | 9216          |
| time_elapsed       | 270           |
| total_timesteps    | 9216          |
| value_loss         | 35.37536      |
--------------------------------------
--------------------------------------
| approxkl           | 0.000783764   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.0125        |
| fps                | 31            |
| n_updates          | 73            |
| policy_entropy     | 1.4673787     |
| policy_loss        | -0.0021169847 |
| serial_timesteps   | 9344          |
| time_elapsed       | 274           |
| total_timesteps    | 9344          |
| value_loss         | 162.7164      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006862312  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.00287       |
| fps                | 36            |
| n_updates          | 74            |
| policy_entropy     | 1.4664108     |
| policy_loss        | -0.0023326688 |
| serial_timesteps   | 9472          |
| time_elapsed       | 278           |
| total_timesteps    | 9472          |
| value_loss         | 40.536255     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0005590691 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.2e+03      |
| explained_variance | 0.00957      |
| fps                | 34           |
| n_updates          | 75           |
| policy_entropy     | 1.4663637    |
| policy_loss        | 0.00662384   |
| serial_timesteps   | 9600         |
| time_elapsed       | 282          |
| total_timesteps    | 9600         |
| value_loss         | 40.940956    |
-------------------------------------
--------------------------------------
| approxkl           | 5.8198468e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.00739       |
| fps                | 31            |
| n_updates          | 76            |
| policy_entropy     | 1.4665105     |
| policy_loss        | -0.0004982379 |
| serial_timesteps   | 9728          |
| time_elapsed       | 285           |
| total_timesteps    | 9728          |
| value_loss         | 219.90942     |
--------------------------------------
--------------------------------------
| approxkl           | 3.2377136e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | 0.00528       |
| fps                | 34            |
| n_updates          | 77            |
| policy_entropy     | 1.4665648     |
| policy_loss        | 0.00010911934 |
| serial_timesteps   | 9856          |
| time_elapsed       | 289           |
| total_timesteps    | 9856          |
| value_loss         | 61.04136      |
--------------------------------------
---------------------------------------
| approxkl           | 8.252068e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.2e+03        |
| explained_variance | -0.00662       |
| fps                | 30             |
| n_updates          | 78             |
| policy_entropy     | 1.4666897      |
| policy_loss        | -0.00012097333 |
| serial_timesteps   | 9984           |
| time_elapsed       | 293            |
| total_timesteps    | 9984           |
| value_loss         | 33.217823      |
---------------------------------------
An average of 45.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1244.07
---------------------------------------
| approxkl           | 4.3583732e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.2e+03        |
| explained_variance | -0.0194        |
| fps                | 33             |
| n_updates          | 79             |
| policy_entropy     | 1.4668307      |
| policy_loss        | -0.00054085156 |
| serial_timesteps   | 10112          |
| time_elapsed       | 297            |
| total_timesteps    | 10112          |
| value_loss         | 45.28228       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00060305797 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.0122       |
| fps                | 36            |
| n_updates          | 80            |
| policy_entropy     | 1.4670224     |
| policy_loss        | 0.0006281348  |
| serial_timesteps   | 10240         |
| time_elapsed       | 301           |
| total_timesteps    | 10240         |
| value_loss         | 32.97         |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005421017  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.00196      |
| fps                | 35            |
| n_updates          | 81            |
| policy_entropy     | 1.4669762     |
| policy_loss        | -0.0006875198 |
| serial_timesteps   | 10368         |
| time_elapsed       | 304           |
| total_timesteps    | 10368         |
| value_loss         | 59.95804      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00038776654 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.2e+03       |
| explained_variance | -0.0059       |
| fps                | 36            |
| n_updates          | 82            |
| policy_entropy     | 1.4668398     |
| policy_loss        | -0.00288494   |
| serial_timesteps   | 10496         |
| time_elapsed       | 308           |
| total_timesteps    | 10496         |
| value_loss         | 155.241       |
--------------------------------------
------------------------------------
| approxkl           | 0.004296293 |
| clipfrac           | 0.0390625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 1.2e+03     |
| explained_variance | 0.00322     |
| fps                | 37          |
| n_updates          | 83          |
| policy_entropy     | 1.466265    |
| policy_loss        | -0.01142245 |
| serial_timesteps   | 10624       |
| time_elapsed       | 312         |
| total_timesteps    | 10624       |
| value_loss         | 142.74606   |
------------------------------------
-------------------------------------
| approxkl           | 8.48416e-05  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.2e+03      |
| explained_variance | -0.00309     |
| fps                | 36           |
| n_updates          | 84           |
| policy_entropy     | 1.4659678    |
| policy_loss        | 0.0012497425 |
| serial_timesteps   | 10752        |
| time_elapsed       | 315          |
| total_timesteps    | 10752        |
| value_loss         | 91.64656     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0011420625  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.000116      |
| fps                | 34            |
| n_updates          | 85            |
| policy_entropy     | 1.4658513     |
| policy_loss        | -0.0047140787 |
| serial_timesteps   | 10880         |
| time_elapsed       | 319           |
| total_timesteps    | 10880         |
| value_loss         | 102.68445     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00027928397  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.18e+03       |
| explained_variance | -0.00199       |
| fps                | 35             |
| n_updates          | 86             |
| policy_entropy     | 1.4655855      |
| policy_loss        | -0.00073484227 |
| serial_timesteps   | 11008          |
| time_elapsed       | 322            |
| total_timesteps    | 11008          |
| value_loss         | 174.6268       |
---------------------------------------
An average of 46.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1178.53
---------------------------------------
| approxkl           | 3.3268643e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.18e+03       |
| explained_variance | 0.0022         |
| fps                | 35             |
| n_updates          | 87             |
| policy_entropy     | 1.4654152      |
| policy_loss        | -0.00050002337 |
| serial_timesteps   | 11136          |
| time_elapsed       | 326            |
| total_timesteps    | 11136          |
| value_loss         | 52.061817      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0007806805  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.00891       |
| fps                | 35            |
| n_updates          | 88            |
| policy_entropy     | 1.4656392     |
| policy_loss        | -0.0004737376 |
| serial_timesteps   | 11264         |
| time_elapsed       | 330           |
| total_timesteps    | 11264         |
| value_loss         | 67.71566      |
--------------------------------------
---------------------------------------
| approxkl           | 1.2096061e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.18e+03       |
| explained_variance | 0.00697        |
| fps                | 29             |
| n_updates          | 89             |
| policy_entropy     | 1.4656367      |
| policy_loss        | -3.8718572e-05 |
| serial_timesteps   | 11392          |
| time_elapsed       | 333            |
| total_timesteps    | 11392          |
| value_loss         | 27.02354       |
---------------------------------------
--------------------------------------
| approxkl           | 7.432558e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.016         |
| fps                | 39            |
| n_updates          | 90            |
| policy_entropy     | 1.465512      |
| policy_loss        | -0.0006629854 |
| serial_timesteps   | 11520         |
| time_elapsed       | 337           |
| total_timesteps    | 11520         |
| value_loss         | 33.36408      |
--------------------------------------
--------------------------------------
| approxkl           | 6.862117e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.000587     |
| fps                | 34            |
| n_updates          | 91            |
| policy_entropy     | 1.4655269     |
| policy_loss        | -0.0008338384 |
| serial_timesteps   | 11648         |
| time_elapsed       | 341           |
| total_timesteps    | 11648         |
| value_loss         | 50.906456     |
--------------------------------------
-------------------------------------
| approxkl           | 0.001589875  |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.18e+03     |
| explained_variance | 0.00219      |
| fps                | 33           |
| n_updates          | 92           |
| policy_entropy     | 1.4661005    |
| policy_loss        | 0.0012073892 |
| serial_timesteps   | 11776        |
| time_elapsed       | 344          |
| total_timesteps    | 11776        |
| value_loss         | 68.06034     |
-------------------------------------
-------------------------------------
| approxkl           | 0.002620505  |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.18e+03     |
| explained_variance | 0.00472      |
| fps                | 36           |
| n_updates          | 93           |
| policy_entropy     | 1.4666718    |
| policy_loss        | 0.0019226873 |
| serial_timesteps   | 11904        |
| time_elapsed       | 348          |
| total_timesteps    | 11904        |
| value_loss         | 260.09665    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0001590049  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.0126        |
| fps                | 30            |
| n_updates          | 94            |
| policy_entropy     | 1.4668907     |
| policy_loss        | -0.0013655438 |
| serial_timesteps   | 12032         |
| time_elapsed       | 352           |
| total_timesteps    | 12032         |
| value_loss         | 58.500237     |
--------------------------------------
An average of 46.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1178.53
--------------------------------------
| approxkl           | 1.4232435e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | 0.00873       |
| fps                | 36            |
| n_updates          | 95            |
| policy_entropy     | 1.4669782     |
| policy_loss        | 0.00031165173 |
| serial_timesteps   | 12160         |
| time_elapsed       | 356           |
| total_timesteps    | 12160         |
| value_loss         | 41.925636     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00077576324 |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.18e+03      |
| explained_variance | -0.028        |
| fps                | 35            |
| n_updates          | 96            |
| policy_entropy     | 1.4674219     |
| policy_loss        | -0.0008301056 |
| serial_timesteps   | 12288         |
| time_elapsed       | 359           |
| total_timesteps    | 12288         |
| value_loss         | 35.898117     |
--------------------------------------
-------------------------------------
| approxkl           | 0.003616307  |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.16e+03     |
| explained_variance | -0.000641    |
| fps                | 38           |
| n_updates          | 97           |
| policy_entropy     | 1.4680226    |
| policy_loss        | -0.007714764 |
| serial_timesteps   | 12416        |
| time_elapsed       | 363          |
| total_timesteps    | 12416        |
| value_loss         | 89.49897     |
-------------------------------------
------------------------------------
| approxkl           | 0.009154491 |
| clipfrac           | 0.12890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 1.16e+03    |
| explained_variance | 0.00453     |
| fps                | 33          |
| n_updates          | 98          |
| policy_entropy     | 1.4683504   |
| policy_loss        | -0.00804493 |
| serial_timesteps   | 12544       |
| time_elapsed       | 366         |
| total_timesteps    | 12544       |
| value_loss         | 39.23458    |
------------------------------------
--------------------------------------
| approxkl           | 6.190944e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.16e+03      |
| explained_variance | -0.00491      |
| fps                | 33            |
| n_updates          | 99            |
| policy_entropy     | 1.4678886     |
| policy_loss        | -6.386073e-05 |
| serial_timesteps   | 12672         |
| time_elapsed       | 370           |
| total_timesteps    | 12672         |
| value_loss         | 83.24741      |
--------------------------------------
--------------------------------------
| approxkl           | 2.0156314e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.16e+03      |
| explained_variance | 0.00463       |
| fps                | 36            |
| n_updates          | 100           |
| policy_entropy     | 1.4678229     |
| policy_loss        | -0.000438069  |
| serial_timesteps   | 12800         |
| time_elapsed       | 374           |
| total_timesteps    | 12800         |
| value_loss         | 186.7668      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0013342381 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.16e+03     |
| explained_variance | -0.000973    |
| fps                | 35           |
| n_updates          | 101          |
| policy_entropy     | 1.4700073    |
| policy_loss        | 0.007253133  |
| serial_timesteps   | 12928        |
| time_elapsed       | 377          |
| total_timesteps    | 12928        |
| value_loss         | 92.600555    |
-------------------------------------
---------------------------------------
| approxkl           | 0.000108922526 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.16e+03       |
| explained_variance | 0.00609        |
| fps                | 34             |
| n_updates          | 102            |
| policy_entropy     | 1.471113       |
| policy_loss        | -0.0016774805  |
| serial_timesteps   | 13056          |
| time_elapsed       | 381            |
| total_timesteps    | 13056          |
| value_loss         | 99.77106       |
---------------------------------------
An average of 47.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1080.74
-------------------------------------
| approxkl           | 0.0015473124 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.16e+03     |
| explained_variance | -0.00453     |
| fps                | 34           |
| n_updates          | 103          |
| policy_entropy     | 1.4715757    |
| policy_loss        | -0.001991672 |
| serial_timesteps   | 13184        |
| time_elapsed       | 385          |
| total_timesteps    | 13184        |
| value_loss         | 67.44199     |
-------------------------------------
---------------------------------------
| approxkl           | 2.9851062e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.16e+03       |
| explained_variance | 0.000638       |
| fps                | 36             |
| n_updates          | 104            |
| policy_entropy     | 1.4718428      |
| policy_loss        | -0.00024464715 |
| serial_timesteps   | 13312          |
| time_elapsed       | 388            |
| total_timesteps    | 13312          |
| value_loss         | 91.51043       |
---------------------------------------
--------------------------------------
| approxkl           | 0.003159237   |
| clipfrac           | 0.029296875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.16e+03      |
| explained_variance | 0.00753       |
| fps                | 34            |
| n_updates          | 105           |
| policy_entropy     | 1.4713261     |
| policy_loss        | -0.0035061324 |
| serial_timesteps   | 13440         |
| time_elapsed       | 392           |
| total_timesteps    | 13440         |
| value_loss         | 67.51883      |
--------------------------------------
---------------------------------------
| approxkl           | 0.00064865453  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.16e+03       |
| explained_variance | 0.0058         |
| fps                | 34             |
| n_updates          | 106            |
| policy_entropy     | 1.4710248      |
| policy_loss        | -0.00042128982 |
| serial_timesteps   | 13568          |
| time_elapsed       | 396            |
| total_timesteps    | 13568          |
| value_loss         | 51.987865      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00030107156 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.16e+03      |
| explained_variance | 0.0086        |
| fps                | 34            |
| n_updates          | 107           |
| policy_entropy     | 1.4705471     |
| policy_loss        | -0.0025885862 |
| serial_timesteps   | 13696         |
| time_elapsed       | 399           |
| total_timesteps    | 13696         |
| value_loss         | 30.993412     |
--------------------------------------
-------------------------------------
| approxkl           | 0.00156788   |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.16e+03     |
| explained_variance | 0.00275      |
| fps                | 34           |
| n_updates          | 108          |
| policy_entropy     | 1.4693825    |
| policy_loss        | -0.010719466 |
| serial_timesteps   | 13824        |
| time_elapsed       | 403          |
| total_timesteps    | 13824        |
| value_loss         | 60.715164    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0002103032 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.19e+03     |
| explained_variance | -0.00154     |
| fps                | 33           |
| n_updates          | 109          |
| policy_entropy     | 1.4691497    |
| policy_loss        | 0.0011617414 |
| serial_timesteps   | 13952        |
| time_elapsed       | 407          |
| total_timesteps    | 13952        |
| value_loss         | 201.86227    |
-------------------------------------
--------------------------------------
| approxkl           | 2.5725421e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.19e+03      |
| explained_variance | 0.00191       |
| fps                | 35            |
| n_updates          | 110           |
| policy_entropy     | 1.4694626     |
| policy_loss        | 9.201141e-05  |
| serial_timesteps   | 14080         |
| time_elapsed       | 411           |
| total_timesteps    | 14080         |
| value_loss         | 215.46739     |
--------------------------------------
An average of 48.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1137.26
---------------------------------------
| approxkl           | 9.874893e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.19e+03       |
| explained_variance | 0.00388        |
| fps                | 35             |
| n_updates          | 111            |
| policy_entropy     | 1.4699082      |
| policy_loss        | -0.00041060697 |
| serial_timesteps   | 14208          |
| time_elapsed       | 414            |
| total_timesteps    | 14208          |
| value_loss         | 23.279408      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0014652282  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.19e+03      |
| explained_variance | -0.00628      |
| fps                | 34            |
| n_updates          | 112           |
| policy_entropy     | 1.4703507     |
| policy_loss        | -0.0012369103 |
| serial_timesteps   | 14336         |
| time_elapsed       | 418           |
| total_timesteps    | 14336         |
| value_loss         | 46.375923     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00067608035 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.19e+03      |
| explained_variance | -0.00946      |
| fps                | 38            |
| n_updates          | 113           |
| policy_entropy     | 1.469987      |
| policy_loss        | 0.0014922727  |
| serial_timesteps   | 14464         |
| time_elapsed       | 421           |
| total_timesteps    | 14464         |
| value_loss         | 55.95141      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017807717 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.19e+03      |
| explained_variance | -0.00234      |
| fps                | 34            |
| n_updates          | 114           |
| policy_entropy     | 1.4698775     |
| policy_loss        | -0.003409749  |
| serial_timesteps   | 14592         |
| time_elapsed       | 425           |
| total_timesteps    | 14592         |
| value_loss         | 231.52234     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011332603  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.19e+03     |
| explained_variance | -0.000778    |
| fps                | 35           |
| n_updates          | 115          |
| policy_entropy     | 1.4693799    |
| policy_loss        | -0.013862773 |
| serial_timesteps   | 14720        |
| time_elapsed       | 429          |
| total_timesteps    | 14720        |
| value_loss         | 22.632875    |
-------------------------------------
--------------------------------------
| approxkl           | 4.7707534e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.19e+03      |
| explained_variance | 0.00367       |
| fps                | 37            |
| n_updates          | 116           |
| policy_entropy     | 1.4690393     |
| policy_loss        | -0.0005127407 |
| serial_timesteps   | 14848         |
| time_elapsed       | 432           |
| total_timesteps    | 14848         |
| value_loss         | 73.99461      |
--------------------------------------
--------------------------------------
| approxkl           | 6.248216e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.19e+03      |
| explained_variance | 0.000315      |
| fps                | 34            |
| n_updates          | 117           |
| policy_entropy     | 1.4689064     |
| policy_loss        | -0.0001629463 |
| serial_timesteps   | 14976         |
| time_elapsed       | 436           |
| total_timesteps    | 14976         |
| value_loss         | 156.48105     |
--------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b8436f7f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b8436f7f0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b842f4b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b842f4b38>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2747 samples, validate on 87 samples
Epoch 119/5000
 - 2s - loss: 0.0226 - val_loss: 0.0376
Epoch 120/5000
 - 0s - loss: 0.0181 - val_loss: 0.0186
Epoch 121/5000
 - 0s - loss: 0.0099 - val_loss: 0.0045
Epoch 122/5000
 - 0s - loss: 0.0057 - val_loss: 0.0019
Epoch 123/5000
 - 0s - loss: 0.0052 - val_loss: 0.0016
Epoch 124/5000
 - 0s - loss: 0.0050 - val_loss: 0.0012
Epoch 125/5000
 - 0s - loss: 0.0049 - val_loss: 0.0012
Epoch 126/5000
 - 0s - loss: 0.0046 - val_loss: 0.0013
Epoch 127/5000
 - 0s - loss: 0.0040 - val_loss: 0.0019
Epoch 128/5000
 - 0s - loss: 0.0040 - val_loss: 0.0017
Epoch 129/5000
 - 0s - loss: 0.0040 - val_loss: 0.0016
Train on 1913 samples, validate on 87 samples
Epoch 117/5000
 - 2s - loss: 0.0262 - val_loss: 0.0048
Epoch 118/5000
 - 0s - loss: 0.0262 - val_loss: 0.0048
Epoch 119/5000
 - 0s - loss: 0.0262 - val_loss: 0.0048
Epoch 120/5000
 - 0s - loss: 0.0262 - val_loss: 0.0048
Epoch 121/5000
 - 0s - loss: 0.0262 - val_loss: 0.0048
Epoch 122/5000
 - 0s - loss: 0.0262 - val_loss: 0.0048
Train on 2748 samples, validate on 87 samples
Epoch 108/5000
 - 3s - loss: 0.6754 - val_loss: 0.5831
Epoch 109/5000
 - 1s - loss: 0.6271 - val_loss: 0.4092
Epoch 110/5000
 - 1s - loss: 0.6139 - val_loss: 0.3422
Epoch 111/5000
 - 1s - loss: 0.6162 - val_loss: 0.3314
Epoch 112/5000
 - 1s - loss: 0.6151 - val_loss: 0.3285
Epoch 113/5000
 - 1s - loss: 0.6133 - val_loss: 0.3262
Epoch 114/5000
 - 1s - loss: 0.6111 - val_loss: 0.3236
Epoch 115/5000
 - 1s - loss: 0.6084 - val_loss: 0.3205
Epoch 116/5000
 - 1s - loss: 0.6050 - val_loss: 0.3169
Epoch 117/5000
 - 1s - loss: 0.6006 - val_loss: 0.3132
Epoch 118/5000
 - 1s - loss: 0.5951 - val_loss: 0.3102
Epoch 119/5000
 - 1s - loss: 0.5882 - val_loss: 0.3087
Epoch 120/5000
 - 1s - loss: 0.5797 - val_loss: 0.3097
Epoch 121/5000
 - 1s - loss: 0.5695 - val_loss: 0.3150
Epoch 122/5000
 - 1s - loss: 0.5550 - val_loss: 0.3352
Epoch 123/5000
 - 1s - loss: 0.5503 - val_loss: 0.3498
Epoch 124/5000
 - 1s - loss: 0.5472 - val_loss: 0.3605
setting environment to train mode..... 

Training Started... 

An average of 49.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 889.31
---------------------------------------
| approxkl           | 3.812859e-05   |
| clipfrac           | 0.0            |
| explained_variance | 0.00112        |
| fps                | 11             |
| n_updates          | 1              |
| policy_entropy     | 1.4691161      |
| policy_loss        | -0.00039194582 |
| serial_timesteps   | 128            |
| time_elapsed       | 1.22e-05       |
| total_timesteps    | 128            |
| value_loss         | 56.28817       |
---------------------------------------
---------------------------------------
| approxkl           | 1.2035568e-05  |
| clipfrac           | 0.0            |
| explained_variance | -0.0117        |
| fps                | 33             |
| n_updates          | 2              |
| policy_entropy     | 1.4694922      |
| policy_loss        | -0.00022233697 |
| serial_timesteps   | 256            |
| time_elapsed       | 11             |
| total_timesteps    | 256            |
| value_loss         | 70.52353       |
---------------------------------------
-------------------------------------
| approxkl           | 0.012447772  |
| clipfrac           | 0.1640625    |
| explained_variance | -0.00183     |
| fps                | 33           |
| n_updates          | 3            |
| policy_entropy     | 1.4693831    |
| policy_loss        | -0.019194022 |
| serial_timesteps   | 384          |
| time_elapsed       | 14.8         |
| total_timesteps    | 384          |
| value_loss         | 38.521877    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00015226551 |
| clipfrac           | 0.0           |
| explained_variance | -0.00108      |
| fps                | 33            |
| n_updates          | 4             |
| policy_entropy     | 1.4691886     |
| policy_loss        | 0.002674952   |
| serial_timesteps   | 512           |
| time_elapsed       | 18.6          |
| total_timesteps    | 512           |
| value_loss         | 65.025085     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0025721835 |
| clipfrac           | 0.021484375  |
| explained_variance | 0.00224      |
| fps                | 36           |
| n_updates          | 5            |
| policy_entropy     | 1.4689351    |
| policy_loss        | -0.013160763 |
| serial_timesteps   | 640          |
| time_elapsed       | 22.4         |
| total_timesteps    | 640          |
| value_loss         | 19.721222    |
-------------------------------------
--------------------------------------
| approxkl           | 0.003400095   |
| clipfrac           | 0.037109375   |
| explained_variance | 0.00028       |
| fps                | 33            |
| n_updates          | 6             |
| policy_entropy     | 1.4683025     |
| policy_loss        | -0.0018343008 |
| serial_timesteps   | 768           |
| time_elapsed       | 25.9          |
| total_timesteps    | 768           |
| value_loss         | 244.27896     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017087173 |
| clipfrac           | 0.0           |
| explained_variance | 0.00386       |
| fps                | 37            |
| n_updates          | 7             |
| policy_entropy     | 1.4679369     |
| policy_loss        | -0.0008633997 |
| serial_timesteps   | 896           |
| time_elapsed       | 29.7          |
| total_timesteps    | 896           |
| value_loss         | 121.112274    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0011114015  |
| clipfrac           | 0.001953125   |
| explained_variance | 0.00223       |
| fps                | 35            |
| n_updates          | 8             |
| policy_entropy     | 1.4685476     |
| policy_loss        | -0.0010394283 |
| serial_timesteps   | 1024          |
| time_elapsed       | 33.1          |
| total_timesteps    | 1024          |
| value_loss         | 89.748085     |
--------------------------------------
An average of 49.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 889.31
-------------------------------------
| approxkl           | 0.0001817927 |
| clipfrac           | 0.0          |
| explained_variance | 0.000856     |
| fps                | 32           |
| n_updates          | 9            |
| policy_entropy     | 1.4696691    |
| policy_loss        | 0.0005834233 |
| serial_timesteps   | 1152         |
| time_elapsed       | 36.7         |
| total_timesteps    | 1152         |
| value_loss         | 241.9161     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00032375366 |
| clipfrac           | 0.0           |
| explained_variance | 0.00784       |
| fps                | 35            |
| n_updates          | 10            |
| policy_entropy     | 1.4706006     |
| policy_loss        | 0.0021877282  |
| serial_timesteps   | 1280          |
| time_elapsed       | 40.7          |
| total_timesteps    | 1280          |
| value_loss         | 14.2093115    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0003863134  |
| clipfrac           | 0.0           |
| explained_variance | -0.0116       |
| fps                | 34            |
| n_updates          | 11            |
| policy_entropy     | 1.4722428     |
| policy_loss        | 0.00044242048 |
| serial_timesteps   | 1408          |
| time_elapsed       | 44.3          |
| total_timesteps    | 1408          |
| value_loss         | 38.632523     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0043017557  |
| clipfrac           | 0.056640625   |
| explained_variance | 0.011         |
| fps                | 33            |
| n_updates          | 12            |
| policy_entropy     | 1.4719689     |
| policy_loss        | -0.0046237614 |
| serial_timesteps   | 1536          |
| time_elapsed       | 48            |
| total_timesteps    | 1536          |
| value_loss         | 24.282578     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018158543 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 991           |
| explained_variance | 0.00607       |
| fps                | 33            |
| n_updates          | 13            |
| policy_entropy     | 1.469876      |
| policy_loss        | 0.00054701546 |
| serial_timesteps   | 1664          |
| time_elapsed       | 51.9          |
| total_timesteps    | 1664          |
| value_loss         | 210.61954     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0002482508   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 991            |
| explained_variance | 0.0105         |
| fps                | 35             |
| n_updates          | 14             |
| policy_entropy     | 1.4695061      |
| policy_loss        | -0.00080715446 |
| serial_timesteps   | 1792           |
| time_elapsed       | 55.7           |
| total_timesteps    | 1792           |
| value_loss         | 87.08851       |
---------------------------------------
-------------------------------------
| approxkl           | 0.012643675  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | 0.0131       |
| fps                | 32           |
| n_updates          | 15           |
| policy_entropy     | 1.4695513    |
| policy_loss        | -0.016525244 |
| serial_timesteps   | 1920         |
| time_elapsed       | 59.3         |
| total_timesteps    | 1920         |
| value_loss         | 44.14136     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00060510705 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 991           |
| explained_variance | -0.00356      |
| fps                | 34            |
| n_updates          | 16            |
| policy_entropy     | 1.4693408     |
| policy_loss        | -0.004313742  |
| serial_timesteps   | 2048          |
| time_elapsed       | 63.2          |
| total_timesteps    | 2048          |
| value_loss         | 215.7925      |
--------------------------------------
An average of 50.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 829.68
-------------------------------------
| approxkl           | 0.0045593604 |
| clipfrac           | 0.044921875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | 0.0115       |
| fps                | 34           |
| n_updates          | 17           |
| policy_entropy     | 1.4692777    |
| policy_loss        | 0.0019161606 |
| serial_timesteps   | 2176         |
| time_elapsed       | 66.9         |
| total_timesteps    | 2176         |
| value_loss         | 70.381       |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016458842 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | 0.102        |
| fps                | 30           |
| n_updates          | 18           |
| policy_entropy     | 1.4699157    |
| policy_loss        | -0.011645852 |
| serial_timesteps   | 2304         |
| time_elapsed       | 70.7         |
| total_timesteps    | 2304         |
| value_loss         | 40.587234    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0064113317 |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | -0.00721     |
| fps                | 33           |
| n_updates          | 19           |
| policy_entropy     | 1.4704012    |
| policy_loss        | -0.00674621  |
| serial_timesteps   | 2432         |
| time_elapsed       | 74.9         |
| total_timesteps    | 2432         |
| value_loss         | 69.67873     |
-------------------------------------
--------------------------------------
| approxkl           | 4.5539342e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 991           |
| explained_variance | -0.0111       |
| fps                | 32            |
| n_updates          | 20            |
| policy_entropy     | 1.4704192     |
| policy_loss        | -0.0008573503 |
| serial_timesteps   | 2560          |
| time_elapsed       | 78.7          |
| total_timesteps    | 2560          |
| value_loss         | 362.8531      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00049406383 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 991           |
| explained_variance | -0.000889     |
| fps                | 35            |
| n_updates          | 21            |
| policy_entropy     | 1.4704729     |
| policy_loss        | -0.0051105404 |
| serial_timesteps   | 2688          |
| time_elapsed       | 82.7          |
| total_timesteps    | 2688          |
| value_loss         | 58.9647       |
--------------------------------------
-------------------------------------
| approxkl           | 0.004488566  |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | -0.00742     |
| fps                | 33           |
| n_updates          | 22           |
| policy_entropy     | 1.4707379    |
| policy_loss        | -0.014968136 |
| serial_timesteps   | 2816         |
| time_elapsed       | 86.3         |
| total_timesteps    | 2816         |
| value_loss         | 42.845295    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0008973639 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | 0.00602      |
| fps                | 33           |
| n_updates          | 23           |
| policy_entropy     | 1.4705153    |
| policy_loss        | 8.571218e-05 |
| serial_timesteps   | 2944         |
| time_elapsed       | 90.1         |
| total_timesteps    | 2944         |
| value_loss         | 352.7285     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0029117593 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 991          |
| explained_variance | 0.0184       |
| fps                | 30           |
| n_updates          | 24           |
| policy_entropy     | 1.468274     |
| policy_loss        | -0.004178546 |
| serial_timesteps   | 3072         |
| time_elapsed       | 93.9         |
| total_timesteps    | 3072         |
| value_loss         | 72.208305    |
-------------------------------------
An average of 51.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 904.00
--------------------------------------
| approxkl           | 0.00036428438 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | 0.00262       |
| fps                | 32            |
| n_updates          | 25            |
| policy_entropy     | 1.4663662     |
| policy_loss        | 0.0007327278  |
| serial_timesteps   | 3200          |
| time_elapsed       | 98.2          |
| total_timesteps    | 3200          |
| value_loss         | 433.5138      |
--------------------------------------
---------------------------------------
| approxkl           | 0.00013118658  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.24e+03       |
| explained_variance | -0.0104        |
| fps                | 32             |
| n_updates          | 26             |
| policy_entropy     | 1.4658735      |
| policy_loss        | -0.00018377102 |
| serial_timesteps   | 3328           |
| time_elapsed       | 102            |
| total_timesteps    | 3328           |
| value_loss         | 115.02394      |
---------------------------------------
--------------------------------------
| approxkl           | 9.007621e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | -0.0117       |
| fps                | 34            |
| n_updates          | 27            |
| policy_entropy     | 1.4663842     |
| policy_loss        | -0.0008722696 |
| serial_timesteps   | 3456          |
| time_elapsed       | 106           |
| total_timesteps    | 3456          |
| value_loss         | 83.06084      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0015756139  |
| clipfrac           | 0.01171875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | -0.0158       |
| fps                | 33            |
| n_updates          | 28            |
| policy_entropy     | 1.4669399     |
| policy_loss        | -0.0012928064 |
| serial_timesteps   | 3584          |
| time_elapsed       | 110           |
| total_timesteps    | 3584          |
| value_loss         | 48.9849       |
--------------------------------------
-------------------------------------
| approxkl           | 0.0047283377 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.24e+03     |
| explained_variance | 0.0138       |
| fps                | 31           |
| n_updates          | 29           |
| policy_entropy     | 1.4686083    |
| policy_loss        | -0.011209376 |
| serial_timesteps   | 3712         |
| time_elapsed       | 114          |
| total_timesteps    | 3712         |
| value_loss         | 62.065277    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0006957877  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | -0.0115       |
| fps                | 31            |
| n_updates          | 30            |
| policy_entropy     | 1.4691561     |
| policy_loss        | -0.0072861477 |
| serial_timesteps   | 3840          |
| time_elapsed       | 118           |
| total_timesteps    | 3840          |
| value_loss         | 187.05043     |
--------------------------------------
--------------------------------------
| approxkl           | 0.017468639   |
| clipfrac           | 0.23046875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | 0.0334        |
| fps                | 31            |
| n_updates          | 31            |
| policy_entropy     | 1.4685208     |
| policy_loss        | -0.0018233368 |
| serial_timesteps   | 3968          |
| time_elapsed       | 122           |
| total_timesteps    | 3968          |
| value_loss         | 18.982618     |
--------------------------------------
---------------------------------------
| approxkl           | 5.714419e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.24e+03       |
| explained_variance | 0.00506        |
| fps                | 33             |
| n_updates          | 32             |
| policy_entropy     | 1.4683126      |
| policy_loss        | -5.2860298e-05 |
| serial_timesteps   | 4096           |
| time_elapsed       | 126            |
| total_timesteps    | 4096           |
| value_loss         | 182.59944      |
---------------------------------------
An average of 51.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 904.00
--------------------------------------
| approxkl           | 2.1407239e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | 0.0268        |
| fps                | 35            |
| n_updates          | 33            |
| policy_entropy     | 1.4683152     |
| policy_loss        | -0.0005105593 |
| serial_timesteps   | 4224          |
| time_elapsed       | 130           |
| total_timesteps    | 4224          |
| value_loss         | 241.43704     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0061962283 |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.24e+03     |
| explained_variance | -0.0501      |
| fps                | 31           |
| n_updates          | 34           |
| policy_entropy     | 1.4692966    |
| policy_loss        | -0.00944364  |
| serial_timesteps   | 4352         |
| time_elapsed       | 133          |
| total_timesteps    | 4352         |
| value_loss         | 34.399994    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00040576092 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | -0.0403       |
| fps                | 36            |
| n_updates          | 35            |
| policy_entropy     | 1.4699818     |
| policy_loss        | -0.0014473875 |
| serial_timesteps   | 4480          |
| time_elapsed       | 137           |
| total_timesteps    | 4480          |
| value_loss         | 37.246197     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0019692138  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.24e+03      |
| explained_variance | -0.0108       |
| fps                | 35            |
| n_updates          | 36            |
| policy_entropy     | 1.4697788     |
| policy_loss        | -0.0080307145 |
| serial_timesteps   | 4608          |
| time_elapsed       | 141           |
| total_timesteps    | 4608          |
| value_loss         | 67.73842      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00034860361 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.00421      |
| fps                | 36            |
| n_updates          | 37            |
| policy_entropy     | 1.46969       |
| policy_loss        | -0.0017259492 |
| serial_timesteps   | 4736          |
| time_elapsed       | 144           |
| total_timesteps    | 4736          |
| value_loss         | 135.10133     |
--------------------------------------
--------------------------------------
| approxkl           | 6.7095076e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.00256      |
| fps                | 30            |
| n_updates          | 38            |
| policy_entropy     | 1.4696525     |
| policy_loss        | -0.0006177949 |
| serial_timesteps   | 4864          |
| time_elapsed       | 148           |
| total_timesteps    | 4864          |
| value_loss         | 147.4059      |
--------------------------------------
--------------------------------------
| approxkl           | 6.246566e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.000301     |
| fps                | 30            |
| n_updates          | 39            |
| policy_entropy     | 1.469538      |
| policy_loss        | -0.0005546701 |
| serial_timesteps   | 4992          |
| time_elapsed       | 152           |
| total_timesteps    | 4992          |
| value_loss         | 78.85407      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011871117 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.4e+03      |
| explained_variance | 0.00595      |
| fps                | 32           |
| n_updates          | 40           |
| policy_entropy     | 1.4694782    |
| policy_loss        | 0.007168407  |
| serial_timesteps   | 5120         |
| time_elapsed       | 156          |
| total_timesteps    | 5120         |
| value_loss         | 230.90157    |
-------------------------------------
An average of 52.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1056.17
--------------------------------------
| approxkl           | 0.0007522318  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.017         |
| fps                | 34            |
| n_updates          | 41            |
| policy_entropy     | 1.4693123     |
| policy_loss        | -0.0011906035 |
| serial_timesteps   | 5248          |
| time_elapsed       | 160           |
| total_timesteps    | 5248          |
| value_loss         | 46.94057      |
--------------------------------------
--------------------------------------
| approxkl           | 1.1610169e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.00241       |
| fps                | 33            |
| n_updates          | 42            |
| policy_entropy     | 1.4692541     |
| policy_loss        | 0.00044707558 |
| serial_timesteps   | 5376          |
| time_elapsed       | 164           |
| total_timesteps    | 5376          |
| value_loss         | 137.25594     |
--------------------------------------
--------------------------------------
| approxkl           | 1.1301511e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.01          |
| fps                | 33            |
| n_updates          | 43            |
| policy_entropy     | 1.4693586     |
| policy_loss        | 0.00028966018 |
| serial_timesteps   | 5504          |
| time_elapsed       | 168           |
| total_timesteps    | 5504          |
| value_loss         | 109.95595     |
--------------------------------------
--------------------------------------
| approxkl           | 6.224712e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.00994      |
| fps                | 36            |
| n_updates          | 44            |
| policy_entropy     | 1.4693061     |
| policy_loss        | -0.0009440596 |
| serial_timesteps   | 5632          |
| time_elapsed       | 171           |
| total_timesteps    | 5632          |
| value_loss         | 56.46497      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0065598334 |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.4e+03      |
| explained_variance | 0.00532      |
| fps                | 32           |
| n_updates          | 45           |
| policy_entropy     | 1.4695107    |
| policy_loss        | -0.01071744  |
| serial_timesteps   | 5760         |
| time_elapsed       | 175          |
| total_timesteps    | 5760         |
| value_loss         | 11.5223055   |
-------------------------------------
--------------------------------------
| approxkl           | 0.00075321354 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.00501      |
| fps                | 39            |
| n_updates          | 46            |
| policy_entropy     | 1.4705462     |
| policy_loss        | -0.0022576519 |
| serial_timesteps   | 5888          |
| time_elapsed       | 179           |
| total_timesteps    | 5888          |
| value_loss         | 162.92133     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00019670566 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | -0.0503       |
| fps                | 34            |
| n_updates          | 47            |
| policy_entropy     | 1.4707984     |
| policy_loss        | -0.0006951025 |
| serial_timesteps   | 6016          |
| time_elapsed       | 182           |
| total_timesteps    | 6016          |
| value_loss         | 401.48315     |
--------------------------------------
An average of 52.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1056.17
--------------------------------------
| approxkl           | 0.0013614513  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.4e+03       |
| explained_variance | 0.0112        |
| fps                | 32            |
| n_updates          | 48            |
| policy_entropy     | 1.4699382     |
| policy_loss        | -0.0084223505 |
| serial_timesteps   | 6144          |
| time_elapsed       | 186           |
| total_timesteps    | 6144          |
| value_loss         | 120.98555     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00053547684 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | -0.000531     |
| fps                | 36            |
| n_updates          | 49            |
| policy_entropy     | 1.4690965     |
| policy_loss        | 0.0027915996  |
| serial_timesteps   | 6272          |
| time_elapsed       | 190           |
| total_timesteps    | 6272          |
| value_loss         | 531.9731      |
--------------------------------------
---------------------------------------
| approxkl           | 6.477934e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.51e+03       |
| explained_variance | 0.00902        |
| fps                | 36             |
| n_updates          | 50             |
| policy_entropy     | 1.4688265      |
| policy_loss        | -0.00041116902 |
| serial_timesteps   | 6400           |
| time_elapsed       | 193            |
| total_timesteps    | 6400           |
| value_loss         | 72.534386      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00077023695 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | -0.00826      |
| fps                | 33            |
| n_updates          | 51            |
| policy_entropy     | 1.4694655     |
| policy_loss        | -0.009463532  |
| serial_timesteps   | 6528          |
| time_elapsed       | 197           |
| total_timesteps    | 6528          |
| value_loss         | 33.01073      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00063105405 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | -0.00827      |
| fps                | 30            |
| n_updates          | 52            |
| policy_entropy     | 1.4699564     |
| policy_loss        | -0.001360305  |
| serial_timesteps   | 6656          |
| time_elapsed       | 201           |
| total_timesteps    | 6656          |
| value_loss         | 67.55606      |
--------------------------------------
-------------------------------------
| approxkl           | 0.01504861   |
| clipfrac           | 0.2109375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.51e+03     |
| explained_variance | -0.00546     |
| fps                | 32           |
| n_updates          | 53           |
| policy_entropy     | 1.4697088    |
| policy_loss        | -0.018622026 |
| serial_timesteps   | 6784         |
| time_elapsed       | 205          |
| total_timesteps    | 6784         |
| value_loss         | 138.11166    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0003154757   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.51e+03       |
| explained_variance | -0.0251        |
| fps                | 33             |
| n_updates          | 54             |
| policy_entropy     | 1.4695288      |
| policy_loss        | -0.00078331446 |
| serial_timesteps   | 6912           |
| time_elapsed       | 209            |
| total_timesteps    | 6912           |
| value_loss         | 61.001144      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00037345756 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | -0.0141       |
| fps                | 31            |
| n_updates          | 55            |
| policy_entropy     | 1.4696388     |
| policy_loss        | -0.0029987488 |
| serial_timesteps   | 7040          |
| time_elapsed       | 212           |
| total_timesteps    | 7040          |
| value_loss         | 83.55383      |
--------------------------------------
An average of 53.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1140.50
--------------------------------------
| approxkl           | 0.00014750361 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | -0.00279      |
| fps                | 33            |
| n_updates          | 56            |
| policy_entropy     | 1.4698302     |
| policy_loss        | 0.0009691961  |
| serial_timesteps   | 7168          |
| time_elapsed       | 217           |
| total_timesteps    | 7168          |
| value_loss         | 197.97449     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00013941935 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | 0.0142        |
| fps                | 34            |
| n_updates          | 57            |
| policy_entropy     | 1.4679357     |
| policy_loss        | 0.0012426989  |
| serial_timesteps   | 7296          |
| time_elapsed       | 220           |
| total_timesteps    | 7296          |
| value_loss         | 167.58397     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00041322364 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | 0.00665       |
| fps                | 35            |
| n_updates          | 58            |
| policy_entropy     | 1.466563      |
| policy_loss        | -0.0025947266 |
| serial_timesteps   | 7424          |
| time_elapsed       | 224           |
| total_timesteps    | 7424          |
| value_loss         | 244.67534     |
--------------------------------------
--------------------------------------
| approxkl           | 3.071289e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | -0.00151      |
| fps                | 34            |
| n_updates          | 59            |
| policy_entropy     | 1.466898      |
| policy_loss        | -0.0003045022 |
| serial_timesteps   | 7552          |
| time_elapsed       | 228           |
| total_timesteps    | 7552          |
| value_loss         | 56.147785     |
--------------------------------------
--------------------------------------
| approxkl           | 4.5825385e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.51e+03      |
| explained_variance | 0.00774       |
| fps                | 32            |
| n_updates          | 60            |
| policy_entropy     | 1.4673573     |
| policy_loss        | -0.0009165355 |
| serial_timesteps   | 7680          |
| time_elapsed       | 231           |
| total_timesteps    | 7680          |
| value_loss         | 117.942444    |
--------------------------------------
--------------------------------------
| approxkl           | 0.00035261823 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.00285      |
| fps                | 33            |
| n_updates          | 61            |
| policy_entropy     | 1.4673914     |
| policy_loss        | -0.002596082  |
| serial_timesteps   | 7808          |
| time_elapsed       | 235           |
| total_timesteps    | 7808          |
| value_loss         | 207.9568      |
--------------------------------------
--------------------------------------
| approxkl           | 3.9512848e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.00718       |
| fps                | 35            |
| n_updates          | 62            |
| policy_entropy     | 1.4674531     |
| policy_loss        | 0.0012335642  |
| serial_timesteps   | 7936          |
| time_elapsed       | 239           |
| total_timesteps    | 7936          |
| value_loss         | 57.18552      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00039832256 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.0145        |
| fps                | 32            |
| n_updates          | 63            |
| policy_entropy     | 1.4675702     |
| policy_loss        | -0.0045401882 |
| serial_timesteps   | 8064          |
| time_elapsed       | 243           |
| total_timesteps    | 8064          |
| value_loss         | 162.41362     |
--------------------------------------
An average of 54.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1563.79
-------------------------------------
| approxkl           | 0.002423658  |
| clipfrac           | 0.017578125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.56e+03     |
| explained_variance | 0.00445      |
| fps                | 35           |
| n_updates          | 64           |
| policy_entropy     | 1.4673918    |
| policy_loss        | -0.004751839 |
| serial_timesteps   | 8192         |
| time_elapsed       | 247          |
| total_timesteps    | 8192         |
| value_loss         | 165.14131    |
-------------------------------------
-------------------------------------
| approxkl           | 0.001606909  |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.56e+03     |
| explained_variance | -0.00037     |
| fps                | 37           |
| n_updates          | 65           |
| policy_entropy     | 1.4672269    |
| policy_loss        | -0.008363697 |
| serial_timesteps   | 8320         |
| time_elapsed       | 250          |
| total_timesteps    | 8320         |
| value_loss         | 97.365036    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0003628911  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.00916       |
| fps                | 34            |
| n_updates          | 66            |
| policy_entropy     | 1.4669725     |
| policy_loss        | -0.0016938795 |
| serial_timesteps   | 8448          |
| time_elapsed       | 254           |
| total_timesteps    | 8448          |
| value_loss         | 274.1819      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00088799885 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | 0.000352      |
| fps                | 34            |
| n_updates          | 67            |
| policy_entropy     | 1.4673638     |
| policy_loss        | -0.003631187  |
| serial_timesteps   | 8576          |
| time_elapsed       | 258           |
| total_timesteps    | 8576          |
| value_loss         | 57.023804     |
--------------------------------------
-------------------------------------
| approxkl           | 0.009264573  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.56e+03     |
| explained_variance | -0.0102      |
| fps                | 34           |
| n_updates          | 68           |
| policy_entropy     | 1.467147     |
| policy_loss        | -0.005556348 |
| serial_timesteps   | 8704         |
| time_elapsed       | 261          |
| total_timesteps    | 8704         |
| value_loss         | 27.60756     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00040823    |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.00254      |
| fps                | 35            |
| n_updates          | 69            |
| policy_entropy     | 1.4664329     |
| policy_loss        | -0.0014510492 |
| serial_timesteps   | 8832          |
| time_elapsed       | 265           |
| total_timesteps    | 8832          |
| value_loss         | 39.63507      |
--------------------------------------
--------------------------------------
| approxkl           | 1.5279964e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -0.000247     |
| fps                | 32            |
| n_updates          | 70            |
| policy_entropy     | 1.4675579     |
| policy_loss        | 0.0006857596  |
| serial_timesteps   | 8960          |
| time_elapsed       | 269           |
| total_timesteps    | 8960          |
| value_loss         | 199.58179     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01607931   |
| clipfrac           | 0.22070312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.56e+03     |
| explained_variance | 0.000387     |
| fps                | 33           |
| n_updates          | 71           |
| policy_entropy     | 1.4676774    |
| policy_loss        | -0.015379107 |
| serial_timesteps   | 9088         |
| time_elapsed       | 273          |
| total_timesteps    | 9088         |
| value_loss         | 45.93028     |
-------------------------------------
An average of 54.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1563.79
--------------------------------------
| approxkl           | 0.00051559636 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.56e+03      |
| explained_variance | -6.63e-05     |
| fps                | 35            |
| n_updates          | 72            |
| policy_entropy     | 1.4669847     |
| policy_loss        | 0.0026959889  |
| serial_timesteps   | 9216          |
| time_elapsed       | 276           |
| total_timesteps    | 9216          |
| value_loss         | 147.06918     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016944279 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 8.34e-07      |
| fps                | 35            |
| n_updates          | 73            |
| policy_entropy     | 1.4665939     |
| policy_loss        | 0.0002170587  |
| serial_timesteps   | 9344          |
| time_elapsed       | 280           |
| total_timesteps    | 9344          |
| value_loss         | 211.3614      |
--------------------------------------
-------------------------------------
| approxkl           | 1.18914e-05  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.59e+03     |
| explained_variance | 0.00175      |
| fps                | 37           |
| n_updates          | 74           |
| policy_entropy     | 1.4658048    |
| policy_loss        | 9.467744e-05 |
| serial_timesteps   | 9472         |
| time_elapsed       | 284          |
| total_timesteps    | 9472         |
| value_loss         | 77.51857     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00077591056 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 0.00131       |
| fps                | 35            |
| n_updates          | 75            |
| policy_entropy     | 1.4648035     |
| policy_loss        | 0.0032325704  |
| serial_timesteps   | 9600          |
| time_elapsed       | 287           |
| total_timesteps    | 9600          |
| value_loss         | 96.83382      |
--------------------------------------
--------------------------------------
| approxkl           | 5.845585e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 0.000936      |
| fps                | 34            |
| n_updates          | 76            |
| policy_entropy     | 1.4645387     |
| policy_loss        | -0.0007582224 |
| serial_timesteps   | 9728          |
| time_elapsed       | 291           |
| total_timesteps    | 9728          |
| value_loss         | 49.431156     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00078327034 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 9.38e-05      |
| fps                | 33            |
| n_updates          | 77            |
| policy_entropy     | 1.4649367     |
| policy_loss        | -0.0019633863 |
| serial_timesteps   | 9856          |
| time_elapsed       | 294           |
| total_timesteps    | 9856          |
| value_loss         | 74.86744      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00075434655 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 0.00468       |
| fps                | 31            |
| n_updates          | 78            |
| policy_entropy     | 1.465146      |
| policy_loss        | -0.002645066  |
| serial_timesteps   | 9984          |
| time_elapsed       | 298           |
| total_timesteps    | 9984          |
| value_loss         | 16.278751     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0019167528  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 0.0045        |
| fps                | 37            |
| n_updates          | 79            |
| policy_entropy     | 1.4650538     |
| policy_loss        | -0.0018633041 |
| serial_timesteps   | 10112         |
| time_elapsed       | 302           |
| total_timesteps    | 10112         |
| value_loss         | 34.645317     |
--------------------------------------
An average of 55.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1709.76
--------------------------------------
| approxkl           | 0.00070689793 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 0.0228        |
| fps                | 31            |
| n_updates          | 80            |
| policy_entropy     | 1.4653739     |
| policy_loss        | -0.005818167  |
| serial_timesteps   | 10240         |
| time_elapsed       | 306           |
| total_timesteps    | 10240         |
| value_loss         | 59.52699      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00063727895 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | 0.0185        |
| fps                | 32            |
| n_updates          | 81            |
| policy_entropy     | 1.4654094     |
| policy_loss        | -0.0017399264 |
| serial_timesteps   | 10368         |
| time_elapsed       | 310           |
| total_timesteps    | 10368         |
| value_loss         | 33.036514     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011493874 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.59e+03     |
| explained_variance | 0.00182      |
| fps                | 37           |
| n_updates          | 82           |
| policy_entropy     | 1.4654909    |
| policy_loss        | -0.008566451 |
| serial_timesteps   | 10496        |
| time_elapsed       | 314          |
| total_timesteps    | 10496        |
| value_loss         | 87.817       |
-------------------------------------
-------------------------------------
| approxkl           | 0.0018843221 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.59e+03     |
| explained_variance | 0.0112       |
| fps                | 31           |
| n_updates          | 83           |
| policy_entropy     | 1.4655207    |
| policy_loss        | -0.011700306 |
| serial_timesteps   | 10624        |
| time_elapsed       | 317          |
| total_timesteps    | 10624        |
| value_loss         | 113.87747    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00053805375 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.59e+03      |
| explained_variance | -0.0141       |
| fps                | 35            |
| n_updates          | 84            |
| policy_entropy     | 1.4650357     |
| policy_loss        | 0.001062419   |
| serial_timesteps   | 10752         |
| time_elapsed       | 321           |
| total_timesteps    | 10752         |
| value_loss         | 33.615936     |
--------------------------------------
--------------------------------------
| approxkl           | 1.5819847e-06 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | -0.00726      |
| fps                | 36            |
| n_updates          | 85            |
| policy_entropy     | 1.4646276     |
| policy_loss        | 9.5435535e-05 |
| serial_timesteps   | 10880         |
| time_elapsed       | 325           |
| total_timesteps    | 10880         |
| value_loss         | 207.2494      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0007149203 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.53e+03     |
| explained_variance | -0.000202    |
| fps                | 32           |
| n_updates          | 86           |
| policy_entropy     | 1.463736     |
| policy_loss        | -0.004962726 |
| serial_timesteps   | 11008        |
| time_elapsed       | 328          |
| total_timesteps    | 11008        |
| value_loss         | 308.73676    |
-------------------------------------
An average of 56.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1648.46
--------------------------------------
| approxkl           | 0.00019917624 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | -0.000134     |
| fps                | 32            |
| n_updates          | 87            |
| policy_entropy     | 1.4630998     |
| policy_loss        | -0.0023291984 |
| serial_timesteps   | 11136         |
| time_elapsed       | 332           |
| total_timesteps    | 11136         |
| value_loss         | 67.39175      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0009891988 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.53e+03     |
| explained_variance | 0.00411      |
| fps                | 33           |
| n_updates          | 88           |
| policy_entropy     | 1.4628729    |
| policy_loss        | -0.010165365 |
| serial_timesteps   | 11264        |
| time_elapsed       | 336          |
| total_timesteps    | 11264        |
| value_loss         | 134.5675     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0006649567  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | 0.000868      |
| fps                | 31            |
| n_updates          | 89            |
| policy_entropy     | 1.4628164     |
| policy_loss        | -0.0021154245 |
| serial_timesteps   | 11392         |
| time_elapsed       | 340           |
| total_timesteps    | 11392         |
| value_loss         | 268.94183     |
--------------------------------------
------------------------------------
| approxkl           | 0.004287498 |
| clipfrac           | 0.046875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 1.53e+03    |
| explained_variance | 0.017       |
| fps                | 33          |
| n_updates          | 90          |
| policy_entropy     | 1.4631518   |
| policy_loss        | 0.012927161 |
| serial_timesteps   | 11520       |
| time_elapsed       | 344         |
| total_timesteps    | 11520       |
| value_loss         | 159.26944   |
------------------------------------
--------------------------------------
| approxkl           | 0.015728127   |
| clipfrac           | 0.20898438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | 0.0066        |
| fps                | 32            |
| n_updates          | 91            |
| policy_entropy     | 1.4639072     |
| policy_loss        | -0.0151413875 |
| serial_timesteps   | 11648         |
| time_elapsed       | 348           |
| total_timesteps    | 11648         |
| value_loss         | 72.94687      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00021402861 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | -0.0108       |
| fps                | 33            |
| n_updates          | 92            |
| policy_entropy     | 1.4641415     |
| policy_loss        | 0.00078577024 |
| serial_timesteps   | 11776         |
| time_elapsed       | 352           |
| total_timesteps    | 11776         |
| value_loss         | 105.63408     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0016435938 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.53e+03     |
| explained_variance | 0.00434      |
| fps                | 35           |
| n_updates          | 93           |
| policy_entropy     | 1.4639856    |
| policy_loss        | -0.013406081 |
| serial_timesteps   | 11904        |
| time_elapsed       | 355          |
| total_timesteps    | 11904        |
| value_loss         | 54.49669     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0071403193  |
| clipfrac           | 0.09765625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | -0.0281       |
| fps                | 32            |
| n_updates          | 94            |
| policy_entropy     | 1.4633434     |
| policy_loss        | -0.0038658213 |
| serial_timesteps   | 12032         |
| time_elapsed       | 359           |
| total_timesteps    | 12032         |
| value_loss         | 46.72041      |
--------------------------------------
An average of 56.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1648.46
--------------------------------------
| approxkl           | 0.00026866788 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.53e+03      |
| explained_variance | 0.00925       |
| fps                | 33            |
| n_updates          | 95            |
| policy_entropy     | 1.4634609     |
| policy_loss        | -0.0008559035 |
| serial_timesteps   | 12160         |
| time_elapsed       | 363           |
| total_timesteps    | 12160         |
| value_loss         | 77.360214     |
--------------------------------------
---------------------------------------
| approxkl           | 1.0519597e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.53e+03       |
| explained_variance | 0.021          |
| fps                | 32             |
| n_updates          | 96             |
| policy_entropy     | 1.4635024      |
| policy_loss        | -0.00023105845 |
| serial_timesteps   | 12288          |
| time_elapsed       | 367            |
| total_timesteps    | 12288          |
| value_loss         | 198.04253      |
---------------------------------------
-------------------------------------
| approxkl           | 0.007946611  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | -0.00444     |
| fps                | 35           |
| n_updates          | 97           |
| policy_entropy     | 1.4635975    |
| policy_loss        | -0.015422137 |
| serial_timesteps   | 12416        |
| time_elapsed       | 371          |
| total_timesteps    | 12416        |
| value_loss         | 165.69849    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00019194487 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.00225      |
| fps                | 33            |
| n_updates          | 98            |
| policy_entropy     | 1.4637086     |
| policy_loss        | -0.0042870976 |
| serial_timesteps   | 12544         |
| time_elapsed       | 374           |
| total_timesteps    | 12544         |
| value_loss         | 341.1961      |
--------------------------------------
--------------------------------------
| approxkl           | 3.8001646e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | 0.00144       |
| fps                | 34            |
| n_updates          | 99            |
| policy_entropy     | 1.4637092     |
| policy_loss        | 0.00073034107 |
| serial_timesteps   | 12672         |
| time_elapsed       | 378           |
| total_timesteps    | 12672         |
| value_loss         | 273.25385     |
--------------------------------------
---------------------------------------
| approxkl           | 7.752798e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.58e+03       |
| explained_variance | -0.000326      |
| fps                | 31             |
| n_updates          | 100            |
| policy_entropy     | 1.4610391      |
| policy_loss        | -0.00040784385 |
| serial_timesteps   | 12800          |
| time_elapsed       | 382            |
| total_timesteps    | 12800          |
| value_loss         | 284.66144      |
---------------------------------------
---------------------------------------
| approxkl           | 9.319378e-06   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.58e+03       |
| explained_variance | 0.0225         |
| fps                | 33             |
| n_updates          | 101            |
| policy_entropy     | 1.4594318      |
| policy_loss        | -0.00026879495 |
| serial_timesteps   | 12928          |
| time_elapsed       | 386            |
| total_timesteps    | 12928          |
| value_loss         | 71.153694      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0006140857 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | 0.000722     |
| fps                | 34           |
| n_updates          | 102          |
| policy_entropy     | 1.4592718    |
| policy_loss        | -0.009709446 |
| serial_timesteps   | 13056        |
| time_elapsed       | 390          |
| total_timesteps    | 13056        |
| value_loss         | 63.778378    |
-------------------------------------
An average of 57.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1680.44
-------------------------------------
| approxkl           | 0.013902379  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.58e+03     |
| explained_variance | -0.00194     |
| fps                | 34           |
| n_updates          | 103          |
| policy_entropy     | 1.459949     |
| policy_loss        | -0.011709803 |
| serial_timesteps   | 13184        |
| time_elapsed       | 393          |
| total_timesteps    | 13184        |
| value_loss         | 28.110748    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00056886784 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | -0.00487      |
| fps                | 32            |
| n_updates          | 104           |
| policy_entropy     | 1.4601278     |
| policy_loss        | 0.0033761307  |
| serial_timesteps   | 13312         |
| time_elapsed       | 397           |
| total_timesteps    | 13312         |
| value_loss         | 54.89914      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0010066486  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | 0.000108      |
| fps                | 36            |
| n_updates          | 105           |
| policy_entropy     | 1.4599199     |
| policy_loss        | -0.0059015024 |
| serial_timesteps   | 13440         |
| time_elapsed       | 401           |
| total_timesteps    | 13440         |
| value_loss         | 75.827034     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0004168046  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | 0.00115       |
| fps                | 32            |
| n_updates          | 106           |
| policy_entropy     | 1.4596401     |
| policy_loss        | -0.0007208185 |
| serial_timesteps   | 13568         |
| time_elapsed       | 404           |
| total_timesteps    | 13568         |
| value_loss         | 510.40918     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0042442214  |
| clipfrac           | 0.052734375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | 0.00287       |
| fps                | 32            |
| n_updates          | 107           |
| policy_entropy     | 1.4593656     |
| policy_loss        | -0.0063562146 |
| serial_timesteps   | 13696         |
| time_elapsed       | 408           |
| total_timesteps    | 13696         |
| value_loss         | 150.85884     |
--------------------------------------
--------------------------------------
| approxkl           | 6.000371e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.58e+03      |
| explained_variance | 0.00157       |
| fps                | 39            |
| n_updates          | 108           |
| policy_entropy     | 1.4591463     |
| policy_loss        | 0.00042293908 |
| serial_timesteps   | 13824         |
| time_elapsed       | 412           |
| total_timesteps    | 13824         |
| value_loss         | 238.5745      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0008830092 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.62e+03     |
| explained_variance | -0.000657    |
| fps                | 30           |
| n_updates          | 109          |
| policy_entropy     | 1.4592729    |
| policy_loss        | 0.0003358639 |
| serial_timesteps   | 13952        |
| time_elapsed       | 415          |
| total_timesteps    | 13952        |
| value_loss         | 245.4256     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0002013507 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.62e+03     |
| explained_variance | -0.00056     |
| fps                | 33           |
| n_updates          | 110          |
| policy_entropy     | 1.4600213    |
| policy_loss        | 0.0007372212 |
| serial_timesteps   | 14080        |
| time_elapsed       | 420          |
| total_timesteps    | 14080        |
| value_loss         | 259.31085    |
-------------------------------------
An average of 58.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1695.59
---------------------------------------
| approxkl           | 3.8049708e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 1.62e+03       |
| explained_variance | -0.0026        |
| fps                | 33             |
| n_updates          | 111            |
| policy_entropy     | 1.4605999      |
| policy_loss        | -0.00043890346 |
| serial_timesteps   | 14208          |
| time_elapsed       | 423            |
| total_timesteps    | 14208          |
| value_loss         | 43.973904      |
---------------------------------------
--------------------------------------
| approxkl           | 3.801647e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.62e+03      |
| explained_variance | -0.000281     |
| fps                | 32            |
| n_updates          | 112           |
| policy_entropy     | 1.4613987     |
| policy_loss        | -0.0011444468 |
| serial_timesteps   | 14336         |
| time_elapsed       | 427           |
| total_timesteps    | 14336         |
| value_loss         | 104.67828     |
--------------------------------------
-------------------------------------
| approxkl           | 0.004702813  |
| clipfrac           | 0.041015625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.62e+03     |
| explained_variance | 0.0058       |
| fps                | 33           |
| n_updates          | 113          |
| policy_entropy     | 1.4621873    |
| policy_loss        | -0.011363905 |
| serial_timesteps   | 14464        |
| time_elapsed       | 431          |
| total_timesteps    | 14464        |
| value_loss         | 120.25221    |
-------------------------------------
-------------------------------------
| approxkl           | 0.003129487  |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.62e+03     |
| explained_variance | 0.00107      |
| fps                | 32           |
| n_updates          | 114          |
| policy_entropy     | 1.462657     |
| policy_loss        | -0.008792264 |
| serial_timesteps   | 14592        |
| time_elapsed       | 435          |
| total_timesteps    | 14592        |
| value_loss         | 116.879456   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016039213 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 1.62e+03     |
| explained_variance | 0.000281     |
| fps                | 33           |
| n_updates          | 115          |
| policy_entropy     | 1.46274      |
| policy_loss        | 0.003359932  |
| serial_timesteps   | 14720        |
| time_elapsed       | 439          |
| total_timesteps    | 14720        |
| value_loss         | 308.40543    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0015988873  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.62e+03      |
| explained_variance | 0.000959      |
| fps                | 33            |
| n_updates          | 116           |
| policy_entropy     | 1.4612751     |
| policy_loss        | 0.00082271826 |
| serial_timesteps   | 14848         |
| time_elapsed       | 443           |
| total_timesteps    | 14848         |
| value_loss         | 295.3016      |
--------------------------------------
--------------------------------------
| approxkl           | 0.004346384   |
| clipfrac           | 0.05078125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 1.62e+03      |
| explained_variance | -0.00261      |
| fps                | 32            |
| n_updates          | 117           |
| policy_entropy     | 1.4591633     |
| policy_loss        | -0.0106943045 |
| serial_timesteps   | 14976         |
| time_elapsed       | 446           |
| total_timesteps    | 14976         |
| value_loss         | 72.42552      |
--------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b809ba358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b809ba358>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b808c4c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b808c4c18>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2430 samples, validate on 219 samples
Epoch 130/5000
 - 2s - loss: 0.0292 - val_loss: 0.0185
Epoch 131/5000
 - 0s - loss: 0.0136 - val_loss: 0.0072
Epoch 132/5000
 - 0s - loss: 0.0107 - val_loss: 0.0058
Epoch 133/5000
 - 0s - loss: 0.0084 - val_loss: 0.0054
Epoch 134/5000
 - 0s - loss: 0.0074 - val_loss: 0.0043
Epoch 135/5000
 - 0s - loss: 0.0061 - val_loss: 0.0038
Epoch 136/5000
 - 0s - loss: 0.0055 - val_loss: 0.0032
Epoch 137/5000
 - 0s - loss: 0.0054 - val_loss: 0.0030
Epoch 138/5000
 - 0s - loss: 0.0051 - val_loss: 0.0029
Epoch 139/5000
 - 0s - loss: 0.0049 - val_loss: 0.0028
Epoch 140/5000
 - 0s - loss: 0.0047 - val_loss: 0.0028
Epoch 141/5000
 - 0s - loss: 0.0039 - val_loss: 0.0034
Epoch 142/5000
 - 0s - loss: 0.0039 - val_loss: 0.0032
Epoch 143/5000
 - 0s - loss: 0.0039 - val_loss: 0.0030
Epoch 144/5000
 - 0s - loss: 0.0039 - val_loss: 0.0029
Epoch 145/5000
 - 0s - loss: 0.0038 - val_loss: 0.0028
Epoch 146/5000
 - 0s - loss: 0.0038 - val_loss: 0.0027
Epoch 147/5000
 - 0s - loss: 0.0037 - val_loss: 0.0027
Epoch 148/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 149/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 150/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 151/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 152/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 153/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 154/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 155/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 156/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 157/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 158/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 159/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 160/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 161/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 162/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 163/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 164/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Epoch 165/5000
 - 0s - loss: 0.0037 - val_loss: 0.0026
Train on 1773 samples, validate on 219 samples
Epoch 123/5000
 - 2s - loss: 0.0227 - val_loss: 0.0068
Epoch 124/5000
 - 0s - loss: 0.0227 - val_loss: 0.0068
Epoch 125/5000
 - 0s - loss: 0.0227 - val_loss: 0.0068
Epoch 126/5000
 - 0s - loss: 0.0227 - val_loss: 0.0068
Epoch 127/5000
 - 0s - loss: 0.0227 - val_loss: 0.0068
Epoch 128/5000
 - 0s - loss: 0.0227 - val_loss: 0.0068
Train on 2431 samples, validate on 219 samples
Epoch 125/5000
 - 3s - loss: 0.6707 - val_loss: 0.5729
Epoch 126/5000
 - 1s - loss: 0.6025 - val_loss: 0.3636
Epoch 127/5000
 - 1s - loss: 0.5817 - val_loss: 0.2984
Epoch 128/5000
 - 1s - loss: 0.5832 - val_loss: 0.2908
Epoch 129/5000
 - 1s - loss: 0.5815 - val_loss: 0.2881
Epoch 130/5000
 - 1s - loss: 0.5793 - val_loss: 0.2857
Epoch 131/5000
 - 1s - loss: 0.5770 - val_loss: 0.2831
Epoch 132/5000
 - 1s - loss: 0.5742 - val_loss: 0.2800
Epoch 133/5000
 - 1s - loss: 0.5710 - val_loss: 0.2766
Epoch 134/5000
 - 1s - loss: 0.5671 - val_loss: 0.2732
Epoch 135/5000
 - 1s - loss: 0.5622 - val_loss: 0.2691
Epoch 136/5000
 - 1s - loss: 0.5564 - val_loss: 0.2648
Epoch 137/5000
 - 1s - loss: 0.5495 - val_loss: 0.2611
Epoch 138/5000
 - 1s - loss: 0.5410 - val_loss: 0.2543
Epoch 139/5000
 - 1s - loss: 0.5291 - val_loss: 0.2310
Epoch 140/5000
 - 1s - loss: 0.5164 - val_loss: 0.2349
Epoch 141/5000
 - 1s - loss: 0.5023 - val_loss: 0.2332
Epoch 142/5000
 - 1s - loss: 0.4914 - val_loss: 0.2711
Epoch 143/5000
 - 1s - loss: 0.4802 - val_loss: 0.2940
Epoch 144/5000
 - 1s - loss: 0.4750 - val_loss: 0.3078
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 2.587758e-05 |
| clipfrac           | 0.0          |
| explained_variance | -0.00171     |
| fps                | 10           |
| n_updates          | 1            |
| policy_entropy     | 1.4582319    |
| policy_loss        | 0.0009008611 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.26e-05     |
| total_timesteps    | 128          |
| value_loss         | 43.9701      |
-------------------------------------
An average of 59.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1301.58
--------------------------------------
| approxkl           | 0.00078119116 |
| clipfrac           | 0.0           |
| explained_variance | -0.00212      |
| fps                | 35            |
| n_updates          | 2             |
| policy_entropy     | 1.4582021     |
| policy_loss        | -0.0026386275 |
| serial_timesteps   | 256           |
| time_elapsed       | 12.6          |
| total_timesteps    | 256           |
| value_loss         | 68.71432      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0056162826 |
| clipfrac           | 0.0703125    |
| explained_variance | 0.000821     |
| fps                | 32           |
| n_updates          | 3            |
| policy_entropy     | 1.4599344    |
| policy_loss        | -0.018982302 |
| serial_timesteps   | 384          |
| time_elapsed       | 16.3         |
| total_timesteps    | 384          |
| value_loss         | 44.776096    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0007917826  |
| clipfrac           | 0.0           |
| explained_variance | -0.000356     |
| fps                | 32            |
| n_updates          | 4             |
| policy_entropy     | 1.4610312     |
| policy_loss        | -0.0067735724 |
| serial_timesteps   | 512           |
| time_elapsed       | 20.2          |
| total_timesteps    | 512           |
| value_loss         | 300.48813     |
--------------------------------------
--------------------------------------
| approxkl           | 9.454364e-05  |
| clipfrac           | 0.0           |
| explained_variance | 0.00031       |
| fps                | 36            |
| n_updates          | 5             |
| policy_entropy     | 1.4611042     |
| policy_loss        | -0.0017888038 |
| serial_timesteps   | 640           |
| time_elapsed       | 24.2          |
| total_timesteps    | 640           |
| value_loss         | 73.35369      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0045029474 |
| clipfrac           | 0.037109375  |
| explained_variance | -0.000345    |
| fps                | 33           |
| n_updates          | 6            |
| policy_entropy     | 1.460995     |
| policy_loss        | 0.006963134  |
| serial_timesteps   | 768          |
| time_elapsed       | 27.6         |
| total_timesteps    | 768          |
| value_loss         | 209.8179     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0011268887  |
| clipfrac           | 0.0           |
| explained_variance | -0.000517     |
| fps                | 31            |
| n_updates          | 7             |
| policy_entropy     | 1.4619629     |
| policy_loss        | -0.0015566818 |
| serial_timesteps   | 896           |
| time_elapsed       | 31.5          |
| total_timesteps    | 896           |
| value_loss         | 240.8414      |
--------------------------------------
--------------------------------------
| approxkl           | 0.001559684   |
| clipfrac           | 0.0078125     |
| explained_variance | -0.000582     |
| fps                | 33            |
| n_updates          | 8             |
| policy_entropy     | 1.4622431     |
| policy_loss        | -0.0020182272 |
| serial_timesteps   | 1024          |
| time_elapsed       | 35.6          |
| total_timesteps    | 1024          |
| value_loss         | 189.1136      |
--------------------------------------
An average of 59.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1301.58
---------------------------------------
| approxkl           | 2.4938425e-05  |
| clipfrac           | 0.0            |
| explained_variance | -0.000308      |
| fps                | 32             |
| n_updates          | 9              |
| policy_entropy     | 1.4619986      |
| policy_loss        | -0.00033324363 |
| serial_timesteps   | 1152           |
| time_elapsed       | 39.4           |
| total_timesteps    | 1152           |
| value_loss         | 204.3645       |
---------------------------------------
------------------------------------
| approxkl           | 0.000946849 |
| clipfrac           | 0.0         |
| explained_variance | 0.000905    |
| fps                | 31          |
| n_updates          | 10          |
| policy_entropy     | 1.4624557   |
| policy_loss        | 0.004680109 |
| serial_timesteps   | 1280        |
| time_elapsed       | 43.3        |
| total_timesteps    | 1280        |
| value_loss         | 171.39413   |
------------------------------------
-------------------------------------
| approxkl           | 0.0020078614 |
| clipfrac           | 0.00390625   |
| explained_variance | -0.00925     |
| fps                | 34           |
| n_updates          | 11           |
| policy_entropy     | 1.462075     |
| policy_loss        | 0.0037140655 |
| serial_timesteps   | 1408         |
| time_elapsed       | 47.3         |
| total_timesteps    | 1408         |
| value_loss         | 156.52412    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0012280548 |
| clipfrac           | 0.0          |
| explained_variance | 0.00248      |
| fps                | 33           |
| n_updates          | 12           |
| policy_entropy     | 1.460835     |
| policy_loss        | 0.0069963774 |
| serial_timesteps   | 1536         |
| time_elapsed       | 51.1         |
| total_timesteps    | 1536         |
| value_loss         | 105.86786    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0044695684  |
| clipfrac           | 0.044921875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.01e+03      |
| explained_variance | 4.66e-05      |
| fps                | 33            |
| n_updates          | 13            |
| policy_entropy     | 1.4609686     |
| policy_loss        | -0.0056728893 |
| serial_timesteps   | 1664          |
| time_elapsed       | 54.9          |
| total_timesteps    | 1664          |
| value_loss         | 215.19794     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00039012762 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.01e+03      |
| explained_variance | 0.00287       |
| fps                | 33            |
| n_updates          | 14            |
| policy_entropy     | 1.4612881     |
| policy_loss        | -0.0031819062 |
| serial_timesteps   | 1792          |
| time_elapsed       | 58.7          |
| total_timesteps    | 1792          |
| value_loss         | 378.77255     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0042197346 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.01e+03     |
| explained_variance | -0.000715    |
| fps                | 31           |
| n_updates          | 15           |
| policy_entropy     | 1.4613411    |
| policy_loss        | -0.011507436 |
| serial_timesteps   | 1920         |
| time_elapsed       | 62.5         |
| total_timesteps    | 1920         |
| value_loss         | 292.85895    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00062689715 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.01e+03      |
| explained_variance | 0.000324      |
| fps                | 32            |
| n_updates          | 16            |
| policy_entropy     | 1.4602507     |
| policy_loss        | -0.001068641  |
| serial_timesteps   | 2048          |
| time_elapsed       | 66.6          |
| total_timesteps    | 2048          |
| value_loss         | 113.94345     |
--------------------------------------
An average of 60.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1359.90
---------------------------------------
| approxkl           | 0.00018153377  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.01e+03       |
| explained_variance | -0.000139      |
| fps                | 32             |
| n_updates          | 17             |
| policy_entropy     | 1.4596037      |
| policy_loss        | -1.0081567e-06 |
| serial_timesteps   | 2176           |
| time_elapsed       | 70.6           |
| total_timesteps    | 2176           |
| value_loss         | 72.62982       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00017328029 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.01e+03      |
| explained_variance | -0.0014       |
| fps                | 31            |
| n_updates          | 18            |
| policy_entropy     | 1.4596933     |
| policy_loss        | -0.0028895917 |
| serial_timesteps   | 2304          |
| time_elapsed       | 74.5          |
| total_timesteps    | 2304          |
| value_loss         | 51.02682      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0040019304 |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.01e+03     |
| explained_variance | -0.000283    |
| fps                | 32           |
| n_updates          | 19           |
| policy_entropy     | 1.4593236    |
| policy_loss        | -0.004306427 |
| serial_timesteps   | 2432         |
| time_elapsed       | 78.5         |
| total_timesteps    | 2432         |
| value_loss         | 173.63121    |
-------------------------------------
--------------------------------------
| approxkl           | 6.596722e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.01e+03      |
| explained_variance | 0.00184       |
| fps                | 32            |
| n_updates          | 20            |
| policy_entropy     | 1.4589176     |
| policy_loss        | 0.00090550166 |
| serial_timesteps   | 2560          |
| time_elapsed       | 82.4          |
| total_timesteps    | 2560          |
| value_loss         | 266.503       |
--------------------------------------
--------------------------------------
| approxkl           | 0.00010866337 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.01e+03      |
| explained_variance | 0.000951      |
| fps                | 34            |
| n_updates          | 21            |
| policy_entropy     | 1.4589577     |
| policy_loss        | -0.0017967565 |
| serial_timesteps   | 2688          |
| time_elapsed       | 86.3          |
| total_timesteps    | 2688          |
| value_loss         | 93.27951      |
--------------------------------------
---------------------------------------
| approxkl           | 0.0007803955   |
| clipfrac           | 0.001953125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.01e+03       |
| explained_variance | 0.000207       |
| fps                | 35             |
| n_updates          | 22             |
| policy_entropy     | 1.4588679      |
| policy_loss        | -0.00090720854 |
| serial_timesteps   | 2816           |
| time_elapsed       | 90             |
| total_timesteps    | 2816           |
| value_loss         | 76.72296       |
---------------------------------------
-------------------------------------
| approxkl           | 0.0012099196 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.01e+03     |
| explained_variance | -0.000429    |
| fps                | 32           |
| n_updates          | 23           |
| policy_entropy     | 1.4582987    |
| policy_loss        | 0.007316243  |
| serial_timesteps   | 2944         |
| time_elapsed       | 93.6         |
| total_timesteps    | 2944         |
| value_loss         | 379.97153    |
-------------------------------------
-------------------------------------
| approxkl           | 0.003969663  |
| clipfrac           | 0.0390625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.01e+03     |
| explained_variance | -0.00169     |
| fps                | 35           |
| n_updates          | 24           |
| policy_entropy     | 1.4580581    |
| policy_loss        | 0.0036206497 |
| serial_timesteps   | 3072         |
| time_elapsed       | 97.6         |
| total_timesteps    | 3072         |
| value_loss         | 61.44692     |
-------------------------------------
An average of 61.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1559.72
--------------------------------------
| approxkl           | 0.00011077313 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -0.000369     |
| fps                | 33            |
| n_updates          | 25            |
| policy_entropy     | 1.4580976     |
| policy_loss        | 0.0006375022  |
| serial_timesteps   | 3200          |
| time_elapsed       | 101           |
| total_timesteps    | 3200          |
| value_loss         | 367.03204     |
--------------------------------------
---------------------------------------
| approxkl           | 8.6079825e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.1e+03        |
| explained_variance | 0.00298        |
| fps                | 33             |
| n_updates          | 26             |
| policy_entropy     | 1.4581075      |
| policy_loss        | -0.00014214637 |
| serial_timesteps   | 3328           |
| time_elapsed       | 105            |
| total_timesteps    | 3328           |
| value_loss         | 243.82024      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0016422181 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.1e+03      |
| explained_variance | -0.00107     |
| fps                | 31           |
| n_updates          | 27           |
| policy_entropy     | 1.4564162    |
| policy_loss        | -0.000349622 |
| serial_timesteps   | 3456         |
| time_elapsed       | 109          |
| total_timesteps    | 3456         |
| value_loss         | 130.70262    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00026308978 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -0.000201     |
| fps                | 32            |
| n_updates          | 28            |
| policy_entropy     | 1.4556552     |
| policy_loss        | -0.0051225903 |
| serial_timesteps   | 3584          |
| time_elapsed       | 113           |
| total_timesteps    | 3584          |
| value_loss         | 336.0216      |
--------------------------------------
------------------------------------
| approxkl           | 0.010801954 |
| clipfrac           | 0.16601562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.1e+03     |
| explained_variance | -0.00013    |
| fps                | 36          |
| n_updates          | 29          |
| policy_entropy     | 1.4551989   |
| policy_loss        | 0.03862842  |
| serial_timesteps   | 3712        |
| time_elapsed       | 117         |
| total_timesteps    | 3712        |
| value_loss         | 137.65758   |
------------------------------------
-------------------------------------
| approxkl           | 0.009331959  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.1e+03      |
| explained_variance | -0.00132     |
| fps                | 32           |
| n_updates          | 30           |
| policy_entropy     | 1.4550645    |
| policy_loss        | 0.0060425038 |
| serial_timesteps   | 3840         |
| time_elapsed       | 120          |
| total_timesteps    | 3840         |
| value_loss         | 284.8959     |
-------------------------------------
--------------------------------------
| approxkl           | 0.005217428   |
| clipfrac           | 0.064453125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -2.16e-05     |
| fps                | 32            |
| n_updates          | 31            |
| policy_entropy     | 1.4556665     |
| policy_loss        | -0.0050789365 |
| serial_timesteps   | 3968          |
| time_elapsed       | 124           |
| total_timesteps    | 3968          |
| value_loss         | 594.32837     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006532603  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -0.000525     |
| fps                | 36            |
| n_updates          | 32            |
| policy_entropy     | 1.4556938     |
| policy_loss        | -0.0013419073 |
| serial_timesteps   | 4096          |
| time_elapsed       | 128           |
| total_timesteps    | 4096          |
| value_loss         | 51.842766     |
--------------------------------------
An average of 61.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1559.72
--------------------------------------
| approxkl           | 0.00029322563 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -0.00136      |
| fps                | 31            |
| n_updates          | 33            |
| policy_entropy     | 1.4555341     |
| policy_loss        | -0.0046944674 |
| serial_timesteps   | 4224          |
| time_elapsed       | 132           |
| total_timesteps    | 4224          |
| value_loss         | 75.98378      |
--------------------------------------
--------------------------------------
| approxkl           | 0.006228095   |
| clipfrac           | 0.1015625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | 7.84e-05      |
| fps                | 36            |
| n_updates          | 34            |
| policy_entropy     | 1.4560145     |
| policy_loss        | -0.0062524946 |
| serial_timesteps   | 4352          |
| time_elapsed       | 136           |
| total_timesteps    | 4352          |
| value_loss         | 30.998848     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0001244768  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -0.000307     |
| fps                | 33            |
| n_updates          | 35            |
| policy_entropy     | 1.4566957     |
| policy_loss        | -0.0022583911 |
| serial_timesteps   | 4480          |
| time_elapsed       | 139           |
| total_timesteps    | 4480          |
| value_loss         | 223.17088     |
--------------------------------------
--------------------------------------
| approxkl           | 1.3583811e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.1e+03       |
| explained_variance | -0.000907     |
| fps                | 36            |
| n_updates          | 36            |
| policy_entropy     | 1.4568686     |
| policy_loss        | 0.0005833091  |
| serial_timesteps   | 4608          |
| time_elapsed       | 143           |
| total_timesteps    | 4608          |
| value_loss         | 348.80444     |
--------------------------------------
--------------------------------------
| approxkl           | 0.004329731   |
| clipfrac           | 0.04296875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.28e+03      |
| explained_variance | -7.15e-05     |
| fps                | 32            |
| n_updates          | 37            |
| policy_entropy     | 1.4564736     |
| policy_loss        | -0.0026503631 |
| serial_timesteps   | 4736          |
| time_elapsed       | 147           |
| total_timesteps    | 4736          |
| value_loss         | 239.53604     |
--------------------------------------
--------------------------------------
| approxkl           | 2.1068461e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.28e+03      |
| explained_variance | -0.000478     |
| fps                | 31            |
| n_updates          | 38            |
| policy_entropy     | 1.456194      |
| policy_loss        | 0.00047853286 |
| serial_timesteps   | 4864          |
| time_elapsed       | 151           |
| total_timesteps    | 4864          |
| value_loss         | 151.5549      |
--------------------------------------
---------------------------------------
| approxkl           | 0.0006474875   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.28e+03       |
| explained_variance | -0.000337      |
| fps                | 33             |
| n_updates          | 39             |
| policy_entropy     | 1.4558144      |
| policy_loss        | -0.00065768673 |
| serial_timesteps   | 4992           |
| time_elapsed       | 155            |
| total_timesteps    | 4992           |
| value_loss         | 127.572845     |
---------------------------------------
---------------------------------------
| approxkl           | 0.00016000756  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.28e+03       |
| explained_variance | -0.00122       |
| fps                | 32             |
| n_updates          | 40             |
| policy_entropy     | 1.4553742      |
| policy_loss        | -0.00019643549 |
| serial_timesteps   | 5120           |
| time_elapsed       | 158            |
| total_timesteps    | 5120           |
| value_loss         | 102.511894     |
---------------------------------------
An average of 62.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1713.29
--------------------------------------
| approxkl           | 1.6183487e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.28e+03      |
| explained_variance | 2.02e-05      |
| fps                | 32            |
| n_updates          | 41            |
| policy_entropy     | 1.455207      |
| policy_loss        | 0.00042705087 |
| serial_timesteps   | 5248          |
| time_elapsed       | 162           |
| total_timesteps    | 5248          |
| value_loss         | 290.12167     |
--------------------------------------
---------------------------------------
| approxkl           | 3.0836425e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.28e+03       |
| explained_variance | -0.00112       |
| fps                | 32             |
| n_updates          | 42             |
| policy_entropy     | 1.4513831      |
| policy_loss        | -0.00083198404 |
| serial_timesteps   | 5376           |
| time_elapsed       | 166            |
| total_timesteps    | 5376           |
| value_loss         | 386.64926      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0016753913 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.28e+03     |
| explained_variance | -0.000297    |
| fps                | 34           |
| n_updates          | 43           |
| policy_entropy     | 1.4496117    |
| policy_loss        | 0.008909881  |
| serial_timesteps   | 5504         |
| time_elapsed       | 170          |
| total_timesteps    | 5504         |
| value_loss         | 344.3884     |
-------------------------------------
-------------------------------------
| approxkl           | 0.006362837  |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.28e+03     |
| explained_variance | -6.48e-05    |
| fps                | 34           |
| n_updates          | 44           |
| policy_entropy     | 1.4507428    |
| policy_loss        | -0.007870111 |
| serial_timesteps   | 5632         |
| time_elapsed       | 174          |
| total_timesteps    | 5632         |
| value_loss         | 289.22153    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0009917959   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.28e+03       |
| explained_variance | 0.0008         |
| fps                | 35             |
| n_updates          | 45             |
| policy_entropy     | 1.451473       |
| policy_loss        | -0.00093306997 |
| serial_timesteps   | 5760           |
| time_elapsed       | 178            |
| total_timesteps    | 5760           |
| value_loss         | 454.31238      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0076587033  |
| clipfrac           | 0.107421875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.28e+03      |
| explained_variance | -0.000536     |
| fps                | 36            |
| n_updates          | 46            |
| policy_entropy     | 1.4512364     |
| policy_loss        | -9.387161e-05 |
| serial_timesteps   | 5888          |
| time_elapsed       | 181           |
| total_timesteps    | 5888          |
| value_loss         | 196.51395     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0012075368 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.28e+03     |
| explained_variance | 6.42e-05     |
| fps                | 30           |
| n_updates          | 47           |
| policy_entropy     | 1.4490895    |
| policy_loss        | 0.0006096354 |
| serial_timesteps   | 6016         |
| time_elapsed       | 185          |
| total_timesteps    | 6016         |
| value_loss         | 271.048      |
-------------------------------------
--------------------------------------
| approxkl           | 0.00027904703 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.28e+03      |
| explained_variance | 2.33e-05      |
| fps                | 34            |
| n_updates          | 48            |
| policy_entropy     | 1.4477146     |
| policy_loss        | -0.0043217335 |
| serial_timesteps   | 6144          |
| time_elapsed       | 189           |
| total_timesteps    | 6144          |
| value_loss         | 87.23772      |
--------------------------------------
An average of 62.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1713.29
--------------------------------------
| approxkl           | 9.7169795e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | 0.00016       |
| fps                | 33            |
| n_updates          | 49            |
| policy_entropy     | 1.4475777     |
| policy_loss        | 0.0012057597  |
| serial_timesteps   | 6272          |
| time_elapsed       | 193           |
| total_timesteps    | 6272          |
| value_loss         | 276.60477     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0069680344 |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.4e+03      |
| explained_variance | 2.5e-05      |
| fps                | 34           |
| n_updates          | 50           |
| policy_entropy     | 1.4477516    |
| policy_loss        | 0.028573662  |
| serial_timesteps   | 6400         |
| time_elapsed       | 197          |
| total_timesteps    | 6400         |
| value_loss         | 126.4693     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00034238087 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | 0.00154       |
| fps                | 31            |
| n_updates          | 51            |
| policy_entropy     | 1.4478738     |
| policy_loss        | -0.006242738  |
| serial_timesteps   | 6528          |
| time_elapsed       | 200           |
| total_timesteps    | 6528          |
| value_loss         | 127.780304    |
--------------------------------------
------------------------------------
| approxkl           | 0.005115679 |
| clipfrac           | 0.072265625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.4e+03     |
| explained_variance | -0.000737   |
| fps                | 33          |
| n_updates          | 52          |
| policy_entropy     | 1.447949    |
| policy_loss        | 0.004467096 |
| serial_timesteps   | 6656        |
| time_elapsed       | 204         |
| total_timesteps    | 6656        |
| value_loss         | 391.85028   |
------------------------------------
------------------------------------
| approxkl           | 0.006813612 |
| clipfrac           | 0.08984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.4e+03     |
| explained_variance | 0.000308    |
| fps                | 34          |
| n_updates          | 53          |
| policy_entropy     | 1.4477258   |
| policy_loss        | 0.009454176 |
| serial_timesteps   | 6784        |
| time_elapsed       | 208         |
| total_timesteps    | 6784        |
| value_loss         | 130.45306   |
------------------------------------
--------------------------------------
| approxkl           | 0.00043905695 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | -0.000536     |
| fps                | 32            |
| n_updates          | 54            |
| policy_entropy     | 1.4476352     |
| policy_loss        | -0.006876752  |
| serial_timesteps   | 6912          |
| time_elapsed       | 212           |
| total_timesteps    | 6912          |
| value_loss         | 206.76468     |
--------------------------------------
-------------------------------------
| approxkl           | 5.241698e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.4e+03      |
| explained_variance | -0.000483    |
| fps                | 34           |
| n_updates          | 55           |
| policy_entropy     | 1.4481697    |
| policy_loss        | 0.0010637005 |
| serial_timesteps   | 7040         |
| time_elapsed       | 216          |
| total_timesteps    | 7040         |
| value_loss         | 54.10941     |
-------------------------------------
An average of 63.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 1875.62
--------------------------------------
| approxkl           | 0.00081380084 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | -0.000301     |
| fps                | 34            |
| n_updates          | 56            |
| policy_entropy     | 1.4484522     |
| policy_loss        | -0.00363228   |
| serial_timesteps   | 7168          |
| time_elapsed       | 219           |
| total_timesteps    | 7168          |
| value_loss         | 379.0585      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0010041681  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | 0.000658      |
| fps                | 33            |
| n_updates          | 57            |
| policy_entropy     | 1.4485735     |
| policy_loss        | -0.0070940503 |
| serial_timesteps   | 7296          |
| time_elapsed       | 223           |
| total_timesteps    | 7296          |
| value_loss         | 83.65356      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0009977559  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | -0.00031      |
| fps                | 36            |
| n_updates          | 58            |
| policy_entropy     | 1.4490715     |
| policy_loss        | -0.0054838024 |
| serial_timesteps   | 7424          |
| time_elapsed       | 227           |
| total_timesteps    | 7424          |
| value_loss         | 152.59988     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0001802647 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.4e+03      |
| explained_variance | -0.000992    |
| fps                | 29           |
| n_updates          | 59           |
| policy_entropy     | 1.4493468    |
| policy_loss        | 0.0015014032 |
| serial_timesteps   | 7552         |
| time_elapsed       | 230          |
| total_timesteps    | 7552         |
| value_loss         | 485.45776    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0038589828  |
| clipfrac           | 0.041015625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.4e+03       |
| explained_variance | 0.000112      |
| fps                | 33            |
| n_updates          | 60            |
| policy_entropy     | 1.4492848     |
| policy_loss        | -0.0048434483 |
| serial_timesteps   | 7680          |
| time_elapsed       | 235           |
| total_timesteps    | 7680          |
| value_loss         | 439.02115     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00060200464 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | 0.000386      |
| fps                | 29            |
| n_updates          | 61            |
| policy_entropy     | 1.4478996     |
| policy_loss        | -0.0024832801 |
| serial_timesteps   | 7808          |
| time_elapsed       | 239           |
| total_timesteps    | 7808          |
| value_loss         | 289.78647     |
--------------------------------------
--------------------------------------
| approxkl           | 3.9679915e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | -5.98e-05     |
| fps                | 36            |
| n_updates          | 62            |
| policy_entropy     | 1.4471501     |
| policy_loss        | -0.000743147  |
| serial_timesteps   | 7936          |
| time_elapsed       | 243           |
| total_timesteps    | 7936          |
| value_loss         | 520.0996      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0012205689 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.46e+03     |
| explained_variance | 9.66e-05     |
| fps                | 36           |
| n_updates          | 63           |
| policy_entropy     | 1.4467329    |
| policy_loss        | -0.005219626 |
| serial_timesteps   | 8064         |
| time_elapsed       | 246          |
| total_timesteps    | 8064         |
| value_loss         | 72.46553     |
-------------------------------------
An average of 64.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2464.58
--------------------------------------
| approxkl           | 0.00016667538 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | -0.001        |
| fps                | 34            |
| n_updates          | 64            |
| policy_entropy     | 1.4464984     |
| policy_loss        | 0.00032310537 |
| serial_timesteps   | 8192          |
| time_elapsed       | 250           |
| total_timesteps    | 8192          |
| value_loss         | 86.74179      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00028026383 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | 0.00015       |
| fps                | 31            |
| n_updates          | 65            |
| policy_entropy     | 1.4463271     |
| policy_loss        | 0.0010609727  |
| serial_timesteps   | 8320          |
| time_elapsed       | 254           |
| total_timesteps    | 8320          |
| value_loss         | 28.221386     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0023037544 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.46e+03     |
| explained_variance | 0.000148     |
| fps                | 32           |
| n_updates          | 66           |
| policy_entropy     | 1.4463365    |
| policy_loss        | -0.004225191 |
| serial_timesteps   | 8448         |
| time_elapsed       | 258          |
| total_timesteps    | 8448         |
| value_loss         | 327.0257     |
-------------------------------------
-------------------------------------
| approxkl           | 3.13161e-05  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.46e+03     |
| explained_variance | 0.000512     |
| fps                | 33           |
| n_updates          | 67           |
| policy_entropy     | 1.4462996    |
| policy_loss        | 0.0006124845 |
| serial_timesteps   | 8576         |
| time_elapsed       | 262          |
| total_timesteps    | 8576         |
| value_loss         | 296.4428     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0032734063 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.46e+03     |
| explained_variance | -1.38e-05    |
| fps                | 33           |
| n_updates          | 68           |
| policy_entropy     | 1.4465841    |
| policy_loss        | 0.0027093596 |
| serial_timesteps   | 8704         |
| time_elapsed       | 266          |
| total_timesteps    | 8704         |
| value_loss         | 316.487      |
-------------------------------------
--------------------------------------
| approxkl           | 0.00015299447 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | -0.000211     |
| fps                | 34            |
| n_updates          | 69            |
| policy_entropy     | 1.4466437     |
| policy_loss        | -0.0010236887 |
| serial_timesteps   | 8832          |
| time_elapsed       | 269           |
| total_timesteps    | 8832          |
| value_loss         | 128.17862     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00010292499 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | -0.000288     |
| fps                | 33            |
| n_updates          | 70            |
| policy_entropy     | 1.4465566     |
| policy_loss        | -0.0003152691 |
| serial_timesteps   | 8960          |
| time_elapsed       | 273           |
| total_timesteps    | 8960          |
| value_loss         | 232.15776     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00045353753 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.46e+03      |
| explained_variance | -0.000502     |
| fps                | 33            |
| n_updates          | 71            |
| policy_entropy     | 1.4461957     |
| policy_loss        | -0.0035428223 |
| serial_timesteps   | 9088          |
| time_elapsed       | 277           |
| total_timesteps    | 9088          |
| value_loss         | 196.94077     |
--------------------------------------
An average of 64.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2464.58
------------------------------------
| approxkl           | 0.012929675 |
| clipfrac           | 0.19335938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.46e+03    |
| explained_variance | -0.000122   |
| fps                | 32          |
| n_updates          | 72          |
| policy_entropy     | 1.4455973   |
| policy_loss        | 0.035532992 |
| serial_timesteps   | 9216        |
| time_elapsed       | 281         |
| total_timesteps    | 9216        |
| value_loss         | 243.4158    |
------------------------------------
------------------------------------
| approxkl           | 0.008725328 |
| clipfrac           | 0.13085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.49e+03    |
| explained_variance | 0.000114    |
| fps                | 33          |
| n_updates          | 73          |
| policy_entropy     | 1.4447501   |
| policy_loss        | 0.012046258 |
| serial_timesteps   | 9344        |
| time_elapsed       | 284         |
| total_timesteps    | 9344        |
| value_loss         | 316.78564   |
------------------------------------
--------------------------------------
| approxkl           | 0.00027830593 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.49e+03      |
| explained_variance | -6.4e-05      |
| fps                | 32            |
| n_updates          | 74            |
| policy_entropy     | 1.4443679     |
| policy_loss        | -0.0022217173 |
| serial_timesteps   | 9472          |
| time_elapsed       | 288           |
| total_timesteps    | 9472          |
| value_loss         | 197.15099     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00015293194  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.49e+03       |
| explained_variance | -0.000145      |
| fps                | 32             |
| n_updates          | 75             |
| policy_entropy     | 1.4442623      |
| policy_loss        | -0.00017720705 |
| serial_timesteps   | 9600           |
| time_elapsed       | 292            |
| total_timesteps    | 9600           |
| value_loss         | 241.53021      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0024423765  |
| clipfrac           | 0.01171875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.49e+03      |
| explained_variance | 0.000993      |
| fps                | 33            |
| n_updates          | 76            |
| policy_entropy     | 1.4447675     |
| policy_loss        | 0.00045579067 |
| serial_timesteps   | 9728          |
| time_elapsed       | 296           |
| total_timesteps    | 9728          |
| value_loss         | 498.52966     |
--------------------------------------
-------------------------------------
| approxkl           | 0.013141395  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.49e+03     |
| explained_variance | -0.00159     |
| fps                | 35           |
| n_updates          | 77           |
| policy_entropy     | 1.445047     |
| policy_loss        | -0.015446575 |
| serial_timesteps   | 9856         |
| time_elapsed       | 300          |
| total_timesteps    | 9856         |
| value_loss         | 271.20398    |
-------------------------------------
--------------------------------------
| approxkl           | 8.8165514e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.49e+03      |
| explained_variance | 5.17e-05      |
| fps                | 35            |
| n_updates          | 78            |
| policy_entropy     | 1.4456338     |
| policy_loss        | -0.0012575001 |
| serial_timesteps   | 9984          |
| time_elapsed       | 304           |
| total_timesteps    | 9984          |
| value_loss         | 229.96202     |
--------------------------------------
--------------------------------------
| approxkl           | 6.0167862e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.49e+03      |
| explained_variance | -0.000935     |
| fps                | 38            |
| n_updates          | 79            |
| policy_entropy     | 1.4460703     |
| policy_loss        | 0.00065110484 |
| serial_timesteps   | 10112         |
| time_elapsed       | 307           |
| total_timesteps    | 10112         |
| value_loss         | 109.32877     |
--------------------------------------
An average of 65.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2587.48
---------------------------------------
| approxkl           | 1.3176194e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.49e+03       |
| explained_variance | 0.000872       |
| fps                | 34             |
| n_updates          | 80             |
| policy_entropy     | 1.4460267      |
| policy_loss        | -3.3853576e-07 |
| serial_timesteps   | 10240          |
| time_elapsed       | 310            |
| total_timesteps    | 10240          |
| value_loss         | 98.084625      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0074341767 |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.49e+03     |
| explained_variance | -0.00014     |
| fps                | 36           |
| n_updates          | 81           |
| policy_entropy     | 1.4466764    |
| policy_loss        | -0.012655558 |
| serial_timesteps   | 10368        |
| time_elapsed       | 314          |
| total_timesteps    | 10368        |
| value_loss         | 43.475143    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0011167449 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.49e+03     |
| explained_variance | 0.000612     |
| fps                | 33           |
| n_updates          | 82           |
| policy_entropy     | 1.4474562    |
| policy_loss        | 0.0043952544 |
| serial_timesteps   | 10496        |
| time_elapsed       | 318          |
| total_timesteps    | 10496        |
| value_loss         | 271.3778     |
-------------------------------------
---------------------------------------
| approxkl           | 6.510648e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.49e+03       |
| explained_variance | -0.000328      |
| fps                | 31             |
| n_updates          | 83             |
| policy_entropy     | 1.4475837      |
| policy_loss        | -0.00058163726 |
| serial_timesteps   | 10624          |
| time_elapsed       | 322            |
| total_timesteps    | 10624          |
| value_loss         | 429.89563      |
---------------------------------------
--------------------------------------
| approxkl           | 0.016189357   |
| clipfrac           | 0.23632812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.49e+03      |
| explained_variance | 0.000178      |
| fps                | 34            |
| n_updates          | 84            |
| policy_entropy     | 1.4456853     |
| policy_loss        | -0.0046518613 |
| serial_timesteps   | 10752         |
| time_elapsed       | 326           |
| total_timesteps    | 10752         |
| value_loss         | 144.71924     |
--------------------------------------
-------------------------------------
| approxkl           | 5.693602e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.5e+03      |
| explained_variance | -6.4e-05     |
| fps                | 31           |
| n_updates          | 85           |
| policy_entropy     | 1.4446698    |
| policy_loss        | 0.0011178898 |
| serial_timesteps   | 10880        |
| time_elapsed       | 329          |
| total_timesteps    | 10880        |
| value_loss         | 409.03976    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00019395784 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.5e+03       |
| explained_variance | 4.48e-05      |
| fps                | 31            |
| n_updates          | 86            |
| policy_entropy     | 1.4443015     |
| policy_loss        | -0.0037655318 |
| serial_timesteps   | 11008         |
| time_elapsed       | 333           |
| total_timesteps    | 11008         |
| value_loss         | 166.16612     |
--------------------------------------
------------------------------------
| approxkl           | 0.016758824 |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.5e+03     |
| explained_variance | -0.000331   |
| fps                | 33          |
| n_updates          | 87          |
| policy_entropy     | 1.442926    |
| policy_loss        | 0.024272848 |
| serial_timesteps   | 11136       |
| time_elapsed       | 338         |
| total_timesteps    | 11136       |
| value_loss         | 143.46417   |
------------------------------------
An average of 66.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2668.42
-------------------------------------
| approxkl           | 0.0070755174 |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.5e+03      |
| explained_variance | 0.000455     |
| fps                | 31           |
| n_updates          | 88           |
| policy_entropy     | 1.4420707    |
| policy_loss        | 0.0023202577 |
| serial_timesteps   | 11264        |
| time_elapsed       | 341          |
| total_timesteps    | 11264        |
| value_loss         | 348.8169     |
-------------------------------------
--------------------------------------
| approxkl           | 0.001993698   |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.5e+03       |
| explained_variance | -0.0013       |
| fps                | 37            |
| n_updates          | 89            |
| policy_entropy     | 1.4416275     |
| policy_loss        | -0.0014574811 |
| serial_timesteps   | 11392         |
| time_elapsed       | 345           |
| total_timesteps    | 11392         |
| value_loss         | 351.5649      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00025689887 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.5e+03       |
| explained_variance | -0.000726     |
| fps                | 32            |
| n_updates          | 90            |
| policy_entropy     | 1.4403896     |
| policy_loss        | 0.004941621   |
| serial_timesteps   | 11520         |
| time_elapsed       | 349           |
| total_timesteps    | 11520         |
| value_loss         | 153.23009     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0059480243 |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.5e+03      |
| explained_variance | -2.41e-05    |
| fps                | 34           |
| n_updates          | 91           |
| policy_entropy     | 1.4394393    |
| policy_loss        | -0.025829855 |
| serial_timesteps   | 11648        |
| time_elapsed       | 353          |
| total_timesteps    | 11648        |
| value_loss         | 131.94785    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00058302353 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.5e+03       |
| explained_variance | -4.4e-05      |
| fps                | 31            |
| n_updates          | 92            |
| policy_entropy     | 1.4386837     |
| policy_loss        | 0.0058571934  |
| serial_timesteps   | 11776         |
| time_elapsed       | 356           |
| total_timesteps    | 11776         |
| value_loss         | 164.72852     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0105229225 |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.5e+03      |
| explained_variance | -7.25e-05    |
| fps                | 35           |
| n_updates          | 93           |
| policy_entropy     | 1.4363754    |
| policy_loss        | -0.0234389   |
| serial_timesteps   | 11904        |
| time_elapsed       | 361          |
| total_timesteps    | 11904        |
| value_loss         | 139.92729    |
-------------------------------------
------------------------------------
| approxkl           | 0.01635753  |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.5e+03     |
| explained_variance | -5.19e-05   |
| fps                | 35          |
| n_updates          | 94          |
| policy_entropy     | 1.4352399   |
| policy_loss        | -0.00928445 |
| serial_timesteps   | 12032       |
| time_elapsed       | 364         |
| total_timesteps    | 12032       |
| value_loss         | 38.857258   |
------------------------------------
An average of 66.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2668.42
-------------------------------------
| approxkl           | 0.0017749495 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.5e+03      |
| explained_variance | -9.35e-05    |
| fps                | 30           |
| n_updates          | 95           |
| policy_entropy     | 1.4354733    |
| policy_loss        | 0.005645192  |
| serial_timesteps   | 12160        |
| time_elapsed       | 368          |
| total_timesteps    | 12160        |
| value_loss         | 96.07678     |
-------------------------------------
--------------------------------------
| approxkl           | 0.000405835   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.5e+03       |
| explained_variance | 9.66e-05      |
| fps                | 33            |
| n_updates          | 96            |
| policy_entropy     | 1.4355692     |
| policy_loss        | -0.0045380145 |
| serial_timesteps   | 12288         |
| time_elapsed       | 372           |
| total_timesteps    | 12288         |
| value_loss         | 56.909958     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00026184347 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.53e+03      |
| explained_variance | -1.35e-05     |
| fps                | 33            |
| n_updates          | 97            |
| policy_entropy     | 1.4355625     |
| policy_loss        | 0.002588608   |
| serial_timesteps   | 12416         |
| time_elapsed       | 376           |
| total_timesteps    | 12416         |
| value_loss         | 482.70477     |
--------------------------------------
--------------------------------------
| approxkl           | 5.691182e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.53e+03      |
| explained_variance | -5.79e-05     |
| fps                | 32            |
| n_updates          | 98            |
| policy_entropy     | 1.4356016     |
| policy_loss        | -0.0010964748 |
| serial_timesteps   | 12544         |
| time_elapsed       | 380           |
| total_timesteps    | 12544         |
| value_loss         | 272.3418      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0106171025 |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.53e+03     |
| explained_variance | 1.16e-05     |
| fps                | 30           |
| n_updates          | 99           |
| policy_entropy     | 1.4360965    |
| policy_loss        | 0.0078345975 |
| serial_timesteps   | 12672        |
| time_elapsed       | 384          |
| total_timesteps    | 12672        |
| value_loss         | 389.80255    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005933635   |
| clipfrac           | 0.0703125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.53e+03      |
| explained_variance | -0.000399     |
| fps                | 30            |
| n_updates          | 100           |
| policy_entropy     | 1.4359763     |
| policy_loss        | 0.00026667968 |
| serial_timesteps   | 12800         |
| time_elapsed       | 388           |
| total_timesteps    | 12800         |
| value_loss         | 46.614838     |
--------------------------------------
---------------------------------------
| approxkl           | 2.1628694e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.53e+03       |
| explained_variance | -0.000212      |
| fps                | 33             |
| n_updates          | 101            |
| policy_entropy     | 1.435514       |
| policy_loss        | -0.00032395916 |
| serial_timesteps   | 12928          |
| time_elapsed       | 392            |
| total_timesteps    | 12928          |
| value_loss         | 253.10918      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0017118576 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.53e+03     |
| explained_variance | -0.000476    |
| fps                | 31           |
| n_updates          | 102          |
| policy_entropy     | 1.4344523    |
| policy_loss        | -0.008489024 |
| serial_timesteps   | 13056        |
| time_elapsed       | 396          |
| total_timesteps    | 13056        |
| value_loss         | 270.2715     |
-------------------------------------
An average of 67.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2670.95
-------------------------------------
| approxkl           | 0.0059861327 |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.53e+03     |
| explained_variance | 0.000117     |
| fps                | 32           |
| n_updates          | 103          |
| policy_entropy     | 1.4332622    |
| policy_loss        | 0.030538442  |
| serial_timesteps   | 13184        |
| time_elapsed       | 400          |
| total_timesteps    | 13184        |
| value_loss         | 226.60413    |
-------------------------------------
------------------------------------
| approxkl           | 0.007656608 |
| clipfrac           | 0.119140625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.53e+03    |
| explained_variance | -0.0009     |
| fps                | 30          |
| n_updates          | 104         |
| policy_entropy     | 1.4320383   |
| policy_loss        | 0.010183148 |
| serial_timesteps   | 13312       |
| time_elapsed       | 404         |
| total_timesteps    | 13312       |
| value_loss         | 502.21655   |
------------------------------------
------------------------------------
| approxkl           | 0.006933976 |
| clipfrac           | 0.109375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 2.53e+03    |
| explained_variance | -5.28e-05   |
| fps                | 32          |
| n_updates          | 105         |
| policy_entropy     | 1.4317665   |
| policy_loss        | 0.020020403 |
| serial_timesteps   | 13440       |
| time_elapsed       | 408         |
| total_timesteps    | 13440       |
| value_loss         | 271.6033    |
------------------------------------
-------------------------------------
| approxkl           | 0.011136642  |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.53e+03     |
| explained_variance | -6.21e-05    |
| fps                | 29           |
| n_updates          | 106          |
| policy_entropy     | 1.4318335    |
| policy_loss        | -0.028376287 |
| serial_timesteps   | 13568        |
| time_elapsed       | 412          |
| total_timesteps    | 13568        |
| value_loss         | 178.92902    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0003519343 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.53e+03     |
| explained_variance | -0.000434    |
| fps                | 32           |
| n_updates          | 107          |
| policy_entropy     | 1.4315414    |
| policy_loss        | 0.004299359  |
| serial_timesteps   | 13696        |
| time_elapsed       | 416          |
| total_timesteps    | 13696        |
| value_loss         | 297.72144    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00023303663 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.53e+03      |
| explained_variance | -0.00048      |
| fps                | 32            |
| n_updates          | 108           |
| policy_entropy     | 1.430649      |
| policy_loss        | 0.0045607765  |
| serial_timesteps   | 13824         |
| time_elapsed       | 420           |
| total_timesteps    | 13824         |
| value_loss         | 344.68246     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012833082  |
| clipfrac           | 0.2109375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.63e+03     |
| explained_variance | -8.82e-06    |
| fps                | 33           |
| n_updates          | 109          |
| policy_entropy     | 1.4293138    |
| policy_loss        | 0.0014939173 |
| serial_timesteps   | 13952        |
| time_elapsed       | 424          |
| total_timesteps    | 13952        |
| value_loss         | 232.72647    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00011102373 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.63e+03      |
| explained_variance | -0.000167     |
| fps                | 31            |
| n_updates          | 110           |
| policy_entropy     | 1.428315      |
| policy_loss        | 0.00067266636 |
| serial_timesteps   | 14080         |
| time_elapsed       | 428           |
| total_timesteps    | 14080         |
| value_loss         | 77.74753      |
--------------------------------------
An average of 68.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2815.41
---------------------------------------
| approxkl           | 1.3776735e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 2.63e+03       |
| explained_variance | 0.000249       |
| fps                | 32             |
| n_updates          | 111            |
| policy_entropy     | 1.4282421      |
| policy_loss        | -0.00013273861 |
| serial_timesteps   | 14208          |
| time_elapsed       | 432            |
| total_timesteps    | 14208          |
| value_loss         | 75.13424       |
---------------------------------------
-------------------------------------
| approxkl           | 0.003170021  |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.63e+03     |
| explained_variance | -5.03e-05    |
| fps                | 32           |
| n_updates          | 112          |
| policy_entropy     | 1.4286883    |
| policy_loss        | -0.013915686 |
| serial_timesteps   | 14336        |
| time_elapsed       | 436          |
| total_timesteps    | 14336        |
| value_loss         | 321.71365    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0002094082  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.63e+03      |
| explained_variance | 0.00013       |
| fps                | 33            |
| n_updates          | 113           |
| policy_entropy     | 1.4288988     |
| policy_loss        | 0.00023765338 |
| serial_timesteps   | 14464         |
| time_elapsed       | 440           |
| total_timesteps    | 14464         |
| value_loss         | 327.88736     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0021790531 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.63e+03     |
| explained_variance | -0.000156    |
| fps                | 33           |
| n_updates          | 114          |
| policy_entropy     | 1.4285604    |
| policy_loss        | -0.004812004 |
| serial_timesteps   | 14592        |
| time_elapsed       | 444          |
| total_timesteps    | 14592        |
| value_loss         | 398.9192     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0007099825 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.63e+03     |
| explained_variance | 4.82e-05     |
| fps                | 33           |
| n_updates          | 115          |
| policy_entropy     | 1.4276108    |
| policy_loss        | 0.0037922862 |
| serial_timesteps   | 14720        |
| time_elapsed       | 447          |
| total_timesteps    | 14720        |
| value_loss         | 183.40977    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00019604032 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 2.63e+03      |
| explained_variance | -0.000124     |
| fps                | 34            |
| n_updates          | 116           |
| policy_entropy     | 1.4270663     |
| policy_loss        | -0.003203416  |
| serial_timesteps   | 14848         |
| time_elapsed       | 451           |
| total_timesteps    | 14848         |
| value_loss         | 469.32516     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0075855125 |
| clipfrac           | 0.107421875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 2.63e+03     |
| explained_variance | -1.72e-05    |
| fps                | 32           |
| n_updates          | 117          |
| policy_entropy     | 1.426676     |
| policy_loss        | -0.019410403 |
| serial_timesteps   | 14976        |
| time_elapsed       | 455          |
| total_timesteps    | 14976        |
| value_loss         | 31.948223    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b7cf99eb8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b7cf99eb8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b7cf19c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b7cf19c18>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2525 samples, validate on 137 samples
Epoch 166/5000
 - 2s - loss: 0.2035 - val_loss: 0.1410
Epoch 167/5000
 - 0s - loss: 0.2035 - val_loss: 0.1410
Epoch 168/5000
 - 0s - loss: 0.2035 - val_loss: 0.1410
Epoch 169/5000
 - 0s - loss: 0.2035 - val_loss: 0.1410
Epoch 170/5000
 - 0s - loss: 0.2035 - val_loss: 0.1410
Epoch 171/5000
 - 0s - loss: 0.2035 - val_loss: 0.1410
Train on 1976 samples, validate on 137 samples
Epoch 129/5000
 - 2s - loss: 0.0049 - val_loss: 0.0015
Epoch 130/5000
 - 0s - loss: 0.0024 - val_loss: 0.0010
Epoch 131/5000
 - 0s - loss: 0.0019 - val_loss: 0.0011
Epoch 132/5000
 - 0s - loss: 0.0014 - val_loss: 0.0013
Epoch 133/5000
 - 0s - loss: 0.0013 - val_loss: 7.4813e-04
Epoch 134/5000
 - 0s - loss: 0.0011 - val_loss: 7.5254e-04
Epoch 135/5000
 - 0s - loss: 0.0010 - val_loss: 7.6318e-04
Epoch 136/5000
 - 0s - loss: 0.0010 - val_loss: 7.7155e-04
Epoch 137/5000
 - 0s - loss: 9.9601e-04 - val_loss: 7.6662e-04
Epoch 138/5000
 - 0s - loss: 9.9356e-04 - val_loss: 7.6171e-04
Train on 2526 samples, validate on 137 samples
Epoch 145/5000
 - 4s - loss: 0.6409 - val_loss: 0.6533
Epoch 146/5000
 - 1s - loss: 0.5233 - val_loss: 0.6990
Epoch 147/5000
 - 1s - loss: 0.5118 - val_loss: 0.7219
Epoch 148/5000
 - 1s - loss: 0.4952 - val_loss: 0.7212
Epoch 149/5000
 - 1s - loss: 0.4950 - val_loss: 0.7205
Epoch 150/5000
 - 1s - loss: 0.4948 - val_loss: 0.7198
setting environment to train mode..... 

Training Started... 

---------------------------------------
| approxkl           | 0.00073068525  |
| clipfrac           | 0.0            |
| explained_variance | -6.25e-05      |
| fps                | 9              |
| n_updates          | 1              |
| policy_entropy     | 1.4262544      |
| policy_loss        | -0.00062885124 |
| serial_timesteps   | 128            |
| time_elapsed       | 1.22e-05       |
| total_timesteps    | 128            |
| value_loss         | 272.11285      |
---------------------------------------
An average of 69.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2224.82
--------------------------------------
| approxkl           | 0.00027260458 |
| clipfrac           | 0.001953125   |
| explained_variance | 1.53e-05      |
| fps                | 31            |
| n_updates          | 2             |
| policy_entropy     | 1.4261429     |
| policy_loss        | -0.0027047484 |
| serial_timesteps   | 256           |
| time_elapsed       | 13.9          |
| total_timesteps    | 256           |
| value_loss         | 144.76807     |
--------------------------------------
--------------------------------------
| approxkl           | 0.017014526   |
| clipfrac           | 0.24804688    |
| explained_variance | -0.000259     |
| fps                | 34            |
| n_updates          | 3             |
| policy_entropy     | 1.4267911     |
| policy_loss        | -0.0021504462 |
| serial_timesteps   | 384           |
| time_elapsed       | 17.9          |
| total_timesteps    | 384           |
| value_loss         | 335.68106     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0010562451   |
| clipfrac           | 0.00390625     |
| explained_variance | 7.63e-05       |
| fps                | 33             |
| n_updates          | 4              |
| policy_entropy     | 1.4272623      |
| policy_loss        | -0.00016892958 |
| serial_timesteps   | 512            |
| time_elapsed       | 21.7           |
| total_timesteps    | 512            |
| value_loss         | 146.63574      |
---------------------------------------
--------------------------------------
| approxkl           | 2.2736296e-05 |
| clipfrac           | 0.0           |
| explained_variance | -8.52e-05     |
| fps                | 36            |
| n_updates          | 5             |
| policy_entropy     | 1.4277272     |
| policy_loss        | -0.00095276   |
| serial_timesteps   | 640           |
| time_elapsed       | 25.5          |
| total_timesteps    | 640           |
| value_loss         | 342.21478     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00045422732 |
| clipfrac           | 0.0           |
| explained_variance | -4.02e-05     |
| fps                | 32            |
| n_updates          | 6             |
| policy_entropy     | 1.4278576     |
| policy_loss        | -0.0051339916 |
| serial_timesteps   | 768           |
| time_elapsed       | 29            |
| total_timesteps    | 768           |
| value_loss         | 63.09592      |
--------------------------------------
------------------------------------
| approxkl           | 0.017572688 |
| clipfrac           | 0.2734375   |
| explained_variance | -6.94e-05   |
| fps                | 31          |
| n_updates          | 7           |
| policy_entropy     | 1.428411    |
| policy_loss        | 0.031107005 |
| serial_timesteps   | 896         |
| time_elapsed       | 32.9        |
| total_timesteps    | 896         |
| value_loss         | 422.19235   |
------------------------------------
-------------------------------------
| approxkl           | 0.0018345874 |
| clipfrac           | 0.013671875  |
| explained_variance | -0.000136    |
| fps                | 31           |
| n_updates          | 8            |
| policy_entropy     | 1.4284518    |
| policy_loss        | -0.009465573 |
| serial_timesteps   | 1024         |
| time_elapsed       | 36.9         |
| total_timesteps    | 1024         |
| value_loss         | 294.50397    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0056970264  |
| clipfrac           | 0.078125      |
| explained_variance | -1.24e-05     |
| fps                | 34            |
| n_updates          | 9             |
| policy_entropy     | 1.426051      |
| policy_loss        | -0.0054796943 |
| serial_timesteps   | 1152          |
| time_elapsed       | 41.1          |
| total_timesteps    | 1152          |
| value_loss         | 329.15652     |
--------------------------------------
An average of 69.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2224.82
--------------------------------------
| approxkl           | 0.000246598   |
| clipfrac           | 0.0           |
| explained_variance | -0.000652     |
| fps                | 32            |
| n_updates          | 10            |
| policy_entropy     | 1.4237963     |
| policy_loss        | -0.0042085564 |
| serial_timesteps   | 1280          |
| time_elapsed       | 44.8          |
| total_timesteps    | 1280          |
| value_loss         | 170.67073     |
--------------------------------------
-------------------------------------
| approxkl           | 0.013578096  |
| clipfrac           | 0.18164062   |
| explained_variance | 2.5e-06      |
| fps                | 35           |
| n_updates          | 11           |
| policy_entropy     | 1.4233464    |
| policy_loss        | -0.022662342 |
| serial_timesteps   | 1408         |
| time_elapsed       | 48.8         |
| total_timesteps    | 1408         |
| value_loss         | 232.9606     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0018614418 |
| clipfrac           | 0.001953125  |
| explained_variance | 5.98e-05     |
| fps                | 29           |
| n_updates          | 12           |
| policy_entropy     | 1.4229063    |
| policy_loss        | 0.0004640501 |
| serial_timesteps   | 1536         |
| time_elapsed       | 52.3         |
| total_timesteps    | 1536         |
| value_loss         | 393.8207     |
-------------------------------------
---------------------------------------
| approxkl           | 0.0024030437   |
| clipfrac           | 0.015625       |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.42e+03       |
| explained_variance | 1.53e-05       |
| fps                | 31             |
| n_updates          | 13             |
| policy_entropy     | 1.4236083      |
| policy_loss        | -0.00041547348 |
| serial_timesteps   | 1664           |
| time_elapsed       | 56.6           |
| total_timesteps    | 1664           |
| value_loss         | 415.5766       |
---------------------------------------
-------------------------------------
| approxkl           | 0.0014430722 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | 0.000454     |
| fps                | 29           |
| n_updates          | 14           |
| policy_entropy     | 1.424038     |
| policy_loss        | 0.001912131  |
| serial_timesteps   | 1792         |
| time_elapsed       | 60.8         |
| total_timesteps    | 1792         |
| value_loss         | 398.5142     |
-------------------------------------
-------------------------------------
| approxkl           | 7.994435e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | 0.000362     |
| fps                | 34           |
| n_updates          | 15           |
| policy_entropy     | 1.4227194    |
| policy_loss        | 0.0004813813 |
| serial_timesteps   | 1920         |
| time_elapsed       | 65           |
| total_timesteps    | 1920         |
| value_loss         | 385.9433     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0034994686 |
| clipfrac           | 0.03125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | -0.00021     |
| fps                | 34           |
| n_updates          | 16           |
| policy_entropy     | 1.4207162    |
| policy_loss        | 0.016272925  |
| serial_timesteps   | 2048         |
| time_elapsed       | 68.8         |
| total_timesteps    | 2048         |
| value_loss         | 154.72125    |
-------------------------------------
An average of 70.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2383.53
-------------------------------------
| approxkl           | 0.0012272665 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | -2.19e-05    |
| fps                | 30           |
| n_updates          | 17           |
| policy_entropy     | 1.4197516    |
| policy_loss        | -0.009605905 |
| serial_timesteps   | 2176         |
| time_elapsed       | 72.5         |
| total_timesteps    | 2176         |
| value_loss         | 202.40445    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0154808    |
| clipfrac           | 0.21679688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | 0.000133     |
| fps                | 32           |
| n_updates          | 18           |
| policy_entropy     | 1.4193054    |
| policy_loss        | 0.0003986596 |
| serial_timesteps   | 2304         |
| time_elapsed       | 76.7         |
| total_timesteps    | 2304         |
| value_loss         | 420.2416     |
-------------------------------------
--------------------------------------
| approxkl           | 0.004211717   |
| clipfrac           | 0.046875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.42e+03      |
| explained_variance | -0.000139     |
| fps                | 34            |
| n_updates          | 19            |
| policy_entropy     | 1.4193542     |
| policy_loss        | -0.0091614425 |
| serial_timesteps   | 2432          |
| time_elapsed       | 80.6          |
| total_timesteps    | 2432          |
| value_loss         | 200.30898     |
--------------------------------------
-------------------------------------
| approxkl           | 0.003620604  |
| clipfrac           | 0.03125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | -4.72e-05    |
| fps                | 33           |
| n_updates          | 20           |
| policy_entropy     | 1.4187496    |
| policy_loss        | -0.014433996 |
| serial_timesteps   | 2560         |
| time_elapsed       | 84.4         |
| total_timesteps    | 2560         |
| value_loss         | 161.97435    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0050684107 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | -0.000189    |
| fps                | 33           |
| n_updates          | 21           |
| policy_entropy     | 1.4176307    |
| policy_loss        | 0.014076804  |
| serial_timesteps   | 2688         |
| time_elapsed       | 88.2         |
| total_timesteps    | 2688         |
| value_loss         | 167.05893    |
-------------------------------------
-------------------------------------
| approxkl           | 0.001876783  |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.42e+03     |
| explained_variance | -0.000209    |
| fps                | 29           |
| n_updates          | 22           |
| policy_entropy     | 1.4168465    |
| policy_loss        | 0.0054924777 |
| serial_timesteps   | 2816         |
| time_elapsed       | 92           |
| total_timesteps    | 2816         |
| value_loss         | 299.53445    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00015915968 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.42e+03      |
| explained_variance | -4.54e-05     |
| fps                | 31            |
| n_updates          | 23            |
| policy_entropy     | 1.4170368     |
| policy_loss        | -0.0011669187 |
| serial_timesteps   | 2944          |
| time_elapsed       | 96.4          |
| total_timesteps    | 2944          |
| value_loss         | 257.6249      |
--------------------------------------
--------------------------------------
| approxkl           | 2.2429098e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.42e+03      |
| explained_variance | -0.000435     |
| fps                | 32            |
| n_updates          | 24            |
| policy_entropy     | 1.4176297     |
| policy_loss        | 4.27037e-05   |
| serial_timesteps   | 3072          |
| time_elapsed       | 100           |
| total_timesteps    | 3072          |
| value_loss         | 371.63193     |
--------------------------------------
An average of 71.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2568.11
---------------------------------------
| approxkl           | 0.0062203044   |
| clipfrac           | 0.080078125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.46e+03       |
| explained_variance | -0.000106      |
| fps                | 32             |
| n_updates          | 25             |
| policy_entropy     | 1.4170305      |
| policy_loss        | -0.00031038327 |
| serial_timesteps   | 3200           |
| time_elapsed       | 104            |
| total_timesteps    | 3200           |
| value_loss         | 526.11163      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00021099471 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.46e+03      |
| explained_variance | -1.08e-05     |
| fps                | 36            |
| n_updates          | 26            |
| policy_entropy     | 1.4164822     |
| policy_loss        | -0.003890175  |
| serial_timesteps   | 3328          |
| time_elapsed       | 108           |
| total_timesteps    | 3328          |
| value_loss         | 74.65313      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0068753986 |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.46e+03     |
| explained_variance | -0.000318    |
| fps                | 32           |
| n_updates          | 27           |
| policy_entropy     | 1.4165169    |
| policy_loss        | -0.010196596 |
| serial_timesteps   | 3456         |
| time_elapsed       | 112          |
| total_timesteps    | 3456         |
| value_loss         | 202.66177    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0031661822 |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.46e+03     |
| explained_variance | -0.000105    |
| fps                | 33           |
| n_updates          | 28           |
| policy_entropy     | 1.4162105    |
| policy_loss        | 0.012415666  |
| serial_timesteps   | 3584         |
| time_elapsed       | 116          |
| total_timesteps    | 3584         |
| value_loss         | 202.01411    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0005212568 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.46e+03     |
| explained_variance | -1.18e-05    |
| fps                | 35           |
| n_updates          | 29           |
| policy_entropy     | 1.4163601    |
| policy_loss        | -0.007064575 |
| serial_timesteps   | 3712         |
| time_elapsed       | 120          |
| total_timesteps    | 3712         |
| value_loss         | 155.94856    |
-------------------------------------
------------------------------------
| approxkl           | 0.009586056 |
| clipfrac           | 0.13671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.46e+03    |
| explained_variance | -0.000469   |
| fps                | 33          |
| n_updates          | 30          |
| policy_entropy     | 1.4167448   |
| policy_loss        | 0.018246474 |
| serial_timesteps   | 3840        |
| time_elapsed       | 123         |
| total_timesteps    | 3840        |
| value_loss         | 289.6225    |
------------------------------------
------------------------------------
| approxkl           | 0.005415339 |
| clipfrac           | 0.064453125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.46e+03    |
| explained_variance | 3.03e-05    |
| fps                | 33          |
| n_updates          | 31          |
| policy_entropy     | 1.4169344   |
| policy_loss        | 0.017333994 |
| serial_timesteps   | 3968        |
| time_elapsed       | 127         |
| total_timesteps    | 3968        |
| value_loss         | 538.58655   |
------------------------------------
-------------------------------------
| approxkl           | 0.0036940048 |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.46e+03     |
| explained_variance | 3.02e-05     |
| fps                | 32           |
| n_updates          | 32           |
| policy_entropy     | 1.4178163    |
| policy_loss        | 0.007188755  |
| serial_timesteps   | 4096         |
| time_elapsed       | 131          |
| total_timesteps    | 4096         |
| value_loss         | 149.64403    |
-------------------------------------
An average of 71.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2568.11
--------------------------------------
| approxkl           | 0.0026807876  |
| clipfrac           | 0.015625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.46e+03      |
| explained_variance | 0.000106      |
| fps                | 32            |
| n_updates          | 33            |
| policy_entropy     | 1.4184394     |
| policy_loss        | -0.0077015175 |
| serial_timesteps   | 4224          |
| time_elapsed       | 135           |
| total_timesteps    | 4224          |
| value_loss         | 281.6612      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00027028265 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.46e+03      |
| explained_variance | -0.000288     |
| fps                | 31            |
| n_updates          | 34            |
| policy_entropy     | 1.4185399     |
| policy_loss        | 0.0034965356  |
| serial_timesteps   | 4352          |
| time_elapsed       | 139           |
| total_timesteps    | 4352          |
| value_loss         | 572.1477      |
--------------------------------------
------------------------------------
| approxkl           | 0.01164245  |
| clipfrac           | 0.1640625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.46e+03    |
| explained_variance | 2.16e-05    |
| fps                | 31          |
| n_updates          | 35          |
| policy_entropy     | 1.4182979   |
| policy_loss        | 0.005116506 |
| serial_timesteps   | 4480        |
| time_elapsed       | 143         |
| total_timesteps    | 4480        |
| value_loss         | 213.16537   |
------------------------------------
-------------------------------------
| approxkl           | 0.007623569  |
| clipfrac           | 0.12109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.46e+03     |
| explained_variance | 1.04e-05     |
| fps                | 33           |
| n_updates          | 36           |
| policy_entropy     | 1.4175453    |
| policy_loss        | -0.022180969 |
| serial_timesteps   | 4608         |
| time_elapsed       | 147          |
| total_timesteps    | 4608         |
| value_loss         | 435.1641     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0001818801  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.51e+03      |
| explained_variance | 5.66e-06      |
| fps                | 33            |
| n_updates          | 37            |
| policy_entropy     | 1.416956      |
| policy_loss        | -5.024986e-05 |
| serial_timesteps   | 4736          |
| time_elapsed       | 151           |
| total_timesteps    | 4736          |
| value_loss         | 304.05377     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00032566703 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.51e+03      |
| explained_variance | -0.000106     |
| fps                | 33            |
| n_updates          | 38            |
| policy_entropy     | 1.416438      |
| policy_loss        | 0.0045297984  |
| serial_timesteps   | 4864          |
| time_elapsed       | 155           |
| total_timesteps    | 4864          |
| value_loss         | 462.0579      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0022108173 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.51e+03     |
| explained_variance | 0.000863     |
| fps                | 30           |
| n_updates          | 39           |
| policy_entropy     | 1.4161309    |
| policy_loss        | 0.005194964  |
| serial_timesteps   | 4992         |
| time_elapsed       | 159          |
| total_timesteps    | 4992         |
| value_loss         | 410.0285     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0008620379 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.51e+03     |
| explained_variance | -0.00027     |
| fps                | 36           |
| n_updates          | 40           |
| policy_entropy     | 1.415936     |
| policy_loss        | 0.0011631581 |
| serial_timesteps   | 5120         |
| time_elapsed       | 163          |
| total_timesteps    | 5120         |
| value_loss         | 397.30588    |
-------------------------------------
An average of 72.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2756.09
--------------------------------------
| approxkl           | 9.763416e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.51e+03      |
| explained_variance | -0.000255     |
| fps                | 34            |
| n_updates          | 41            |
| policy_entropy     | 1.4148039     |
| policy_loss        | -0.0017485945 |
| serial_timesteps   | 5248          |
| time_elapsed       | 166           |
| total_timesteps    | 5248          |
| value_loss         | 350.5831      |
--------------------------------------
-------------------------------------
| approxkl           | 0.010344054  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.51e+03     |
| explained_variance | -5.84e-06    |
| fps                | 34           |
| n_updates          | 42           |
| policy_entropy     | 1.4124707    |
| policy_loss        | -0.016175698 |
| serial_timesteps   | 5376         |
| time_elapsed       | 170          |
| total_timesteps    | 5376         |
| value_loss         | 262.9551     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0004847771 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.51e+03     |
| explained_variance | -0.000251    |
| fps                | 33           |
| n_updates          | 43           |
| policy_entropy     | 1.411596     |
| policy_loss        | 0.0023167473 |
| serial_timesteps   | 5504         |
| time_elapsed       | 174          |
| total_timesteps    | 5504         |
| value_loss         | 495.72134    |
-------------------------------------
------------------------------------
| approxkl           | 0.008999021 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.51e+03    |
| explained_variance | -0.000372   |
| fps                | 29          |
| n_updates          | 44          |
| policy_entropy     | 1.4112695   |
| policy_loss        | 0.014882561 |
| serial_timesteps   | 5632        |
| time_elapsed       | 178         |
| total_timesteps    | 5632        |
| value_loss         | 419.42847   |
------------------------------------
--------------------------------------
| approxkl           | 2.9913237e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.51e+03      |
| explained_variance | -1.66e-05     |
| fps                | 33            |
| n_updates          | 45            |
| policy_entropy     | 1.4107845     |
| policy_loss        | 0.00071788556 |
| serial_timesteps   | 5760          |
| time_elapsed       | 182           |
| total_timesteps    | 5760          |
| value_loss         | 241.93071     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0020479895 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.51e+03     |
| explained_variance | 0.000277     |
| fps                | 33           |
| n_updates          | 46           |
| policy_entropy     | 1.4103425    |
| policy_loss        | 0.009680802  |
| serial_timesteps   | 5888         |
| time_elapsed       | 186          |
| total_timesteps    | 5888         |
| value_loss         | 363.3107     |
-------------------------------------
------------------------------------
| approxkl           | 0.006441751 |
| clipfrac           | 0.076171875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.51e+03    |
| explained_variance | -0.000174   |
| fps                | 32          |
| n_updates          | 47          |
| policy_entropy     | 1.409667    |
| policy_loss        | 0.018394498 |
| serial_timesteps   | 6016        |
| time_elapsed       | 189         |
| total_timesteps    | 6016        |
| value_loss         | 307.3166    |
------------------------------------
---------------------------------------
| approxkl           | 0.00021831406  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.51e+03       |
| explained_variance | -1.38e-05      |
| fps                | 33             |
| n_updates          | 48             |
| policy_entropy     | 1.4093258      |
| policy_loss        | -0.00022596761 |
| serial_timesteps   | 6144           |
| time_elapsed       | 193            |
| total_timesteps    | 6144           |
| value_loss         | 242.77571      |
---------------------------------------
An average of 72.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2756.09
-------------------------------------
| approxkl           | 0.0004643267 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.62e+03     |
| explained_variance | -3.67e-05    |
| fps                | 34           |
| n_updates          | 49           |
| policy_entropy     | 1.4077677    |
| policy_loss        | 0.002952232  |
| serial_timesteps   | 6272         |
| time_elapsed       | 197          |
| total_timesteps    | 6272         |
| value_loss         | 659.2179     |
-------------------------------------
---------------------------------------
| approxkl           | 2.0170828e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.62e+03       |
| explained_variance | -3.36e-05      |
| fps                | 32             |
| n_updates          | 50             |
| policy_entropy     | 1.4066976      |
| policy_loss        | -0.00037978264 |
| serial_timesteps   | 6400           |
| time_elapsed       | 201            |
| total_timesteps    | 6400           |
| value_loss         | 411.27405      |
---------------------------------------
---------------------------------------
| approxkl           | 0.004030787    |
| clipfrac           | 0.041015625    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.62e+03       |
| explained_variance | -6.51e-05      |
| fps                | 31             |
| n_updates          | 51             |
| policy_entropy     | 1.4064368      |
| policy_loss        | -0.00010449486 |
| serial_timesteps   | 6528           |
| time_elapsed       | 205            |
| total_timesteps    | 6528           |
| value_loss         | 87.74968       |
---------------------------------------
--------------------------------------
| approxkl           | 0.012225162   |
| clipfrac           | 0.18164062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.62e+03      |
| explained_variance | -8.37e-05     |
| fps                | 31            |
| n_updates          | 52            |
| policy_entropy     | 1.4067158     |
| policy_loss        | -0.0032540895 |
| serial_timesteps   | 6656          |
| time_elapsed       | 209           |
| total_timesteps    | 6656          |
| value_loss         | 254.15974     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0055736904 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.62e+03     |
| explained_variance | -8.12e-05    |
| fps                | 34           |
| n_updates          | 53           |
| policy_entropy     | 1.4067986    |
| policy_loss        | 0.020721264  |
| serial_timesteps   | 6784         |
| time_elapsed       | 213          |
| total_timesteps    | 6784         |
| value_loss         | 258.67502    |
-------------------------------------
------------------------------------
| approxkl           | 0.009751939 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.62e+03    |
| explained_variance | -8.26e-05   |
| fps                | 33          |
| n_updates          | 54          |
| policy_entropy     | 1.407077    |
| policy_loss        | 0.014274137 |
| serial_timesteps   | 6912        |
| time_elapsed       | 217         |
| total_timesteps    | 6912        |
| value_loss         | 412.19156   |
------------------------------------
------------------------------------
| approxkl           | 0.007947969 |
| clipfrac           | 0.111328125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.62e+03    |
| explained_variance | 0.000442    |
| fps                | 33          |
| n_updates          | 55          |
| policy_entropy     | 1.4068205   |
| policy_loss        | 0.021499354 |
| serial_timesteps   | 7040        |
| time_elapsed       | 221         |
| total_timesteps    | 7040        |
| value_loss         | 362.92685   |
------------------------------------
-------------------------------------
| approxkl           | 0.010236187  |
| clipfrac           | 0.16601562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.62e+03     |
| explained_variance | -0.000246    |
| fps                | 30           |
| n_updates          | 56           |
| policy_entropy     | 1.4066011    |
| policy_loss        | 0.0026326273 |
| serial_timesteps   | 7168         |
| time_elapsed       | 224          |
| total_timesteps    | 7168         |
| value_loss         | 356.67722    |
-------------------------------------
An average of 73.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 2853.90
-------------------------------------
| approxkl           | 0.010075377  |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.62e+03     |
| explained_variance | -8.79e-05    |
| fps                | 31           |
| n_updates          | 57           |
| policy_entropy     | 1.4056236    |
| policy_loss        | -0.013841504 |
| serial_timesteps   | 7296         |
| time_elapsed       | 229          |
| total_timesteps    | 7296         |
| value_loss         | 173.81268    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00035172695 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.62e+03      |
| explained_variance | 0.00022       |
| fps                | 32            |
| n_updates          | 58            |
| policy_entropy     | 1.4049796     |
| policy_loss        | -0.0015358826 |
| serial_timesteps   | 7424          |
| time_elapsed       | 233           |
| total_timesteps    | 7424          |
| value_loss         | 325.51962     |
--------------------------------------
------------------------------------
| approxkl           | 0.009464512 |
| clipfrac           | 0.14648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.62e+03    |
| explained_variance | -0.000201   |
| fps                | 31          |
| n_updates          | 59          |
| policy_entropy     | 1.4042227   |
| policy_loss        | 0.013449538 |
| serial_timesteps   | 7552        |
| time_elapsed       | 237         |
| total_timesteps    | 7552        |
| value_loss         | 673.11646   |
------------------------------------
------------------------------------
| approxkl           | 0.006222971 |
| clipfrac           | 0.072265625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.62e+03    |
| explained_variance | -1.41e-05   |
| fps                | 35          |
| n_updates          | 60          |
| policy_entropy     | 1.4032695   |
| policy_loss        | 0.01669247  |
| serial_timesteps   | 7680        |
| time_elapsed       | 241         |
| total_timesteps    | 7680        |
| value_loss         | 342.61328   |
------------------------------------
-------------------------------------
| approxkl           | 0.015133452  |
| clipfrac           | 0.20898438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | -7.43e-05    |
| fps                | 33           |
| n_updates          | 61           |
| policy_entropy     | 1.4029248    |
| policy_loss        | 0.0041578943 |
| serial_timesteps   | 7808         |
| time_elapsed       | 244          |
| total_timesteps    | 7808         |
| value_loss         | 370.00348    |
-------------------------------------
--------------------------------------
| approxkl           | 3.949774e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -0.000164     |
| fps                | 34            |
| n_updates          | 62            |
| policy_entropy     | 1.4028116     |
| policy_loss        | 0.00031762797 |
| serial_timesteps   | 7936          |
| time_elapsed       | 248           |
| total_timesteps    | 7936          |
| value_loss         | 422.50098     |
--------------------------------------
-------------------------------------
| approxkl           | 0.000525285  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | -0.000106    |
| fps                | 31           |
| n_updates          | 63           |
| policy_entropy     | 1.4021826    |
| policy_loss        | -0.004012443 |
| serial_timesteps   | 8064         |
| time_elapsed       | 252          |
| total_timesteps    | 8064         |
| value_loss         | 202.1208     |
-------------------------------------
An average of 74.0 episodes completed
Best mean reward: 2874.81 - Latest 5 sample mean reward per episode: 3709.67
Saving new best model
-------------------------------------
| approxkl           | 0.002105203  |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | 5.84e-06     |
| fps                | 31           |
| n_updates          | 64           |
| policy_entropy     | 1.4016055    |
| policy_loss        | -0.008029465 |
| serial_timesteps   | 8192         |
| time_elapsed       | 256          |
| total_timesteps    | 8192         |
| value_loss         | 227.50246    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00091219007 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -0.000101     |
| fps                | 31            |
| n_updates          | 65            |
| policy_entropy     | 1.4023272     |
| policy_loss        | -0.0001187661 |
| serial_timesteps   | 8320          |
| time_elapsed       | 260           |
| total_timesteps    | 8320          |
| value_loss         | 555.97144     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0012469384 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | 5.19e-06     |
| fps                | 31           |
| n_updates          | 66           |
| policy_entropy     | 1.402409     |
| policy_loss        | 0.001395648  |
| serial_timesteps   | 8448         |
| time_elapsed       | 264          |
| total_timesteps    | 8448         |
| value_loss         | 364.89484    |
-------------------------------------
--------------------------------------
| approxkl           | 2.7417478e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -3.19e-05     |
| fps                | 31            |
| n_updates          | 67            |
| policy_entropy     | 1.4022207     |
| policy_loss        | -0.0005194741 |
| serial_timesteps   | 8576          |
| time_elapsed       | 268           |
| total_timesteps    | 8576          |
| value_loss         | 147.93173     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0026379204  |
| clipfrac           | 0.0234375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -2.54e-05     |
| fps                | 35            |
| n_updates          | 68            |
| policy_entropy     | 1.4020381     |
| policy_loss        | -0.0035914516 |
| serial_timesteps   | 8704          |
| time_elapsed       | 272           |
| total_timesteps    | 8704          |
| value_loss         | 124.76088     |
--------------------------------------
--------------------------------------
| approxkl           | 9.738799e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -3.12e-05     |
| fps                | 31            |
| n_updates          | 69            |
| policy_entropy     | 1.4019816     |
| policy_loss        | 0.00074136234 |
| serial_timesteps   | 8832          |
| time_elapsed       | 276           |
| total_timesteps    | 8832          |
| value_loss         | 225.9352      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0013186148 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | -1.31e-06    |
| fps                | 33           |
| n_updates          | 70           |
| policy_entropy     | 1.4014697    |
| policy_loss        | 0.002668005  |
| serial_timesteps   | 8960         |
| time_elapsed       | 280          |
| total_timesteps    | 8960         |
| value_loss         | 517.0083     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00026530767 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -0.000891     |
| fps                | 32            |
| n_updates          | 71            |
| policy_entropy     | 1.4016768     |
| policy_loss        | 0.004895996   |
| serial_timesteps   | 9088          |
| time_elapsed       | 284           |
| total_timesteps    | 9088          |
| value_loss         | 94.13919      |
--------------------------------------
An average of 74.0 episodes completed
Best mean reward: 3709.67 - Latest 5 sample mean reward per episode: 3709.67
-------------------------------------
| approxkl           | 0.009889266  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | -0.000134    |
| fps                | 34           |
| n_updates          | 72           |
| policy_entropy     | 1.4014828    |
| policy_loss        | 0.0035649403 |
| serial_timesteps   | 9216         |
| time_elapsed       | 288          |
| total_timesteps    | 9216         |
| value_loss         | 486.34998    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0013395363 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | -1.55e-06    |
| fps                | 31           |
| n_updates          | 73           |
| policy_entropy     | 1.4014816    |
| policy_loss        | 0.0007712629 |
| serial_timesteps   | 9344         |
| time_elapsed       | 291          |
| total_timesteps    | 9344         |
| value_loss         | 423.6895     |
-------------------------------------
--------------------------------------
| approxkl           | 3.9600927e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -8.89e-05     |
| fps                | 31            |
| n_updates          | 74            |
| policy_entropy     | 1.4018463     |
| policy_loss        | 8.325378e-05  |
| serial_timesteps   | 9472          |
| time_elapsed       | 295           |
| total_timesteps    | 9472          |
| value_loss         | 407.5399      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0134329805 |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | 0.000104     |
| fps                | 32           |
| n_updates          | 75           |
| policy_entropy     | 1.4009776    |
| policy_loss        | -0.019986002 |
| serial_timesteps   | 9600         |
| time_elapsed       | 299          |
| total_timesteps    | 9600         |
| value_loss         | 258.5124     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0066512916  |
| clipfrac           | 0.078125      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | 1.13e-05      |
| fps                | 32            |
| n_updates          | 76            |
| policy_entropy     | 1.4002124     |
| policy_loss        | -0.0027552783 |
| serial_timesteps   | 9728          |
| time_elapsed       | 303           |
| total_timesteps    | 9728          |
| value_loss         | 414.60886     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00037429167 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -0.000168     |
| fps                | 32            |
| n_updates          | 77            |
| policy_entropy     | 1.4008048     |
| policy_loss        | 9.830482e-05  |
| serial_timesteps   | 9856          |
| time_elapsed       | 307           |
| total_timesteps    | 9856          |
| value_loss         | 258.5932      |
--------------------------------------
------------------------------------
| approxkl           | 0.008947799 |
| clipfrac           | 0.13085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.71e+03    |
| explained_variance | -7.74e-05   |
| fps                | 33          |
| n_updates          | 78          |
| policy_entropy     | 1.3998646   |
| policy_loss        | 0.029687159 |
| serial_timesteps   | 9984        |
| time_elapsed       | 311         |
| total_timesteps    | 9984        |
| value_loss         | 213.57031   |
------------------------------------
------------------------------------
| approxkl           | 0.010884365 |
| clipfrac           | 0.15820312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.71e+03    |
| explained_variance | -8.94e-06   |
| fps                | 33          |
| n_updates          | 79          |
| policy_entropy     | 1.3993733   |
| policy_loss        | 0.009494223 |
| serial_timesteps   | 10112       |
| time_elapsed       | 315         |
| total_timesteps    | 10112       |
| value_loss         | 230.09918   |
------------------------------------
An average of 75.0 episodes completed
Best mean reward: 3709.67 - Latest 5 sample mean reward per episode: 3770.60
Saving new best model
--------------------------------------
| approxkl           | 0.0002563631  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | 0.000143      |
| fps                | 31            |
| n_updates          | 80            |
| policy_entropy     | 1.3994046     |
| policy_loss        | 0.00079140766 |
| serial_timesteps   | 10240         |
| time_elapsed       | 319           |
| total_timesteps    | 10240         |
| value_loss         | 259.3643      |
--------------------------------------
--------------------------------------
| approxkl           | 5.4442586e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -6.88e-05     |
| fps                | 33            |
| n_updates          | 81            |
| policy_entropy     | 1.3989682     |
| policy_loss        | 0.0005673914  |
| serial_timesteps   | 10368         |
| time_elapsed       | 323           |
| total_timesteps    | 10368         |
| value_loss         | 381.5257      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0033409684 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | 7.69e-06     |
| fps                | 31           |
| n_updates          | 82           |
| policy_entropy     | 1.3982596    |
| policy_loss        | 0.0036206618 |
| serial_timesteps   | 10496        |
| time_elapsed       | 327          |
| total_timesteps    | 10496        |
| value_loss         | 127.7661     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0012477974 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.71e+03     |
| explained_variance | -4.88e-05    |
| fps                | 32           |
| n_updates          | 83           |
| policy_entropy     | 1.3972886    |
| policy_loss        | 0.002629829  |
| serial_timesteps   | 10624        |
| time_elapsed       | 331          |
| total_timesteps    | 10624        |
| value_loss         | 494.45245    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00095669704 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.71e+03      |
| explained_variance | -4.02e-05     |
| fps                | 35            |
| n_updates          | 84            |
| policy_entropy     | 1.3968155     |
| policy_loss        | -0.005319028  |
| serial_timesteps   | 10752         |
| time_elapsed       | 335           |
| total_timesteps    | 10752         |
| value_loss         | 70.97259      |
--------------------------------------
---------------------------------------
| approxkl           | 6.8060326e-06  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.74e+03       |
| explained_variance | -4.77e-06      |
| fps                | 31             |
| n_updates          | 85             |
| policy_entropy     | 1.396401       |
| policy_loss        | -0.00022240344 |
| serial_timesteps   | 10880          |
| time_elapsed       | 338            |
| total_timesteps    | 10880          |
| value_loss         | 567.5766       |
---------------------------------------
--------------------------------------
| approxkl           | 1.4679697e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.74e+03      |
| explained_variance | 0.000471      |
| fps                | 33            |
| n_updates          | 86            |
| policy_entropy     | 1.3963037     |
| policy_loss        | 0.0007764476  |
| serial_timesteps   | 11008         |
| time_elapsed       | 342           |
| total_timesteps    | 11008         |
| value_loss         | 449.33444     |
--------------------------------------
---------------------------------------
| approxkl           | 7.459708e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.74e+03       |
| explained_variance | -0.0002        |
| fps                | 34             |
| n_updates          | 87             |
| policy_entropy     | 1.3961658      |
| policy_loss        | -0.00055774127 |
| serial_timesteps   | 11136          |
| time_elapsed       | 346            |
| total_timesteps    | 11136          |
| value_loss         | 424.48553      |
---------------------------------------
An average of 76.0 episodes completed
Best mean reward: 3770.60 - Latest 5 sample mean reward per episode: 3847.99
Saving new best model
-------------------------------------
| approxkl           | 0.000503268  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.74e+03     |
| explained_variance | -0.000263    |
| fps                | 32           |
| n_updates          | 88           |
| policy_entropy     | 1.3968198    |
| policy_loss        | -0.003461163 |
| serial_timesteps   | 11264        |
| time_elapsed       | 350          |
| total_timesteps    | 11264        |
| value_loss         | 322.4362     |
-------------------------------------
--------------------------------------
| approxkl           | 0.000328668   |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.74e+03      |
| explained_variance | 7.57e-06      |
| fps                | 34            |
| n_updates          | 89            |
| policy_entropy     | 1.397108      |
| policy_loss        | -0.0036315792 |
| serial_timesteps   | 11392         |
| time_elapsed       | 354           |
| total_timesteps    | 11392         |
| value_loss         | 288.66827     |
--------------------------------------
--------------------------------------
| approxkl           | 0.014331716   |
| clipfrac           | 0.19921875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.74e+03      |
| explained_variance | -2.6e-05      |
| fps                | 34            |
| n_updates          | 90            |
| policy_entropy     | 1.3969165     |
| policy_loss        | -0.0018756562 |
| serial_timesteps   | 11520         |
| time_elapsed       | 358           |
| total_timesteps    | 11520         |
| value_loss         | 540.62494     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0047791856 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.74e+03     |
| explained_variance | -4.77e-06    |
| fps                | 33           |
| n_updates          | 91           |
| policy_entropy     | 1.3965325    |
| policy_loss        | 0.024188757  |
| serial_timesteps   | 11648        |
| time_elapsed       | 361          |
| total_timesteps    | 11648        |
| value_loss         | 363.56348    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009605493  |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.74e+03     |
| explained_variance | 0.000312     |
| fps                | 33           |
| n_updates          | 92           |
| policy_entropy     | 1.3959442    |
| policy_loss        | 0.0025467218 |
| serial_timesteps   | 11776        |
| time_elapsed       | 365          |
| total_timesteps    | 11776        |
| value_loss         | 414.29166    |
-------------------------------------
---------------------------------------
| approxkl           | 0.008061748    |
| clipfrac           | 0.123046875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.74e+03       |
| explained_variance | 0.000115       |
| fps                | 36             |
| n_updates          | 93             |
| policy_entropy     | 1.3956994      |
| policy_loss        | -0.00032750785 |
| serial_timesteps   | 11904          |
| time_elapsed       | 369            |
| total_timesteps    | 11904          |
| value_loss         | 356.44177      |
---------------------------------------
------------------------------------
| approxkl           | 0.009536998 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.74e+03    |
| explained_variance | -7.03e-05   |
| fps                | 33          |
| n_updates          | 94          |
| policy_entropy     | 1.3949958   |
| policy_loss        | 0.007793206 |
| serial_timesteps   | 12032       |
| time_elapsed       | 372         |
| total_timesteps    | 12032       |
| value_loss         | 167.71625   |
------------------------------------
-------------------------------------
| approxkl           | 0.015103599  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.74e+03     |
| explained_variance | -8.34e-06    |
| fps                | 33           |
| n_updates          | 95           |
| policy_entropy     | 1.3942627    |
| policy_loss        | -0.029642759 |
| serial_timesteps   | 12160        |
| time_elapsed       | 376          |
| total_timesteps    | 12160        |
| value_loss         | 112.35045    |
-------------------------------------
An average of 76.0 episodes completed
Best mean reward: 3847.99 - Latest 5 sample mean reward per episode: 3847.99
-------------------------------------
| approxkl           | 0.0018189793 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.74e+03     |
| explained_variance | 0.000128     |
| fps                | 30           |
| n_updates          | 96           |
| policy_entropy     | 1.3932408    |
| policy_loss        | 0.0035838112 |
| serial_timesteps   | 12288        |
| time_elapsed       | 380          |
| total_timesteps    | 12288        |
| value_loss         | 517.8418     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0028145136  |
| clipfrac           | 0.029296875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.8e+03       |
| explained_variance | 5.36e-06      |
| fps                | 33            |
| n_updates          | 97            |
| policy_entropy     | 1.3923571     |
| policy_loss        | -0.0078650005 |
| serial_timesteps   | 12416         |
| time_elapsed       | 384           |
| total_timesteps    | 12416         |
| value_loss         | 491.8035      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0015919976 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.8e+03      |
| explained_variance | -2.97e-05    |
| fps                | 34           |
| n_updates          | 98           |
| policy_entropy     | 1.3923587    |
| policy_loss        | -0.007084571 |
| serial_timesteps   | 12544        |
| time_elapsed       | 388          |
| total_timesteps    | 12544        |
| value_loss         | 169.5435     |
-------------------------------------
---------------------------------------
| approxkl           | 0.007717094    |
| clipfrac           | 0.109375       |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.8e+03        |
| explained_variance | -3.22e-05      |
| fps                | 29             |
| n_updates          | 99             |
| policy_entropy     | 1.3916725      |
| policy_loss        | -0.00040207664 |
| serial_timesteps   | 12672          |
| time_elapsed       | 392            |
| total_timesteps    | 12672          |
| value_loss         | 438.4516       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0011336466  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.8e+03       |
| explained_variance | -0.000115     |
| fps                | 32            |
| n_updates          | 100           |
| policy_entropy     | 1.3909241     |
| policy_loss        | -0.0003690141 |
| serial_timesteps   | 12800         |
| time_elapsed       | 396           |
| total_timesteps    | 12800         |
| value_loss         | 257.41025     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00048214366 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.8e+03       |
| explained_variance | -2.04e-05     |
| fps                | 35            |
| n_updates          | 101           |
| policy_entropy     | 1.3895297     |
| policy_loss        | -0.00572677   |
| serial_timesteps   | 12928         |
| time_elapsed       | 400           |
| total_timesteps    | 12928         |
| value_loss         | 361.06555     |
--------------------------------------
------------------------------------
| approxkl           | 0.009763703 |
| clipfrac           | 0.13867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.8e+03     |
| explained_variance | 7.71e-05    |
| fps                | 34          |
| n_updates          | 102         |
| policy_entropy     | 1.3879987   |
| policy_loss        | 0.0254258   |
| serial_timesteps   | 13056       |
| time_elapsed       | 404         |
| total_timesteps    | 13056       |
| value_loss         | 393.31442   |
------------------------------------
An average of 77.0 episodes completed
Best mean reward: 3847.99 - Latest 5 sample mean reward per episode: 3979.06
Saving new best model
-------------------------------------
| approxkl           | 0.011171816  |
| clipfrac           | 0.16015625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.8e+03      |
| explained_variance | -0.000106    |
| fps                | 36           |
| n_updates          | 103          |
| policy_entropy     | 1.3873703    |
| policy_loss        | 0.0067898557 |
| serial_timesteps   | 13184        |
| time_elapsed       | 407          |
| total_timesteps    | 13184        |
| value_loss         | 479.03497    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010687546  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.8e+03      |
| explained_variance | -1.6e-05     |
| fps                | 31           |
| n_updates          | 104          |
| policy_entropy     | 1.3872026    |
| policy_loss        | -0.010522386 |
| serial_timesteps   | 13312        |
| time_elapsed       | 411          |
| total_timesteps    | 13312        |
| value_loss         | 341.7017     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00015467578 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.8e+03       |
| explained_variance | 7.24e-05      |
| fps                | 31            |
| n_updates          | 105           |
| policy_entropy     | 1.3870175     |
| policy_loss        | -0.0013004774 |
| serial_timesteps   | 13440         |
| time_elapsed       | 415           |
| total_timesteps    | 13440         |
| value_loss         | 530.2554      |
--------------------------------------
------------------------------------
| approxkl           | 0.005907323 |
| clipfrac           | 0.08203125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.8e+03     |
| explained_variance | -0.000104   |
| fps                | 34          |
| n_updates          | 106         |
| policy_entropy     | 1.3871169   |
| policy_loss        | 0.012075278 |
| serial_timesteps   | 13568       |
| time_elapsed       | 419         |
| total_timesteps    | 13568       |
| value_loss         | 401.1046    |
------------------------------------
-------------------------------------
| approxkl           | 0.011168184  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.8e+03      |
| explained_variance | 1.16e-05     |
| fps                | 33           |
| n_updates          | 107          |
| policy_entropy     | 1.3869582    |
| policy_loss        | -0.008819949 |
| serial_timesteps   | 13696        |
| time_elapsed       | 423          |
| total_timesteps    | 13696        |
| value_loss         | 272.08862    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009704368  |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.8e+03      |
| explained_variance | -0.00012     |
| fps                | 29           |
| n_updates          | 108          |
| policy_entropy     | 1.3866861    |
| policy_loss        | -0.006916968 |
| serial_timesteps   | 13824        |
| time_elapsed       | 427          |
| total_timesteps    | 13824        |
| value_loss         | 358.136      |
-------------------------------------
---------------------------------------
| approxkl           | 2.3889646e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.85e+03       |
| explained_variance | 1.95e-05       |
| fps                | 31             |
| n_updates          | 109            |
| policy_entropy     | 1.3860831      |
| policy_loss        | -0.00019888673 |
| serial_timesteps   | 13952          |
| time_elapsed       | 431            |
| total_timesteps    | 13952          |
| value_loss         | 378.89224      |
---------------------------------------
------------------------------------
| approxkl           | 0.000450522 |
| clipfrac           | 0.0         |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.85e+03    |
| explained_variance | 5.25e-06    |
| fps                | 35          |
| n_updates          | 110         |
| policy_entropy     | 1.3860419   |
| policy_loss        | -0.00427063 |
| serial_timesteps   | 14080       |
| time_elapsed       | 435         |
| total_timesteps    | 14080       |
| value_loss         | 190.15097   |
------------------------------------
An average of 78.0 episodes completed
Best mean reward: 3979.06 - Latest 5 sample mean reward per episode: 4033.31
Saving new best model
--------------------------------------
| approxkl           | 0.0008150368  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.85e+03      |
| explained_variance | 4.04e-05      |
| fps                | 32            |
| n_updates          | 111           |
| policy_entropy     | 1.3860494     |
| policy_loss        | -0.0026075386 |
| serial_timesteps   | 14208         |
| time_elapsed       | 439           |
| total_timesteps    | 14208         |
| value_loss         | 426.9633      |
--------------------------------------
---------------------------------------
| approxkl           | 0.000108366585 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.85e+03       |
| explained_variance | -1.81e-05      |
| fps                | 31             |
| n_updates          | 112            |
| policy_entropy     | 1.3847498      |
| policy_loss        | 0.001456836    |
| serial_timesteps   | 14336          |
| time_elapsed       | 443            |
| total_timesteps    | 14336          |
| value_loss         | 360.01108      |
---------------------------------------
------------------------------------
| approxkl           | 0.008168644 |
| clipfrac           | 0.13671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.85e+03    |
| explained_variance | 1.09e-05    |
| fps                | 30          |
| n_updates          | 113         |
| policy_entropy     | 1.3845065   |
| policy_loss        | 0.032894876 |
| serial_timesteps   | 14464       |
| time_elapsed       | 447         |
| total_timesteps    | 14464       |
| value_loss         | 278.3462    |
------------------------------------
--------------------------------------
| approxkl           | 0.0030728115  |
| clipfrac           | 0.021484375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.85e+03      |
| explained_variance | -1.47e-05     |
| fps                | 31            |
| n_updates          | 114           |
| policy_entropy     | 1.384696      |
| policy_loss        | -0.0069009545 |
| serial_timesteps   | 14592         |
| time_elapsed       | 451           |
| total_timesteps    | 14592         |
| value_loss         | 299.51154     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0065252846  |
| clipfrac           | 0.080078125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.85e+03      |
| explained_variance | -2.29e-05     |
| fps                | 33            |
| n_updates          | 115           |
| policy_entropy     | 1.3847221     |
| policy_loss        | -0.0015185059 |
| serial_timesteps   | 14720         |
| time_elapsed       | 455           |
| total_timesteps    | 14720         |
| value_loss         | 61.223015     |
--------------------------------------
--------------------------------------
| approxkl           | 0.006186232   |
| clipfrac           | 0.078125      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.85e+03      |
| explained_variance | -1.55e-05     |
| fps                | 32            |
| n_updates          | 116           |
| policy_entropy     | 1.3851728     |
| policy_loss        | -0.0052760714 |
| serial_timesteps   | 14848         |
| time_elapsed       | 459           |
| total_timesteps    | 14848         |
| value_loss         | 313.05777     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00022944219  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.85e+03       |
| explained_variance | 0.000488       |
| fps                | 31             |
| n_updates          | 117            |
| policy_entropy     | 1.385293       |
| policy_loss        | -0.00095445884 |
| serial_timesteps   | 14976          |
| time_elapsed       | 463            |
| total_timesteps    | 14976          |
| value_loss         | 451.57968      |
---------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b791bb4e0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b791bb4e0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b790d1e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b790d1e80>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2330 samples, validate on 326 samples
Epoch 172/5000
 - 3s - loss: 0.0360 - val_loss: 0.0088
Epoch 173/5000
 - 0s - loss: 0.0210 - val_loss: 0.0063
Epoch 174/5000
 - 0s - loss: 0.0125 - val_loss: 0.0054
Epoch 175/5000
 - 0s - loss: 0.0074 - val_loss: 0.0057
Epoch 176/5000
 - 0s - loss: 0.0058 - val_loss: 0.0058
Epoch 177/5000
 - 0s - loss: 0.0047 - val_loss: 0.0046
Epoch 178/5000
 - 0s - loss: 0.0043 - val_loss: 0.0044
Epoch 179/5000
 - 0s - loss: 0.0042 - val_loss: 0.0043
Epoch 180/5000
 - 0s - loss: 0.0042 - val_loss: 0.0042
Epoch 181/5000
 - 0s - loss: 0.0042 - val_loss: 0.0042
Epoch 182/5000
 - 1s - loss: 0.0041 - val_loss: 0.0041
Epoch 183/5000
 - 0s - loss: 0.0041 - val_loss: 0.0040
Epoch 184/5000
 - 0s - loss: 0.0041 - val_loss: 0.0040
Epoch 185/5000
 - 0s - loss: 0.0041 - val_loss: 0.0039
Epoch 186/5000
 - 1s - loss: 0.0039 - val_loss: 0.0040
Epoch 187/5000
 - 1s - loss: 0.0039 - val_loss: 0.0040
Epoch 188/5000
 - 1s - loss: 0.0039 - val_loss: 0.0040
Epoch 189/5000
 - 1s - loss: 0.0039 - val_loss: 0.0040
Epoch 190/5000
 - 1s - loss: 0.0039 - val_loss: 0.0040
Train on 1820 samples, validate on 326 samples
Epoch 139/5000
 - 3s - loss: 0.0175 - val_loss: 0.0089
Epoch 140/5000
 - 0s - loss: 0.0175 - val_loss: 0.0089
Epoch 141/5000
 - 0s - loss: 0.0175 - val_loss: 0.0089
Epoch 142/5000
 - 0s - loss: 0.0175 - val_loss: 0.0089
Epoch 143/5000
 - 0s - loss: 0.0175 - val_loss: 0.0089
Epoch 144/5000
 - 0s - loss: 0.0175 - val_loss: 0.0089
Train on 2331 samples, validate on 326 samples
Epoch 151/5000
 - 4s - loss: 0.6663 - val_loss: 0.5971
Epoch 152/5000
 - 1s - loss: 0.5437 - val_loss: 0.3850
Epoch 153/5000
 - 1s - loss: 0.5200 - val_loss: 0.3824
Epoch 154/5000
 - 1s - loss: 0.5172 - val_loss: 0.3822
Epoch 155/5000
 - 1s - loss: 0.5145 - val_loss: 0.3816
Epoch 156/5000
 - 1s - loss: 0.5128 - val_loss: 0.3807
Epoch 157/5000
 - 1s - loss: 0.5114 - val_loss: 0.3796
Epoch 158/5000
 - 1s - loss: 0.5101 - val_loss: 0.3782
Epoch 159/5000
 - 1s - loss: 0.5088 - val_loss: 0.3766
Epoch 160/5000
 - 1s - loss: 0.5075 - val_loss: 0.3747
Epoch 161/5000
 - 1s - loss: 0.5062 - val_loss: 0.3726
Epoch 162/5000
 - 1s - loss: 0.5047 - val_loss: 0.3702
Epoch 163/5000
 - 1s - loss: 0.5030 - val_loss: 0.3674
Epoch 164/5000
 - 1s - loss: 0.5011 - val_loss: 0.3644
Epoch 165/5000
 - 1s - loss: 0.4990 - val_loss: 0.3609
Epoch 166/5000
 - 1s - loss: 0.4966 - val_loss: 0.3570
Epoch 167/5000
 - 1s - loss: 0.4939 - val_loss: 0.3527
Epoch 168/5000
 - 1s - loss: 0.4908 - val_loss: 0.3480
Epoch 169/5000
 - 1s - loss: 0.4873 - val_loss: 0.3428
Epoch 170/5000
 - 1s - loss: 0.4832 - val_loss: 0.3371
Epoch 171/5000
 - 1s - loss: 0.4778 - val_loss: 0.3292
Epoch 172/5000
 - 1s - loss: 0.4756 - val_loss: 0.3234
Epoch 173/5000
 - 1s - loss: 0.4669 - val_loss: 0.3167
Epoch 174/5000
 - 1s - loss: 0.4609 - val_loss: 0.3100
Epoch 175/5000
 - 1s - loss: 0.4539 - val_loss: 0.3035
Epoch 176/5000
 - 1s - loss: 0.4465 - val_loss: 0.2975
Epoch 177/5000
 - 1s - loss: 0.4389 - val_loss: 0.2922
Epoch 178/5000
 - 1s - loss: 0.4319 - val_loss: 0.2880
Epoch 179/5000
 - 1s - loss: 0.4222 - val_loss: 0.2916
Epoch 180/5000
 - 1s - loss: 0.4217 - val_loss: 0.2832
Epoch 181/5000
 - 1s - loss: 0.4112 - val_loss: 0.2803
Epoch 182/5000
 - 1s - loss: 0.4056 - val_loss: 0.2790
Epoch 183/5000
 - 1s - loss: 0.4009 - val_loss: 0.2768
Epoch 184/5000
 - 1s - loss: 0.3955 - val_loss: 0.2745
Epoch 185/5000
 - 1s - loss: 0.3895 - val_loss: 0.2737
Epoch 186/5000
 - 1s - loss: 0.3854 - val_loss: 0.2740
Epoch 187/5000
 - 1s - loss: 0.3816 - val_loss: 0.2721
Epoch 188/5000
 - 1s - loss: 0.3779 - val_loss: 0.2714
Epoch 189/5000
 - 1s - loss: 0.3744 - val_loss: 0.2719
Epoch 190/5000
 - 1s - loss: 0.3720 - val_loss: 0.2713
Epoch 191/5000
 - 1s - loss: 0.3626 - val_loss: 0.2576
Epoch 192/5000
 - 1s - loss: 0.3456 - val_loss: 0.2530
Epoch 193/5000
 - 1s - loss: 0.3384 - val_loss: 0.2517
Epoch 194/5000
 - 1s - loss: 0.3355 - val_loss: 0.2513
Epoch 195/5000
 - 1s - loss: 0.3342 - val_loss: 0.2511
Epoch 196/5000
 - 1s - loss: 0.3333 - val_loss: 0.2510
Epoch 197/5000
 - 1s - loss: 0.3327 - val_loss: 0.2508
Epoch 198/5000
 - 1s - loss: 0.3322 - val_loss: 0.2507
Epoch 199/5000
 - 1s - loss: 0.3318 - val_loss: 0.2506
Epoch 200/5000
 - 1s - loss: 0.3313 - val_loss: 0.2505
Epoch 201/5000
 - 1s - loss: 0.3309 - val_loss: 0.2503
Epoch 202/5000
 - 1s - loss: 0.3305 - val_loss: 0.2502
Epoch 203/5000
 - 1s - loss: 0.3302 - val_loss: 0.2501
Epoch 204/5000
 - 1s - loss: 0.3298 - val_loss: 0.2500
Epoch 205/5000
 - 1s - loss: 0.3295 - val_loss: 0.2499
Epoch 206/5000
 - 1s - loss: 0.3291 - val_loss: 0.2498
Epoch 207/5000
 - 1s - loss: 0.3288 - val_loss: 0.2497
Epoch 208/5000
 - 1s - loss: 0.3285 - val_loss: 0.2496
Epoch 209/5000
 - 1s - loss: 0.3282 - val_loss: 0.2494
Epoch 210/5000
 - 1s - loss: 0.3278 - val_loss: 0.2493
Epoch 211/5000
 - 1s - loss: 0.3275 - val_loss: 0.2492
Epoch 212/5000
 - 1s - loss: 0.3272 - val_loss: 0.2491
Epoch 213/5000
 - 1s - loss: 0.3269 - val_loss: 0.2490
Epoch 214/5000
 - 1s - loss: 0.3266 - val_loss: 0.2489
Epoch 215/5000
 - 1s - loss: 0.3263 - val_loss: 0.2488
Epoch 216/5000
 - 1s - loss: 0.3260 - val_loss: 0.2487
Epoch 217/5000
 - 1s - loss: 0.3257 - val_loss: 0.2486
Epoch 218/5000
 - 1s - loss: 0.3255 - val_loss: 0.2484
Epoch 219/5000
 - 1s - loss: 0.3252 - val_loss: 0.2483
Epoch 220/5000
 - 1s - loss: 0.3249 - val_loss: 0.2482
Epoch 221/5000
 - 1s - loss: 0.3247 - val_loss: 0.2481
Epoch 222/5000
 - 1s - loss: 0.3244 - val_loss: 0.2480
Epoch 223/5000
 - 1s - loss: 0.3242 - val_loss: 0.2480
Epoch 224/5000
 - 1s - loss: 0.3239 - val_loss: 0.2479
Epoch 225/5000
 - 1s - loss: 0.3237 - val_loss: 0.2478
Epoch 226/5000
 - 1s - loss: 0.3234 - val_loss: 0.2477
Epoch 227/5000
 - 1s - loss: 0.3232 - val_loss: 0.2476
Epoch 228/5000
 - 1s - loss: 0.3230 - val_loss: 0.2475
Epoch 229/5000
 - 1s - loss: 0.3227 - val_loss: 0.2474
Epoch 230/5000
 - 1s - loss: 0.3225 - val_loss: 0.2473
Epoch 231/5000
 - 1s - loss: 0.3223 - val_loss: 0.2472
Epoch 232/5000
 - 1s - loss: 0.3220 - val_loss: 0.2471
Epoch 233/5000
 - 1s - loss: 0.3218 - val_loss: 0.2470
Epoch 234/5000
 - 1s - loss: 0.3216 - val_loss: 0.2469
Epoch 235/5000
 - 1s - loss: 0.3214 - val_loss: 0.2469
Epoch 236/5000
 - 1s - loss: 0.3211 - val_loss: 0.2468
Epoch 237/5000
 - 1s - loss: 0.3209 - val_loss: 0.2467
Epoch 238/5000
 - 1s - loss: 0.3207 - val_loss: 0.2466
Epoch 239/5000
 - 1s - loss: 0.3205 - val_loss: 0.2465
Epoch 240/5000
 - 1s - loss: 0.3203 - val_loss: 0.2465
Epoch 241/5000
 - 1s - loss: 0.3201 - val_loss: 0.2464
Epoch 242/5000
 - 1s - loss: 0.3199 - val_loss: 0.2463
Epoch 243/5000
 - 1s - loss: 0.3197 - val_loss: 0.2463
Epoch 244/5000
 - 1s - loss: 0.3195 - val_loss: 0.2462
Epoch 245/5000
 - 1s - loss: 0.3193 - val_loss: 0.2461
Epoch 246/5000
 - 1s - loss: 0.3191 - val_loss: 0.2461
Epoch 247/5000
 - 1s - loss: 0.3190 - val_loss: 0.2460
Epoch 248/5000
 - 1s - loss: 0.3188 - val_loss: 0.2460
Epoch 249/5000
 - 1s - loss: 0.3186 - val_loss: 0.2459
Epoch 250/5000
 - 1s - loss: 0.3184 - val_loss: 0.2458
Epoch 251/5000
 - 1s - loss: 0.3183 - val_loss: 0.2458
Epoch 252/5000
 - 1s - loss: 0.3181 - val_loss: 0.2457
Epoch 253/5000
 - 1s - loss: 0.3159 - val_loss: 0.2457
Epoch 254/5000
 - 1s - loss: 0.3158 - val_loss: 0.2457
Epoch 255/5000
 - 1s - loss: 0.3158 - val_loss: 0.2457
Epoch 256/5000
 - 1s - loss: 0.3158 - val_loss: 0.2457
Epoch 257/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 258/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 259/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 260/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 261/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 262/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 263/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 264/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 265/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 266/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 267/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 268/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 269/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
Epoch 270/5000
 - 1s - loss: 0.3155 - val_loss: 0.2457
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.002460854 |
| clipfrac           | 0.013671875 |
| explained_variance | 9.54e-07    |
| fps                | 8           |
| n_updates          | 1           |
| policy_entropy     | 1.3838663   |
| policy_loss        | 0.003452389 |
| serial_timesteps   | 128         |
| time_elapsed       | 1.22e-05    |
| total_timesteps    | 128         |
| value_loss         | 400.3247    |
------------------------------------
An average of 79.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3902.00
--------------------------------------
| approxkl           | 4.7761863e-05 |
| clipfrac           | 0.0           |
| explained_variance | -3.64e-05     |
| fps                | 31            |
| n_updates          | 2             |
| policy_entropy     | 1.3828878     |
| policy_loss        | -0.000411937  |
| serial_timesteps   | 256           |
| time_elapsed       | 15.3          |
| total_timesteps    | 256           |
| value_loss         | 127.96823     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00083065557 |
| clipfrac           | 0.001953125   |
| explained_variance | -1.25e-05     |
| fps                | 30            |
| n_updates          | 3             |
| policy_entropy     | 1.3827528     |
| policy_loss        | -0.003947349  |
| serial_timesteps   | 384           |
| time_elapsed       | 19.4          |
| total_timesteps    | 384           |
| value_loss         | 286.60907     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00050185045  |
| clipfrac           | 0.0            |
| explained_variance | -6.66e-05      |
| fps                | 30             |
| n_updates          | 4              |
| policy_entropy     | 1.3827014      |
| policy_loss        | -0.00018200057 |
| serial_timesteps   | 512            |
| time_elapsed       | 23.6           |
| total_timesteps    | 512            |
| value_loss         | 276.59305      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00054099323 |
| clipfrac           | 0.0           |
| explained_variance | -2.78e-05     |
| fps                | 30            |
| n_updates          | 5             |
| policy_entropy     | 1.3828768     |
| policy_loss        | 0.0025653136  |
| serial_timesteps   | 640           |
| time_elapsed       | 27.8          |
| total_timesteps    | 640           |
| value_loss         | 419.20468     |
--------------------------------------
------------------------------------
| approxkl           | 0.009161135 |
| clipfrac           | 0.13867188  |
| explained_variance | -0.00031    |
| fps                | 33          |
| n_updates          | 6           |
| policy_entropy     | 1.3818787   |
| policy_loss        | 0.004964272 |
| serial_timesteps   | 768         |
| time_elapsed       | 32          |
| total_timesteps    | 768         |
| value_loss         | 429.90106   |
------------------------------------
-------------------------------------
| approxkl           | 0.009696491  |
| clipfrac           | 0.14648438   |
| explained_variance | -5.32e-05    |
| fps                | 33           |
| n_updates          | 7            |
| policy_entropy     | 1.3811373    |
| policy_loss        | -0.007777168 |
| serial_timesteps   | 896          |
| time_elapsed       | 35.8         |
| total_timesteps    | 896          |
| value_loss         | 366.47693    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073929494 |
| clipfrac           | 0.111328125  |
| explained_variance | -8.34e-07    |
| fps                | 34           |
| n_updates          | 8            |
| policy_entropy     | 1.3800645    |
| policy_loss        | 0.027750114  |
| serial_timesteps   | 1024         |
| time_elapsed       | 39.7         |
| total_timesteps    | 1024         |
| value_loss         | 371.433      |
-------------------------------------
---------------------------------------
| approxkl           | 0.013335492    |
| clipfrac           | 0.1953125      |
| explained_variance | 0.000148       |
| fps                | 33             |
| n_updates          | 9              |
| policy_entropy     | 1.3795869      |
| policy_loss        | -0.00015043188 |
| serial_timesteps   | 1152           |
| time_elapsed       | 43.4           |
| total_timesteps    | 1152           |
| value_loss         | 398.84058      |
---------------------------------------
An average of 79.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3902.00
-------------------------------------
| approxkl           | 0.0072967634 |
| clipfrac           | 0.0859375    |
| explained_variance | -6.75e-05    |
| fps                | 33           |
| n_updates          | 10           |
| policy_entropy     | 1.3794566    |
| policy_loss        | 0.035192743  |
| serial_timesteps   | 1280         |
| time_elapsed       | 47.2         |
| total_timesteps    | 1280         |
| value_loss         | 317.0031     |
-------------------------------------
------------------------------------
| approxkl           | 0.016024163 |
| clipfrac           | 0.22851562  |
| explained_variance | 1.79e-06    |
| fps                | 33          |
| n_updates          | 11          |
| policy_entropy     | 1.3793149   |
| policy_loss        | -0.01694457 |
| serial_timesteps   | 1408        |
| time_elapsed       | 51.1        |
| total_timesteps    | 1408        |
| value_loss         | 279.33276   |
------------------------------------
------------------------------------
| approxkl           | 0.006582293 |
| clipfrac           | 0.09765625  |
| explained_variance | -0.000129   |
| fps                | 33          |
| n_updates          | 12          |
| policy_entropy     | 1.37898     |
| policy_loss        | 0.01840889  |
| serial_timesteps   | 1536        |
| time_elapsed       | 55          |
| total_timesteps    | 1536        |
| value_loss         | 497.54938   |
------------------------------------
-------------------------------------
| approxkl           | 0.023191825  |
| clipfrac           | 0.25195312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | -2.98e-06    |
| fps                | 32           |
| n_updates          | 13           |
| policy_entropy     | 1.3782402    |
| policy_loss        | -0.012132534 |
| serial_timesteps   | 1664         |
| time_elapsed       | 58.7         |
| total_timesteps    | 1664         |
| value_loss         | 373.51746    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0018007329 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | -3.24e-05    |
| fps                | 32           |
| n_updates          | 14           |
| policy_entropy     | 1.378037     |
| policy_loss        | -0.009649398 |
| serial_timesteps   | 1792         |
| time_elapsed       | 62.6         |
| total_timesteps    | 1792         |
| value_loss         | 138.53351    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010341181  |
| clipfrac           | 0.15429688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | 4.77e-07     |
| fps                | 33           |
| n_updates          | 15           |
| policy_entropy     | 1.3778555    |
| policy_loss        | -0.018709417 |
| serial_timesteps   | 1920         |
| time_elapsed       | 66.5         |
| total_timesteps    | 1920         |
| value_loss         | 192.01233    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00028594406 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.18e+03      |
| explained_variance | -2.36e-05     |
| fps                | 30            |
| n_updates          | 16            |
| policy_entropy     | 1.3774529     |
| policy_loss        | 0.001900802   |
| serial_timesteps   | 2048          |
| time_elapsed       | 70.3          |
| total_timesteps    | 2048          |
| value_loss         | 288.3772      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00023146711 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.18e+03      |
| explained_variance | 1.76e-05      |
| fps                | 31            |
| n_updates          | 17            |
| policy_entropy     | 1.3767234     |
| policy_loss        | 0.0022728029  |
| serial_timesteps   | 2176          |
| time_elapsed       | 74.5          |
| total_timesteps    | 2176          |
| value_loss         | 143.90366     |
--------------------------------------
An average of 80.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3992.27
--------------------------------------
| approxkl           | 0.0009582788  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.18e+03      |
| explained_variance | -1.68e-05     |
| fps                | 32            |
| n_updates          | 18            |
| policy_entropy     | 1.3763505     |
| policy_loss        | -0.0051505864 |
| serial_timesteps   | 2304          |
| time_elapsed       | 78.5          |
| total_timesteps    | 2304          |
| value_loss         | 203.76714     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005149873  |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | -4.48e-05    |
| fps                | 31           |
| n_updates          | 19           |
| policy_entropy     | 1.3758595    |
| policy_loss        | -0.010156758 |
| serial_timesteps   | 2432         |
| time_elapsed       | 82.5         |
| total_timesteps    | 2432         |
| value_loss         | 53.4802      |
-------------------------------------
-------------------------------------
| approxkl           | 0.0035373818 |
| clipfrac           | 0.029296875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | -1.3e-05     |
| fps                | 32           |
| n_updates          | 20           |
| policy_entropy     | 1.3754102    |
| policy_loss        | -0.013807654 |
| serial_timesteps   | 2560         |
| time_elapsed       | 86.6         |
| total_timesteps    | 2560         |
| value_loss         | 297.323      |
-------------------------------------
--------------------------------------
| approxkl           | 0.0009010432  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.18e+03      |
| explained_variance | 0.000308      |
| fps                | 31            |
| n_updates          | 21            |
| policy_entropy     | 1.3752784     |
| policy_loss        | -0.0063494323 |
| serial_timesteps   | 2688          |
| time_elapsed       | 90.6          |
| total_timesteps    | 2688          |
| value_loss         | 297.87338     |
--------------------------------------
-------------------------------------
| approxkl           | 0.018686939  |
| clipfrac           | 0.22265625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | 0.000213     |
| fps                | 34           |
| n_updates          | 22           |
| policy_entropy     | 1.3758085    |
| policy_loss        | -0.011485903 |
| serial_timesteps   | 2816         |
| time_elapsed       | 94.6         |
| total_timesteps    | 2816         |
| value_loss         | 425.31046    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0018803703 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | -0.000186    |
| fps                | 32           |
| n_updates          | 23           |
| policy_entropy     | 1.3759683    |
| policy_loss        | -0.011175105 |
| serial_timesteps   | 2944         |
| time_elapsed       | 98.3         |
| total_timesteps    | 2944         |
| value_loss         | 220.46896    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02397022   |
| clipfrac           | 0.32617188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.18e+03     |
| explained_variance | 8.29e-06     |
| fps                | 31           |
| n_updates          | 24           |
| policy_entropy     | 1.3752272    |
| policy_loss        | -0.028459553 |
| serial_timesteps   | 3072         |
| time_elapsed       | 102          |
| total_timesteps    | 3072         |
| value_loss         | 300.7601     |
-------------------------------------
An average of 81.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3942.24
-------------------------------------
| approxkl           | 0.011683501  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | -2.97e-05    |
| fps                | 33           |
| n_updates          | 25           |
| policy_entropy     | 1.3750321    |
| policy_loss        | -0.005548844 |
| serial_timesteps   | 3200         |
| time_elapsed       | 106          |
| total_timesteps    | 3200         |
| value_loss         | 630.6808     |
-------------------------------------
--------------------------------------
| approxkl           | 3.2159107e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.91e+03      |
| explained_variance | -1.42e-05     |
| fps                | 32            |
| n_updates          | 26            |
| policy_entropy     | 1.3750083     |
| policy_loss        | 0.0009139397  |
| serial_timesteps   | 3328          |
| time_elapsed       | 110           |
| total_timesteps    | 3328          |
| value_loss         | 182.81488     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0053409487 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | 9.18e-05     |
| fps                | 32           |
| n_updates          | 27           |
| policy_entropy     | 1.3749236    |
| policy_loss        | -0.009667241 |
| serial_timesteps   | 3456         |
| time_elapsed       | 114          |
| total_timesteps    | 3456         |
| value_loss         | 351.04214    |
-------------------------------------
--------------------------------------
| approxkl           | 0.003642968   |
| clipfrac           | 0.0390625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.91e+03      |
| explained_variance | 3.46e-05      |
| fps                | 33            |
| n_updates          | 28            |
| policy_entropy     | 1.3745339     |
| policy_loss        | -0.0030613393 |
| serial_timesteps   | 3584          |
| time_elapsed       | 118           |
| total_timesteps    | 3584          |
| value_loss         | 346.25272     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0026095742 |
| clipfrac           | 0.029296875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | 4.32e-05     |
| fps                | 32           |
| n_updates          | 29           |
| policy_entropy     | 1.3744797    |
| policy_loss        | -0.012462843 |
| serial_timesteps   | 3712         |
| time_elapsed       | 122          |
| total_timesteps    | 3712         |
| value_loss         | 46.70411     |
-------------------------------------
-------------------------------------
| approxkl           | 0.03320022   |
| clipfrac           | 0.3359375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | 6.49e-05     |
| fps                | 32           |
| n_updates          | 30           |
| policy_entropy     | 1.3742595    |
| policy_loss        | -0.024851007 |
| serial_timesteps   | 3840         |
| time_elapsed       | 126          |
| total_timesteps    | 3840         |
| value_loss         | 106.464775   |
-------------------------------------
------------------------------------
| approxkl           | 0.010322429 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.91e+03    |
| explained_variance | -8.37e-05   |
| fps                | 31          |
| n_updates          | 31          |
| policy_entropy     | 1.3740892   |
| policy_loss        | 0.02046986  |
| serial_timesteps   | 3968        |
| time_elapsed       | 130         |
| total_timesteps    | 3968        |
| value_loss         | 363.74576   |
------------------------------------
-------------------------------------
| approxkl           | 0.011936799  |
| clipfrac           | 0.20117188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | -1.14e-05    |
| fps                | 35           |
| n_updates          | 32           |
| policy_entropy     | 1.3734192    |
| policy_loss        | 0.0028178697 |
| serial_timesteps   | 4096         |
| time_elapsed       | 134          |
| total_timesteps    | 4096         |
| value_loss         | 374.81686    |
-------------------------------------
An average of 81.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3942.24
-------------------------------------
| approxkl           | 0.011104327  |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | -1.66e-05    |
| fps                | 33           |
| n_updates          | 33           |
| policy_entropy     | 1.3730295    |
| policy_loss        | -0.011806536 |
| serial_timesteps   | 4224         |
| time_elapsed       | 137          |
| total_timesteps    | 4224         |
| value_loss         | 84.100845    |
-------------------------------------
--------------------------------------
| approxkl           | 8.9085755e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.91e+03      |
| explained_variance | -1.63e-05     |
| fps                | 31            |
| n_updates          | 34            |
| policy_entropy     | 1.3730544     |
| policy_loss        | -0.0020077622 |
| serial_timesteps   | 4352          |
| time_elapsed       | 141           |
| total_timesteps    | 4352          |
| value_loss         | 272.79578     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0010300572 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.91e+03     |
| explained_variance | 1.44e-05     |
| fps                | 31           |
| n_updates          | 35           |
| policy_entropy     | 1.373036     |
| policy_loss        | -0.011010446 |
| serial_timesteps   | 4480         |
| time_elapsed       | 145          |
| total_timesteps    | 4480         |
| value_loss         | 199.56375    |
-------------------------------------
------------------------------------
| approxkl           | 0.010706066 |
| clipfrac           | 0.171875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.91e+03    |
| explained_variance | -2.8e-05    |
| fps                | 31          |
| n_updates          | 36          |
| policy_entropy     | 1.3723036   |
| policy_loss        | 0.002862027 |
| serial_timesteps   | 4608        |
| time_elapsed       | 149         |
| total_timesteps    | 4608        |
| value_loss         | 431.08484   |
------------------------------------
--------------------------------------
| approxkl           | 4.5143082e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | -4.94e-05     |
| fps                | 34            |
| n_updates          | 37            |
| policy_entropy     | 1.3727839     |
| policy_loss        | 0.001129475   |
| serial_timesteps   | 4736          |
| time_elapsed       | 153           |
| total_timesteps    | 4736          |
| value_loss         | 612.0672      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016019923 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | -4.15e-05     |
| fps                | 33            |
| n_updates          | 38            |
| policy_entropy     | 1.3731681     |
| policy_loss        | 0.0009559733  |
| serial_timesteps   | 4864          |
| time_elapsed       | 157           |
| total_timesteps    | 4864          |
| value_loss         | 322.70035     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00088799465 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | -6.32e-06     |
| fps                | 32            |
| n_updates          | 39            |
| policy_entropy     | 1.3720354     |
| policy_loss        | 0.005564075   |
| serial_timesteps   | 4992          |
| time_elapsed       | 161           |
| total_timesteps    | 4992          |
| value_loss         | 434.95724     |
--------------------------------------
------------------------------------
| approxkl           | 0.00896411  |
| clipfrac           | 0.125       |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.92e+03    |
| explained_variance | -3.4e-05    |
| fps                | 31          |
| n_updates          | 40          |
| policy_entropy     | 1.3696684   |
| policy_loss        | -0.01126975 |
| serial_timesteps   | 5120        |
| time_elapsed       | 165         |
| total_timesteps    | 5120        |
| value_loss         | 362.58508   |
------------------------------------
An average of 82.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3876.48
--------------------------------------
| approxkl           | 0.0009763625  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | -7.44e-05     |
| fps                | 32            |
| n_updates          | 41            |
| policy_entropy     | 1.3683418     |
| policy_loss        | -0.0047395187 |
| serial_timesteps   | 5248          |
| time_elapsed       | 169           |
| total_timesteps    | 5248          |
| value_loss         | 221.81018     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005236273  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | 8.34e-06      |
| fps                | 32            |
| n_updates          | 42            |
| policy_entropy     | 1.3678229     |
| policy_loss        | -0.0070420057 |
| serial_timesteps   | 5376          |
| time_elapsed       | 173           |
| total_timesteps    | 5376          |
| value_loss         | 243.92145     |
--------------------------------------
------------------------------------
| approxkl           | 0.014359446 |
| clipfrac           | 0.203125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.92e+03    |
| explained_variance | 9.95e-06    |
| fps                | 32          |
| n_updates          | 43          |
| policy_entropy     | 1.3679495   |
| policy_loss        | 0.03008905  |
| serial_timesteps   | 5504        |
| time_elapsed       | 177         |
| total_timesteps    | 5504        |
| value_loss         | 278.7167    |
------------------------------------
------------------------------------
| approxkl           | 0.009156486 |
| clipfrac           | 0.13867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.92e+03    |
| explained_variance | 3.35e-05    |
| fps                | 33          |
| n_updates          | 44          |
| policy_entropy     | 1.3677905   |
| policy_loss        | 0.018602664 |
| serial_timesteps   | 5632        |
| time_elapsed       | 181         |
| total_timesteps    | 5632        |
| value_loss         | 323.8841    |
------------------------------------
-------------------------------------
| approxkl           | 0.021927811  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.92e+03     |
| explained_variance | 4.88e-05     |
| fps                | 32           |
| n_updates          | 45           |
| policy_entropy     | 1.3674977    |
| policy_loss        | -0.021606011 |
| serial_timesteps   | 5760         |
| time_elapsed       | 184          |
| total_timesteps    | 5760         |
| value_loss         | 231.18227    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0006898312  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | 0.000184      |
| fps                | 31            |
| n_updates          | 46            |
| policy_entropy     | 1.3675472     |
| policy_loss        | -0.0017747467 |
| serial_timesteps   | 5888          |
| time_elapsed       | 188           |
| total_timesteps    | 5888          |
| value_loss         | 553.068       |
--------------------------------------
-------------------------------------
| approxkl           | 0.0015502991 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.92e+03     |
| explained_variance | -2.43e-05    |
| fps                | 31           |
| n_updates          | 47           |
| policy_entropy     | 1.3678803    |
| policy_loss        | 0.006551521  |
| serial_timesteps   | 6016         |
| time_elapsed       | 192          |
| total_timesteps    | 6016         |
| value_loss         | 351.7338     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00018881538 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.92e+03      |
| explained_variance | 9.36e-06      |
| fps                | 33            |
| n_updates          | 48            |
| policy_entropy     | 1.3693151     |
| policy_loss        | 0.00055215403 |
| serial_timesteps   | 6144          |
| time_elapsed       | 196           |
| total_timesteps    | 6144          |
| value_loss         | 97.52611      |
--------------------------------------
An average of 83.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3885.79
--------------------------------------
| approxkl           | 0.00013233375 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.01e+03      |
| explained_variance | -2.15e-06     |
| fps                | 33            |
| n_updates          | 49            |
| policy_entropy     | 1.3712543     |
| policy_loss        | 0.00016102684 |
| serial_timesteps   | 6272          |
| time_elapsed       | 200           |
| total_timesteps    | 6272          |
| value_loss         | 554.0197      |
--------------------------------------
-------------------------------------
| approxkl           | 0.010693757  |
| clipfrac           | 0.13085938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.01e+03     |
| explained_variance | -3.34e-06    |
| fps                | 30           |
| n_updates          | 50           |
| policy_entropy     | 1.3723212    |
| policy_loss        | -0.008824332 |
| serial_timesteps   | 6400         |
| time_elapsed       | 204          |
| total_timesteps    | 6400         |
| value_loss         | 71.266556    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00012715944 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.01e+03      |
| explained_variance | -2.15e-06     |
| fps                | 32            |
| n_updates          | 51            |
| policy_entropy     | 1.3722719     |
| policy_loss        | -0.0021106387 |
| serial_timesteps   | 6528          |
| time_elapsed       | 208           |
| total_timesteps    | 6528          |
| value_loss         | 292.52917     |
--------------------------------------
------------------------------------
| approxkl           | 0.017786585 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.01e+03    |
| explained_variance | 9.8e-05     |
| fps                | 35          |
| n_updates          | 52          |
| policy_entropy     | 1.3723334   |
| policy_loss        | 0.011146088 |
| serial_timesteps   | 6656        |
| time_elapsed       | 212         |
| total_timesteps    | 6656        |
| value_loss         | 332.16174   |
------------------------------------
------------------------------------
| approxkl           | 0.008861879 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.01e+03    |
| explained_variance | -0.000118   |
| fps                | 32          |
| n_updates          | 53          |
| policy_entropy     | 1.3722801   |
| policy_loss        | 0.005149372 |
| serial_timesteps   | 6784        |
| time_elapsed       | 216         |
| total_timesteps    | 6784        |
| value_loss         | 370.41486   |
------------------------------------
------------------------------------
| approxkl           | 0.010566324 |
| clipfrac           | 0.15234375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.01e+03    |
| explained_variance | -6.12e-05   |
| fps                | 29          |
| n_updates          | 54          |
| policy_entropy     | 1.3727301   |
| policy_loss        | 0.023036698 |
| serial_timesteps   | 6912        |
| time_elapsed       | 220         |
| total_timesteps    | 6912        |
| value_loss         | 327.13446   |
------------------------------------
-------------------------------------
| approxkl           | 0.014464384  |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.01e+03     |
| explained_variance | 7.75e-07     |
| fps                | 30           |
| n_updates          | 55           |
| policy_entropy     | 1.3730615    |
| policy_loss        | 0.0071690176 |
| serial_timesteps   | 7040         |
| time_elapsed       | 224          |
| total_timesteps    | 7040         |
| value_loss         | 350.0898     |
-------------------------------------
--------------------------------------
| approxkl           | 0.010015743   |
| clipfrac           | 0.14453125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.01e+03      |
| explained_variance | 4.29e-05      |
| fps                | 32            |
| n_updates          | 56            |
| policy_entropy     | 1.3724344     |
| policy_loss        | -0.0006000949 |
| serial_timesteps   | 7168          |
| time_elapsed       | 228           |
| total_timesteps    | 7168          |
| value_loss         | 457.114       |
--------------------------------------
An average of 83.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 3885.79
-------------------------------------
| approxkl           | 0.009314069  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.01e+03     |
| explained_variance | 6.62e-06     |
| fps                | 32           |
| n_updates          | 57           |
| policy_entropy     | 1.3713607    |
| policy_loss        | -0.026677182 |
| serial_timesteps   | 7296         |
| time_elapsed       | 232          |
| total_timesteps    | 7296         |
| value_loss         | 296.9019     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0014356222 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.01e+03     |
| explained_variance | 1.17e-05     |
| fps                | 29           |
| n_updates          | 58           |
| policy_entropy     | 1.3709052    |
| policy_loss        | -0.005083712 |
| serial_timesteps   | 7424         |
| time_elapsed       | 236          |
| total_timesteps    | 7424         |
| value_loss         | 427.21072    |
-------------------------------------
------------------------------------
| approxkl           | 0.011412    |
| clipfrac           | 0.18164062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.01e+03    |
| explained_variance | 2.93e-05    |
| fps                | 30          |
| n_updates          | 59          |
| policy_entropy     | 1.3704543   |
| policy_loss        | 0.023954129 |
| serial_timesteps   | 7552        |
| time_elapsed       | 241         |
| total_timesteps    | 7552        |
| value_loss         | 246.05402   |
------------------------------------
------------------------------------
| approxkl           | 0.013956019 |
| clipfrac           | 0.22851562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.01e+03    |
| explained_variance | -3.59e-05   |
| fps                | 32          |
| n_updates          | 60          |
| policy_entropy     | 1.3698994   |
| policy_loss        | 0.002513492 |
| serial_timesteps   | 7680        |
| time_elapsed       | 245         |
| total_timesteps    | 7680        |
| value_loss         | 458.0739    |
------------------------------------
---------------------------------------
| approxkl           | 6.6836306e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.07e+03       |
| explained_variance | -1.07e-05      |
| fps                | 30             |
| n_updates          | 61             |
| policy_entropy     | 1.3691775      |
| policy_loss        | -0.00034376222 |
| serial_timesteps   | 7808           |
| time_elapsed       | 249            |
| total_timesteps    | 7808           |
| value_loss         | 544.5751       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00011684906 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.07e+03      |
| explained_variance | -4.4e-05      |
| fps                | 29            |
| n_updates          | 62            |
| policy_entropy     | 1.3686788     |
| policy_loss        | -0.0022090238 |
| serial_timesteps   | 7936          |
| time_elapsed       | 253           |
| total_timesteps    | 7936          |
| value_loss         | 434.8267      |
--------------------------------------
------------------------------------
| approxkl           | 0.012289648 |
| clipfrac           | 0.19140625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.07e+03    |
| explained_variance | -8.23e-06   |
| fps                | 32          |
| n_updates          | 63          |
| policy_entropy     | 1.3673481   |
| policy_loss        | 0.017545411 |
| serial_timesteps   | 8064        |
| time_elapsed       | 257         |
| total_timesteps    | 8064        |
| value_loss         | 415.158     |
------------------------------------
-------------------------------------
| approxkl           | 0.0071926354 |
| clipfrac           | 0.08984375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.07e+03     |
| explained_variance | -6.44e-06    |
| fps                | 33           |
| n_updates          | 64           |
| policy_entropy     | 1.3661513    |
| policy_loss        | 0.018138953  |
| serial_timesteps   | 8192         |
| time_elapsed       | 261          |
| total_timesteps    | 8192         |
| value_loss         | 119.04198    |
-------------------------------------
An average of 84.0 episodes completed
Best mean reward: 4033.31 - Latest 5 sample mean reward per episode: 4066.87
Saving new best model
--------------------------------------
| approxkl           | 0.0014991288  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.07e+03      |
| explained_variance | -1.44e-05     |
| fps                | 31            |
| n_updates          | 65            |
| policy_entropy     | 1.3659437     |
| policy_loss        | -0.0022699833 |
| serial_timesteps   | 8320          |
| time_elapsed       | 265           |
| total_timesteps    | 8320          |
| value_loss         | 448.68387     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0051261866 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.07e+03     |
| explained_variance | -1.54e-05    |
| fps                | 32           |
| n_updates          | 66           |
| policy_entropy     | 1.3649102    |
| policy_loss        | -0.010921569 |
| serial_timesteps   | 8448         |
| time_elapsed       | 269          |
| total_timesteps    | 8448         |
| value_loss         | 120.39902    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0014864675 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.07e+03     |
| explained_variance | -1.1e-05     |
| fps                | 31           |
| n_updates          | 67           |
| policy_entropy     | 1.3638042    |
| policy_loss        | -0.008795191 |
| serial_timesteps   | 8576         |
| time_elapsed       | 273          |
| total_timesteps    | 8576         |
| value_loss         | 413.53503    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0034293472 |
| clipfrac           | 0.029296875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.07e+03     |
| explained_variance | 1.47e-05     |
| fps                | 35           |
| n_updates          | 68           |
| policy_entropy     | 1.3632042    |
| policy_loss        | 0.013757909  |
| serial_timesteps   | 8704         |
| time_elapsed       | 277          |
| total_timesteps    | 8704         |
| value_loss         | 233.76862    |
-------------------------------------
------------------------------------
| approxkl           | 0.009955753 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.07e+03    |
| explained_variance | -6.56e-05   |
| fps                | 32          |
| n_updates          | 69          |
| policy_entropy     | 1.3621877   |
| policy_loss        | 0.009038692 |
| serial_timesteps   | 8832        |
| time_elapsed       | 281         |
| total_timesteps    | 8832        |
| value_loss         | 410.27576   |
------------------------------------
-------------------------------------
| approxkl           | 0.013249622  |
| clipfrac           | 0.18164062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.07e+03     |
| explained_variance | -2.03e-05    |
| fps                | 31           |
| n_updates          | 70           |
| policy_entropy     | 1.3612418    |
| policy_loss        | 0.0061637643 |
| serial_timesteps   | 8960         |
| time_elapsed       | 285          |
| total_timesteps    | 8960         |
| value_loss         | 362.2797     |
-------------------------------------
------------------------------------
| approxkl           | 0.004439214 |
| clipfrac           | 0.048828125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.07e+03    |
| explained_variance | 0.000123    |
| fps                | 31          |
| n_updates          | 71          |
| policy_entropy     | 1.3600565   |
| policy_loss        | 0.01351741  |
| serial_timesteps   | 9088        |
| time_elapsed       | 289         |
| total_timesteps    | 9088        |
| value_loss         | 483.36667   |
------------------------------------
An average of 84.0 episodes completed
Best mean reward: 4066.87 - Latest 5 sample mean reward per episode: 4066.87
-------------------------------------
| approxkl           | 0.004182156  |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.07e+03     |
| explained_variance | -4.37e-05    |
| fps                | 31           |
| n_updates          | 72           |
| policy_entropy     | 1.3585199    |
| policy_loss        | -0.013806328 |
| serial_timesteps   | 9216         |
| time_elapsed       | 293          |
| total_timesteps    | 9216         |
| value_loss         | 255.30875    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0015396329 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.13e+03     |
| explained_variance | 1.91e-06     |
| fps                | 30           |
| n_updates          | 73           |
| policy_entropy     | 1.357616     |
| policy_loss        | 0.0015649181 |
| serial_timesteps   | 9344         |
| time_elapsed       | 297          |
| total_timesteps    | 9344         |
| value_loss         | 583.2402     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00022782263 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.13e+03      |
| explained_variance | -4.73e-05     |
| fps                | 32            |
| n_updates          | 74            |
| policy_entropy     | 1.3572332     |
| policy_loss        | -0.0015652223 |
| serial_timesteps   | 9472          |
| time_elapsed       | 301           |
| total_timesteps    | 9472          |
| value_loss         | 412.63596     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00013695162  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.13e+03       |
| explained_variance | 3.87e-05       |
| fps                | 32             |
| n_updates          | 75             |
| policy_entropy     | 1.3571842      |
| policy_loss        | -0.00079445075 |
| serial_timesteps   | 9600           |
| time_elapsed       | 305            |
| total_timesteps    | 9600           |
| value_loss         | 331.68835      |
---------------------------------------
--------------------------------------
| approxkl           | 0.025642194   |
| clipfrac           | 0.30273438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.13e+03      |
| explained_variance | 1.19e-06      |
| fps                | 30            |
| n_updates          | 76            |
| policy_entropy     | 1.3569565     |
| policy_loss        | -0.0013043932 |
| serial_timesteps   | 9728          |
| time_elapsed       | 309           |
| total_timesteps    | 9728          |
| value_loss         | 285.34323     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005813802  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.13e+03      |
| explained_variance | 5.01e-06      |
| fps                | 31            |
| n_updates          | 77            |
| policy_entropy     | 1.3567327     |
| policy_loss        | -0.0021867494 |
| serial_timesteps   | 9856          |
| time_elapsed       | 313           |
| total_timesteps    | 9856          |
| value_loss         | 485.70807     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0048602223 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.13e+03     |
| explained_variance | -0.000134    |
| fps                | 32           |
| n_updates          | 78           |
| policy_entropy     | 1.3572553    |
| policy_loss        | -0.007829882 |
| serial_timesteps   | 9984         |
| time_elapsed       | 317          |
| total_timesteps    | 9984         |
| value_loss         | 318.75635    |
-------------------------------------
------------------------------------
| approxkl           | 0.011894679 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.13e+03    |
| explained_variance | 1.43e-06    |
| fps                | 31          |
| n_updates          | 79          |
| policy_entropy     | 1.3568342   |
| policy_loss        | 0.017138263 |
| serial_timesteps   | 10112       |
| time_elapsed       | 321         |
| total_timesteps    | 10112       |
| value_loss         | 204.43515   |
------------------------------------
An average of 85.0 episodes completed
Best mean reward: 4066.87 - Latest 5 sample mean reward per episode: 4118.55
Saving new best model
-------------------------------------
| approxkl           | 0.011238535  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.13e+03     |
| explained_variance | -3.52e-05    |
| fps                | 29           |
| n_updates          | 80           |
| policy_entropy     | 1.3563092    |
| policy_loss        | -0.012233334 |
| serial_timesteps   | 10240        |
| time_elapsed       | 325          |
| total_timesteps    | 10240        |
| value_loss         | 26.328       |
-------------------------------------
-------------------------------------
| approxkl           | 0.009572211  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.13e+03     |
| explained_variance | -5.96e-06    |
| fps                | 30           |
| n_updates          | 81           |
| policy_entropy     | 1.3561263    |
| policy_loss        | -0.013471682 |
| serial_timesteps   | 10368        |
| time_elapsed       | 330          |
| total_timesteps    | 10368        |
| value_loss         | 89.12719     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0027081699 |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.13e+03     |
| explained_variance | -5.02e-05    |
| fps                | 31           |
| n_updates          | 82           |
| policy_entropy     | 1.3563355    |
| policy_loss        | -0.00713263  |
| serial_timesteps   | 10496        |
| time_elapsed       | 334          |
| total_timesteps    | 10496        |
| value_loss         | 135.4338     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00029366158 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.13e+03      |
| explained_variance | 0.000142      |
| fps                | 34            |
| n_updates          | 83            |
| policy_entropy     | 1.3563918     |
| policy_loss        | -0.0016670643 |
| serial_timesteps   | 10624         |
| time_elapsed       | 338           |
| total_timesteps    | 10624         |
| value_loss         | 407.7103      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00043556653 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.13e+03      |
| explained_variance | 7.27e-06      |
| fps                | 34            |
| n_updates          | 84            |
| policy_entropy     | 1.3560514     |
| policy_loss        | 0.0066704224  |
| serial_timesteps   | 10752         |
| time_elapsed       | 342           |
| total_timesteps    | 10752         |
| value_loss         | 235.76485     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0014770557  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.11e+03      |
| explained_variance | 1.23e-05      |
| fps                | 31            |
| n_updates          | 85            |
| policy_entropy     | 1.3556774     |
| policy_loss        | -0.0026050154 |
| serial_timesteps   | 10880         |
| time_elapsed       | 345           |
| total_timesteps    | 10880         |
| value_loss         | 687.09357     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0018511888 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.11e+03     |
| explained_variance | -5.25e-06    |
| fps                | 30           |
| n_updates          | 86           |
| policy_entropy     | 1.3551676    |
| policy_loss        | 0.0006493117 |
| serial_timesteps   | 11008        |
| time_elapsed       | 350          |
| total_timesteps    | 11008        |
| value_loss         | 458.88135    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00010133571 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.11e+03      |
| explained_variance | 6.74e-06      |
| fps                | 31            |
| n_updates          | 87            |
| policy_entropy     | 1.3548946     |
| policy_loss        | 0.0006858242  |
| serial_timesteps   | 11136         |
| time_elapsed       | 354           |
| total_timesteps    | 11136         |
| value_loss         | 403.3007      |
--------------------------------------
An average of 86.0 episodes completed
Best mean reward: 4118.55 - Latest 5 sample mean reward per episode: 4192.81
Saving new best model
-------------------------------------
| approxkl           | 0.003996662  |
| clipfrac           | 0.037109375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.11e+03     |
| explained_variance | -3.95e-05    |
| fps                | 32           |
| n_updates          | 88           |
| policy_entropy     | 1.3541367    |
| policy_loss        | -0.014160735 |
| serial_timesteps   | 11264        |
| time_elapsed       | 358          |
| total_timesteps    | 11264        |
| value_loss         | 311.7395     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00778906    |
| clipfrac           | 0.107421875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.11e+03      |
| explained_variance | 4.08e-05      |
| fps                | 33            |
| n_updates          | 89            |
| policy_entropy     | 1.3547329     |
| policy_loss        | -0.0030700506 |
| serial_timesteps   | 11392         |
| time_elapsed       | 362           |
| total_timesteps    | 11392         |
| value_loss         | 289.07968     |
--------------------------------------
-------------------------------------
| approxkl           | 0.021349449  |
| clipfrac           | 0.25976562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.11e+03     |
| explained_variance | 2.73e-05     |
| fps                | 31           |
| n_updates          | 90           |
| policy_entropy     | 1.355204     |
| policy_loss        | -0.036792334 |
| serial_timesteps   | 11520        |
| time_elapsed       | 366          |
| total_timesteps    | 11520        |
| value_loss         | 212.96704    |
-------------------------------------
--------------------------------------
| approxkl           | 9.7888165e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.11e+03      |
| explained_variance | 2.59e-05      |
| fps                | 29            |
| n_updates          | 91            |
| policy_entropy     | 1.3563633     |
| policy_loss        | 0.001551908   |
| serial_timesteps   | 11648         |
| time_elapsed       | 370           |
| total_timesteps    | 11648         |
| value_loss         | 298.01935     |
--------------------------------------
--------------------------------------
| approxkl           | 0.02693965    |
| clipfrac           | 0.34375       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.11e+03      |
| explained_variance | -9.06e-05     |
| fps                | 31            |
| n_updates          | 92            |
| policy_entropy     | 1.3582604     |
| policy_loss        | -0.0067861117 |
| serial_timesteps   | 11776         |
| time_elapsed       | 374           |
| total_timesteps    | 11776         |
| value_loss         | 235.90343     |
--------------------------------------
------------------------------------
| approxkl           | 0.014211383 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.11e+03    |
| explained_variance | -5.96e-05   |
| fps                | 29          |
| n_updates          | 93          |
| policy_entropy     | 1.3595058   |
| policy_loss        | 0.018608648 |
| serial_timesteps   | 11904       |
| time_elapsed       | 378         |
| total_timesteps    | 11904       |
| value_loss         | 380.17612   |
------------------------------------
-------------------------------------
| approxkl           | 0.013587497  |
| clipfrac           | 0.18945312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.11e+03     |
| explained_variance | 8.11e-06     |
| fps                | 31           |
| n_updates          | 94           |
| policy_entropy     | 1.3597959    |
| policy_loss        | 0.0074108187 |
| serial_timesteps   | 12032        |
| time_elapsed       | 382          |
| total_timesteps    | 12032        |
| value_loss         | 345.4192     |
-------------------------------------
-------------------------------------
| approxkl           | 0.008064644  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.11e+03     |
| explained_variance | 9.54e-06     |
| fps                | 33           |
| n_updates          | 95           |
| policy_entropy     | 1.3609235    |
| policy_loss        | 0.0013294087 |
| serial_timesteps   | 12160        |
| time_elapsed       | 386          |
| total_timesteps    | 12160        |
| value_loss         | 60.286182    |
-------------------------------------
An average of 86.0 episodes completed
Best mean reward: 4192.81 - Latest 5 sample mean reward per episode: 4192.81
-------------------------------------
| approxkl           | 0.0003077088 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.11e+03     |
| explained_variance | -8.23e-06    |
| fps                | 31           |
| n_updates          | 96           |
| policy_entropy     | 1.3624055    |
| policy_loss        | 0.004228911  |
| serial_timesteps   | 12288        |
| time_elapsed       | 390          |
| total_timesteps    | 12288        |
| value_loss         | 390.64053    |
-------------------------------------
--------------------------------------
| approxkl           | 0.014141544   |
| clipfrac           | 0.15820312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.14e+03      |
| explained_variance | -3.7e-06      |
| fps                | 33            |
| n_updates          | 97            |
| policy_entropy     | 1.3632143     |
| policy_loss        | -0.0005960441 |
| serial_timesteps   | 12416         |
| time_elapsed       | 394           |
| total_timesteps    | 12416         |
| value_loss         | 573.5015      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0006459849 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.14e+03     |
| explained_variance | -1.56e-05    |
| fps                | 34           |
| n_updates          | 98           |
| policy_entropy     | 1.3638922    |
| policy_loss        | -0.000348293 |
| serial_timesteps   | 12544        |
| time_elapsed       | 398          |
| total_timesteps    | 12544        |
| value_loss         | 391.7002     |
-------------------------------------
--------------------------------------
| approxkl           | 9.700705e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.14e+03      |
| explained_variance | 0.000184      |
| fps                | 33            |
| n_updates          | 99            |
| policy_entropy     | 1.3640153     |
| policy_loss        | -0.0010991568 |
| serial_timesteps   | 12672         |
| time_elapsed       | 402           |
| total_timesteps    | 12672         |
| value_loss         | 358.6067      |
--------------------------------------
------------------------------------
| approxkl           | 0.018811146 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.14e+03    |
| explained_variance | 4.44e-05    |
| fps                | 33          |
| n_updates          | 100         |
| policy_entropy     | 1.3643541   |
| policy_loss        | 0.014425442 |
| serial_timesteps   | 12800       |
| time_elapsed       | 406         |
| total_timesteps    | 12800       |
| value_loss         | 346.17422   |
------------------------------------
-------------------------------------
| approxkl           | 0.015224033  |
| clipfrac           | 0.21679688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.14e+03     |
| explained_variance | -2.5e-06     |
| fps                | 31           |
| n_updates          | 101          |
| policy_entropy     | 1.3634       |
| policy_loss        | -0.020394253 |
| serial_timesteps   | 12928        |
| time_elapsed       | 409          |
| total_timesteps    | 12928        |
| value_loss         | 226.35532    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00050569256 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.14e+03      |
| explained_variance | 9.36e-06      |
| fps                | 32            |
| n_updates          | 102           |
| policy_entropy     | 1.362133      |
| policy_loss        | 0.0077642975  |
| serial_timesteps   | 13056         |
| time_elapsed       | 414           |
| total_timesteps    | 13056         |
| value_loss         | 359.9924      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0058326717 |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.14e+03     |
| explained_variance | -5.53e-05    |
| fps                | 33           |
| n_updates          | 103          |
| policy_entropy     | 1.3612219    |
| policy_loss        | -0.009150631 |
| serial_timesteps   | 13184        |
| time_elapsed       | 417          |
| total_timesteps    | 13184        |
| value_loss         | 354.4413     |
-------------------------------------
An average of 87.0 episodes completed
Best mean reward: 4192.81 - Latest 5 sample mean reward per episode: 4276.43
Saving new best model
------------------------------------
| approxkl           | 0.014027392 |
| clipfrac           | 0.21679688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.14e+03    |
| explained_variance | -1.19e-07   |
| fps                | 32          |
| n_updates          | 104         |
| policy_entropy     | 1.3596991   |
| policy_loss        | 0.024316385 |
| serial_timesteps   | 13312       |
| time_elapsed       | 421         |
| total_timesteps    | 13312       |
| value_loss         | 220.61633   |
------------------------------------
-------------------------------------
| approxkl           | 0.0046696034 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.14e+03     |
| explained_variance | -2.28e-05    |
| fps                | 34           |
| n_updates          | 105          |
| policy_entropy     | 1.359151     |
| policy_loss        | -0.013303405 |
| serial_timesteps   | 13440        |
| time_elapsed       | 425          |
| total_timesteps    | 13440        |
| value_loss         | 442.49554    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005059683  |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.14e+03     |
| explained_variance | 1.5e-05      |
| fps                | 33           |
| n_updates          | 106          |
| policy_entropy     | 1.357963     |
| policy_loss        | -0.008000938 |
| serial_timesteps   | 13568        |
| time_elapsed       | 429          |
| total_timesteps    | 13568        |
| value_loss         | 269.6068     |
-------------------------------------
-------------------------------------
| approxkl           | 0.016718348  |
| clipfrac           | 0.21679688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.14e+03     |
| explained_variance | -2.97e-05    |
| fps                | 32           |
| n_updates          | 107          |
| policy_entropy     | 1.3560071    |
| policy_loss        | -0.010115919 |
| serial_timesteps   | 13696        |
| time_elapsed       | 433          |
| total_timesteps    | 13696        |
| value_loss         | 278.70084    |
-------------------------------------
------------------------------------
| approxkl           | 0.012380292 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.14e+03    |
| explained_variance | -5.36e-06   |
| fps                | 30          |
| n_updates          | 108         |
| policy_entropy     | 1.3547101   |
| policy_loss        | 0.013484683 |
| serial_timesteps   | 13824       |
| time_elapsed       | 437         |
| total_timesteps    | 13824       |
| value_loss         | 453.13776   |
------------------------------------
---------------------------------------
| approxkl           | 0.009228474    |
| clipfrac           | 0.1328125      |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.19e+03       |
| explained_variance | 1.79e-07       |
| fps                | 32             |
| n_updates          | 109            |
| policy_entropy     | 1.3545154      |
| policy_loss        | -0.00091608206 |
| serial_timesteps   | 13952          |
| time_elapsed       | 441            |
| total_timesteps    | 13952          |
| value_loss         | 651.04895      |
---------------------------------------
---------------------------------------
| approxkl           | 9.333765e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.19e+03       |
| explained_variance | 2.56e-06       |
| fps                | 31             |
| n_updates          | 110            |
| policy_entropy     | 1.3544744      |
| policy_loss        | -0.00063407246 |
| serial_timesteps   | 14080          |
| time_elapsed       | 445            |
| total_timesteps    | 14080          |
| value_loss         | 240.81311      |
---------------------------------------
An average of 88.0 episodes completed
Best mean reward: 4276.43 - Latest 5 sample mean reward per episode: 4331.46
Saving new best model
--------------------------------------
| approxkl           | 0.00051546755 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.19e+03      |
| explained_variance | -1.25e-05     |
| fps                | 30            |
| n_updates          | 111           |
| policy_entropy     | 1.354407      |
| policy_loss        | -0.0022421689 |
| serial_timesteps   | 14208         |
| time_elapsed       | 449           |
| total_timesteps    | 14208         |
| value_loss         | 110.21603     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0027415939 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.19e+03     |
| explained_variance | -4.17e-06    |
| fps                | 29           |
| n_updates          | 112          |
| policy_entropy     | 1.353024     |
| policy_loss        | -0.005080945 |
| serial_timesteps   | 14336        |
| time_elapsed       | 453          |
| total_timesteps    | 14336        |
| value_loss         | 287.67377    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0019063738 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.19e+03     |
| explained_variance | -9.18e-06    |
| fps                | 30           |
| n_updates          | 113          |
| policy_entropy     | 1.351221     |
| policy_loss        | 0.0041507473 |
| serial_timesteps   | 14464        |
| time_elapsed       | 457          |
| total_timesteps    | 14464        |
| value_loss         | 305.94666    |
-------------------------------------
------------------------------------
| approxkl           | 0.004116384 |
| clipfrac           | 0.033203125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.19e+03    |
| explained_variance | -3.34e-06   |
| fps                | 34          |
| n_updates          | 114         |
| policy_entropy     | 1.3498969   |
| policy_loss        | 0.008267708 |
| serial_timesteps   | 14592       |
| time_elapsed       | 462         |
| total_timesteps    | 14592       |
| value_loss         | 297.69806   |
------------------------------------
------------------------------------
| approxkl           | 0.002833025 |
| clipfrac           | 0.017578125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.19e+03    |
| explained_variance | -0.000162   |
| fps                | 33          |
| n_updates          | 115         |
| policy_entropy     | 1.3488461   |
| policy_loss        | 0.010552628 |
| serial_timesteps   | 14720       |
| time_elapsed       | 465         |
| total_timesteps    | 14720       |
| value_loss         | 322.87088   |
------------------------------------
------------------------------------
| approxkl           | 0.013198212 |
| clipfrac           | 0.18554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.19e+03    |
| explained_variance | -5.25e-05   |
| fps                | 29          |
| n_updates          | 116         |
| policy_entropy     | 1.3486916   |
| policy_loss        | 0.02436779  |
| serial_timesteps   | 14848       |
| time_elapsed       | 469         |
| total_timesteps    | 14848       |
| value_loss         | 378.03174   |
------------------------------------
-------------------------------------
| approxkl           | 0.016203275  |
| clipfrac           | 0.24023438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.19e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 117          |
| policy_entropy     | 1.3492072    |
| policy_loss        | -0.017493265 |
| serial_timesteps   | 14976        |
| time_elapsed       | 473          |
| total_timesteps    | 14976        |
| value_loss         | 316.5913     |
-------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b75c28d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b75c28d30>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b75babe48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b75babe48>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2336 samples, validate on 318 samples
Epoch 191/5000
 - 3s - loss: 0.2432 - val_loss: 0.3556
Epoch 192/5000
 - 0s - loss: 0.2432 - val_loss: 0.3556
Epoch 193/5000
 - 0s - loss: 0.2432 - val_loss: 0.3556
Epoch 194/5000
 - 0s - loss: 0.2432 - val_loss: 0.3556
Epoch 195/5000
 - 1s - loss: 0.2432 - val_loss: 0.3556
Epoch 196/5000
 - 1s - loss: 0.2432 - val_loss: 0.3556
Train on 1910 samples, validate on 318 samples
Epoch 145/5000
 - 3s - loss: 0.0032 - val_loss: 0.0015
Epoch 146/5000
 - 0s - loss: 0.0019 - val_loss: 0.0016
Epoch 147/5000
 - 0s - loss: 0.0012 - val_loss: 0.0014
Epoch 148/5000
 - 0s - loss: 0.0011 - val_loss: 0.0014
Epoch 149/5000
 - 0s - loss: 7.9931e-04 - val_loss: 0.0013
Epoch 150/5000
 - 0s - loss: 7.1380e-04 - val_loss: 0.0013
Epoch 151/5000
 - 0s - loss: 6.4812e-04 - val_loss: 0.0013
Epoch 152/5000
 - 0s - loss: 6.3740e-04 - val_loss: 0.0012
Epoch 153/5000
 - 0s - loss: 6.4484e-04 - val_loss: 0.0012
Epoch 154/5000
 - 0s - loss: 6.4333e-04 - val_loss: 0.0012
Epoch 155/5000
 - 0s - loss: 6.4123e-04 - val_loss: 0.0012
Epoch 156/5000
 - 0s - loss: 6.3948e-04 - val_loss: 0.0012
Epoch 157/5000
 - 0s - loss: 6.2983e-04 - val_loss: 0.0013
Epoch 158/5000
 - 0s - loss: 6.1815e-04 - val_loss: 0.0013
Epoch 159/5000
 - 0s - loss: 6.1451e-04 - val_loss: 0.0014
Epoch 160/5000
 - 0s - loss: 6.1316e-04 - val_loss: 0.0014
Epoch 161/5000
 - 0s - loss: 6.0966e-04 - val_loss: 0.0014
Train on 2337 samples, validate on 318 samples
Epoch 271/5000
 - 4s - loss: 0.5943 - val_loss: 0.3821
Epoch 272/5000
 - 1s - loss: 0.4606 - val_loss: 0.2728
Epoch 273/5000
 - 1s - loss: 0.4714 - val_loss: 0.2716
Epoch 274/5000
 - 1s - loss: 0.4685 - val_loss: 0.2711
Epoch 275/5000
 - 1s - loss: 0.4663 - val_loss: 0.2702
Epoch 276/5000
 - 1s - loss: 0.4644 - val_loss: 0.2689
Epoch 277/5000
 - 1s - loss: 0.4627 - val_loss: 0.2674
Epoch 278/5000
 - 1s - loss: 0.4609 - val_loss: 0.2656
Epoch 279/5000
 - 1s - loss: 0.4590 - val_loss: 0.2636
Epoch 280/5000
 - 1s - loss: 0.4569 - val_loss: 0.2614
Epoch 281/5000
 - 1s - loss: 0.4545 - val_loss: 0.2587
Epoch 282/5000
 - 1s - loss: 0.4519 - val_loss: 0.2560
Epoch 283/5000
 - 1s - loss: 0.4490 - val_loss: 0.2531
Epoch 284/5000
 - 1s - loss: 0.4456 - val_loss: 0.2498
Epoch 285/5000
 - 1s - loss: 0.4418 - val_loss: 0.2463
Epoch 286/5000
 - 1s - loss: 0.4375 - val_loss: 0.2425
Epoch 287/5000
 - 1s - loss: 0.4327 - val_loss: 0.2385
Epoch 288/5000
 - 1s - loss: 0.4272 - val_loss: 0.2344
Epoch 289/5000
 - 1s - loss: 0.4209 - val_loss: 0.2302
Epoch 290/5000
 - 1s - loss: 0.4140 - val_loss: 0.2262
Epoch 291/5000
 - 1s - loss: 0.4064 - val_loss: 0.2225
Epoch 292/5000
 - 1s - loss: 0.3979 - val_loss: 0.2194
Epoch 293/5000
 - 1s - loss: 0.3885 - val_loss: 0.2170
Epoch 294/5000
 - 1s - loss: 0.3754 - val_loss: 0.2169
Epoch 295/5000
 - 1s - loss: 0.3629 - val_loss: 0.2194
Epoch 296/5000
 - 1s - loss: 0.3389 - val_loss: 0.2144
Epoch 297/5000
 - 1s - loss: 0.3273 - val_loss: 0.2119
Epoch 298/5000
 - 1s - loss: 0.3208 - val_loss: 0.2104
Epoch 299/5000
 - 1s - loss: 0.3172 - val_loss: 0.2097
Epoch 300/5000
 - 1s - loss: 0.3150 - val_loss: 0.2095
Epoch 301/5000
 - 1s - loss: 0.3134 - val_loss: 0.2095
Epoch 302/5000
 - 1s - loss: 0.3120 - val_loss: 0.2095
Epoch 303/5000
 - 1s - loss: 0.3084 - val_loss: 0.2095
Epoch 304/5000
 - 1s - loss: 0.3083 - val_loss: 0.2094
Epoch 305/5000
 - 1s - loss: 0.3081 - val_loss: 0.2094
Epoch 306/5000
 - 1s - loss: 0.3080 - val_loss: 0.2094
Epoch 307/5000
 - 1s - loss: 0.3078 - val_loss: 0.2093
Epoch 308/5000
 - 1s - loss: 0.3075 - val_loss: 0.2093
Epoch 309/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 310/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 311/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 312/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 313/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 314/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 315/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 316/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 317/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 318/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 319/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 320/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 321/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 322/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 323/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 324/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 325/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 326/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
Epoch 327/5000
 - 1s - loss: 0.3074 - val_loss: 0.2093
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.023321958  |
| clipfrac           | 0.33789062   |
| explained_variance | 6.62e-06     |
| fps                | 7            |
| n_updates          | 1            |
| policy_entropy     | 1.3492627    |
| policy_loss        | -0.018112063 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.14e-05     |
| total_timesteps    | 128          |
| value_loss         | 20.573072    |
-------------------------------------
An average of 89.0 episodes completed
Best mean reward: 4331.46 - Latest 5 sample mean reward per episode: 4397.92
Saving new best model
--------------------------------------
| approxkl           | 0.0009980007  |
| clipfrac           | 0.0           |
| explained_variance | -1.72e-05     |
| fps                | 30            |
| n_updates          | 2             |
| policy_entropy     | 1.3493079     |
| policy_loss        | -0.0010231922 |
| serial_timesteps   | 256           |
| time_elapsed       | 17.2          |
| total_timesteps    | 256           |
| value_loss         | 36.745644     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0014926359  |
| clipfrac           | 0.0           |
| explained_variance | -1.53e-05     |
| fps                | 34            |
| n_updates          | 3             |
| policy_entropy     | 1.348831      |
| policy_loss        | -0.0005665383 |
| serial_timesteps   | 384           |
| time_elapsed       | 21.4          |
| total_timesteps    | 384           |
| value_loss         | 59.934723     |
--------------------------------------
--------------------------------------
| approxkl           | 0.008111613   |
| clipfrac           | 0.123046875   |
| explained_variance | -2.56e-05     |
| fps                | 33            |
| n_updates          | 4             |
| policy_entropy     | 1.3478966     |
| policy_loss        | -0.0073428773 |
| serial_timesteps   | 512           |
| time_elapsed       | 25.1          |
| total_timesteps    | 512           |
| value_loss         | 66.538124     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0013677592  |
| clipfrac           | 0.009765625   |
| explained_variance | -3.14e-05     |
| fps                | 29            |
| n_updates          | 5             |
| policy_entropy     | 1.3472425     |
| policy_loss        | -0.0064181145 |
| serial_timesteps   | 640           |
| time_elapsed       | 28.9          |
| total_timesteps    | 640           |
| value_loss         | 48.29583      |
--------------------------------------
-------------------------------------
| approxkl           | 0.011307101  |
| clipfrac           | 0.19726562   |
| explained_variance | 3.4e-06      |
| fps                | 29           |
| n_updates          | 6            |
| policy_entropy     | 1.3464673    |
| policy_loss        | 0.0052990727 |
| serial_timesteps   | 768          |
| time_elapsed       | 33.3         |
| total_timesteps    | 768          |
| value_loss         | 30.464188    |
-------------------------------------
--------------------------------------
| approxkl           | 0.009087786   |
| clipfrac           | 0.13867188    |
| explained_variance | -8.34e-05     |
| fps                | 30            |
| n_updates          | 7             |
| policy_entropy     | 1.3457989     |
| policy_loss        | 0.00075060176 |
| serial_timesteps   | 896           |
| time_elapsed       | 37.6          |
| total_timesteps    | 896           |
| value_loss         | 145.66264     |
--------------------------------------
--------------------------------------
| approxkl           | 0.03600268    |
| clipfrac           | 0.39648438    |
| explained_variance | 2.68e-06      |
| fps                | 30            |
| n_updates          | 8             |
| policy_entropy     | 1.3433064     |
| policy_loss        | -0.0097630955 |
| serial_timesteps   | 1024          |
| time_elapsed       | 41.8          |
| total_timesteps    | 1024          |
| value_loss         | 33.460728     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0041407268 |
| clipfrac           | 0.048828125  |
| explained_variance | 8.34e-06     |
| fps                | 29           |
| n_updates          | 9            |
| policy_entropy     | 1.3414826    |
| policy_loss        | -0.002986504 |
| serial_timesteps   | 1152         |
| time_elapsed       | 46           |
| total_timesteps    | 1152         |
| value_loss         | 39.64291     |
-------------------------------------
An average of 89.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 4397.92
-------------------------------------
| approxkl           | 0.004026621  |
| clipfrac           | 0.0546875    |
| explained_variance | -3.58e-06    |
| fps                | 28           |
| n_updates          | 10           |
| policy_entropy     | 1.3412613    |
| policy_loss        | -0.020355571 |
| serial_timesteps   | 1280         |
| time_elapsed       | 50.3         |
| total_timesteps    | 1280         |
| value_loss         | 163.02098    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0006485602 |
| clipfrac           | 0.0          |
| explained_variance | -1.12e-05    |
| fps                | 29           |
| n_updates          | 11           |
| policy_entropy     | 1.3409259    |
| policy_loss        | 0.0075603696 |
| serial_timesteps   | 1408         |
| time_elapsed       | 54.8         |
| total_timesteps    | 1408         |
| value_loss         | 257.43924    |
-------------------------------------
------------------------------------
| approxkl           | 0.020207956 |
| clipfrac           | 0.28125     |
| explained_variance | 6.38e-06    |
| fps                | 28          |
| n_updates          | 12          |
| policy_entropy     | 1.339707    |
| policy_loss        | 0.017126612 |
| serial_timesteps   | 1536        |
| time_elapsed       | 59.1        |
| total_timesteps    | 1536        |
| value_loss         | 264.98383   |
------------------------------------
------------------------------------
| approxkl           | 0.010887034 |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.1e+03     |
| explained_variance | -3.58e-06   |
| fps                | 30          |
| n_updates          | 13          |
| policy_entropy     | 1.3389511   |
| policy_loss        | 0.01735486  |
| serial_timesteps   | 1664        |
| time_elapsed       | 63.6        |
| total_timesteps    | 1664        |
| value_loss         | 592.11096   |
------------------------------------
-------------------------------------
| approxkl           | 0.008625636  |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -1.67e-06    |
| fps                | 31           |
| n_updates          | 14           |
| policy_entropy     | 1.3387237    |
| policy_loss        | -0.018931942 |
| serial_timesteps   | 1792         |
| time_elapsed       | 67.8         |
| total_timesteps    | 1792         |
| value_loss         | 58.563725    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0008060825 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | 6.47e-05     |
| fps                | 30           |
| n_updates          | 15           |
| policy_entropy     | 1.3383105    |
| policy_loss        | 0.0011561259 |
| serial_timesteps   | 1920         |
| time_elapsed       | 71.9         |
| total_timesteps    | 1920         |
| value_loss         | 192.76048    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0059807524 |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -4.65e-06    |
| fps                | 29           |
| n_updates          | 16           |
| policy_entropy     | 1.3377922    |
| policy_loss        | -0.011622973 |
| serial_timesteps   | 2048         |
| time_elapsed       | 76.1         |
| total_timesteps    | 2048         |
| value_loss         | 31.97782     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0018197681 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | 3.99e-06     |
| fps                | 28           |
| n_updates          | 17           |
| policy_entropy     | 1.3367171    |
| policy_loss        | -0.008928374 |
| serial_timesteps   | 2176         |
| time_elapsed       | 80.5         |
| total_timesteps    | 2176         |
| value_loss         | 85.26799     |
-------------------------------------
An average of 90.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 4131.04
--------------------------------------
| approxkl           | 0.00048336072 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.1e+03       |
| explained_variance | -2.35e-05     |
| fps                | 27            |
| n_updates          | 18            |
| policy_entropy     | 1.3360796     |
| policy_loss        | 0.0025428806  |
| serial_timesteps   | 2304          |
| time_elapsed       | 84.9          |
| total_timesteps    | 2304          |
| value_loss         | 50.03568      |
--------------------------------------
-------------------------------------
| approxkl           | 0.009107751  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -0.000133    |
| fps                | 33           |
| n_updates          | 19           |
| policy_entropy     | 1.3355511    |
| policy_loss        | -0.006855147 |
| serial_timesteps   | 2432         |
| time_elapsed       | 89.6         |
| total_timesteps    | 2432         |
| value_loss         | 39.35837     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0007727844 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -4.17e-05    |
| fps                | 31           |
| n_updates          | 20           |
| policy_entropy     | 1.3349103    |
| policy_loss        | 0.0015101919 |
| serial_timesteps   | 2560         |
| time_elapsed       | 93.5         |
| total_timesteps    | 2560         |
| value_loss         | 154.7305     |
-------------------------------------
-------------------------------------
| approxkl           | 0.013059277  |
| clipfrac           | 0.16992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -5.36e-06    |
| fps                | 30           |
| n_updates          | 21           |
| policy_entropy     | 1.3341222    |
| policy_loss        | -0.016762022 |
| serial_timesteps   | 2688         |
| time_elapsed       | 97.6         |
| total_timesteps    | 2688         |
| value_loss         | 38.086777    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0014671778 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -1.42e-05    |
| fps                | 27           |
| n_updates          | 22           |
| policy_entropy     | 1.3331667    |
| policy_loss        | 0.0052912626 |
| serial_timesteps   | 2816         |
| time_elapsed       | 102          |
| total_timesteps    | 2816         |
| value_loss         | 110.72516    |
-------------------------------------
-------------------------------------
| approxkl           | 0.019121455  |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.1e+03      |
| explained_variance | -9.23e-05    |
| fps                | 29           |
| n_updates          | 23           |
| policy_entropy     | 1.3323563    |
| policy_loss        | 0.0020648246 |
| serial_timesteps   | 2944         |
| time_elapsed       | 106          |
| total_timesteps    | 2944         |
| value_loss         | 103.3902     |
-------------------------------------
---------------------------------------
| approxkl           | 5.6399786e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.1e+03        |
| explained_variance | 5.01e-06       |
| fps                | 29             |
| n_updates          | 24             |
| policy_entropy     | 1.3311737      |
| policy_loss        | -0.00064635207 |
| serial_timesteps   | 3072           |
| time_elapsed       | 111            |
| total_timesteps    | 3072           |
| value_loss         | 53.23725       |
---------------------------------------
--------------------------------------
| approxkl           | 7.3811956e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.09e+03      |
| explained_variance | -6.32e-06     |
| fps                | 29            |
| n_updates          | 25            |
| policy_entropy     | 1.3292879     |
| policy_loss        | 0.0013127053  |
| serial_timesteps   | 3200          |
| time_elapsed       | 115           |
| total_timesteps    | 3200          |
| value_loss         | 727.8991      |
--------------------------------------
An average of 91.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3941.95
--------------------------------------
| approxkl           | 1.5482656e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.09e+03      |
| explained_variance | -3.09e-05     |
| fps                | 28            |
| n_updates          | 26            |
| policy_entropy     | 1.3283484     |
| policy_loss        | 7.9414574e-05 |
| serial_timesteps   | 3328          |
| time_elapsed       | 120           |
| total_timesteps    | 3328          |
| value_loss         | 249.33127     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016499001 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.09e+03      |
| explained_variance | -5.07e-05     |
| fps                | 31            |
| n_updates          | 27            |
| policy_entropy     | 1.3280411     |
| policy_loss        | -0.0010975598 |
| serial_timesteps   | 3456          |
| time_elapsed       | 124           |
| total_timesteps    | 3456          |
| value_loss         | 243.77882     |
--------------------------------------
-------------------------------------
| approxkl           | 0.022638652  |
| clipfrac           | 0.30273438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.09e+03     |
| explained_variance | 2.2e-05      |
| fps                | 29           |
| n_updates          | 28           |
| policy_entropy     | 1.3282478    |
| policy_loss        | 0.0060103815 |
| serial_timesteps   | 3584         |
| time_elapsed       | 128          |
| total_timesteps    | 3584         |
| value_loss         | 302.86743    |
-------------------------------------
------------------------------------
| approxkl           | 0.013020664 |
| clipfrac           | 0.18554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.09e+03    |
| explained_variance | -2.11e-05   |
| fps                | 29          |
| n_updates          | 29          |
| policy_entropy     | 1.3283302   |
| policy_loss        | 0.02124496  |
| serial_timesteps   | 3712        |
| time_elapsed       | 132         |
| total_timesteps    | 3712        |
| value_loss         | 228.1518    |
------------------------------------
-------------------------------------
| approxkl           | 0.024346951  |
| clipfrac           | 0.32226562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.09e+03     |
| explained_variance | -6.08e-06    |
| fps                | 27           |
| n_updates          | 30           |
| policy_entropy     | 1.3282256    |
| policy_loss        | 0.0036959636 |
| serial_timesteps   | 3840         |
| time_elapsed       | 137          |
| total_timesteps    | 3840         |
| value_loss         | 151.77039    |
-------------------------------------
------------------------------------
| approxkl           | 0.01636832  |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.09e+03    |
| explained_variance | -3.35e-05   |
| fps                | 28          |
| n_updates          | 31          |
| policy_entropy     | 1.3277293   |
| policy_loss        | -0.01461432 |
| serial_timesteps   | 3968        |
| time_elapsed       | 141         |
| total_timesteps    | 3968        |
| value_loss         | 70.449234   |
------------------------------------
---------------------------------------
| approxkl           | 0.0023535732   |
| clipfrac           | 0.021484375    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.09e+03       |
| explained_variance | -1.29e-05      |
| fps                | 30             |
| n_updates          | 32             |
| policy_entropy     | 1.3268017      |
| policy_loss        | -6.9090864e-05 |
| serial_timesteps   | 4096           |
| time_elapsed       | 146            |
| total_timesteps    | 4096           |
| value_loss         | 11.854629      |
---------------------------------------
An average of 91.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3941.95
-------------------------------------
| approxkl           | 0.009943225  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.09e+03     |
| explained_variance | -3.46e-06    |
| fps                | 31           |
| n_updates          | 33           |
| policy_entropy     | 1.3251759    |
| policy_loss        | -0.000936412 |
| serial_timesteps   | 4224         |
| time_elapsed       | 150          |
| total_timesteps    | 4224         |
| value_loss         | 46.601414    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00016100702 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.09e+03      |
| explained_variance | 5.97e-05      |
| fps                | 29            |
| n_updates          | 34            |
| policy_entropy     | 1.3241712     |
| policy_loss        | 0.0013105698  |
| serial_timesteps   | 4352          |
| time_elapsed       | 154           |
| total_timesteps    | 4352          |
| value_loss         | 60.176388     |
--------------------------------------
--------------------------------------
| approxkl           | 0.006510182   |
| clipfrac           | 0.064453125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.09e+03      |
| explained_variance | -4.78e-05     |
| fps                | 28            |
| n_updates          | 35            |
| policy_entropy     | 1.3238196     |
| policy_loss        | -0.0033541415 |
| serial_timesteps   | 4480          |
| time_elapsed       | 158           |
| total_timesteps    | 4480          |
| value_loss         | 60.651287     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0050845062 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.09e+03     |
| explained_variance | -2.15e-05    |
| fps                | 28           |
| n_updates          | 36           |
| policy_entropy     | 1.3243415    |
| policy_loss        | 0.00657051   |
| serial_timesteps   | 4608         |
| time_elapsed       | 163          |
| total_timesteps    | 4608         |
| value_loss         | 99.28233     |
-------------------------------------
--------------------------------------
| approxkl           | 1.4357861e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | -2.38e-07     |
| fps                | 29            |
| n_updates          | 37            |
| policy_entropy     | 1.3245301     |
| policy_loss        | 0.00023145648 |
| serial_timesteps   | 4736          |
| time_elapsed       | 167           |
| total_timesteps    | 4736          |
| value_loss         | 648.26855     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0002544457  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | 6.08e-06      |
| fps                | 28            |
| n_updates          | 38            |
| policy_entropy     | 1.3245261     |
| policy_loss        | -0.0026866808 |
| serial_timesteps   | 4864          |
| time_elapsed       | 172           |
| total_timesteps    | 4864          |
| value_loss         | 124.13698     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0031458675 |
| clipfrac           | 0.037109375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.17e+03     |
| explained_variance | -4.53e-06    |
| fps                | 29           |
| n_updates          | 39           |
| policy_entropy     | 1.3242087    |
| policy_loss        | -0.010942732 |
| serial_timesteps   | 4992         |
| time_elapsed       | 176          |
| total_timesteps    | 4992         |
| value_loss         | 42.69313     |
-------------------------------------
--------------------------------------
| approxkl           | 1.1285695e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | 1.29e-05      |
| fps                | 29            |
| n_updates          | 40            |
| policy_entropy     | 1.3236095     |
| policy_loss        | 6.783777e-05  |
| serial_timesteps   | 5120          |
| time_elapsed       | 181           |
| total_timesteps    | 5120          |
| value_loss         | 30.213446     |
--------------------------------------
An average of 92.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3739.59
-------------------------------------
| approxkl           | 0.0025481293 |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.17e+03     |
| explained_variance | 1.01e-06     |
| fps                | 28           |
| n_updates          | 41           |
| policy_entropy     | 1.3225864    |
| policy_loss        | -0.006361743 |
| serial_timesteps   | 5248         |
| time_elapsed       | 185          |
| total_timesteps    | 5248         |
| value_loss         | 138.06328    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00083923625 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | -1.25e-05     |
| fps                | 31            |
| n_updates          | 42            |
| policy_entropy     | 1.3217845     |
| policy_loss        | -0.0017548206 |
| serial_timesteps   | 5376          |
| time_elapsed       | 189           |
| total_timesteps    | 5376          |
| value_loss         | 384.87286     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0026799026  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | -3.24e-05     |
| fps                | 30            |
| n_updates          | 43            |
| policy_entropy     | 1.3208172     |
| policy_loss        | -0.0015631428 |
| serial_timesteps   | 5504          |
| time_elapsed       | 193           |
| total_timesteps    | 5504          |
| value_loss         | 410.33212     |
--------------------------------------
-------------------------------------
| approxkl           | 0.016580032  |
| clipfrac           | 0.22460938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.17e+03     |
| explained_variance | -2.37e-05    |
| fps                | 29           |
| n_updates          | 44           |
| policy_entropy     | 1.3176584    |
| policy_loss        | 0.0016498184 |
| serial_timesteps   | 5632         |
| time_elapsed       | 198          |
| total_timesteps    | 5632         |
| value_loss         | 288.62234    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0009004425  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | 4.77e-07      |
| fps                | 29            |
| n_updates          | 45            |
| policy_entropy     | 1.3163258     |
| policy_loss        | -0.0046240576 |
| serial_timesteps   | 5760          |
| time_elapsed       | 202           |
| total_timesteps    | 5760          |
| value_loss         | 132.50598     |
--------------------------------------
------------------------------------
| approxkl           | 0.019245567 |
| clipfrac           | 0.26757812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.17e+03    |
| explained_variance | 3.87e-05    |
| fps                | 28          |
| n_updates          | 46          |
| policy_entropy     | 1.3159378   |
| policy_loss        | 0.027066438 |
| serial_timesteps   | 5888        |
| time_elapsed       | 206         |
| total_timesteps    | 5888        |
| value_loss         | 114.36255   |
------------------------------------
--------------------------------------
| approxkl           | 0.014900625   |
| clipfrac           | 0.19140625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | -2.8e-05      |
| fps                | 29            |
| n_updates          | 47            |
| policy_entropy     | 1.314887      |
| policy_loss        | -0.0023799117 |
| serial_timesteps   | 6016          |
| time_elapsed       | 211           |
| total_timesteps    | 6016          |
| value_loss         | 15.527634     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00064708677 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.17e+03      |
| explained_variance | -1.19e-06     |
| fps                | 29            |
| n_updates          | 48            |
| policy_entropy     | 1.3145777     |
| policy_loss        | -0.0019428779 |
| serial_timesteps   | 6144          |
| time_elapsed       | 215           |
| total_timesteps    | 6144          |
| value_loss         | 78.82783      |
--------------------------------------
An average of 93.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3521.31
-------------------------------------
| approxkl           | 0.004216769  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.24e+03     |
| explained_variance | 1.85e-06     |
| fps                | 28           |
| n_updates          | 49           |
| policy_entropy     | 1.3150028    |
| policy_loss        | 0.0051980265 |
| serial_timesteps   | 6272         |
| time_elapsed       | 220          |
| total_timesteps    | 6272         |
| value_loss         | 661.2607     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00022593154 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.24e+03      |
| explained_variance | -6.41e-05     |
| fps                | 32            |
| n_updates          | 50            |
| policy_entropy     | 1.315179      |
| policy_loss        | -0.0009884454 |
| serial_timesteps   | 6400          |
| time_elapsed       | 224           |
| total_timesteps    | 6400          |
| value_loss         | 35.769306     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0042241924  |
| clipfrac           | 0.037109375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.24e+03      |
| explained_variance | -1.42e-05     |
| fps                | 29            |
| n_updates          | 51            |
| policy_entropy     | 1.3151135     |
| policy_loss        | -0.0076548373 |
| serial_timesteps   | 6528          |
| time_elapsed       | 228           |
| total_timesteps    | 6528          |
| value_loss         | 87.3719       |
--------------------------------------
--------------------------------------
| approxkl           | 0.00028327596 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.24e+03      |
| explained_variance | -4.05e-06     |
| fps                | 29            |
| n_updates          | 52            |
| policy_entropy     | 1.3148851     |
| policy_loss        | -0.0014566747 |
| serial_timesteps   | 6656          |
| time_elapsed       | 232           |
| total_timesteps    | 6656          |
| value_loss         | 31.596231     |
--------------------------------------
------------------------------------
| approxkl           | 0.008770937 |
| clipfrac           | 0.13085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.24e+03    |
| explained_variance | -9.78e-06   |
| fps                | 29          |
| n_updates          | 53          |
| policy_entropy     | 1.3144546   |
| policy_loss        | 0.003483078 |
| serial_timesteps   | 6784        |
| time_elapsed       | 237         |
| total_timesteps    | 6784        |
| value_loss         | 78.369194   |
------------------------------------
------------------------------------
| approxkl           | 0.027360339 |
| clipfrac           | 0.31640625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.24e+03    |
| explained_variance | -4.11e-05   |
| fps                | 31          |
| n_updates          | 54          |
| policy_entropy     | 1.3135446   |
| policy_loss        | 0.030470084 |
| serial_timesteps   | 6912        |
| time_elapsed       | 241         |
| total_timesteps    | 6912        |
| value_loss         | 157.2041    |
------------------------------------
-------------------------------------
| approxkl           | 0.0013977052 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.24e+03     |
| explained_variance | 1.85e-06     |
| fps                | 28           |
| n_updates          | 55           |
| policy_entropy     | 1.3126378    |
| policy_loss        | -0.00387841  |
| serial_timesteps   | 7040         |
| time_elapsed       | 245          |
| total_timesteps    | 7040         |
| value_loss         | 51.25152     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00024094366 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.24e+03      |
| explained_variance | -3.18e-05     |
| fps                | 29            |
| n_updates          | 56            |
| policy_entropy     | 1.3120763     |
| policy_loss        | 0.00031005195 |
| serial_timesteps   | 7168          |
| time_elapsed       | 250           |
| total_timesteps    | 7168          |
| value_loss         | 41.106445     |
--------------------------------------
An average of 93.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3521.31
--------------------------------------
| approxkl           | 8.230387e-06  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.24e+03      |
| explained_variance | -5.96e-07     |
| fps                | 33            |
| n_updates          | 57            |
| policy_entropy     | 1.3118931     |
| policy_loss        | 7.1844435e-05 |
| serial_timesteps   | 7296          |
| time_elapsed       | 254           |
| total_timesteps    | 7296          |
| value_loss         | 246.46138     |
--------------------------------------
-------------------------------------
| approxkl           | 0.001001668  |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.24e+03     |
| explained_variance | 1.39e-05     |
| fps                | 29           |
| n_updates          | 58           |
| policy_entropy     | 1.311748     |
| policy_loss        | -0.005602901 |
| serial_timesteps   | 7424         |
| time_elapsed       | 258          |
| total_timesteps    | 7424         |
| value_loss         | 201.46452    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00079623115 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.24e+03      |
| explained_variance | 2.77e-05      |
| fps                | 29            |
| n_updates          | 59            |
| policy_entropy     | 1.3110589     |
| policy_loss        | -0.0032900334 |
| serial_timesteps   | 7552          |
| time_elapsed       | 262           |
| total_timesteps    | 7552          |
| value_loss         | 250.9561      |
--------------------------------------
-------------------------------------
| approxkl           | 0.033716932  |
| clipfrac           | 0.34375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.24e+03     |
| explained_variance | -2.1e-05     |
| fps                | 29           |
| n_updates          | 60           |
| policy_entropy     | 1.3101228    |
| policy_loss        | -0.022706319 |
| serial_timesteps   | 7680         |
| time_elapsed       | 266          |
| total_timesteps    | 7680         |
| value_loss         | 173.9036     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070648063 |
| clipfrac           | 0.099609375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -5.96e-07    |
| fps                | 30           |
| n_updates          | 61           |
| policy_entropy     | 1.3097792    |
| policy_loss        | 0.01090803   |
| serial_timesteps   | 7808         |
| time_elapsed       | 271          |
| total_timesteps    | 7808         |
| value_loss         | 852.2779     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00092016236 |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | 1.54e-05      |
| fps                | 32            |
| n_updates          | 62            |
| policy_entropy     | 1.3096867     |
| policy_loss        | -0.0058703795 |
| serial_timesteps   | 7936          |
| time_elapsed       | 275           |
| total_timesteps    | 7936          |
| value_loss         | 59.766766     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0151889995 |
| clipfrac           | 0.22070312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -7.63e-06    |
| fps                | 29           |
| n_updates          | 63           |
| policy_entropy     | 1.3085172    |
| policy_loss        | -0.022026893 |
| serial_timesteps   | 8064         |
| time_elapsed       | 279          |
| total_timesteps    | 8064         |
| value_loss         | 13.090265    |
-------------------------------------
-------------------------------------
| approxkl           | 0.019774383  |
| clipfrac           | 0.27539062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -7.39e-06    |
| fps                | 28           |
| n_updates          | 64           |
| policy_entropy     | 1.3062093    |
| policy_loss        | -0.009115982 |
| serial_timesteps   | 8192         |
| time_elapsed       | 283          |
| total_timesteps    | 8192         |
| value_loss         | 50.892776    |
-------------------------------------
An average of 94.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3253.63
------------------------------------
| approxkl           | 0.003486882 |
| clipfrac           | 0.017578125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.25e+03    |
| explained_variance | 4.27e-05    |
| fps                | 33          |
| n_updates          | 65          |
| policy_entropy     | 1.3052716   |
| policy_loss        | 0.010480343 |
| serial_timesteps   | 8320        |
| time_elapsed       | 288         |
| total_timesteps    | 8320        |
| value_loss         | 52.89203    |
------------------------------------
-------------------------------------
| approxkl           | 0.009168725  |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | 1.8e-05      |
| fps                | 29           |
| n_updates          | 66           |
| policy_entropy     | 1.3047146    |
| policy_loss        | -0.008600888 |
| serial_timesteps   | 8448         |
| time_elapsed       | 292          |
| total_timesteps    | 8448         |
| value_loss         | 71.342514    |
-------------------------------------
------------------------------------
| approxkl           | 0.004946566 |
| clipfrac           | 0.0859375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.25e+03    |
| explained_variance | -2.63e-05   |
| fps                | 30          |
| n_updates          | 67          |
| policy_entropy     | 1.3036641   |
| policy_loss        | 0.008935661 |
| serial_timesteps   | 8576        |
| time_elapsed       | 296         |
| total_timesteps    | 8576        |
| value_loss         | 145.7779    |
------------------------------------
-------------------------------------
| approxkl           | 0.0009802539 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -1.19e-06    |
| fps                | 29           |
| n_updates          | 68           |
| policy_entropy     | 1.3030047    |
| policy_loss        | -0.003630304 |
| serial_timesteps   | 8704         |
| time_elapsed       | 300          |
| total_timesteps    | 8704         |
| value_loss         | 37.100292    |
-------------------------------------
------------------------------------
| approxkl           | 0.008759575 |
| clipfrac           | 0.10546875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.25e+03    |
| explained_variance | -3.48e-05   |
| fps                | 28          |
| n_updates          | 69          |
| policy_entropy     | 1.3014969   |
| policy_loss        | 0.022119785 |
| serial_timesteps   | 8832        |
| time_elapsed       | 305         |
| total_timesteps    | 8832        |
| value_loss         | 170.81493   |
------------------------------------
-------------------------------------
| approxkl           | 0.0068758302 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -4.85e-05    |
| fps                | 28           |
| n_updates          | 70           |
| policy_entropy     | 1.2997448    |
| policy_loss        | 0.000383344  |
| serial_timesteps   | 8960         |
| time_elapsed       | 309          |
| total_timesteps    | 8960         |
| value_loss         | 89.36317     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00045296276 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | 9.18e-06      |
| fps                | 28            |
| n_updates          | 71            |
| policy_entropy     | 1.2971618     |
| policy_loss        | 0.0010900944  |
| serial_timesteps   | 9088          |
| time_elapsed       | 314           |
| total_timesteps    | 9088          |
| value_loss         | 42.914116     |
--------------------------------------
-------------------------------------
| approxkl           | 0.008701447  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -4.89e-06    |
| fps                | 29           |
| n_updates          | 72           |
| policy_entropy     | 1.2950486    |
| policy_loss        | -0.003985638 |
| serial_timesteps   | 9216         |
| time_elapsed       | 318          |
| total_timesteps    | 9216         |
| value_loss         | 79.72993     |
-------------------------------------
An average of 94.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3253.63
---------------------------------------
| approxkl           | 0.000109762375 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 3.23e+03       |
| explained_variance | -2.86e-06      |
| fps                | 29             |
| n_updates          | 73             |
| policy_entropy     | 1.2944607      |
| policy_loss        | -0.00026021537 |
| serial_timesteps   | 9344           |
| time_elapsed       | 322            |
| total_timesteps    | 9344           |
| value_loss         | 720.0273       |
---------------------------------------
-------------------------------------
| approxkl           | 0.0010004222 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.23e+03     |
| explained_variance | -2.46e-05    |
| fps                | 27           |
| n_updates          | 74           |
| policy_entropy     | 1.2947564    |
| policy_loss        | 0.014015472  |
| serial_timesteps   | 9472         |
| time_elapsed       | 327          |
| total_timesteps    | 9472         |
| value_loss         | 234.03876    |
-------------------------------------
------------------------------------
| approxkl           | 0.012823254 |
| clipfrac           | 0.18554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.23e+03    |
| explained_variance | -2.22e-05   |
| fps                | 32          |
| n_updates          | 75          |
| policy_entropy     | 1.2949847   |
| policy_loss        | -0.01990858 |
| serial_timesteps   | 9600        |
| time_elapsed       | 331         |
| total_timesteps    | 9600        |
| value_loss         | 303.7208    |
------------------------------------
-------------------------------------
| approxkl           | 0.017511357  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.23e+03     |
| explained_variance | -2.26e-06    |
| fps                | 30           |
| n_updates          | 76           |
| policy_entropy     | 1.2954171    |
| policy_loss        | -0.021032082 |
| serial_timesteps   | 9728         |
| time_elapsed       | 335          |
| total_timesteps    | 9728         |
| value_loss         | 41.695362    |
-------------------------------------
-------------------------------------
| approxkl           | 8.883898e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.23e+03     |
| explained_variance | 9.36e-06     |
| fps                | 28           |
| n_updates          | 77           |
| policy_entropy     | 1.2954636    |
| policy_loss        | 0.0012474312 |
| serial_timesteps   | 9856         |
| time_elapsed       | 340          |
| total_timesteps    | 9856         |
| value_loss         | 131.64688    |
-------------------------------------
------------------------------------
| approxkl           | 0.010151539 |
| clipfrac           | 0.13476562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.23e+03    |
| explained_variance | -2.46e-05   |
| fps                | 31          |
| n_updates          | 78          |
| policy_entropy     | 1.2941948   |
| policy_loss        | 0.0286713   |
| serial_timesteps   | 9984        |
| time_elapsed       | 344         |
| total_timesteps    | 9984        |
| value_loss         | 67.57984    |
------------------------------------
------------------------------------
| approxkl           | 0.009467454 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.23e+03    |
| explained_variance | -8.34e-07   |
| fps                | 29          |
| n_updates          | 79          |
| policy_entropy     | 1.2926791   |
| policy_loss        | 0.004211647 |
| serial_timesteps   | 10112       |
| time_elapsed       | 348         |
| total_timesteps    | 10112       |
| value_loss         | 65.0718     |
------------------------------------
An average of 95.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3261.40
--------------------------------------
| approxkl           | 0.0019936725  |
| clipfrac           | 0.017578125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.23e+03      |
| explained_variance | -1.45e-05     |
| fps                | 28            |
| n_updates          | 80            |
| policy_entropy     | 1.2919325     |
| policy_loss        | -0.0033992766 |
| serial_timesteps   | 10240         |
| time_elapsed       | 352           |
| total_timesteps    | 10240         |
| value_loss         | 33.1501       |
--------------------------------------
-------------------------------------
| approxkl           | 0.016857794  |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.23e+03     |
| explained_variance | -4.58e-05    |
| fps                | 32           |
| n_updates          | 81           |
| policy_entropy     | 1.2915403    |
| policy_loss        | -0.013856614 |
| serial_timesteps   | 10368        |
| time_elapsed       | 357          |
| total_timesteps    | 10368        |
| value_loss         | 20.256098    |
-------------------------------------
------------------------------------
| approxkl           | 0.009159203 |
| clipfrac           | 0.13671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.23e+03    |
| explained_variance | -1.17e-05   |
| fps                | 26          |
| n_updates          | 82          |
| policy_entropy     | 1.2911254   |
| policy_loss        | 0.020715304 |
| serial_timesteps   | 10496       |
| time_elapsed       | 361         |
| total_timesteps    | 10496       |
| value_loss         | 128.00932   |
------------------------------------
--------------------------------------
| approxkl           | 0.0041198665  |
| clipfrac           | 0.05078125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.23e+03      |
| explained_variance | -5.72e-06     |
| fps                | 27            |
| n_updates          | 83            |
| policy_entropy     | 1.2906746     |
| policy_loss        | -0.0019053037 |
| serial_timesteps   | 10624         |
| time_elapsed       | 366           |
| total_timesteps    | 10624         |
| value_loss         | 38.0728       |
--------------------------------------
-------------------------------------
| approxkl           | 0.0050228396 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.23e+03     |
| explained_variance | 1.63e-05     |
| fps                | 28           |
| n_updates          | 84           |
| policy_entropy     | 1.2900385    |
| policy_loss        | -0.002615822 |
| serial_timesteps   | 10752        |
| time_elapsed       | 370          |
| total_timesteps    | 10752        |
| value_loss         | 84.60389     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00011003178 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | -1.31e-06     |
| fps                | 31            |
| n_updates          | 85            |
| policy_entropy     | 1.2900258     |
| policy_loss        | 0.0005625774  |
| serial_timesteps   | 10880         |
| time_elapsed       | 375           |
| total_timesteps    | 10880         |
| value_loss         | 718.1428      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00041532159 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | -1.91e-06     |
| fps                | 31            |
| n_updates          | 86            |
| policy_entropy     | 1.2902565     |
| policy_loss        | 0.000897862   |
| serial_timesteps   | 11008         |
| time_elapsed       | 379           |
| total_timesteps    | 11008         |
| value_loss         | 111.84479     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0014319685 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -9.06e-06    |
| fps                | 29           |
| n_updates          | 87           |
| policy_entropy     | 1.2899711    |
| policy_loss        | 0.0003778293 |
| serial_timesteps   | 11136        |
| time_elapsed       | 383          |
| total_timesteps    | 11136        |
| value_loss         | 33.459114    |
-------------------------------------
An average of 96.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3319.52
--------------------------------------
| approxkl           | 0.0045780074  |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | -9.89e-06     |
| fps                | 31            |
| n_updates          | 88            |
| policy_entropy     | 1.2902629     |
| policy_loss        | -0.0030605616 |
| serial_timesteps   | 11264         |
| time_elapsed       | 387           |
| total_timesteps    | 11264         |
| value_loss         | 168.21936     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00010385304 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | 1.97e-06      |
| fps                | 27            |
| n_updates          | 89            |
| policy_entropy     | 1.2904834     |
| policy_loss        | -0.0005615448 |
| serial_timesteps   | 11392         |
| time_elapsed       | 391           |
| total_timesteps    | 11392         |
| value_loss         | 276.57547     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0019033249  |
| clipfrac           | 0.01171875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | -2.53e-05     |
| fps                | 30            |
| n_updates          | 90            |
| policy_entropy     | 1.2897604     |
| policy_loss        | -0.0045846496 |
| serial_timesteps   | 11520         |
| time_elapsed       | 396           |
| total_timesteps    | 11520         |
| value_loss         | 297.6751      |
--------------------------------------
-------------------------------------
| approxkl           | 0.033681057  |
| clipfrac           | 0.37890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -3.02e-05    |
| fps                | 31           |
| n_updates          | 91           |
| policy_entropy     | 1.2893254    |
| policy_loss        | 0.0083343685 |
| serial_timesteps   | 11648        |
| time_elapsed       | 400          |
| total_timesteps    | 11648        |
| value_loss         | 254.56453    |
-------------------------------------
------------------------------------
| approxkl           | 0.028278094 |
| clipfrac           | 0.33984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 3.25e+03    |
| explained_variance | 4.77e-07    |
| fps                | 30          |
| n_updates          | 92          |
| policy_entropy     | 1.2890481   |
| policy_loss        | -0.02044849 |
| serial_timesteps   | 11776       |
| time_elapsed       | 404         |
| total_timesteps    | 11776       |
| value_loss         | 87.21845    |
------------------------------------
-------------------------------------
| approxkl           | 0.016733276  |
| clipfrac           | 0.21679688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -1.79e-06    |
| fps                | 29           |
| n_updates          | 93           |
| policy_entropy     | 1.2896724    |
| policy_loss        | 0.0031859884 |
| serial_timesteps   | 11904        |
| time_elapsed       | 409          |
| total_timesteps    | 11904        |
| value_loss         | 97.900314    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021791242  |
| clipfrac           | 0.21679688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.25e+03     |
| explained_variance | -1.63e-05    |
| fps                | 29           |
| n_updates          | 94           |
| policy_entropy     | 1.2906572    |
| policy_loss        | -0.016000932 |
| serial_timesteps   | 12032        |
| time_elapsed       | 413          |
| total_timesteps    | 12032        |
| value_loss         | 15.905437    |
-------------------------------------
--------------------------------------
| approxkl           | 0.009226922   |
| clipfrac           | 0.11328125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | -6.79e-06     |
| fps                | 29            |
| n_updates          | 95            |
| policy_entropy     | 1.292878      |
| policy_loss        | -0.0044679064 |
| serial_timesteps   | 12160         |
| time_elapsed       | 417           |
| total_timesteps    | 12160         |
| value_loss         | 33.28948      |
--------------------------------------
An average of 96.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3319.52
--------------------------------------
| approxkl           | 0.0006008013  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.25e+03      |
| explained_variance | 9.2e-05       |
| fps                | 28            |
| n_updates          | 96            |
| policy_entropy     | 1.293576      |
| policy_loss        | -0.0024341496 |
| serial_timesteps   | 12288         |
| time_elapsed       | 422           |
| total_timesteps    | 12288         |
| value_loss         | 28.598648     |
--------------------------------------
--------------------------------------
| approxkl           | 0.011796118   |
| clipfrac           | 0.15625       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | 0             |
| fps                | 28            |
| n_updates          | 97            |
| policy_entropy     | 1.2935346     |
| policy_loss        | -0.0038308054 |
| serial_timesteps   | 12416         |
| time_elapsed       | 426           |
| total_timesteps    | 12416         |
| value_loss         | 710.5631      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00020313139 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | -1.92e-05     |
| fps                | 28            |
| n_updates          | 98            |
| policy_entropy     | 1.2934369     |
| policy_loss        | -0.0013238136 |
| serial_timesteps   | 12544         |
| time_elapsed       | 431           |
| total_timesteps    | 12544         |
| value_loss         | 107.79295     |
--------------------------------------
-------------------------------------
| approxkl           | 0.00727301   |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.29e+03     |
| explained_variance | -5.13e-06    |
| fps                | 29           |
| n_updates          | 99           |
| policy_entropy     | 1.2931335    |
| policy_loss        | -0.014530251 |
| serial_timesteps   | 12672        |
| time_elapsed       | 435          |
| total_timesteps    | 12672        |
| value_loss         | 30.23184     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00095125806 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | -1.97e-05     |
| fps                | 28            |
| n_updates          | 100           |
| policy_entropy     | 1.2926121     |
| policy_loss        | -0.0028653392 |
| serial_timesteps   | 12800         |
| time_elapsed       | 439           |
| total_timesteps    | 12800         |
| value_loss         | 142.2257      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0024642108  |
| clipfrac           | 0.025390625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | -1.85e-05     |
| fps                | 30            |
| n_updates          | 101           |
| policy_entropy     | 1.2922701     |
| policy_loss        | -0.0061105555 |
| serial_timesteps   | 12928         |
| time_elapsed       | 444           |
| total_timesteps    | 12928         |
| value_loss         | 77.71574      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00046917592 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | 2.32e-06      |
| fps                | 28            |
| n_updates          | 102           |
| policy_entropy     | 1.2910813     |
| policy_loss        | -0.0008705645 |
| serial_timesteps   | 13056         |
| time_elapsed       | 448           |
| total_timesteps    | 13056         |
| value_loss         | 32.43541      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00040868795 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | 1.01e-06      |
| fps                | 31            |
| n_updates          | 103           |
| policy_entropy     | 1.2894069     |
| policy_loss        | -0.0001749444 |
| serial_timesteps   | 13184         |
| time_elapsed       | 453           |
| total_timesteps    | 13184         |
| value_loss         | 58.502182     |
--------------------------------------
An average of 97.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3356.55
-------------------------------------
| approxkl           | 0.0037586198 |
| clipfrac           | 0.037109375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.29e+03     |
| explained_variance | -5.96e-07    |
| fps                | 32           |
| n_updates          | 104          |
| policy_entropy     | 1.2880557    |
| policy_loss        | -0.008348329 |
| serial_timesteps   | 13312        |
| time_elapsed       | 457          |
| total_timesteps    | 13312        |
| value_loss         | 326.96423    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00015254434 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | 1.67e-05      |
| fps                | 27            |
| n_updates          | 105           |
| policy_entropy     | 1.2875736     |
| policy_loss        | 0.00019407494 |
| serial_timesteps   | 13440         |
| time_elapsed       | 461           |
| total_timesteps    | 13440         |
| value_loss         | 315.90363     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00045025314 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | -9.42e-06     |
| fps                | 27            |
| n_updates          | 106           |
| policy_entropy     | 1.2869761     |
| policy_loss        | -0.0016858802 |
| serial_timesteps   | 13568         |
| time_elapsed       | 465           |
| total_timesteps    | 13568         |
| value_loss         | 272.9802      |
--------------------------------------
-------------------------------------
| approxkl           | 0.03157077   |
| clipfrac           | 0.33203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.29e+03     |
| explained_variance | -7.51e-06    |
| fps                | 30           |
| n_updates          | 107          |
| policy_entropy     | 1.285018     |
| policy_loss        | 0.0015333127 |
| serial_timesteps   | 13696        |
| time_elapsed       | 470          |
| total_timesteps    | 13696        |
| value_loss         | 140.3061     |
-------------------------------------
--------------------------------------
| approxkl           | 0.032386232   |
| clipfrac           | 0.38867188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.29e+03      |
| explained_variance | 9.36e-06      |
| fps                | 28            |
| n_updates          | 108           |
| policy_entropy     | 1.2837614     |
| policy_loss        | 4.8703514e-05 |
| serial_timesteps   | 13824         |
| time_elapsed       | 474           |
| total_timesteps    | 13824         |
| value_loss         | 145.22765     |
--------------------------------------
-----------------------------------
| approxkl           | 0.0371715  |
| clipfrac           | 0.40429688 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 3.33e+03   |
| explained_variance | -3.34e-06  |
| fps                | 29         |
| n_updates          | 109        |
| policy_entropy     | 1.2829148  |
| policy_loss        | 0.04409446 |
| serial_timesteps   | 13952      |
| time_elapsed       | 479        |
| total_timesteps    | 13952      |
| value_loss         | 714.05115  |
-----------------------------------
--------------------------------------
| approxkl           | 0.0008937206  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.33e+03      |
| explained_variance | 9.95e-06      |
| fps                | 30            |
| n_updates          | 110           |
| policy_entropy     | 1.2824775     |
| policy_loss        | -0.0013886421 |
| serial_timesteps   | 14080         |
| time_elapsed       | 483           |
| total_timesteps    | 14080         |
| value_loss         | 109.37265     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0061869957 |
| clipfrac           | 0.087890625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.33e+03     |
| explained_variance | -3.22e-06    |
| fps                | 30           |
| n_updates          | 111          |
| policy_entropy     | 1.2820137    |
| policy_loss        | -0.012953648 |
| serial_timesteps   | 14208        |
| time_elapsed       | 487          |
| total_timesteps    | 14208        |
| value_loss         | 32.88442     |
-------------------------------------
An average of 98.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3395.05
-------------------------------------
| approxkl           | 0.010771321  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.33e+03     |
| explained_variance | -1.44e-05    |
| fps                | 33           |
| n_updates          | 112          |
| policy_entropy     | 1.2802576    |
| policy_loss        | -0.007883108 |
| serial_timesteps   | 14336        |
| time_elapsed       | 492          |
| total_timesteps    | 14336        |
| value_loss         | 18.280735    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01060523   |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.33e+03     |
| explained_variance | -8.58e-06    |
| fps                | 33           |
| n_updates          | 113          |
| policy_entropy     | 1.2778373    |
| policy_loss        | -0.013543541 |
| serial_timesteps   | 14464        |
| time_elapsed       | 495          |
| total_timesteps    | 14464        |
| value_loss         | 79.77522     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0010445263  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.33e+03      |
| explained_variance | -1.91e-06     |
| fps                | 30            |
| n_updates          | 114           |
| policy_entropy     | 1.2760463     |
| policy_loss        | -0.0037298894 |
| serial_timesteps   | 14592         |
| time_elapsed       | 499           |
| total_timesteps    | 14592         |
| value_loss         | 72.57985      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0034862263 |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.33e+03     |
| explained_variance | 4.29e-06     |
| fps                | 29           |
| n_updates          | 115          |
| policy_entropy     | 1.2747006    |
| policy_loss        | 0.0007639881 |
| serial_timesteps   | 14720        |
| time_elapsed       | 503          |
| total_timesteps    | 14720        |
| value_loss         | 51.33104     |
-------------------------------------
-------------------------------------
| approxkl           | 0.004737024  |
| clipfrac           | 0.044921875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 3.33e+03     |
| explained_variance | -1.81e-05    |
| fps                | 28           |
| n_updates          | 116          |
| policy_entropy     | 1.273469     |
| policy_loss        | -0.011867957 |
| serial_timesteps   | 14848        |
| time_elapsed       | 508          |
| total_timesteps    | 14848        |
| value_loss         | 197.96315    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0040349276  |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 3.33e+03      |
| explained_variance | -5.96e-07     |
| fps                | 30            |
| n_updates          | 117           |
| policy_entropy     | 1.2703665     |
| policy_loss        | -0.0062519177 |
| serial_timesteps   | 14976         |
| time_elapsed       | 512           |
| total_timesteps    | 14976         |
| value_loss         | 25.601208     |
--------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b735debe0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b735debe0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b71d6b358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b71d6b358>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2346 samples, validate on 319 samples
Epoch 197/5000
 - 3s - loss: 0.1066 - val_loss: 0.0080
Epoch 198/5000
 - 0s - loss: 0.0306 - val_loss: 0.0074
Epoch 199/5000
 - 0s - loss: 0.0263 - val_loss: 0.0055
Epoch 200/5000
 - 0s - loss: 0.0211 - val_loss: 0.0044
Epoch 201/5000
 - 0s - loss: 0.0137 - val_loss: 0.0029
Epoch 202/5000
 - 0s - loss: 0.0065 - val_loss: 0.0013
Epoch 203/5000
 - 1s - loss: 0.0055 - val_loss: 0.0012
Epoch 204/5000
 - 1s - loss: 0.0052 - val_loss: 0.0011
Epoch 205/5000
 - 0s - loss: 0.0051 - val_loss: 0.0011
Epoch 206/5000
 - 0s - loss: 0.0043 - val_loss: 0.0015
Epoch 207/5000
 - 0s - loss: 0.0042 - val_loss: 0.0015
Epoch 208/5000
 - 1s - loss: 0.0041 - val_loss: 0.0015
Epoch 209/5000
 - 1s - loss: 0.0041 - val_loss: 0.0015
Epoch 210/5000
 - 1s - loss: 0.0040 - val_loss: 0.0015
Train on 1902 samples, validate on 319 samples
Epoch 162/5000
 - 3s - loss: 0.0013 - val_loss: 0.0013
Epoch 163/5000
 - 0s - loss: 0.0011 - val_loss: 0.0016
Epoch 164/5000
 - 0s - loss: 0.0011 - val_loss: 0.0020
Epoch 165/5000
 - 0s - loss: 9.3754e-04 - val_loss: 0.0028
Epoch 166/5000
 - 0s - loss: 8.4525e-04 - val_loss: 0.0028
Epoch 167/5000
 - 0s - loss: 8.3911e-04 - val_loss: 0.0027
Train on 2347 samples, validate on 319 samples
Epoch 328/5000
 - 5s - loss: 0.6468 - val_loss: 0.6855
Epoch 329/5000
 - 1s - loss: 0.4479 - val_loss: 0.9541
Epoch 330/5000
 - 1s - loss: 0.3915 - val_loss: 1.0263
Epoch 331/5000
 - 1s - loss: 0.3857 - val_loss: 1.0180
Epoch 332/5000
 - 1s - loss: 0.3851 - val_loss: 1.0117
Epoch 333/5000
 - 1s - loss: 0.3846 - val_loss: 1.0067
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0031223926 |
| clipfrac           | 0.025390625  |
| explained_variance | 4.74e-05     |
| fps                | 6            |
| n_updates          | 1            |
| policy_entropy     | 1.2686858    |
| policy_loss        | 0.011286592  |
| serial_timesteps   | 128          |
| time_elapsed       | 1.31e-05     |
| total_timesteps    | 128          |
| value_loss         | 124.92964    |
-------------------------------------
An average of 99.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.036281884  |
| clipfrac           | 0.43554688   |
| explained_variance | -3.7e-06     |
| fps                | 29           |
| n_updates          | 2            |
| policy_entropy     | 1.2681761    |
| policy_loss        | -0.020609109 |
| serial_timesteps   | 256          |
| time_elapsed       | 18.9         |
| total_timesteps    | 256          |
| value_loss         | 256.39267    |
-------------------------------------
------------------------------------
| approxkl           | 0.017033525 |
| clipfrac           | 0.26171875  |
| explained_variance | -1.43e-06   |
| fps                | 29          |
| n_updates          | 3           |
| policy_entropy     | 1.2682271   |
| policy_loss        | 0.035383604 |
| serial_timesteps   | 384         |
| time_elapsed       | 23.3        |
| total_timesteps    | 384         |
| value_loss         | 385.8747    |
------------------------------------
-------------------------------------
| approxkl           | 0.021743959  |
| clipfrac           | 0.27929688   |
| explained_variance | 1.56e-05     |
| fps                | 30           |
| n_updates          | 4            |
| policy_entropy     | 1.2684338    |
| policy_loss        | 0.0014678931 |
| serial_timesteps   | 512          |
| time_elapsed       | 27.6         |
| total_timesteps    | 512          |
| value_loss         | 422.0722     |
-------------------------------------
------------------------------------
| approxkl           | 0.018492922 |
| clipfrac           | 0.23632812  |
| explained_variance | -1.23e-05   |
| fps                | 29          |
| n_updates          | 5           |
| policy_entropy     | 1.2690259   |
| policy_loss        | 0.017750867 |
| serial_timesteps   | 640         |
| time_elapsed       | 31.8        |
| total_timesteps    | 640         |
| value_loss         | 299.48553   |
------------------------------------
------------------------------------
| approxkl           | 0.01102776  |
| clipfrac           | 0.15039062  |
| explained_variance | -1.31e-06   |
| fps                | 29          |
| n_updates          | 6           |
| policy_entropy     | 1.2690935   |
| policy_loss        | 0.025363656 |
| serial_timesteps   | 768         |
| time_elapsed       | 36.2        |
| total_timesteps    | 768         |
| value_loss         | 271.84827   |
------------------------------------
------------------------------------
| approxkl           | 0.018394388 |
| clipfrac           | 0.23828125  |
| explained_variance | -1.48e-05   |
| fps                | 29          |
| n_updates          | 7           |
| policy_entropy     | 1.2688376   |
| policy_loss        | 0.019967053 |
| serial_timesteps   | 896         |
| time_elapsed       | 40.5        |
| total_timesteps    | 896         |
| value_loss         | 349.76398   |
------------------------------------
------------------------------------
| approxkl           | 0.01864325  |
| clipfrac           | 0.2578125   |
| explained_variance | 9.54e-07    |
| fps                | 30          |
| n_updates          | 8           |
| policy_entropy     | 1.2688253   |
| policy_loss        | 0.009474628 |
| serial_timesteps   | 1024        |
| time_elapsed       | 44.8        |
| total_timesteps    | 1024        |
| value_loss         | 380.9625    |
------------------------------------
-------------------------------------
| approxkl           | 0.028638206  |
| clipfrac           | 0.31835938   |
| explained_variance | -3.81e-06    |
| fps                | 31           |
| n_updates          | 9            |
| policy_entropy     | 1.2688298    |
| policy_loss        | 6.693881e-08 |
| serial_timesteps   | 1152         |
| time_elapsed       | 48.9         |
| total_timesteps    | 1152         |
| value_loss         | 275.71606    |
-------------------------------------
An average of 99.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.012631533 |
| clipfrac           | 0.1875      |
| explained_variance | 4.77e-06    |
| fps                | 30          |
| n_updates          | 10          |
| policy_entropy     | 1.2686251   |
| policy_loss        | 0.043029547 |
| serial_timesteps   | 1280        |
| time_elapsed       | 53          |
| total_timesteps    | 1280        |
| value_loss         | 393.16766   |
------------------------------------
--------------------------------------
| approxkl           | 0.027688503   |
| clipfrac           | 0.33984375    |
| explained_variance | -1.03e-05     |
| fps                | 28            |
| n_updates          | 11            |
| policy_entropy     | 1.2682974     |
| policy_loss        | -0.0025665285 |
| serial_timesteps   | 1408          |
| time_elapsed       | 57.2          |
| total_timesteps    | 1408          |
| value_loss         | 236.08887     |
--------------------------------------
------------------------------------
| approxkl           | 0.01716099  |
| clipfrac           | 0.2265625   |
| explained_variance | 0           |
| fps                | 32          |
| n_updates          | 12          |
| policy_entropy     | 1.2682052   |
| policy_loss        | 0.038972322 |
| serial_timesteps   | 1536        |
| time_elapsed       | 61.8        |
| total_timesteps    | 1536        |
| value_loss         | 364.9384    |
------------------------------------
------------------------------------
| approxkl           | 0.013056948 |
| clipfrac           | 0.2109375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.93e+03    |
| explained_variance | -1.43e-06   |
| fps                | 31          |
| n_updates          | 13          |
| policy_entropy     | 1.2682      |
| policy_loss        | 0.01786759  |
| serial_timesteps   | 1664        |
| time_elapsed       | 65.7        |
| total_timesteps    | 1664        |
| value_loss         | 896.28503   |
------------------------------------
-------------------------------------
| approxkl           | 0.0047778673 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.93e+03     |
| explained_variance | 8.4e-06      |
| fps                | 28           |
| n_updates          | 14           |
| policy_entropy     | 1.2680392    |
| policy_loss        | -0.015156203 |
| serial_timesteps   | 1792         |
| time_elapsed       | 69.7         |
| total_timesteps    | 1792         |
| value_loss         | 238.1437     |
-------------------------------------
---------------------------------------
| approxkl           | 9.579463e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.93e+03       |
| explained_variance | -5.25e-06      |
| fps                | 30             |
| n_updates          | 15             |
| policy_entropy     | 1.267824       |
| policy_loss        | -0.00026705617 |
| serial_timesteps   | 1920           |
| time_elapsed       | 74.2           |
| total_timesteps    | 1920           |
| value_loss         | 382.78473      |
---------------------------------------
------------------------------------
| approxkl           | 0.026682006 |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.93e+03    |
| explained_variance | 4.15e-05    |
| fps                | 30          |
| n_updates          | 16          |
| policy_entropy     | 1.2669858   |
| policy_loss        | 0.024225865 |
| serial_timesteps   | 2048        |
| time_elapsed       | 78.4        |
| total_timesteps    | 2048        |
| value_loss         | 215.46346   |
------------------------------------
-------------------------------------
| approxkl           | 0.021072818  |
| clipfrac           | 0.28320312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.93e+03     |
| explained_variance | -2.62e-06    |
| fps                | 31           |
| n_updates          | 17           |
| policy_entropy     | 1.26656      |
| policy_loss        | -0.008602266 |
| serial_timesteps   | 2176         |
| time_elapsed       | 82.6         |
| total_timesteps    | 2176         |
| value_loss         | 170.4032     |
-------------------------------------
An average of 100.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.013786777 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.93e+03    |
| explained_variance | -1.55e-06   |
| fps                | 30          |
| n_updates          | 18          |
| policy_entropy     | 1.2667048   |
| policy_loss        | 0.032019004 |
| serial_timesteps   | 2304        |
| time_elapsed       | 86.7        |
| total_timesteps    | 2304        |
| value_loss         | 316.3701    |
------------------------------------
-------------------------------------
| approxkl           | 0.024486694  |
| clipfrac           | 0.30664062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.93e+03     |
| explained_variance | 5.36e-07     |
| fps                | 29           |
| n_updates          | 19           |
| policy_entropy     | 1.2666808    |
| policy_loss        | 0.0063351355 |
| serial_timesteps   | 2432         |
| time_elapsed       | 90.9         |
| total_timesteps    | 2432         |
| value_loss         | 375.31177    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015268373  |
| clipfrac           | 0.22851562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.93e+03     |
| explained_variance | 1.12e-05     |
| fps                | 29           |
| n_updates          | 20           |
| policy_entropy     | 1.2667602    |
| policy_loss        | 0.0071344147 |
| serial_timesteps   | 2560         |
| time_elapsed       | 95.2         |
| total_timesteps    | 2560         |
| value_loss         | 430.20877    |
-------------------------------------
------------------------------------
| approxkl           | 0.012373058 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.93e+03    |
| explained_variance | -2.15e-06   |
| fps                | 29          |
| n_updates          | 21          |
| policy_entropy     | 1.2676469   |
| policy_loss        | 0.027775686 |
| serial_timesteps   | 2688        |
| time_elapsed       | 99.6        |
| total_timesteps    | 2688        |
| value_loss         | 327.263     |
------------------------------------
------------------------------------
| approxkl           | 0.017576324 |
| clipfrac           | 0.25195312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.93e+03    |
| explained_variance | 5.42e-06    |
| fps                | 33          |
| n_updates          | 22          |
| policy_entropy     | 1.2679845   |
| policy_loss        | 0.009194307 |
| serial_timesteps   | 2816        |
| time_elapsed       | 104         |
| total_timesteps    | 2816        |
| value_loss         | 359.80753   |
------------------------------------
-------------------------------------
| approxkl           | 0.026422027  |
| clipfrac           | 0.32421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.93e+03     |
| explained_variance | 1.88e-05     |
| fps                | 31           |
| n_updates          | 23           |
| policy_entropy     | 1.268175     |
| policy_loss        | -0.013122616 |
| serial_timesteps   | 2944         |
| time_elapsed       | 108          |
| total_timesteps    | 2944         |
| value_loss         | 216.20721    |
-------------------------------------
-------------------------------------
| approxkl           | 0.022810116  |
| clipfrac           | 0.26367188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.93e+03     |
| explained_variance | -3.81e-06    |
| fps                | 32           |
| n_updates          | 24           |
| policy_entropy     | 1.2687879    |
| policy_loss        | -0.016298182 |
| serial_timesteps   | 3072         |
| time_elapsed       | 112          |
| total_timesteps    | 3072         |
| value_loss         | 366.1375     |
-------------------------------------
------------------------------------
| approxkl           | 0.006223117 |
| clipfrac           | 0.080078125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 1.61e-06    |
| fps                | 30          |
| n_updates          | 25          |
| policy_entropy     | 1.268991    |
| policy_loss        | 0.01270134  |
| serial_timesteps   | 3200        |
| time_elapsed       | 116         |
| total_timesteps    | 3200        |
| value_loss         | 1022.0322   |
------------------------------------
An average of 101.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0018691157 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | -1.65e-05    |
| fps                | 29           |
| n_updates          | 26           |
| policy_entropy     | 1.269231     |
| policy_loss        | -0.004800685 |
| serial_timesteps   | 3328         |
| time_elapsed       | 120          |
| total_timesteps    | 3328         |
| value_loss         | 326.28647    |
-------------------------------------
--------------------------------------
| approxkl           | 0.012224048   |
| clipfrac           | 0.20703125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | 2.03e-06      |
| fps                | 31            |
| n_updates          | 27            |
| policy_entropy     | 1.2691789     |
| policy_loss        | -0.0022006175 |
| serial_timesteps   | 3456          |
| time_elapsed       | 124           |
| total_timesteps    | 3456          |
| value_loss         | 333.77277     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0071236435  |
| clipfrac           | 0.095703125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | 1.81e-05      |
| fps                | 29            |
| n_updates          | 28            |
| policy_entropy     | 1.2694151     |
| policy_loss        | -0.0017687478 |
| serial_timesteps   | 3584          |
| time_elapsed       | 128           |
| total_timesteps    | 3584          |
| value_loss         | 312.60034     |
--------------------------------------
------------------------------------
| approxkl           | 0.010634189 |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 1.79e-05    |
| fps                | 32          |
| n_updates          | 29          |
| policy_entropy     | 1.2689435   |
| policy_loss        | 0.039901003 |
| serial_timesteps   | 3712        |
| time_elapsed       | 133         |
| total_timesteps    | 3712        |
| value_loss         | 295.92606   |
------------------------------------
-------------------------------------
| approxkl           | 0.028309619  |
| clipfrac           | 0.3515625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 30           |
| policy_entropy     | 1.2686237    |
| policy_loss        | -0.017127361 |
| serial_timesteps   | 3840         |
| time_elapsed       | 137          |
| total_timesteps    | 3840         |
| value_loss         | 379.7653     |
-------------------------------------
-------------------------------------
| approxkl           | 0.020132806  |
| clipfrac           | 0.25         |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 3.7e-06      |
| fps                | 34           |
| n_updates          | 31           |
| policy_entropy     | 1.2686384    |
| policy_loss        | 0.0050090235 |
| serial_timesteps   | 3968         |
| time_elapsed       | 141          |
| total_timesteps    | 3968         |
| value_loss         | 383.05862    |
-------------------------------------
------------------------------------
| approxkl           | 0.018848617 |
| clipfrac           | 0.25390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 4.67e-05    |
| fps                | 27          |
| n_updates          | 32          |
| policy_entropy     | 1.2692041   |
| policy_loss        | -0.00437433 |
| serial_timesteps   | 4096        |
| time_elapsed       | 145         |
| total_timesteps    | 4096        |
| value_loss         | 90.383736   |
------------------------------------
--------------------------------------
| approxkl           | 0.00067240867 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | -2.07e-05     |
| fps                | 29            |
| n_updates          | 33            |
| policy_entropy     | 1.269716      |
| policy_loss        | 0.007250659   |
| serial_timesteps   | 4224          |
| time_elapsed       | 149           |
| total_timesteps    | 4224          |
| value_loss         | 199.33163     |
--------------------------------------
An average of 101.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-----------------------------------
| approxkl           | 0.00794129 |
| clipfrac           | 0.10546875 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 4.97e+03   |
| explained_variance | -1.79e-06  |
| fps                | 30         |
| n_updates          | 34         |
| policy_entropy     | 1.269524   |
| policy_loss        | 0.00729558 |
| serial_timesteps   | 4352       |
| time_elapsed       | 154        |
| total_timesteps    | 4352       |
| value_loss         | 415.08255  |
-----------------------------------
------------------------------------
| approxkl           | 0.04448677  |
| clipfrac           | 0.33789062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 2.66e-05    |
| fps                | 31          |
| n_updates          | 35          |
| policy_entropy     | 1.2690933   |
| policy_loss        | 0.041883763 |
| serial_timesteps   | 4480        |
| time_elapsed       | 158         |
| total_timesteps    | 4480        |
| value_loss         | 307.1513    |
------------------------------------
------------------------------------
| approxkl           | 0.019135153 |
| clipfrac           | 0.25195312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -1.63e-05   |
| fps                | 27          |
| n_updates          | 36          |
| policy_entropy     | 1.2686495   |
| policy_loss        | 0.00063487  |
| serial_timesteps   | 4608        |
| time_elapsed       | 162         |
| total_timesteps    | 4608        |
| value_loss         | 315.4856    |
------------------------------------
--------------------------------------
| approxkl           | 0.00034447212 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 37            |
| policy_entropy     | 1.2673651     |
| policy_loss        | 0.0011129812  |
| serial_timesteps   | 4736          |
| time_elapsed       | 167           |
| total_timesteps    | 4736          |
| value_loss         | 948.9502      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0043361858  |
| clipfrac           | 0.0546875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | -4.89e-06     |
| fps                | 30            |
| n_updates          | 38            |
| policy_entropy     | 1.2666676     |
| policy_loss        | -0.0062718885 |
| serial_timesteps   | 4864          |
| time_elapsed       | 171           |
| total_timesteps    | 4864          |
| value_loss         | 310.93738     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0084132105 |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 1.06e-05     |
| fps                | 28           |
| n_updates          | 39           |
| policy_entropy     | 1.2665803    |
| policy_loss        | 0.0013061948 |
| serial_timesteps   | 4992         |
| time_elapsed       | 175          |
| total_timesteps    | 4992         |
| value_loss         | 388.81058    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008651645  |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 7.15e-07     |
| fps                | 31           |
| n_updates          | 40           |
| policy_entropy     | 1.2665999    |
| policy_loss        | -0.004269176 |
| serial_timesteps   | 5120         |
| time_elapsed       | 180          |
| total_timesteps    | 5120         |
| value_loss         | 297.1405     |
-------------------------------------
An average of 102.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0012840063 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 7.15e-07     |
| fps                | 31           |
| n_updates          | 41           |
| policy_entropy     | 1.2665335    |
| policy_loss        | -0.00586576  |
| serial_timesteps   | 5248         |
| time_elapsed       | 184          |
| total_timesteps    | 5248         |
| value_loss         | 290.08258    |
-------------------------------------
------------------------------------
| approxkl           | 0.032470565 |
| clipfrac           | 0.36132812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -1.1e-05    |
| fps                | 31          |
| n_updates          | 42          |
| policy_entropy     | 1.2664447   |
| policy_loss        | 0.008760938 |
| serial_timesteps   | 5376        |
| time_elapsed       | 188         |
| total_timesteps    | 5376        |
| value_loss         | 360.40018   |
------------------------------------
------------------------------------
| approxkl           | 0.019157695 |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 2.38e-06    |
| fps                | 31          |
| n_updates          | 43          |
| policy_entropy     | 1.2669108   |
| policy_loss        | 0.023598611 |
| serial_timesteps   | 5504        |
| time_elapsed       | 192         |
| total_timesteps    | 5504        |
| value_loss         | 311.08496   |
------------------------------------
------------------------------------
| approxkl           | 0.021018773 |
| clipfrac           | 0.265625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 1.01e-06    |
| fps                | 29          |
| n_updates          | 44          |
| policy_entropy     | 1.2670397   |
| policy_loss        | 0.02072618  |
| serial_timesteps   | 5632        |
| time_elapsed       | 196         |
| total_timesteps    | 5632        |
| value_loss         | 298.6705    |
------------------------------------
--------------------------------------
| approxkl           | 0.018853316   |
| clipfrac           | 0.265625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | 3.02e-05      |
| fps                | 28            |
| n_updates          | 45            |
| policy_entropy     | 1.2668747     |
| policy_loss        | -0.0130669465 |
| serial_timesteps   | 5760          |
| time_elapsed       | 200           |
| total_timesteps    | 5760          |
| value_loss         | 264.54147     |
--------------------------------------
------------------------------------
| approxkl           | 0.021364465 |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -8.82e-06   |
| fps                | 28          |
| n_updates          | 46          |
| policy_entropy     | 1.2661968   |
| policy_loss        | 0.021944666 |
| serial_timesteps   | 5888        |
| time_elapsed       | 205         |
| total_timesteps    | 5888        |
| value_loss         | 319.06433   |
------------------------------------
------------------------------------
| approxkl           | 0.024511885 |
| clipfrac           | 0.26953125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 2.07e-05    |
| fps                | 31          |
| n_updates          | 47          |
| policy_entropy     | 1.2652758   |
| policy_loss        | 0.01753595  |
| serial_timesteps   | 6016        |
| time_elapsed       | 209         |
| total_timesteps    | 6016        |
| value_loss         | 323.9846    |
------------------------------------
------------------------------------
| approxkl           | 0.008296768 |
| clipfrac           | 0.12109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -1.86e-05   |
| fps                | 29          |
| n_updates          | 48          |
| policy_entropy     | 1.2653263   |
| policy_loss        | 0.026769742 |
| serial_timesteps   | 6144        |
| time_elapsed       | 213         |
| total_timesteps    | 6144        |
| value_loss         | 151.172     |
------------------------------------
An average of 103.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.03191645   |
| clipfrac           | 0.3671875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | -5.96e-07    |
| fps                | 29           |
| n_updates          | 49           |
| policy_entropy     | 1.2657796    |
| policy_loss        | 0.0015472372 |
| serial_timesteps   | 6272         |
| time_elapsed       | 218          |
| total_timesteps    | 6272         |
| value_loss         | 941.03       |
-------------------------------------
-------------------------------------
| approxkl           | 0.0012562535 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | -1.43e-06    |
| fps                | 31           |
| n_updates          | 50           |
| policy_entropy     | 1.2664393    |
| policy_loss        | 0.00293207   |
| serial_timesteps   | 6400         |
| time_elapsed       | 222          |
| total_timesteps    | 6400         |
| value_loss         | 428.68628    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00024935062 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.99e+03      |
| explained_variance | 8.34e-06      |
| fps                | 29            |
| n_updates          | 51            |
| policy_entropy     | 1.2666276     |
| policy_loss        | -0.0011303704 |
| serial_timesteps   | 6528          |
| time_elapsed       | 226           |
| total_timesteps    | 6528          |
| value_loss         | 306.54312     |
--------------------------------------
------------------------------------
| approxkl           | 0.037480775 |
| clipfrac           | 0.35351562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.99e+03    |
| explained_variance | -5.84e-06   |
| fps                | 29          |
| n_updates          | 52          |
| policy_entropy     | 1.2657522   |
| policy_loss        | 0.023014218 |
| serial_timesteps   | 6656        |
| time_elapsed       | 231         |
| total_timesteps    | 6656        |
| value_loss         | 313.42386   |
------------------------------------
--------------------------------------
| approxkl           | 0.01944805    |
| clipfrac           | 0.25976562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.99e+03      |
| explained_variance | 2.74e-06      |
| fps                | 33            |
| n_updates          | 53            |
| policy_entropy     | 1.2651664     |
| policy_loss        | -0.0117195975 |
| serial_timesteps   | 6784          |
| time_elapsed       | 235           |
| total_timesteps    | 6784          |
| value_loss         | 114.806786    |
--------------------------------------
-------------------------------------
| approxkl           | 0.020821987  |
| clipfrac           | 0.28710938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | -1.79e-06    |
| fps                | 31           |
| n_updates          | 54           |
| policy_entropy     | 1.2642636    |
| policy_loss        | -0.005444617 |
| serial_timesteps   | 6912         |
| time_elapsed       | 239          |
| total_timesteps    | 6912         |
| value_loss         | 293.82288    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021622734  |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | 1.19e-06     |
| fps                | 30           |
| n_updates          | 55           |
| policy_entropy     | 1.2637982    |
| policy_loss        | -0.008780545 |
| serial_timesteps   | 7040         |
| time_elapsed       | 243          |
| total_timesteps    | 7040         |
| value_loss         | 197.16673    |
-------------------------------------
------------------------------------
| approxkl           | 0.012206184 |
| clipfrac           | 0.20117188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.99e+03    |
| explained_variance | -4.05e-06   |
| fps                | 28          |
| n_updates          | 56          |
| policy_entropy     | 1.2634773   |
| policy_loss        | 0.04129022  |
| serial_timesteps   | 7168        |
| time_elapsed       | 247         |
| total_timesteps    | 7168        |
| value_loss         | 202.03313   |
------------------------------------
An average of 103.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.027658891  |
| clipfrac           | 0.328125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | -5.6e-06     |
| fps                | 29           |
| n_updates          | 57           |
| policy_entropy     | 1.2629128    |
| policy_loss        | 0.0101300245 |
| serial_timesteps   | 7296         |
| time_elapsed       | 252          |
| total_timesteps    | 7296         |
| value_loss         | 291.75073    |
-------------------------------------
------------------------------------
| approxkl           | 0.01056891  |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.99e+03    |
| explained_variance | -3.7e-06    |
| fps                | 29          |
| n_updates          | 58          |
| policy_entropy     | 1.2623968   |
| policy_loss        | 0.032087676 |
| serial_timesteps   | 7424        |
| time_elapsed       | 256         |
| total_timesteps    | 7424        |
| value_loss         | 175.59015   |
------------------------------------
-------------------------------------
| approxkl           | 0.0389206    |
| clipfrac           | 0.375        |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | 7.81e-06     |
| fps                | 30           |
| n_updates          | 59           |
| policy_entropy     | 1.2617285    |
| policy_loss        | -0.012127674 |
| serial_timesteps   | 7552         |
| time_elapsed       | 260          |
| total_timesteps    | 7552         |
| value_loss         | 232.25818    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00028800475  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.99e+03       |
| explained_variance | 2.91e-05       |
| fps                | 31             |
| n_updates          | 60             |
| policy_entropy     | 1.2606095      |
| policy_loss        | -0.00040302193 |
| serial_timesteps   | 7680           |
| time_elapsed       | 264            |
| total_timesteps    | 7680           |
| value_loss         | 245.54747      |
---------------------------------------
-------------------------------------
| approxkl           | 0.004776618  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.96e+03     |
| explained_variance | 3.58e-06     |
| fps                | 29           |
| n_updates          | 61           |
| policy_entropy     | 1.2598021    |
| policy_loss        | -0.004242548 |
| serial_timesteps   | 7808         |
| time_elapsed       | 269          |
| total_timesteps    | 7808         |
| value_loss         | 1005.7892    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0038467739  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.96e+03      |
| explained_variance | -2.98e-06     |
| fps                | 31            |
| n_updates          | 62            |
| policy_entropy     | 1.2586342     |
| policy_loss        | -0.0014831541 |
| serial_timesteps   | 7936          |
| time_elapsed       | 273           |
| total_timesteps    | 7936          |
| value_loss         | 373.8652      |
--------------------------------------
--------------------------------------
| approxkl           | 9.758153e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.96e+03      |
| explained_variance | 4.26e-05      |
| fps                | 29            |
| n_updates          | 63            |
| policy_entropy     | 1.2582719     |
| policy_loss        | 0.00014453556 |
| serial_timesteps   | 8064          |
| time_elapsed       | 277           |
| total_timesteps    | 8064          |
| value_loss         | 196.82329     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01427073   |
| clipfrac           | 0.20117188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.96e+03     |
| explained_variance | 2.38e-07     |
| fps                | 31           |
| n_updates          | 64           |
| policy_entropy     | 1.2578498    |
| policy_loss        | -0.015569388 |
| serial_timesteps   | 8192         |
| time_elapsed       | 281          |
| total_timesteps    | 8192         |
| value_loss         | 154.25905    |
-------------------------------------
An average of 104.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.0005818766   |
| clipfrac           | 0.00390625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.96e+03       |
| explained_variance | 1.79e-06       |
| fps                | 30             |
| n_updates          | 65             |
| policy_entropy     | 1.2575518      |
| policy_loss        | -0.00074490963 |
| serial_timesteps   | 8320           |
| time_elapsed       | 285            |
| total_timesteps    | 8320           |
| value_loss         | 310.08997      |
---------------------------------------
------------------------------------
| approxkl           | 0.041692957 |
| clipfrac           | 0.38671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.96e+03    |
| explained_variance | 6.56e-07    |
| fps                | 32          |
| n_updates          | 66          |
| policy_entropy     | 1.2555157   |
| policy_loss        | 0.035624757 |
| serial_timesteps   | 8448        |
| time_elapsed       | 290         |
| total_timesteps    | 8448        |
| value_loss         | 366.46704   |
------------------------------------
--------------------------------------
| approxkl           | 0.012110651   |
| clipfrac           | 0.20507812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.96e+03      |
| explained_variance | -7.15e-06     |
| fps                | 30            |
| n_updates          | 67            |
| policy_entropy     | 1.2546914     |
| policy_loss        | -0.0011846088 |
| serial_timesteps   | 8576          |
| time_elapsed       | 294           |
| total_timesteps    | 8576          |
| value_loss         | 321.45914     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017620664 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.96e+03      |
| explained_variance | -1.19e-07     |
| fps                | 28            |
| n_updates          | 68            |
| policy_entropy     | 1.2538944     |
| policy_loss        | -0.0006449433 |
| serial_timesteps   | 8704          |
| time_elapsed       | 298           |
| total_timesteps    | 8704          |
| value_loss         | 251.62761     |
--------------------------------------
------------------------------------
| approxkl           | 0.01114735  |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.96e+03    |
| explained_variance | 1.93e-05    |
| fps                | 30          |
| n_updates          | 69          |
| policy_entropy     | 1.2536503   |
| policy_loss        | 0.013317855 |
| serial_timesteps   | 8832        |
| time_elapsed       | 302         |
| total_timesteps    | 8832        |
| value_loss         | 264.30112   |
------------------------------------
-------------------------------------
| approxkl           | 0.014375725  |
| clipfrac           | 0.23632812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.96e+03     |
| explained_variance | 9.6e-06      |
| fps                | 30           |
| n_updates          | 70           |
| policy_entropy     | 1.2533265    |
| policy_loss        | -0.009664722 |
| serial_timesteps   | 8960         |
| time_elapsed       | 306          |
| total_timesteps    | 8960         |
| value_loss         | 270.34692    |
-------------------------------------
------------------------------------
| approxkl           | 0.010369301 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.96e+03    |
| explained_variance | 3.1e-06     |
| fps                | 32          |
| n_updates          | 71          |
| policy_entropy     | 1.2529234   |
| policy_loss        | 0.02577519  |
| serial_timesteps   | 9088        |
| time_elapsed       | 310         |
| total_timesteps    | 9088        |
| value_loss         | 222.92947   |
------------------------------------
-------------------------------------
| approxkl           | 0.031275626  |
| clipfrac           | 0.37109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.96e+03     |
| explained_variance | 6.74e-06     |
| fps                | 32           |
| n_updates          | 72           |
| policy_entropy     | 1.2524221    |
| policy_loss        | -0.008933134 |
| serial_timesteps   | 9216         |
| time_elapsed       | 314          |
| total_timesteps    | 9216         |
| value_loss         | 121.670105   |
-------------------------------------
An average of 104.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.018528441  |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | 5.54e-06     |
| fps                | 30           |
| n_updates          | 73           |
| policy_entropy     | 1.2522036    |
| policy_loss        | 0.0076310514 |
| serial_timesteps   | 9344         |
| time_elapsed       | 318          |
| total_timesteps    | 9344         |
| value_loss         | 848.7345     |
-------------------------------------
-------------------------------------
| approxkl           | 0.03319208   |
| clipfrac           | 0.34960938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | 1.79e-07     |
| fps                | 31           |
| n_updates          | 74           |
| policy_entropy     | 1.2524726    |
| policy_loss        | -0.024112869 |
| serial_timesteps   | 9472         |
| time_elapsed       | 323          |
| total_timesteps    | 9472         |
| value_loss         | 87.05749     |
-------------------------------------
-------------------------------------
| approxkl           | 8.337401e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | 1.27e-05     |
| fps                | 28           |
| n_updates          | 75           |
| policy_entropy     | 1.2525276    |
| policy_loss        | 0.0002812536 |
| serial_timesteps   | 9600         |
| time_elapsed       | 327          |
| total_timesteps    | 9600         |
| value_loss         | 248.0765     |
-------------------------------------
------------------------------------
| approxkl           | 0.014214787 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | 4.54e-05    |
| fps                | 32          |
| n_updates          | 76          |
| policy_entropy     | 1.251913    |
| policy_loss        | 0.0193627   |
| serial_timesteps   | 9728        |
| time_elapsed       | 331         |
| total_timesteps    | 9728        |
| value_loss         | 365.40692   |
------------------------------------
------------------------------------
| approxkl           | 0.017132876 |
| clipfrac           | 0.26953125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -5.96e-06   |
| fps                | 30          |
| n_updates          | 77          |
| policy_entropy     | 1.2515917   |
| policy_loss        | 0.01683246  |
| serial_timesteps   | 9856        |
| time_elapsed       | 335         |
| total_timesteps    | 9856        |
| value_loss         | 354.91425   |
------------------------------------
-------------------------------------
| approxkl           | 0.02105701   |
| clipfrac           | 0.26367188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | -4.77e-07    |
| fps                | 28           |
| n_updates          | 78           |
| policy_entropy     | 1.251401     |
| policy_loss        | 0.0028557056 |
| serial_timesteps   | 9984         |
| time_elapsed       | 339          |
| total_timesteps    | 9984         |
| value_loss         | 351.80704    |
-------------------------------------
-------------------------------------
| approxkl           | 0.026599154  |
| clipfrac           | 0.31054688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | -1.34e-05    |
| fps                | 29           |
| n_updates          | 79           |
| policy_entropy     | 1.2513936    |
| policy_loss        | -0.019953344 |
| serial_timesteps   | 10112        |
| time_elapsed       | 344          |
| total_timesteps    | 10112        |
| value_loss         | 44.56549     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071945116 |
| clipfrac           | 0.107421875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | -1.31e-06    |
| fps                | 29           |
| n_updates          | 80           |
| policy_entropy     | 1.2515686    |
| policy_loss        | 0.014953606  |
| serial_timesteps   | 10240        |
| time_elapsed       | 348          |
| total_timesteps    | 10240        |
| value_loss         | 294.7415     |
-------------------------------------
An average of 105.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.014431706   |
| clipfrac           | 0.21679688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.94e+03      |
| explained_variance | -2.62e-06     |
| fps                | 31            |
| n_updates          | 81            |
| policy_entropy     | 1.2510223     |
| policy_loss        | -0.0055977525 |
| serial_timesteps   | 10368         |
| time_elapsed       | 352           |
| total_timesteps    | 10368         |
| value_loss         | 289.55072     |
--------------------------------------
--------------------------------------
| approxkl           | 0.019723415   |
| clipfrac           | 0.26367188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.94e+03      |
| explained_variance | 1.06e-05      |
| fps                | 30            |
| n_updates          | 82            |
| policy_entropy     | 1.2505474     |
| policy_loss        | -0.0052462863 |
| serial_timesteps   | 10496         |
| time_elapsed       | 357           |
| total_timesteps    | 10496         |
| value_loss         | 352.7392      |
--------------------------------------
------------------------------------
| approxkl           | 0.012171471 |
| clipfrac           | 0.1953125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -1.91e-05   |
| fps                | 27          |
| n_updates          | 83          |
| policy_entropy     | 1.2498868   |
| policy_loss        | 0.029840134 |
| serial_timesteps   | 10624       |
| time_elapsed       | 361         |
| total_timesteps    | 10624       |
| value_loss         | 282.04645   |
------------------------------------
-------------------------------------
| approxkl           | 0.021438709  |
| clipfrac           | 0.29882812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | 7.15e-07     |
| fps                | 28           |
| n_updates          | 84           |
| policy_entropy     | 1.2487692    |
| policy_loss        | 0.0149396425 |
| serial_timesteps   | 10752        |
| time_elapsed       | 365          |
| total_timesteps    | 10752        |
| value_loss         | 293.25433    |
-------------------------------------
------------------------------------
| approxkl           | 0.008890249 |
| clipfrac           | 0.12890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -1.31e-06   |
| fps                | 29          |
| n_updates          | 85          |
| policy_entropy     | 1.2483433   |
| policy_loss        | 0.004786188 |
| serial_timesteps   | 10880       |
| time_elapsed       | 370         |
| total_timesteps    | 10880       |
| value_loss         | 908.9378    |
------------------------------------
--------------------------------------
| approxkl           | 0.00010296723 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.94e+03      |
| explained_variance | 1.19e-07      |
| fps                | 29            |
| n_updates          | 86            |
| policy_entropy     | 1.248578      |
| policy_loss        | 0.0020300602  |
| serial_timesteps   | 11008         |
| time_elapsed       | 374           |
| total_timesteps    | 11008         |
| value_loss         | 384.3516      |
--------------------------------------
-------------------------------------
| approxkl           | 2.64752e-05  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | 1.04e-05     |
| fps                | 30           |
| n_updates          | 87           |
| policy_entropy     | 1.2485338    |
| policy_loss        | 0.0008004805 |
| serial_timesteps   | 11136        |
| time_elapsed       | 379          |
| total_timesteps    | 11136        |
| value_loss         | 332.7265     |
-------------------------------------
An average of 106.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0014393671  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.94e+03      |
| explained_variance | 2.26e-05      |
| fps                | 31            |
| n_updates          | 88            |
| policy_entropy     | 1.24784       |
| policy_loss        | -0.0048134234 |
| serial_timesteps   | 11264         |
| time_elapsed       | 383           |
| total_timesteps    | 11264         |
| value_loss         | 280.6092      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00050034444 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.94e+03      |
| explained_variance | -9.42e-06     |
| fps                | 29            |
| n_updates          | 89            |
| policy_entropy     | 1.2468488     |
| policy_loss        | 0.00045053358 |
| serial_timesteps   | 11392         |
| time_elapsed       | 387           |
| total_timesteps    | 11392         |
| value_loss         | 317.20007     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00026150135 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.94e+03      |
| explained_variance | 1.07e-06      |
| fps                | 32            |
| n_updates          | 90            |
| policy_entropy     | 1.2444705     |
| policy_loss        | 5.0947885e-05 |
| serial_timesteps   | 11520         |
| time_elapsed       | 391           |
| total_timesteps    | 11520         |
| value_loss         | 349.0735      |
--------------------------------------
------------------------------------
| approxkl           | 0.017984826 |
| clipfrac           | 0.265625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -5.13e-06   |
| fps                | 29          |
| n_updates          | 91          |
| policy_entropy     | 1.243389    |
| policy_loss        | 0.006372388 |
| serial_timesteps   | 11648       |
| time_elapsed       | 395         |
| total_timesteps    | 11648       |
| value_loss         | 318.32834   |
------------------------------------
------------------------------------
| approxkl           | 0.015763855 |
| clipfrac           | 0.203125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -1.72e-05   |
| fps                | 28          |
| n_updates          | 92          |
| policy_entropy     | 1.2431957   |
| policy_loss        | 0.010349801 |
| serial_timesteps   | 11776       |
| time_elapsed       | 399         |
| total_timesteps    | 11776       |
| value_loss         | 373.78098   |
------------------------------------
------------------------------------
| approxkl           | 0.016181849 |
| clipfrac           | 0.234375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -1.67e-06   |
| fps                | 30          |
| n_updates          | 93          |
| policy_entropy     | 1.2430124   |
| policy_loss        | 0.026178304 |
| serial_timesteps   | 11904       |
| time_elapsed       | 404         |
| total_timesteps    | 11904       |
| value_loss         | 267.83224   |
------------------------------------
------------------------------------
| approxkl           | 0.019953005 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | 4.19e-05    |
| fps                | 30          |
| n_updates          | 94          |
| policy_entropy     | 1.242489    |
| policy_loss        | 0.010575846 |
| serial_timesteps   | 12032       |
| time_elapsed       | 408         |
| total_timesteps    | 12032       |
| value_loss         | 235.37465   |
------------------------------------
-------------------------------------
| approxkl           | 0.019109944  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.94e+03     |
| explained_variance | -4.89e-06    |
| fps                | 28           |
| n_updates          | 95           |
| policy_entropy     | 1.2421057    |
| policy_loss        | -0.001580307 |
| serial_timesteps   | 12160        |
| time_elapsed       | 412          |
| total_timesteps    | 12160        |
| value_loss         | 142.68228    |
-------------------------------------
An average of 106.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.012848499 |
| clipfrac           | 0.1953125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.94e+03    |
| explained_variance | -4.77e-06   |
| fps                | 28          |
| n_updates          | 96          |
| policy_entropy     | 1.2425728   |
| policy_loss        | 0.013157513 |
| serial_timesteps   | 12288       |
| time_elapsed       | 417         |
| total_timesteps    | 12288       |
| value_loss         | 339.3782    |
------------------------------------
-------------------------------------
| approxkl           | 0.0140857315 |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 97           |
| policy_entropy     | 1.2426237    |
| policy_loss        | -0.014567232 |
| serial_timesteps   | 12416        |
| time_elapsed       | 421          |
| total_timesteps    | 12416        |
| value_loss         | 1132.4906    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00016444644 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | -3.93e-06     |
| fps                | 29            |
| n_updates          | 98            |
| policy_entropy     | 1.2423748     |
| policy_loss        | 0.0022229617  |
| serial_timesteps   | 12544         |
| time_elapsed       | 425           |
| total_timesteps    | 12544         |
| value_loss         | 298.94803     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00031795108 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | -1.43e-06     |
| fps                | 31            |
| n_updates          | 99            |
| policy_entropy     | 1.2422522     |
| policy_loss        | -0.0018344555 |
| serial_timesteps   | 12672         |
| time_elapsed       | 430           |
| total_timesteps    | 12672         |
| value_loss         | 336.36667     |
--------------------------------------
------------------------------------
| approxkl           | 0.01971952  |
| clipfrac           | 0.26171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 7.75e-07    |
| fps                | 28          |
| n_updates          | 100         |
| policy_entropy     | 1.2415242   |
| policy_loss        | 0.034001842 |
| serial_timesteps   | 12800       |
| time_elapsed       | 434         |
| total_timesteps    | 12800       |
| value_loss         | 186.04825   |
------------------------------------
------------------------------------
| approxkl           | 0.015960881 |
| clipfrac           | 0.234375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -5.01e-06   |
| fps                | 31          |
| n_updates          | 101         |
| policy_entropy     | 1.240716    |
| policy_loss        | 0.029525407 |
| serial_timesteps   | 12928       |
| time_elapsed       | 438         |
| total_timesteps    | 12928       |
| value_loss         | 343.838     |
------------------------------------
------------------------------------
| approxkl           | 0.018687647 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -3.46e-06   |
| fps                | 32          |
| n_updates          | 102         |
| policy_entropy     | 1.2403992   |
| policy_loss        | 0.016868124 |
| serial_timesteps   | 13056       |
| time_elapsed       | 442         |
| total_timesteps    | 13056       |
| value_loss         | 263.55725   |
------------------------------------
------------------------------------
| approxkl           | 0.02829931  |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -1.41e-05   |
| fps                | 30          |
| n_updates          | 103         |
| policy_entropy     | 1.2402998   |
| policy_loss        | 0.008922664 |
| serial_timesteps   | 13184       |
| time_elapsed       | 446         |
| total_timesteps    | 13184       |
| value_loss         | 226.09146   |
------------------------------------
An average of 107.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.018114906 |
| clipfrac           | 0.25195312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | -7.63e-06   |
| fps                | 31          |
| n_updates          | 104         |
| policy_entropy     | 1.2401915   |
| policy_loss        | 0.018097986 |
| serial_timesteps   | 13312       |
| time_elapsed       | 450         |
| total_timesteps    | 13312       |
| value_loss         | 351.87354   |
------------------------------------
-------------------------------------
| approxkl           | 0.01670577   |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 9.54e-07     |
| fps                | 28           |
| n_updates          | 105          |
| policy_entropy     | 1.2397988    |
| policy_loss        | 0.0037753053 |
| serial_timesteps   | 13440        |
| time_elapsed       | 454          |
| total_timesteps    | 13440        |
| value_loss         | 243.4591     |
-------------------------------------
------------------------------------
| approxkl           | 0.020592239 |
| clipfrac           | 0.28320312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.97e+03    |
| explained_variance | 2.21e-06    |
| fps                | 30          |
| n_updates          | 106         |
| policy_entropy     | 1.2400215   |
| policy_loss        | 0.033561792 |
| serial_timesteps   | 13568       |
| time_elapsed       | 459         |
| total_timesteps    | 13568       |
| value_loss         | 287.52744   |
------------------------------------
-------------------------------------
| approxkl           | 0.019176567  |
| clipfrac           | 0.24023438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.97e+03     |
| explained_variance | 6.56e-06     |
| fps                | 30           |
| n_updates          | 107          |
| policy_entropy     | 1.240142     |
| policy_loss        | 0.0040441826 |
| serial_timesteps   | 13696        |
| time_elapsed       | 463          |
| total_timesteps    | 13696        |
| value_loss         | 303.64444    |
-------------------------------------
--------------------------------------
| approxkl           | 0.017165205   |
| clipfrac           | 0.24414062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.97e+03      |
| explained_variance | -2.48e-05     |
| fps                | 33            |
| n_updates          | 108           |
| policy_entropy     | 1.2403142     |
| policy_loss        | -0.0008969072 |
| serial_timesteps   | 13824         |
| time_elapsed       | 467           |
| total_timesteps    | 13824         |
| value_loss         | 314.6178      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008134262  |
| clipfrac           | 0.12109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | -2.38e-07    |
| fps                | 29           |
| n_updates          | 109          |
| policy_entropy     | 1.2397925    |
| policy_loss        | 0.0059399456 |
| serial_timesteps   | 13952        |
| time_elapsed       | 471          |
| total_timesteps    | 13952        |
| value_loss         | 1020.81555   |
-------------------------------------
---------------------------------------
| approxkl           | 0.00028019462  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 4.99e+03       |
| explained_variance | 3.99e-05       |
| fps                | 30             |
| n_updates          | 110            |
| policy_entropy     | 1.2392478      |
| policy_loss        | -0.00024088513 |
| serial_timesteps   | 14080          |
| time_elapsed       | 475            |
| total_timesteps    | 14080          |
| value_loss         | 128.45876      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00010701779 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.99e+03      |
| explained_variance | 7.57e-06      |
| fps                | 28            |
| n_updates          | 111           |
| policy_entropy     | 1.2388692     |
| policy_loss        | -0.0006355087 |
| serial_timesteps   | 14208         |
| time_elapsed       | 480           |
| total_timesteps    | 14208         |
| value_loss         | 221.97528     |
--------------------------------------
An average of 108.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00057758065 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 4.99e+03      |
| explained_variance | -1.31e-06     |
| fps                | 29            |
| n_updates          | 112           |
| policy_entropy     | 1.2368654     |
| policy_loss        | -0.0016416365 |
| serial_timesteps   | 14336         |
| time_elapsed       | 484           |
| total_timesteps    | 14336         |
| value_loss         | 307.7542      |
--------------------------------------
------------------------------------
| approxkl           | 0.004235462 |
| clipfrac           | 0.05078125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.99e+03    |
| explained_variance | 1.4e-05     |
| fps                | 29          |
| n_updates          | 113         |
| policy_entropy     | 1.2324519   |
| policy_loss        | 0.001977533 |
| serial_timesteps   | 14464       |
| time_elapsed       | 488         |
| total_timesteps    | 14464       |
| value_loss         | 201.38237   |
------------------------------------
------------------------------------
| approxkl           | 0.010984584 |
| clipfrac           | 0.13476562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.99e+03    |
| explained_variance | -1.13e-05   |
| fps                | 29          |
| n_updates          | 114         |
| policy_entropy     | 1.2297275   |
| policy_loss        | 0.014281301 |
| serial_timesteps   | 14592       |
| time_elapsed       | 493         |
| total_timesteps    | 14592       |
| value_loss         | 342.02155   |
------------------------------------
------------------------------------
| approxkl           | 0.012759587 |
| clipfrac           | 0.18554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 4.99e+03    |
| explained_variance | -5.96e-07   |
| fps                | 30          |
| n_updates          | 115         |
| policy_entropy     | 1.2285426   |
| policy_loss        | 0.02637802  |
| serial_timesteps   | 14720       |
| time_elapsed       | 497         |
| total_timesteps    | 14720       |
| value_loss         | 263.5356    |
------------------------------------
-------------------------------------
| approxkl           | 0.021705907  |
| clipfrac           | 0.28515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | 1.49e-06     |
| fps                | 30           |
| n_updates          | 116          |
| policy_entropy     | 1.2280011    |
| policy_loss        | 0.0018728245 |
| serial_timesteps   | 14848        |
| time_elapsed       | 501          |
| total_timesteps    | 14848        |
| value_loss         | 321.87634    |
-------------------------------------
-------------------------------------
| approxkl           | 0.017510332  |
| clipfrac           | 0.25195312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 4.99e+03     |
| explained_variance | -2.5e-06     |
| fps                | 30           |
| n_updates          | 117          |
| policy_entropy     | 1.2274306    |
| policy_loss        | 0.0055934177 |
| serial_timesteps   | 14976        |
| time_elapsed       | 505          |
| total_timesteps    | 14976        |
| value_loss         | 291.41782    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6e8bcba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6e8bcba8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6e7c6e48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6e7c6e48>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2348 samples, validate on 327 samples
Epoch 211/5000
 - 4s - loss: 0.0560 - val_loss: 0.0111
Epoch 212/5000
 - 0s - loss: 0.0165 - val_loss: 0.0067
Epoch 213/5000
 - 0s - loss: 0.0100 - val_loss: 0.0050
Epoch 214/5000
 - 1s - loss: 0.0059 - val_loss: 0.0048
Epoch 215/5000
 - 0s - loss: 0.0043 - val_loss: 0.0046
Epoch 216/5000
 - 1s - loss: 0.0040 - val_loss: 0.0047
Epoch 217/5000
 - 0s - loss: 0.0039 - val_loss: 0.0049
Epoch 218/5000
 - 1s - loss: 0.0034 - val_loss: 0.0050
Epoch 219/5000
 - 1s - loss: 0.0033 - val_loss: 0.0050
Epoch 220/5000
 - 0s - loss: 0.0033 - val_loss: 0.0050
Train on 1863 samples, validate on 327 samples
Epoch 168/5000
 - 4s - loss: 0.0016 - val_loss: 5.1997e-04
Epoch 169/5000
 - 0s - loss: 0.0025 - val_loss: 0.0012
Epoch 170/5000
 - 0s - loss: 0.0017 - val_loss: 0.0010
Epoch 171/5000
 - 0s - loss: 0.0017 - val_loss: 0.0023
Epoch 172/5000
 - 0s - loss: 0.0013 - val_loss: 0.0028
Epoch 173/5000
 - 1s - loss: 0.0012 - val_loss: 0.0028
Train on 2349 samples, validate on 327 samples
Epoch 334/5000
 - 5s - loss: 0.5925 - val_loss: 0.7682
Epoch 335/5000
 - 1s - loss: 0.4388 - val_loss: 0.9139
Epoch 336/5000
 - 1s - loss: 0.4219 - val_loss: 0.9114
Epoch 337/5000
 - 1s - loss: 0.4077 - val_loss: 0.9139
Epoch 338/5000
 - 1s - loss: 0.4074 - val_loss: 0.9179
Epoch 339/5000
 - 1s - loss: 0.4071 - val_loss: 0.9211
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.013224313 |
| clipfrac           | 0.19335938  |
| explained_variance | 8.94e-07    |
| fps                | 6           |
| n_updates          | 1           |
| policy_entropy     | 1.2272079   |
| policy_loss        | 0.025394555 |
| serial_timesteps   | 128         |
| time_elapsed       | 1.22e-05    |
| total_timesteps    | 128         |
| value_loss         | 328.75928   |
------------------------------------
-------------------------------------
| approxkl           | 0.023070091  |
| clipfrac           | 0.27148438   |
| explained_variance | 4.23e-06     |
| fps                | 29           |
| n_updates          | 2            |
| policy_entropy     | 1.2269344    |
| policy_loss        | -0.005739848 |
| serial_timesteps   | 256          |
| time_elapsed       | 19.8         |
| total_timesteps    | 256          |
| value_loss         | 320.4405     |
-------------------------------------
An average of 109.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-----------------------------------
| approxkl           | 0.01657921 |
| clipfrac           | 0.23242188 |
| explained_variance | -1.79e-06  |
| fps                | 29         |
| n_updates          | 3          |
| policy_entropy     | 1.2263567  |
| policy_loss        | -0.0109109 |
| serial_timesteps   | 384        |
| time_elapsed       | 24.2       |
| total_timesteps    | 384        |
| value_loss         | 240.24417  |
-----------------------------------
--------------------------------------
| approxkl           | 0.018286573   |
| clipfrac           | 0.25          |
| explained_variance | 1.54e-05      |
| fps                | 30            |
| n_updates          | 4             |
| policy_entropy     | 1.225797      |
| policy_loss        | -0.0057958188 |
| serial_timesteps   | 512           |
| time_elapsed       | 28.5          |
| total_timesteps    | 512           |
| value_loss         | 278.33472     |
--------------------------------------
------------------------------------
| approxkl           | 0.015368894 |
| clipfrac           | 0.20898438  |
| explained_variance | 3.28e-06    |
| fps                | 29          |
| n_updates          | 5           |
| policy_entropy     | 1.2255292   |
| policy_loss        | 0.014055634 |
| serial_timesteps   | 640         |
| time_elapsed       | 32.8        |
| total_timesteps    | 640         |
| value_loss         | 259.90942   |
------------------------------------
------------------------------------
| approxkl           | 0.019599345 |
| clipfrac           | 0.2734375   |
| explained_variance | 1.37e-06    |
| fps                | 30          |
| n_updates          | 6           |
| policy_entropy     | 1.2253785   |
| policy_loss        | 0.02297839  |
| serial_timesteps   | 768         |
| time_elapsed       | 37.1        |
| total_timesteps    | 768         |
| value_loss         | 286.5276    |
------------------------------------
-------------------------------------
| approxkl           | 0.03306301   |
| clipfrac           | 0.33789062   |
| explained_variance | -1.38e-05    |
| fps                | 30           |
| n_updates          | 7            |
| policy_entropy     | 1.2261181    |
| policy_loss        | -0.013001762 |
| serial_timesteps   | 896          |
| time_elapsed       | 41.4         |
| total_timesteps    | 896          |
| value_loss         | 265.59772    |
-------------------------------------
-----------------------------------
| approxkl           | 0.01497685 |
| clipfrac           | 0.19921875 |
| explained_variance | -1.32e-05  |
| fps                | 31         |
| n_updates          | 8          |
| policy_entropy     | 1.2265035  |
| policy_loss        | 0.03048405 |
| serial_timesteps   | 1024       |
| time_elapsed       | 45.6       |
| total_timesteps    | 1024       |
| value_loss         | 304.5879   |
-----------------------------------
--------------------------------------
| approxkl           | 0.017109899   |
| clipfrac           | 0.2265625     |
| explained_variance | 1.19e-07      |
| fps                | 28            |
| n_updates          | 9             |
| policy_entropy     | 1.2264715     |
| policy_loss        | -0.0034885656 |
| serial_timesteps   | 1152          |
| time_elapsed       | 49.7          |
| total_timesteps    | 1152          |
| value_loss         | 274.90375     |
--------------------------------------
An average of 109.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.015632452 |
| clipfrac           | 0.234375    |
| explained_variance | 2.59e-05    |
| fps                | 29          |
| n_updates          | 10          |
| policy_entropy     | 1.2265307   |
| policy_loss        | 0.029577034 |
| serial_timesteps   | 1280        |
| time_elapsed       | 54.3        |
| total_timesteps    | 1280        |
| value_loss         | 271.42722   |
------------------------------------
-------------------------------------
| approxkl           | 0.025396122  |
| clipfrac           | 0.29882812   |
| explained_variance | 2.94e-05     |
| fps                | 29           |
| n_updates          | 11           |
| policy_entropy     | 1.2267165    |
| policy_loss        | 0.0033262607 |
| serial_timesteps   | 1408         |
| time_elapsed       | 58.5         |
| total_timesteps    | 1408         |
| value_loss         | 270.0144     |
-------------------------------------
------------------------------------
| approxkl           | 0.01578733  |
| clipfrac           | 0.22460938  |
| explained_variance | -8.94e-06   |
| fps                | 29          |
| n_updates          | 12          |
| policy_entropy     | 1.2271093   |
| policy_loss        | 0.012872657 |
| serial_timesteps   | 1536        |
| time_elapsed       | 62.8        |
| total_timesteps    | 1536        |
| value_loss         | 347.57706   |
------------------------------------
------------------------------------
| approxkl           | 0.006269073 |
| clipfrac           | 0.087890625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 1.37e-06    |
| fps                | 28          |
| n_updates          | 13          |
| policy_entropy     | 1.2270415   |
| policy_loss        | 0.02179928  |
| serial_timesteps   | 1664        |
| time_elapsed       | 67.1        |
| total_timesteps    | 1664        |
| value_loss         | 975.4988    |
------------------------------------
-------------------------------------
| approxkl           | 0.0033728743 |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | -3.58e-07    |
| fps                | 30           |
| n_updates          | 14           |
| policy_entropy     | 1.2263411    |
| policy_loss        | 0.011324793  |
| serial_timesteps   | 1792         |
| time_elapsed       | 71.6         |
| total_timesteps    | 1792         |
| value_loss         | 260.96713    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0054676887 |
| clipfrac           | 0.05078125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | 3.7e-06      |
| fps                | 28           |
| n_updates          | 15           |
| policy_entropy     | 1.2260922    |
| policy_loss        | -0.016875718 |
| serial_timesteps   | 1920         |
| time_elapsed       | 75.8         |
| total_timesteps    | 1920         |
| value_loss         | 144.84763    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0059036105 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | -2.62e-06    |
| fps                | 31           |
| n_updates          | 16           |
| policy_entropy     | 1.2254676    |
| policy_loss        | 0.0035024558 |
| serial_timesteps   | 2048         |
| time_elapsed       | 80.2         |
| total_timesteps    | 2048         |
| value_loss         | 317.06015    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023320014  |
| clipfrac           | 0.296875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | 1.97e-05     |
| fps                | 29           |
| n_updates          | 17           |
| policy_entropy     | 1.2249185    |
| policy_loss        | -0.010651881 |
| serial_timesteps   | 2176         |
| time_elapsed       | 84.3         |
| total_timesteps    | 2176         |
| value_loss         | 297.2777     |
-------------------------------------
An average of 110.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.01827181    |
| clipfrac           | 0.23242188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.26e+03      |
| explained_variance | -7.03e-06     |
| fps                | 28            |
| n_updates          | 18            |
| policy_entropy     | 1.2250876     |
| policy_loss        | -0.0070737395 |
| serial_timesteps   | 2304          |
| time_elapsed       | 88.7          |
| total_timesteps    | 2304          |
| value_loss         | 315.9862      |
--------------------------------------
-------------------------------------
| approxkl           | 0.015195874  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | -4.77e-07    |
| fps                | 28           |
| n_updates          | 19           |
| policy_entropy     | 1.225318     |
| policy_loss        | 0.0032384228 |
| serial_timesteps   | 2432         |
| time_elapsed       | 93.2         |
| total_timesteps    | 2432         |
| value_loss         | 348.21323    |
-------------------------------------
------------------------------------
| approxkl           | 0.017192699 |
| clipfrac           | 0.24414062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -5.96e-07   |
| fps                | 28          |
| n_updates          | 20          |
| policy_entropy     | 1.2260611   |
| policy_loss        | 0.019740753 |
| serial_timesteps   | 2560        |
| time_elapsed       | 97.8        |
| total_timesteps    | 2560        |
| value_loss         | 263.86075   |
------------------------------------
------------------------------------
| approxkl           | 0.023929264 |
| clipfrac           | 0.27734375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 3.1e-06     |
| fps                | 29          |
| n_updates          | 21          |
| policy_entropy     | 1.2265629   |
| policy_loss        | 0.004792258 |
| serial_timesteps   | 2688        |
| time_elapsed       | 102         |
| total_timesteps    | 2688        |
| value_loss         | 226.3117    |
------------------------------------
-------------------------------------
| approxkl           | 0.025993912  |
| clipfrac           | 0.32226562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | 1.25e-06     |
| fps                | 28           |
| n_updates          | 22           |
| policy_entropy     | 1.2269864    |
| policy_loss        | 0.0040833233 |
| serial_timesteps   | 2816         |
| time_elapsed       | 107          |
| total_timesteps    | 2816         |
| value_loss         | 308.16748    |
-------------------------------------
------------------------------------
| approxkl           | 0.019416364 |
| clipfrac           | 0.23828125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -5.96e-07   |
| fps                | 29          |
| n_updates          | 23          |
| policy_entropy     | 1.2271315   |
| policy_loss        | 0.016790034 |
| serial_timesteps   | 2944        |
| time_elapsed       | 111         |
| total_timesteps    | 2944        |
| value_loss         | 345.249     |
------------------------------------
------------------------------------
| approxkl           | 0.018481655 |
| clipfrac           | 0.24804688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -1.73e-05   |
| fps                | 29          |
| n_updates          | 24          |
| policy_entropy     | 1.2270967   |
| policy_loss        | 0.016864493 |
| serial_timesteps   | 3072        |
| time_elapsed       | 115         |
| total_timesteps    | 3072        |
| value_loss         | 295.4626    |
------------------------------------
------------------------------------
| approxkl           | 0.010390102 |
| clipfrac           | 0.14257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 0           |
| fps                | 32          |
| n_updates          | 25          |
| policy_entropy     | 1.2272397   |
| policy_loss        | 0.015678857 |
| serial_timesteps   | 3200        |
| time_elapsed       | 120         |
| total_timesteps    | 3200        |
| value_loss         | 1098.2538   |
------------------------------------
An average of 111.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.004221577  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | 4.77e-06     |
| fps                | 28           |
| n_updates          | 26           |
| policy_entropy     | 1.2270945    |
| policy_loss        | 0.0069841784 |
| serial_timesteps   | 3328         |
| time_elapsed       | 124          |
| total_timesteps    | 3328         |
| value_loss         | 235.49185    |
-------------------------------------
-------------------------------------
| approxkl           | 0.025359068  |
| clipfrac           | 0.29101562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | -1.28e-05    |
| fps                | 29           |
| n_updates          | 27           |
| policy_entropy     | 1.2268108    |
| policy_loss        | 0.0023955423 |
| serial_timesteps   | 3456         |
| time_elapsed       | 128          |
| total_timesteps    | 3456         |
| value_loss         | 267.3793     |
-------------------------------------
------------------------------------
| approxkl           | 0.018570868 |
| clipfrac           | 0.2734375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -3.93e-06   |
| fps                | 30          |
| n_updates          | 28          |
| policy_entropy     | 1.226743    |
| policy_loss        | 0.00338455  |
| serial_timesteps   | 3584        |
| time_elapsed       | 132         |
| total_timesteps    | 3584        |
| value_loss         | 243.8324    |
------------------------------------
------------------------------------
| approxkl           | 0.016737763 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 1.55e-06    |
| fps                | 31          |
| n_updates          | 29          |
| policy_entropy     | 1.2260947   |
| policy_loss        | 0.04176649  |
| serial_timesteps   | 3712        |
| time_elapsed       | 137         |
| total_timesteps    | 3712        |
| value_loss         | 267.24023   |
------------------------------------
-------------------------------------
| approxkl           | 0.027785216  |
| clipfrac           | 0.33203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.26e+03     |
| explained_variance | 1.79e-06     |
| fps                | 28           |
| n_updates          | 30           |
| policy_entropy     | 1.2253169    |
| policy_loss        | 0.0032886162 |
| serial_timesteps   | 3840         |
| time_elapsed       | 141          |
| total_timesteps    | 3840         |
| value_loss         | 208.60497    |
-------------------------------------
------------------------------------
| approxkl           | 0.019330967 |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 5.36e-07    |
| fps                | 28          |
| n_updates          | 31          |
| policy_entropy     | 1.225018    |
| policy_loss        | 0.031120794 |
| serial_timesteps   | 3968        |
| time_elapsed       | 145         |
| total_timesteps    | 3968        |
| value_loss         | 330.2017    |
------------------------------------
------------------------------------
| approxkl           | 0.0212323   |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -1.55e-06   |
| fps                | 29          |
| n_updates          | 32          |
| policy_entropy     | 1.2249866   |
| policy_loss        | 0.022350209 |
| serial_timesteps   | 4096        |
| time_elapsed       | 150         |
| total_timesteps    | 4096        |
| value_loss         | 211.74698   |
------------------------------------
------------------------------------
| approxkl           | 0.0238226   |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 1.2e-05     |
| fps                | 30          |
| n_updates          | 33          |
| policy_entropy     | 1.2246597   |
| policy_loss        | 0.009669556 |
| serial_timesteps   | 4224        |
| time_elapsed       | 154         |
| total_timesteps    | 4224        |
| value_loss         | 265.5301    |
------------------------------------
An average of 111.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.017234415 |
| clipfrac           | 0.22851562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -9.3e-06    |
| fps                | 29          |
| n_updates          | 34          |
| policy_entropy     | 1.224772    |
| policy_loss        | 0.000441066 |
| serial_timesteps   | 4352        |
| time_elapsed       | 158         |
| total_timesteps    | 4352        |
| value_loss         | 245.50578   |
------------------------------------
------------------------------------
| approxkl           | 0.016168373 |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 35          |
| policy_entropy     | 1.2249749   |
| policy_loss        | 0.016428214 |
| serial_timesteps   | 4480        |
| time_elapsed       | 163         |
| total_timesteps    | 4480        |
| value_loss         | 289.30002   |
------------------------------------
------------------------------------
| approxkl           | 0.011775436 |
| clipfrac           | 0.17382812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.26e+03    |
| explained_variance | -7.15e-06   |
| fps                | 29          |
| n_updates          | 36          |
| policy_entropy     | 1.2249006   |
| policy_loss        | 0.03089616  |
| serial_timesteps   | 4608        |
| time_elapsed       | 167         |
| total_timesteps    | 4608        |
| value_loss         | 212.45888   |
------------------------------------
------------------------------------
| approxkl           | 0.00477911  |
| clipfrac           | 0.0546875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -3.58e-07   |
| fps                | 30          |
| n_updates          | 37          |
| policy_entropy     | 1.2238269   |
| policy_loss        | 0.011363432 |
| serial_timesteps   | 4736        |
| time_elapsed       | 172         |
| total_timesteps    | 4736        |
| value_loss         | 1198.3103   |
------------------------------------
--------------------------------------
| approxkl           | 0.00343303    |
| clipfrac           | 0.021484375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | -1.31e-06     |
| fps                | 30            |
| n_updates          | 38            |
| policy_entropy     | 1.2227865     |
| policy_loss        | -0.0076158587 |
| serial_timesteps   | 4864          |
| time_elapsed       | 176           |
| total_timesteps    | 4864          |
| value_loss         | 236.4002      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0011637341  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | -1.07e-06     |
| fps                | 29            |
| n_updates          | 39            |
| policy_entropy     | 1.222403      |
| policy_loss        | -0.0038087128 |
| serial_timesteps   | 4992          |
| time_elapsed       | 180           |
| total_timesteps    | 4992          |
| value_loss         | 306.37387     |
--------------------------------------
------------------------------------
| approxkl           | 0.05105502  |
| clipfrac           | 0.45117188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -4.53e-06   |
| fps                | 30          |
| n_updates          | 40          |
| policy_entropy     | 1.2228179   |
| policy_loss        | 0.014882617 |
| serial_timesteps   | 5120        |
| time_elapsed       | 184         |
| total_timesteps    | 5120        |
| value_loss         | 287.03745   |
------------------------------------
------------------------------------
| approxkl           | 0.023775253 |
| clipfrac           | 0.31640625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | 1.61e-06    |
| fps                | 29          |
| n_updates          | 41          |
| policy_entropy     | 1.222861    |
| policy_loss        | 0.003004564 |
| serial_timesteps   | 5248        |
| time_elapsed       | 189         |
| total_timesteps    | 5248        |
| value_loss         | 198.82037   |
------------------------------------
An average of 112.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0129579175 |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -1.31e-05    |
| fps                | 29           |
| n_updates          | 42           |
| policy_entropy     | 1.2226927    |
| policy_loss        | 0.02200566   |
| serial_timesteps   | 5376         |
| time_elapsed       | 193          |
| total_timesteps    | 5376         |
| value_loss         | 188.7431     |
-------------------------------------
------------------------------------
| approxkl           | 0.023215314 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -8.46e-06   |
| fps                | 29          |
| n_updates          | 43          |
| policy_entropy     | 1.2224891   |
| policy_loss        | 0.009861847 |
| serial_timesteps   | 5504        |
| time_elapsed       | 197         |
| total_timesteps    | 5504        |
| value_loss         | 137.83228   |
------------------------------------
-------------------------------------
| approxkl           | 0.024786834  |
| clipfrac           | 0.296875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -6.56e-06    |
| fps                | 28           |
| n_updates          | 44           |
| policy_entropy     | 1.2226512    |
| policy_loss        | 0.0035115562 |
| serial_timesteps   | 5632         |
| time_elapsed       | 202          |
| total_timesteps    | 5632         |
| value_loss         | 313.87878    |
-------------------------------------
------------------------------------
| approxkl           | 0.022316746 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | 1.19e-06    |
| fps                | 29          |
| n_updates          | 45          |
| policy_entropy     | 1.2227447   |
| policy_loss        | 0.011552445 |
| serial_timesteps   | 5760        |
| time_elapsed       | 206         |
| total_timesteps    | 5760        |
| value_loss         | 236.78706   |
------------------------------------
--------------------------------------
| approxkl           | 0.031688962   |
| clipfrac           | 0.37304688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | 2.03e-06      |
| fps                | 29            |
| n_updates          | 46            |
| policy_entropy     | 1.2220814     |
| policy_loss        | 0.00075024203 |
| serial_timesteps   | 5888          |
| time_elapsed       | 210           |
| total_timesteps    | 5888          |
| value_loss         | 269.08047     |
--------------------------------------
-------------------------------------
| approxkl           | 0.026374679  |
| clipfrac           | 0.33203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -3.46e-06    |
| fps                | 29           |
| n_updates          | 47           |
| policy_entropy     | 1.221705     |
| policy_loss        | -0.021970678 |
| serial_timesteps   | 6016         |
| time_elapsed       | 215          |
| total_timesteps    | 6016         |
| value_loss         | 235.22083    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077240793 |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | 7.75e-07     |
| fps                | 28           |
| n_updates          | 48           |
| policy_entropy     | 1.2220507    |
| policy_loss        | 0.024803825  |
| serial_timesteps   | 6144         |
| time_elapsed       | 219          |
| total_timesteps    | 6144         |
| value_loss         | 142.05751    |
-------------------------------------
An average of 113.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.025020353 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -1.79e-06   |
| fps                | 28          |
| n_updates          | 49          |
| policy_entropy     | 1.2220687   |
| policy_loss        | 0.019130405 |
| serial_timesteps   | 6272        |
| time_elapsed       | 223         |
| total_timesteps    | 6272        |
| value_loss         | 1092.3273   |
------------------------------------
-------------------------------------
| approxkl           | 6.110204e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | -7.15e-07    |
| fps                | 29           |
| n_updates          | 50           |
| policy_entropy     | 1.221858     |
| policy_loss        | 0.0010638987 |
| serial_timesteps   | 6400         |
| time_elapsed       | 228          |
| total_timesteps    | 6400         |
| value_loss         | 268.32745    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00014069551 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | 9.48e-06      |
| fps                | 30            |
| n_updates          | 51            |
| policy_entropy     | 1.2216198     |
| policy_loss        | -0.0004563894 |
| serial_timesteps   | 6528          |
| time_elapsed       | 232           |
| total_timesteps    | 6528          |
| value_loss         | 244.28934     |
--------------------------------------
------------------------------------
| approxkl           | 0.016408551 |
| clipfrac           | 0.23242188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -1.31e-06   |
| fps                | 31          |
| n_updates          | 52          |
| policy_entropy     | 1.22164     |
| policy_loss        | 0.011716728 |
| serial_timesteps   | 6656        |
| time_elapsed       | 236         |
| total_timesteps    | 6656        |
| value_loss         | 206.30424   |
------------------------------------
------------------------------------
| approxkl           | 0.019529473 |
| clipfrac           | 0.26757812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -2.38e-06   |
| fps                | 28          |
| n_updates          | 53          |
| policy_entropy     | 1.2219486   |
| policy_loss        | 0.009419235 |
| serial_timesteps   | 6784        |
| time_elapsed       | 241         |
| total_timesteps    | 6784        |
| value_loss         | 320.7991    |
------------------------------------
------------------------------------
| approxkl           | 0.021529818 |
| clipfrac           | 0.31445312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -1e-05      |
| fps                | 30          |
| n_updates          | 54          |
| policy_entropy     | 1.2221949   |
| policy_loss        | 0.017722152 |
| serial_timesteps   | 6912        |
| time_elapsed       | 245         |
| total_timesteps    | 6912        |
| value_loss         | 231.68307   |
------------------------------------
--------------------------------------
| approxkl           | 0.025562031   |
| clipfrac           | 0.29882812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | -1.14e-05     |
| fps                | 30            |
| n_updates          | 55            |
| policy_entropy     | 1.221954      |
| policy_loss        | -0.0021630498 |
| serial_timesteps   | 7040          |
| time_elapsed       | 249           |
| total_timesteps    | 7040          |
| value_loss         | 275.78766     |
--------------------------------------
------------------------------------
| approxkl           | 0.013936356 |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 4.77e-07    |
| fps                | 30          |
| n_updates          | 56          |
| policy_entropy     | 1.2219002   |
| policy_loss        | 0.017951086 |
| serial_timesteps   | 7168        |
| time_elapsed       | 253         |
| total_timesteps    | 7168        |
| value_loss         | 316.2189    |
------------------------------------
An average of 113.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.020960549 |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 1.34e-05    |
| fps                | 30          |
| n_updates          | 57          |
| policy_entropy     | 1.221065    |
| policy_loss        | 0.006278349 |
| serial_timesteps   | 7296        |
| time_elapsed       | 258         |
| total_timesteps    | 7296        |
| value_loss         | 301.81784   |
------------------------------------
--------------------------------------
| approxkl           | 0.00091273943 |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | 2.5e-05       |
| fps                | 30            |
| n_updates          | 58            |
| policy_entropy     | 1.219281      |
| policy_loss        | -0.0037569883 |
| serial_timesteps   | 7424          |
| time_elapsed       | 262           |
| total_timesteps    | 7424          |
| value_loss         | 206.97197     |
--------------------------------------
--------------------------------------
| approxkl           | 0.037169646   |
| clipfrac           | 0.38476562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | -3.58e-07     |
| fps                | 29            |
| n_updates          | 59            |
| policy_entropy     | 1.2185881     |
| policy_loss        | -0.0030910478 |
| serial_timesteps   | 7552          |
| time_elapsed       | 266           |
| total_timesteps    | 7552          |
| value_loss         | 227.0224      |
--------------------------------------
-------------------------------------
| approxkl           | 0.01836963   |
| clipfrac           | 0.24414062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | 3.58e-07     |
| fps                | 30           |
| n_updates          | 60           |
| policy_entropy     | 1.2193346    |
| policy_loss        | 0.0049213497 |
| serial_timesteps   | 7680         |
| time_elapsed       | 270          |
| total_timesteps    | 7680         |
| value_loss         | 220.58803    |
-------------------------------------
------------------------------------
| approxkl           | 0.013705175 |
| clipfrac           | 0.22265625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 1.19e-07    |
| fps                | 30          |
| n_updates          | 61          |
| policy_entropy     | 1.2193815   |
| policy_loss        | 0.008007843 |
| serial_timesteps   | 7808        |
| time_elapsed       | 275         |
| total_timesteps    | 7808        |
| value_loss         | 1156.6627   |
------------------------------------
-------------------------------------
| approxkl           | 0.012182454  |
| clipfrac           | 0.18945312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | 5.13e-06     |
| fps                | 32           |
| n_updates          | 62           |
| policy_entropy     | 1.2190175    |
| policy_loss        | -0.018779544 |
| serial_timesteps   | 7936         |
| time_elapsed       | 279          |
| total_timesteps    | 7936         |
| value_loss         | 171.6239     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00013060968 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | -1.19e-06     |
| fps                | 29            |
| n_updates          | 63            |
| policy_entropy     | 1.2186569     |
| policy_loss        | 0.00023214589 |
| serial_timesteps   | 8064          |
| time_elapsed       | 283           |
| total_timesteps    | 8064          |
| value_loss         | 257.0631      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0036529345 |
| clipfrac           | 0.0390625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | 2.11e-05     |
| fps                | 28           |
| n_updates          | 64           |
| policy_entropy     | 1.2159243    |
| policy_loss        | 0.006390739  |
| serial_timesteps   | 8192         |
| time_elapsed       | 287          |
| total_timesteps    | 8192         |
| value_loss         | 200.37944    |
-------------------------------------
An average of 114.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00031775213 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | -1.72e-05     |
| fps                | 27            |
| n_updates          | 65            |
| policy_entropy     | 1.213974      |
| policy_loss        | -0.0046076863 |
| serial_timesteps   | 8320          |
| time_elapsed       | 292           |
| total_timesteps    | 8320          |
| value_loss         | 221.54987     |
--------------------------------------
------------------------------------
| approxkl           | 0.035186388 |
| clipfrac           | 0.35351562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -4.77e-07   |
| fps                | 27          |
| n_updates          | 66          |
| policy_entropy     | 1.2138436   |
| policy_loss        | 0.025054622 |
| serial_timesteps   | 8448        |
| time_elapsed       | 296         |
| total_timesteps    | 8448        |
| value_loss         | 231.7844    |
------------------------------------
------------------------------------
| approxkl           | 0.015110854 |
| clipfrac           | 0.20117188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -1.43e-06   |
| fps                | 27          |
| n_updates          | 67          |
| policy_entropy     | 1.2136883   |
| policy_loss        | 0.021688452 |
| serial_timesteps   | 8576        |
| time_elapsed       | 301         |
| total_timesteps    | 8576        |
| value_loss         | 237.32915   |
------------------------------------
-------------------------------------
| approxkl           | 0.02611498   |
| clipfrac           | 0.3359375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | 2.62e-06     |
| fps                | 31           |
| n_updates          | 68           |
| policy_entropy     | 1.21329      |
| policy_loss        | -0.011378404 |
| serial_timesteps   | 8704         |
| time_elapsed       | 306          |
| total_timesteps    | 8704         |
| value_loss         | 199.90685    |
-------------------------------------
------------------------------------
| approxkl           | 0.016710466 |
| clipfrac           | 0.21679688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -1.55e-06   |
| fps                | 31          |
| n_updates          | 69          |
| policy_entropy     | 1.2130066   |
| policy_loss        | 0.014396312 |
| serial_timesteps   | 8832        |
| time_elapsed       | 310         |
| total_timesteps    | 8832        |
| value_loss         | 287.6949    |
------------------------------------
-------------------------------------
| approxkl           | 0.0050708735 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | -3.58e-06    |
| fps                | 27           |
| n_updates          | 70           |
| policy_entropy     | 1.2130703    |
| policy_loss        | 0.017190063  |
| serial_timesteps   | 8960         |
| time_elapsed       | 314          |
| total_timesteps    | 8960         |
| value_loss         | 290.16916    |
-------------------------------------
-----------------------------------
| approxkl           | 0.02300845 |
| clipfrac           | 0.31640625 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.21e+03   |
| explained_variance | -9.78e-06  |
| fps                | 28         |
| n_updates          | 71         |
| policy_entropy     | 1.2128094  |
| policy_loss        | 0.03621729 |
| serial_timesteps   | 9088       |
| time_elapsed       | 318        |
| total_timesteps    | 9088       |
| value_loss         | 273.68173  |
-----------------------------------
------------------------------------
| approxkl           | 0.026158307 |
| clipfrac           | 0.28710938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 2.21e-06    |
| fps                | 29          |
| n_updates          | 72          |
| policy_entropy     | 1.2124349   |
| policy_loss        | 0.02005973  |
| serial_timesteps   | 9216        |
| time_elapsed       | 323         |
| total_timesteps    | 9216        |
| value_loss         | 304.09778   |
------------------------------------
An average of 115.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.001091716  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | -8.34e-07    |
| fps                | 29           |
| n_updates          | 73           |
| policy_entropy     | 1.2121105    |
| policy_loss        | 0.0014123018 |
| serial_timesteps   | 9344         |
| time_elapsed       | 327          |
| total_timesteps    | 9344         |
| value_loss         | 1255.0697    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0010772764 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | -9.3e-06     |
| fps                | 29           |
| n_updates          | 74           |
| policy_entropy     | 1.2115189    |
| policy_loss        | 0.0026742236 |
| serial_timesteps   | 9472         |
| time_elapsed       | 332          |
| total_timesteps    | 9472         |
| value_loss         | 248.4505     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0012478525  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | -6.56e-06     |
| fps                | 29            |
| n_updates          | 75            |
| policy_entropy     | 1.2112755     |
| policy_loss        | -0.0055587096 |
| serial_timesteps   | 9600          |
| time_elapsed       | 336           |
| total_timesteps    | 9600          |
| value_loss         | 157.93703     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0011154644 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | 2.98e-07     |
| fps                | 28           |
| n_updates          | 76           |
| policy_entropy     | 1.2111315    |
| policy_loss        | -0.004410449 |
| serial_timesteps   | 9728         |
| time_elapsed       | 340          |
| total_timesteps    | 9728         |
| value_loss         | 198.16745    |
-------------------------------------
------------------------------------
| approxkl           | 0.02701128  |
| clipfrac           | 0.3203125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 2.44e-06    |
| fps                | 29          |
| n_updates          | 77          |
| policy_entropy     | 1.2087599   |
| policy_loss        | 0.020830128 |
| serial_timesteps   | 9856        |
| time_elapsed       | 345         |
| total_timesteps    | 9856        |
| value_loss         | 266.44873   |
------------------------------------
------------------------------------
| approxkl           | 0.021400899 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 4.59e-06    |
| fps                | 30          |
| n_updates          | 78          |
| policy_entropy     | 1.2071365   |
| policy_loss        | 0.006894749 |
| serial_timesteps   | 9984        |
| time_elapsed       | 349         |
| total_timesteps    | 9984        |
| value_loss         | 271.4462    |
------------------------------------
------------------------------------
| approxkl           | 0.018093634 |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -7.15e-07   |
| fps                | 30          |
| n_updates          | 79          |
| policy_entropy     | 1.2063818   |
| policy_loss        | 0.018674048 |
| serial_timesteps   | 10112       |
| time_elapsed       | 353         |
| total_timesteps    | 10112       |
| value_loss         | 270.38745   |
------------------------------------
-------------------------------------
| approxkl           | 0.019922711  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.21e+03     |
| explained_variance | 1.55e-05     |
| fps                | 29           |
| n_updates          | 80           |
| policy_entropy     | 1.2062027    |
| policy_loss        | 0.0133090215 |
| serial_timesteps   | 10240        |
| time_elapsed       | 358          |
| total_timesteps    | 10240        |
| value_loss         | 144.04306    |
-------------------------------------
An average of 115.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.026471524 |
| clipfrac           | 0.33789062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -5.6e-06    |
| fps                | 29          |
| n_updates          | 81          |
| policy_entropy     | 1.2058222   |
| policy_loss        | 0.005936008 |
| serial_timesteps   | 10368       |
| time_elapsed       | 362         |
| total_timesteps    | 10368       |
| value_loss         | 180.43596   |
------------------------------------
------------------------------------
| approxkl           | 0.022666499 |
| clipfrac           | 0.28710938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | 1.43e-06    |
| fps                | 29          |
| n_updates          | 82          |
| policy_entropy     | 1.2053812   |
| policy_loss        | 0.01122242  |
| serial_timesteps   | 10496       |
| time_elapsed       | 366         |
| total_timesteps    | 10496       |
| value_loss         | 253.31992   |
------------------------------------
------------------------------------
| approxkl           | 0.010860118 |
| clipfrac           | 0.1484375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.21e+03    |
| explained_variance | -3.81e-06   |
| fps                | 29          |
| n_updates          | 83          |
| policy_entropy     | 1.2049991   |
| policy_loss        | 0.026612591 |
| serial_timesteps   | 10624       |
| time_elapsed       | 371         |
| total_timesteps    | 10624       |
| value_loss         | 187.99467   |
------------------------------------
--------------------------------------
| approxkl           | 0.02639641    |
| clipfrac           | 0.31640625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.21e+03      |
| explained_variance | -1.67e-06     |
| fps                | 29            |
| n_updates          | 84            |
| policy_entropy     | 1.2047606     |
| policy_loss        | -0.0016108407 |
| serial_timesteps   | 10752         |
| time_elapsed       | 375           |
| total_timesteps    | 10752         |
| value_loss         | 231.42136     |
--------------------------------------
---------------------------------------
| approxkl           | 0.004073249    |
| clipfrac           | 0.044921875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.22e+03       |
| explained_variance | 2.98e-07       |
| fps                | 29             |
| n_updates          | 85             |
| policy_entropy     | 1.2044042      |
| policy_loss        | -0.00042931945 |
| serial_timesteps   | 10880          |
| time_elapsed       | 379            |
| total_timesteps    | 10880          |
| value_loss         | 1221.6282      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0059313937 |
| clipfrac           | 0.08984375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.22e+03     |
| explained_variance | 2.03e-06     |
| fps                | 28           |
| n_updates          | 86           |
| policy_entropy     | 1.2039783    |
| policy_loss        | 0.008667607  |
| serial_timesteps   | 11008        |
| time_elapsed       | 384          |
| total_timesteps    | 11008        |
| value_loss         | 248.03069    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016062619 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.22e+03     |
| explained_variance | -3.58e-06    |
| fps                | 29           |
| n_updates          | 87           |
| policy_entropy     | 1.2037542    |
| policy_loss        | -0.007570641 |
| serial_timesteps   | 11136        |
| time_elapsed       | 388          |
| total_timesteps    | 11136        |
| value_loss         | 159.48868    |
-------------------------------------
------------------------------------
| approxkl           | 0.030155856 |
| clipfrac           | 0.31445312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.22e+03    |
| explained_variance | 4.17e-07    |
| fps                | 29          |
| n_updates          | 88          |
| policy_entropy     | 1.2035738   |
| policy_loss        | 0.016184293 |
| serial_timesteps   | 11264       |
| time_elapsed       | 393         |
| total_timesteps    | 11264       |
| value_loss         | 300.40726   |
------------------------------------
An average of 116.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.018434504    |
| clipfrac           | 0.22851562     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.22e+03       |
| explained_variance | -1.08e-05      |
| fps                | 30             |
| n_updates          | 89             |
| policy_entropy     | 1.203013       |
| policy_loss        | -0.00019862736 |
| serial_timesteps   | 11392          |
| time_elapsed       | 397            |
| total_timesteps    | 11392          |
| value_loss         | 186.28671      |
---------------------------------------
-------------------------------------
| approxkl           | 0.02058921   |
| clipfrac           | 0.26757812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.22e+03     |
| explained_variance | -1.51e-05    |
| fps                | 29           |
| n_updates          | 90           |
| policy_entropy     | 1.2016859    |
| policy_loss        | -0.005270604 |
| serial_timesteps   | 11520        |
| time_elapsed       | 401          |
| total_timesteps    | 11520        |
| value_loss         | 252.83414    |
-------------------------------------
------------------------------------
| approxkl           | 0.013965833 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.22e+03    |
| explained_variance | -5.36e-06   |
| fps                | 28          |
| n_updates          | 91          |
| policy_entropy     | 1.2009695   |
| policy_loss        | 0.03300064  |
| serial_timesteps   | 11648       |
| time_elapsed       | 405         |
| total_timesteps    | 11648       |
| value_loss         | 277.6049    |
------------------------------------
-------------------------------------
| approxkl           | 0.027369864  |
| clipfrac           | 0.33789062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.22e+03     |
| explained_variance | 1.19e-06     |
| fps                | 26           |
| n_updates          | 92           |
| policy_entropy     | 1.2009016    |
| policy_loss        | -0.009756205 |
| serial_timesteps   | 11776        |
| time_elapsed       | 410          |
| total_timesteps    | 11776        |
| value_loss         | 196.35764    |
-------------------------------------
------------------------------------
| approxkl           | 0.014046395 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.22e+03    |
| explained_variance | 2.98e-07    |
| fps                | 31          |
| n_updates          | 93          |
| policy_entropy     | 1.2012957   |
| policy_loss        | 0.027054004 |
| serial_timesteps   | 11904       |
| time_elapsed       | 415         |
| total_timesteps    | 11904       |
| value_loss         | 322.72937   |
------------------------------------
-------------------------------------
| approxkl           | 0.026730161  |
| clipfrac           | 0.33203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.22e+03     |
| explained_variance | 1.79e-07     |
| fps                | 29           |
| n_updates          | 94           |
| policy_entropy     | 1.2016288    |
| policy_loss        | 0.0025511202 |
| serial_timesteps   | 12032        |
| time_elapsed       | 419          |
| total_timesteps    | 12032        |
| value_loss         | 241.03212    |
-------------------------------------
-------------------------------------
| approxkl           | 0.018402474  |
| clipfrac           | 0.26171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.22e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 95           |
| policy_entropy     | 1.201549     |
| policy_loss        | 0.0035249572 |
| serial_timesteps   | 12160        |
| time_elapsed       | 423          |
| total_timesteps    | 12160        |
| value_loss         | 188.3611     |
-------------------------------------
An average of 116.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01449292  |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.22e+03    |
| explained_variance | 2.56e-06    |
| fps                | 27          |
| n_updates          | 96          |
| policy_entropy     | 1.200821    |
| policy_loss        | 0.027439557 |
| serial_timesteps   | 12288       |
| time_elapsed       | 427         |
| total_timesteps    | 12288       |
| value_loss         | 265.78992   |
------------------------------------
------------------------------------
| approxkl           | 0.013236116 |
| clipfrac           | 0.22265625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.23e+03    |
| explained_variance | -2.38e-07   |
| fps                | 28          |
| n_updates          | 97          |
| policy_entropy     | 1.2004242   |
| policy_loss        | 0.009766734 |
| serial_timesteps   | 12416       |
| time_elapsed       | 432         |
| total_timesteps    | 12416       |
| value_loss         | 1286.0854   |
------------------------------------
--------------------------------------
| approxkl           | 0.0014667925  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.23e+03      |
| explained_variance | 3.4e-06       |
| fps                | 28            |
| n_updates          | 98            |
| policy_entropy     | 1.2002168     |
| policy_loss        | -0.0021625436 |
| serial_timesteps   | 12544         |
| time_elapsed       | 436           |
| total_timesteps    | 12544         |
| value_loss         | 282.01984     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006094776  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.23e+03      |
| explained_variance | -7.39e-06     |
| fps                | 30            |
| n_updates          | 99            |
| policy_entropy     | 1.2000185     |
| policy_loss        | -0.0044435496 |
| serial_timesteps   | 12672         |
| time_elapsed       | 441           |
| total_timesteps    | 12672         |
| value_loss         | 107.41806     |
--------------------------------------
-----------------------------------
| approxkl           | 0.0236583  |
| clipfrac           | 0.30859375 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.23e+03   |
| explained_variance | -4.17e-06  |
| fps                | 29         |
| n_updates          | 100        |
| policy_entropy     | 1.1994091  |
| policy_loss        | 0.03147668 |
| serial_timesteps   | 12800      |
| time_elapsed       | 445        |
| total_timesteps    | 12800      |
| value_loss         | 281.81876  |
-----------------------------------
------------------------------------
| approxkl           | 0.028029973 |
| clipfrac           | 0.31445312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.23e+03    |
| explained_variance | -3.22e-06   |
| fps                | 27          |
| n_updates          | 101         |
| policy_entropy     | 1.1992179   |
| policy_loss        | -0.01717714 |
| serial_timesteps   | 12928       |
| time_elapsed       | 450         |
| total_timesteps    | 12928       |
| value_loss         | 223.83142   |
------------------------------------
------------------------------------
| approxkl           | 0.013731714 |
| clipfrac           | 0.20117188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.23e+03    |
| explained_variance | -7.75e-06   |
| fps                | 27          |
| n_updates          | 102         |
| policy_entropy     | 1.1996641   |
| policy_loss        | 0.029572167 |
| serial_timesteps   | 13056       |
| time_elapsed       | 454         |
| total_timesteps    | 13056       |
| value_loss         | 249.48131   |
------------------------------------
-------------------------------------
| approxkl           | 0.030737141  |
| clipfrac           | 0.34960938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.23e+03     |
| explained_variance | 1.01e-06     |
| fps                | 30           |
| n_updates          | 103          |
| policy_entropy     | 1.1997039    |
| policy_loss        | 0.0063664042 |
| serial_timesteps   | 13184        |
| time_elapsed       | 459          |
| total_timesteps    | 13184        |
| value_loss         | 231.78427    |
-------------------------------------
An average of 117.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.026051812  |
| clipfrac           | 0.31054688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.23e+03     |
| explained_variance | 4.71e-06     |
| fps                | 31           |
| n_updates          | 104          |
| policy_entropy     | 1.1998397    |
| policy_loss        | 0.0037892242 |
| serial_timesteps   | 13312        |
| time_elapsed       | 463          |
| total_timesteps    | 13312        |
| value_loss         | 236.91411    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0139107155 |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.23e+03     |
| explained_variance | 9.54e-07     |
| fps                | 30           |
| n_updates          | 105          |
| policy_entropy     | 1.2002311    |
| policy_loss        | 0.022521295  |
| serial_timesteps   | 13440        |
| time_elapsed       | 467          |
| total_timesteps    | 13440        |
| value_loss         | 244.55096    |
-------------------------------------
------------------------------------
| approxkl           | 0.020461893 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.23e+03    |
| explained_variance | -8.58e-06   |
| fps                | 29          |
| n_updates          | 106         |
| policy_entropy     | 1.2002848   |
| policy_loss        | 0.019224346 |
| serial_timesteps   | 13568       |
| time_elapsed       | 471         |
| total_timesteps    | 13568       |
| value_loss         | 209.9942    |
------------------------------------
--------------------------------------
| approxkl           | 0.025036499   |
| clipfrac           | 0.33007812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.23e+03      |
| explained_variance | 2.38e-07      |
| fps                | 28            |
| n_updates          | 107           |
| policy_entropy     | 1.1994239     |
| policy_loss        | 0.00056594494 |
| serial_timesteps   | 13696         |
| time_elapsed       | 475           |
| total_timesteps    | 13696         |
| value_loss         | 234.24533     |
--------------------------------------
------------------------------------
| approxkl           | 0.020372482 |
| clipfrac           | 0.27539062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.23e+03    |
| explained_variance | -1.19e-06   |
| fps                | 29          |
| n_updates          | 108         |
| policy_entropy     | 1.1992655   |
| policy_loss        | 0.019977301 |
| serial_timesteps   | 13824       |
| time_elapsed       | 480         |
| total_timesteps    | 13824       |
| value_loss         | 253.67209   |
------------------------------------
------------------------------------
| approxkl           | 0.036452807 |
| clipfrac           | 0.39257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -1.19e-07   |
| fps                | 28          |
| n_updates          | 109         |
| policy_entropy     | 1.1990806   |
| policy_loss        | 0.019918391 |
| serial_timesteps   | 13952       |
| time_elapsed       | 484         |
| total_timesteps    | 13952       |
| value_loss         | 1252.2163   |
------------------------------------
--------------------------------------
| approxkl           | 0.01214979    |
| clipfrac           | 0.20117188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | -3.93e-06     |
| fps                | 30            |
| n_updates          | 110           |
| policy_entropy     | 1.1985223     |
| policy_loss        | 0.00010815845 |
| serial_timesteps   | 14080         |
| time_elapsed       | 489           |
| total_timesteps    | 14080         |
| value_loss         | 188.99693     |
--------------------------------------
---------------------------------------
| approxkl           | 3.564081e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.24e+03       |
| explained_variance | 5.13e-06       |
| fps                | 28             |
| n_updates          | 111            |
| policy_entropy     | 1.1981437      |
| policy_loss        | -1.0492513e-06 |
| serial_timesteps   | 14208          |
| time_elapsed       | 493            |
| total_timesteps    | 14208          |
| value_loss         | 238.84503      |
---------------------------------------
An average of 118.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0004012622  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | -1.05e-05     |
| fps                | 29            |
| n_updates          | 112           |
| policy_entropy     | 1.1956328     |
| policy_loss        | -0.0002151907 |
| serial_timesteps   | 14336         |
| time_elapsed       | 497           |
| total_timesteps    | 14336         |
| value_loss         | 300.7124      |
--------------------------------------
--------------------------------------
| approxkl           | 0.031923186   |
| clipfrac           | 0.31054688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | -1.07e-06     |
| fps                | 29            |
| n_updates          | 113           |
| policy_entropy     | 1.1939089     |
| policy_loss        | -0.0032911208 |
| serial_timesteps   | 14464         |
| time_elapsed       | 502           |
| total_timesteps    | 14464         |
| value_loss         | 238.90253     |
--------------------------------------
-------------------------------------
| approxkl           | 0.016423471  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -2.74e-06    |
| fps                | 30           |
| n_updates          | 114          |
| policy_entropy     | 1.1938101    |
| policy_loss        | -0.004819724 |
| serial_timesteps   | 14592        |
| time_elapsed       | 506          |
| total_timesteps    | 14592        |
| value_loss         | 149.36508    |
-------------------------------------
------------------------------------
| approxkl           | 0.009423511 |
| clipfrac           | 0.14257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -2.74e-06   |
| fps                | 28          |
| n_updates          | 115         |
| policy_entropy     | 1.1936202   |
| policy_loss        | 0.027296232 |
| serial_timesteps   | 14720       |
| time_elapsed       | 510         |
| total_timesteps    | 14720       |
| value_loss         | 203.09192   |
------------------------------------
-------------------------------------
| approxkl           | 0.0268665    |
| clipfrac           | 0.28710938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -5.36e-06    |
| fps                | 28           |
| n_updates          | 116          |
| policy_entropy     | 1.1932726    |
| policy_loss        | 0.0059116744 |
| serial_timesteps   | 14848        |
| time_elapsed       | 515          |
| total_timesteps    | 14848        |
| value_loss         | 260.25052    |
-------------------------------------
-------------------------------------
| approxkl           | 0.020892609  |
| clipfrac           | 0.30664062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -2.38e-07    |
| fps                | 28           |
| n_updates          | 117          |
| policy_entropy     | 1.1933475    |
| policy_loss        | 0.0105766505 |
| serial_timesteps   | 14976        |
| time_elapsed       | 519          |
| total_timesteps    | 14976        |
| value_loss         | 173.55338    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6e47fac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6e47fac8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6a9f6438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b6a9f6438>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2374 samples, validate on 322 samples
Epoch 221/5000
 - 4s - loss: 0.0749 - val_loss: 0.0102
Epoch 222/5000
 - 1s - loss: 0.0162 - val_loss: 0.0050
Epoch 223/5000
 - 1s - loss: 0.0095 - val_loss: 0.0042
Epoch 224/5000
 - 1s - loss: 0.0068 - val_loss: 0.0043
Epoch 225/5000
 - 1s - loss: 0.0053 - val_loss: 0.0042
Epoch 226/5000
 - 1s - loss: 0.0040 - val_loss: 0.0047
Epoch 227/5000
 - 1s - loss: 0.0036 - val_loss: 0.0046
Epoch 228/5000
 - 1s - loss: 0.0036 - val_loss: 0.0046
Epoch 229/5000
 - 1s - loss: 0.0036 - val_loss: 0.0046
Epoch 230/5000
 - 1s - loss: 0.0035 - val_loss: 0.0047
Train on 1887 samples, validate on 322 samples
Epoch 174/5000
 - 4s - loss: 0.0025 - val_loss: 0.0016
Epoch 175/5000
 - 0s - loss: 0.0017 - val_loss: 0.0016
Epoch 176/5000
 - 0s - loss: 0.0015 - val_loss: 0.0017
Epoch 177/5000
 - 0s - loss: 0.0023 - val_loss: 0.0016
Epoch 178/5000
 - 0s - loss: 0.0012 - val_loss: 0.0018
Epoch 179/5000
 - 0s - loss: 0.0011 - val_loss: 0.0018
Epoch 180/5000
 - 1s - loss: 0.0011 - val_loss: 0.0018
Epoch 181/5000
 - 0s - loss: 9.9783e-04 - val_loss: 0.0018
Epoch 182/5000
 - 0s - loss: 9.8973e-04 - val_loss: 0.0018
Train on 2375 samples, validate on 322 samples
Epoch 340/5000
 - 5s - loss: 0.6467 - val_loss: 0.4894
Epoch 341/5000
 - 1s - loss: 0.5465 - val_loss: 0.3682
Epoch 342/5000
 - 1s - loss: 0.5173 - val_loss: 0.3563
Epoch 343/5000
 - 1s - loss: 0.5117 - val_loss: 0.3523
Epoch 344/5000
 - 1s - loss: 0.5085 - val_loss: 0.3500
Epoch 345/5000
 - 1s - loss: 0.5053 - val_loss: 0.3510
Epoch 346/5000
 - 1s - loss: 0.5029 - val_loss: 0.3474
Epoch 347/5000
 - 1s - loss: 0.4983 - val_loss: 0.3470
Epoch 348/5000
 - 1s - loss: 0.4935 - val_loss: 0.3471
Epoch 349/5000
 - 1s - loss: 0.4877 - val_loss: 0.3481
Epoch 350/5000
 - 1s - loss: 0.4702 - val_loss: 0.3429
Epoch 351/5000
 - 1s - loss: 0.4678 - val_loss: 0.3375
Epoch 352/5000
 - 1s - loss: 0.4659 - val_loss: 0.3332
Epoch 353/5000
 - 1s - loss: 0.4643 - val_loss: 0.3298
Epoch 354/5000
 - 1s - loss: 0.4630 - val_loss: 0.3271
Epoch 355/5000
 - 1s - loss: 0.4619 - val_loss: 0.3251
Epoch 356/5000
 - 1s - loss: 0.4609 - val_loss: 0.3235
Epoch 357/5000
 - 1s - loss: 0.4600 - val_loss: 0.3224
Epoch 358/5000
 - 1s - loss: 0.4592 - val_loss: 0.3215
Epoch 359/5000
 - 1s - loss: 0.4583 - val_loss: 0.3209
Epoch 360/5000
 - 1s - loss: 0.4576 - val_loss: 0.3205
Epoch 361/5000
 - 1s - loss: 0.4568 - val_loss: 0.3203
Epoch 362/5000
 - 1s - loss: 0.4560 - val_loss: 0.3202
Epoch 363/5000
 - 1s - loss: 0.4553 - val_loss: 0.3201
Epoch 364/5000
 - 1s - loss: 0.4545 - val_loss: 0.3202
Epoch 365/5000
 - 1s - loss: 0.4522 - val_loss: 0.3202
Epoch 366/5000
 - 1s - loss: 0.4521 - val_loss: 0.3201
Epoch 367/5000
 - 1s - loss: 0.4521 - val_loss: 0.3201
Epoch 368/5000
 - 1s - loss: 0.4520 - val_loss: 0.3201
Epoch 369/5000
 - 1s - loss: 0.4518 - val_loss: 0.3201
Epoch 370/5000
 - 1s - loss: 0.4518 - val_loss: 0.3201
Epoch 371/5000
 - 1s - loss: 0.4518 - val_loss: 0.3201
Epoch 372/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 373/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 374/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 375/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 376/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 377/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 378/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 379/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 380/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 381/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 382/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
Epoch 383/5000
 - 1s - loss: 0.4517 - val_loss: 0.3201
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.017201474 |
| clipfrac           | 0.23828125  |
| explained_variance | 9.54e-07    |
| fps                | 5           |
| n_updates          | 1           |
| policy_entropy     | 1.1930627   |
| policy_loss        | 0.02029714  |
| serial_timesteps   | 128         |
| time_elapsed       | 2.43e-05    |
| total_timesteps    | 128         |
| value_loss         | 183.58693   |
------------------------------------
--------------------------------------
| approxkl           | 0.019724641   |
| clipfrac           | 0.26171875    |
| explained_variance | -9.42e-06     |
| fps                | 28            |
| n_updates          | 2             |
| policy_entropy     | 1.1929778     |
| policy_loss        | -0.0013890122 |
| serial_timesteps   | 256           |
| time_elapsed       | 21.8          |
| total_timesteps    | 256           |
| value_loss         | 93.582306     |
--------------------------------------
An average of 119.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.019658858  |
| clipfrac           | 0.2421875    |
| explained_variance | -1.07e-06    |
| fps                | 27           |
| n_updates          | 3            |
| policy_entropy     | 1.1927075    |
| policy_loss        | 0.0033503806 |
| serial_timesteps   | 384          |
| time_elapsed       | 26.3         |
| total_timesteps    | 384          |
| value_loss         | 246.99493    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023539554  |
| clipfrac           | 0.25390625   |
| explained_variance | 1.73e-06     |
| fps                | 29           |
| n_updates          | 4            |
| policy_entropy     | 1.1922808    |
| policy_loss        | -0.011584717 |
| serial_timesteps   | 512          |
| time_elapsed       | 30.9         |
| total_timesteps    | 512          |
| value_loss         | 252.53015    |
-------------------------------------
------------------------------------
| approxkl           | 0.017207494 |
| clipfrac           | 0.265625    |
| explained_variance | 8.34e-06    |
| fps                | 27          |
| n_updates          | 5           |
| policy_entropy     | 1.1918837   |
| policy_loss        | 0.008803658 |
| serial_timesteps   | 640         |
| time_elapsed       | 35.2        |
| total_timesteps    | 640         |
| value_loss         | 286.50336   |
------------------------------------
-------------------------------------
| approxkl           | 0.029270304  |
| clipfrac           | 0.31445312   |
| explained_variance | -1.91e-06    |
| fps                | 28           |
| n_updates          | 6            |
| policy_entropy     | 1.1911287    |
| policy_loss        | -0.009491944 |
| serial_timesteps   | 768          |
| time_elapsed       | 39.9         |
| total_timesteps    | 768          |
| value_loss         | 157.55598    |
-------------------------------------
------------------------------------
| approxkl           | 0.015184497 |
| clipfrac           | 0.20898438  |
| explained_variance | -1.31e-06   |
| fps                | 31          |
| n_updates          | 7           |
| policy_entropy     | 1.190556    |
| policy_loss        | 0.018004946 |
| serial_timesteps   | 896         |
| time_elapsed       | 44.3        |
| total_timesteps    | 896         |
| value_loss         | 184.28241   |
------------------------------------
-------------------------------------
| approxkl           | 0.013765866  |
| clipfrac           | 0.20117188   |
| explained_variance | 4.41e-06     |
| fps                | 30           |
| n_updates          | 8            |
| policy_entropy     | 1.1899673    |
| policy_loss        | 0.0137717845 |
| serial_timesteps   | 1024         |
| time_elapsed       | 48.3         |
| total_timesteps    | 1024         |
| value_loss         | 245.5139     |
-------------------------------------
-------------------------------------
| approxkl           | 0.018764388  |
| clipfrac           | 0.26171875   |
| explained_variance | -1.14e-05    |
| fps                | 27           |
| n_updates          | 9            |
| policy_entropy     | 1.1892054    |
| policy_loss        | 0.0040736916 |
| serial_timesteps   | 1152         |
| time_elapsed       | 52.6         |
| total_timesteps    | 1152         |
| value_loss         | 158.27737    |
-------------------------------------
--------------------------------------
| approxkl           | 0.024266515   |
| clipfrac           | 0.30664062    |
| explained_variance | -1.43e-06     |
| fps                | 28            |
| n_updates          | 10            |
| policy_entropy     | 1.188459      |
| policy_loss        | -0.0031180005 |
| serial_timesteps   | 1280          |
| time_elapsed       | 57.2          |
| total_timesteps    | 1280          |
| value_loss         | 203.96974     |
--------------------------------------
An average of 119.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01767112  |
| clipfrac           | 0.26757812  |
| explained_variance | 8.94e-07    |
| fps                | 29          |
| n_updates          | 11          |
| policy_entropy     | 1.187311    |
| policy_loss        | 0.010732491 |
| serial_timesteps   | 1408        |
| time_elapsed       | 61.8        |
| total_timesteps    | 1408        |
| value_loss         | 230.44844   |
------------------------------------
------------------------------------
| approxkl           | 0.026738929 |
| clipfrac           | 0.265625    |
| explained_variance | -1.55e-06   |
| fps                | 30          |
| n_updates          | 12          |
| policy_entropy     | 1.1864536   |
| policy_loss        | -0.0122177  |
| serial_timesteps   | 1536        |
| time_elapsed       | 66.1        |
| total_timesteps    | 1536        |
| value_loss         | 237.77919   |
------------------------------------
---------------------------------------
| approxkl           | 0.00018827566  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.24e+03       |
| explained_variance | -2.38e-07      |
| fps                | 28             |
| n_updates          | 13             |
| policy_entropy     | 1.1865321      |
| policy_loss        | -0.00032065017 |
| serial_timesteps   | 1664           |
| time_elapsed       | 70.3           |
| total_timesteps    | 1664           |
| value_loss         | 1042.762       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0012149579  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | 1.79e-06      |
| fps                | 27            |
| n_updates          | 14            |
| policy_entropy     | 1.1864812     |
| policy_loss        | -0.0033832742 |
| serial_timesteps   | 1792          |
| time_elapsed       | 74.9          |
| total_timesteps    | 1792          |
| value_loss         | 211.45697     |
--------------------------------------
-------------------------------------
| approxkl           | 0.008346115  |
| clipfrac           | 0.12109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | 1.13e-06     |
| fps                | 26           |
| n_updates          | 15           |
| policy_entropy     | 1.184392     |
| policy_loss        | -0.009400358 |
| serial_timesteps   | 1920         |
| time_elapsed       | 79.5         |
| total_timesteps    | 1920         |
| value_loss         | 231.82663    |
-------------------------------------
--------------------------------------
| approxkl           | 9.155081e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | -7.15e-07     |
| fps                | 30            |
| n_updates          | 16            |
| policy_entropy     | 1.1825535     |
| policy_loss        | -0.0003355455 |
| serial_timesteps   | 2048          |
| time_elapsed       | 84.4          |
| total_timesteps    | 2048          |
| value_loss         | 182.20772     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00049194926 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.24e+03      |
| explained_variance | 1.43e-06      |
| fps                | 30            |
| n_updates          | 17            |
| policy_entropy     | 1.181793      |
| policy_loss        | 0.0006828726  |
| serial_timesteps   | 2176          |
| time_elapsed       | 88.5          |
| total_timesteps    | 2176          |
| value_loss         | 164.32932     |
--------------------------------------
An average of 120.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0006002347 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -3.81e-06    |
| fps                | 28           |
| n_updates          | 18           |
| policy_entropy     | 1.1821365    |
| policy_loss        | -0.003047655 |
| serial_timesteps   | 2304         |
| time_elapsed       | 92.7         |
| total_timesteps    | 2304         |
| value_loss         | 92.63191     |
-------------------------------------
------------------------------------
| approxkl           | 0.026010968 |
| clipfrac           | 0.35351562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -1.43e-06   |
| fps                | 30          |
| n_updates          | 19          |
| policy_entropy     | 1.1819268   |
| policy_loss        | 0.027227644 |
| serial_timesteps   | 2432        |
| time_elapsed       | 97.2        |
| total_timesteps    | 2432        |
| value_loss         | 217.49536   |
------------------------------------
-------------------------------------
| approxkl           | 0.03464884   |
| clipfrac           | 0.39257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -1.19e-06    |
| fps                | 30           |
| n_updates          | 20           |
| policy_entropy     | 1.1817425    |
| policy_loss        | -0.015444304 |
| serial_timesteps   | 2560         |
| time_elapsed       | 101          |
| total_timesteps    | 2560         |
| value_loss         | 196.9226     |
-------------------------------------
------------------------------------
| approxkl           | 0.014494768 |
| clipfrac           | 0.19726562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | -2.5e-06    |
| fps                | 30          |
| n_updates          | 21          |
| policy_entropy     | 1.1823205   |
| policy_loss        | 0.008689942 |
| serial_timesteps   | 2688        |
| time_elapsed       | 106         |
| total_timesteps    | 2688        |
| value_loss         | 274.60638   |
------------------------------------
-------------------------------------
| approxkl           | 0.0048065977 |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | -2.86e-06    |
| fps                | 29           |
| n_updates          | 22           |
| policy_entropy     | 1.1826684    |
| policy_loss        | -0.009680057 |
| serial_timesteps   | 2816         |
| time_elapsed       | 110          |
| total_timesteps    | 2816         |
| value_loss         | 184.3614     |
-------------------------------------
-------------------------------------
| approxkl           | 0.011405066  |
| clipfrac           | 0.18945312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.24e+03     |
| explained_variance | 1.67e-06     |
| fps                | 29           |
| n_updates          | 23           |
| policy_entropy     | 1.1829753    |
| policy_loss        | 0.0006873752 |
| serial_timesteps   | 2944         |
| time_elapsed       | 114          |
| total_timesteps    | 2944         |
| value_loss         | 274.10455    |
-------------------------------------
------------------------------------
| approxkl           | 0.015531295 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.24e+03    |
| explained_variance | 1.19e-07    |
| fps                | 30          |
| n_updates          | 24          |
| policy_entropy     | 1.1832734   |
| policy_loss        | 0.006453718 |
| serial_timesteps   | 3072        |
| time_elapsed       | 119         |
| total_timesteps    | 3072        |
| value_loss         | 178.74304   |
------------------------------------
-------------------------------------
| approxkl           | 0.0011622477 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.27e+03     |
| explained_variance | 8.94e-07     |
| fps                | 28           |
| n_updates          | 25           |
| policy_entropy     | 1.1832659    |
| policy_loss        | 0.0034673198 |
| serial_timesteps   | 3200         |
| time_elapsed       | 123          |
| total_timesteps    | 3200         |
| value_loss         | 1351.0638    |
-------------------------------------
An average of 121.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.006509269 |
| clipfrac           | 0.078125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.27e+03    |
| explained_variance | -2.38e-06   |
| fps                | 30          |
| n_updates          | 26          |
| policy_entropy     | 1.1833755   |
| policy_loss        | 0.010048087 |
| serial_timesteps   | 3328        |
| time_elapsed       | 127         |
| total_timesteps    | 3328        |
| value_loss         | 154.86873   |
------------------------------------
-------------------------------------
| approxkl           | 0.0013111451 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.27e+03     |
| explained_variance | 1.55e-06     |
| fps                | 28           |
| n_updates          | 27           |
| policy_entropy     | 1.1831757    |
| policy_loss        | -0.005696158 |
| serial_timesteps   | 3456         |
| time_elapsed       | 132          |
| total_timesteps    | 3456         |
| value_loss         | 140.94519    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0173789     |
| clipfrac           | 0.265625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.27e+03      |
| explained_variance | 1.07e-06      |
| fps                | 29            |
| n_updates          | 28            |
| policy_entropy     | 1.1816329     |
| policy_loss        | -0.0024283961 |
| serial_timesteps   | 3584          |
| time_elapsed       | 136           |
| total_timesteps    | 3584          |
| value_loss         | 168.25806     |
--------------------------------------
------------------------------------
| approxkl           | 0.018579923 |
| clipfrac           | 0.26953125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.27e+03    |
| explained_variance | 2.98e-07    |
| fps                | 29          |
| n_updates          | 29          |
| policy_entropy     | 1.1811022   |
| policy_loss        | 0.021320395 |
| serial_timesteps   | 3712        |
| time_elapsed       | 140         |
| total_timesteps    | 3712        |
| value_loss         | 246.69952   |
------------------------------------
-------------------------------------
| approxkl           | 0.030267682  |
| clipfrac           | 0.33789062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.27e+03     |
| explained_variance | -1.43e-06    |
| fps                | 30           |
| n_updates          | 30           |
| policy_entropy     | 1.180564     |
| policy_loss        | -0.009450649 |
| serial_timesteps   | 3840         |
| time_elapsed       | 145          |
| total_timesteps    | 3840         |
| value_loss         | 149.67163    |
-------------------------------------
------------------------------------
| approxkl           | 0.011474453 |
| clipfrac           | 0.17773438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.27e+03    |
| explained_variance | -3.81e-06   |
| fps                | 29          |
| n_updates          | 31          |
| policy_entropy     | 1.1798916   |
| policy_loss        | 0.032395948 |
| serial_timesteps   | 3968        |
| time_elapsed       | 149         |
| total_timesteps    | 3968        |
| value_loss         | 221.27237   |
------------------------------------
--------------------------------------
| approxkl           | 0.0005481043  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.27e+03      |
| explained_variance | -1.19e-07     |
| fps                | 29            |
| n_updates          | 32            |
| policy_entropy     | 1.1798785     |
| policy_loss        | -0.0026867478 |
| serial_timesteps   | 4096          |
| time_elapsed       | 153           |
| total_timesteps    | 4096          |
| value_loss         | 195.00139     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00043029027 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.27e+03      |
| explained_variance | 2.21e-06      |
| fps                | 28            |
| n_updates          | 33            |
| policy_entropy     | 1.1795064     |
| policy_loss        | -0.002222884  |
| serial_timesteps   | 4224          |
| time_elapsed       | 158           |
| total_timesteps    | 4224          |
| value_loss         | 121.169136    |
--------------------------------------
An average of 121.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.013370734 |
| clipfrac           | 0.19335938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.27e+03    |
| explained_variance | -3.1e-06    |
| fps                | 29          |
| n_updates          | 34          |
| policy_entropy     | 1.1783581   |
| policy_loss        | 0.022751406 |
| serial_timesteps   | 4352        |
| time_elapsed       | 162         |
| total_timesteps    | 4352        |
| value_loss         | 97.180916   |
------------------------------------
------------------------------------
| approxkl           | 0.026591597 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.27e+03    |
| explained_variance | -1.19e-06   |
| fps                | 30          |
| n_updates          | 35          |
| policy_entropy     | 1.1775259   |
| policy_loss        | 0.016471598 |
| serial_timesteps   | 4480        |
| time_elapsed       | 167         |
| total_timesteps    | 4480        |
| value_loss         | 227.81909   |
------------------------------------
------------------------------------
| approxkl           | 0.013304642 |
| clipfrac           | 0.19921875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.27e+03    |
| explained_variance | -3.93e-06   |
| fps                | 31          |
| n_updates          | 36          |
| policy_entropy     | 1.1766849   |
| policy_loss        | 0.017999977 |
| serial_timesteps   | 4608        |
| time_elapsed       | 171         |
| total_timesteps    | 4608        |
| value_loss         | 221.33194   |
------------------------------------
------------------------------------
| approxkl           | 0.007705652 |
| clipfrac           | 0.11328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | -4.77e-07   |
| fps                | 29          |
| n_updates          | 37          |
| policy_entropy     | 1.1760393   |
| policy_loss        | 0.017290363 |
| serial_timesteps   | 4736        |
| time_elapsed       | 175         |
| total_timesteps    | 4736        |
| value_loss         | 1430.2916   |
------------------------------------
-------------------------------------
| approxkl           | 0.006381147  |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.25e+03     |
| explained_variance | 2.98e-07     |
| fps                | 29           |
| n_updates          | 38           |
| policy_entropy     | 1.1761616    |
| policy_loss        | 0.0062337937 |
| serial_timesteps   | 4864         |
| time_elapsed       | 179          |
| total_timesteps    | 4864         |
| value_loss         | 198.71738    |
-------------------------------------
--------------------------------------
| approxkl           | 8.0847334e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.25e+03      |
| explained_variance | 1.55e-06      |
| fps                | 28            |
| n_updates          | 39            |
| policy_entropy     | 1.1762735     |
| policy_loss        | 7.626356e-05  |
| serial_timesteps   | 4992          |
| time_elapsed       | 184           |
| total_timesteps    | 4992          |
| value_loss         | 239.87836     |
--------------------------------------
------------------------------------
| approxkl           | 0.002321311 |
| clipfrac           | 0.01171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | 5.36e-06    |
| fps                | 29          |
| n_updates          | 40          |
| policy_entropy     | 1.1762518   |
| policy_loss        | 0.010684376 |
| serial_timesteps   | 5120        |
| time_elapsed       | 188         |
| total_timesteps    | 5120        |
| value_loss         | 149.92087   |
------------------------------------
------------------------------------
| approxkl           | 0.033475615 |
| clipfrac           | 0.35351562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | -5.72e-06   |
| fps                | 30          |
| n_updates          | 41          |
| policy_entropy     | 1.1753618   |
| policy_loss        | 0.011591662 |
| serial_timesteps   | 5248        |
| time_elapsed       | 193         |
| total_timesteps    | 5248        |
| value_loss         | 263.01917   |
------------------------------------
An average of 122.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.02711821    |
| clipfrac           | 0.31054688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.25e+03      |
| explained_variance | -4.77e-07     |
| fps                | 27            |
| n_updates          | 42            |
| policy_entropy     | 1.1747772     |
| policy_loss        | -0.0091567235 |
| serial_timesteps   | 5376          |
| time_elapsed       | 197           |
| total_timesteps    | 5376          |
| value_loss         | 198.25972     |
--------------------------------------
-------------------------------------
| approxkl           | 0.027061893  |
| clipfrac           | 0.31640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.25e+03     |
| explained_variance | -4.77e-07    |
| fps                | 29           |
| n_updates          | 43           |
| policy_entropy     | 1.1746445    |
| policy_loss        | -0.006555935 |
| serial_timesteps   | 5504         |
| time_elapsed       | 201          |
| total_timesteps    | 5504         |
| value_loss         | 194.37248    |
-------------------------------------
------------------------------------
| approxkl           | 0.022654967 |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | 1.19e-07    |
| fps                | 28          |
| n_updates          | 44          |
| policy_entropy     | 1.1750603   |
| policy_loss        | 0.018220618 |
| serial_timesteps   | 5632        |
| time_elapsed       | 206         |
| total_timesteps    | 5632        |
| value_loss         | 187.2818    |
------------------------------------
------------------------------------
| approxkl           | 0.017123608 |
| clipfrac           | 0.2578125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | -2.38e-06   |
| fps                | 30          |
| n_updates          | 45          |
| policy_entropy     | 1.1748203   |
| policy_loss        | 0.027272264 |
| serial_timesteps   | 5760        |
| time_elapsed       | 210         |
| total_timesteps    | 5760        |
| value_loss         | 254.19086   |
------------------------------------
--------------------------------------
| approxkl           | 0.029748406   |
| clipfrac           | 0.3671875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.25e+03      |
| explained_variance | 2.56e-06      |
| fps                | 30            |
| n_updates          | 46            |
| policy_entropy     | 1.1744431     |
| policy_loss        | -0.0014269035 |
| serial_timesteps   | 5888          |
| time_elapsed       | 214           |
| total_timesteps    | 5888          |
| value_loss         | 213.48155     |
--------------------------------------
------------------------------------
| approxkl           | 0.016738962 |
| clipfrac           | 0.25        |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | -2.5e-06    |
| fps                | 28          |
| n_updates          | 47          |
| policy_entropy     | 1.1746413   |
| policy_loss        | 0.033198684 |
| serial_timesteps   | 6016        |
| time_elapsed       | 218         |
| total_timesteps    | 6016        |
| value_loss         | 197.99066   |
------------------------------------
------------------------------------
| approxkl           | 0.026082618 |
| clipfrac           | 0.32226562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.25e+03    |
| explained_variance | -5.96e-07   |
| fps                | 28          |
| n_updates          | 48          |
| policy_entropy     | 1.1745317   |
| policy_loss        | 0.024434004 |
| serial_timesteps   | 6144        |
| time_elapsed       | 223         |
| total_timesteps    | 6144        |
| value_loss         | 173.26514   |
------------------------------------
------------------------------------
| approxkl           | 0.01746866  |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | -5.96e-07   |
| fps                | 28          |
| n_updates          | 49          |
| policy_entropy     | 1.1740179   |
| policy_loss        | 0.018882854 |
| serial_timesteps   | 6272        |
| time_elapsed       | 227         |
| total_timesteps    | 6272        |
| value_loss         | 1411.326    |
------------------------------------
An average of 123.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.002779975 |
| clipfrac           | 0.015625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | -4.77e-07   |
| fps                | 30          |
| n_updates          | 50          |
| policy_entropy     | 1.1734766   |
| policy_loss        | 0.004756226 |
| serial_timesteps   | 6400        |
| time_elapsed       | 232         |
| total_timesteps    | 6400        |
| value_loss         | 152.2206    |
------------------------------------
--------------------------------------
| approxkl           | 0.0013704662  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.29e+03      |
| explained_variance | 5.72e-06      |
| fps                | 29            |
| n_updates          | 51            |
| policy_entropy     | 1.1732109     |
| policy_loss        | -0.0048417132 |
| serial_timesteps   | 6528          |
| time_elapsed       | 236           |
| total_timesteps    | 6528          |
| value_loss         | 182.25577     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00025538058 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.29e+03      |
| explained_variance | -7.15e-07     |
| fps                | 30            |
| n_updates          | 52            |
| policy_entropy     | 1.1730373     |
| policy_loss        | 0.0010130054  |
| serial_timesteps   | 6656          |
| time_elapsed       | 240           |
| total_timesteps    | 6656          |
| value_loss         | 253.19458     |
--------------------------------------
------------------------------------
| approxkl           | 0.017277004 |
| clipfrac           | 0.25        |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | -7.15e-06   |
| fps                | 29          |
| n_updates          | 53          |
| policy_entropy     | 1.1733286   |
| policy_loss        | 0.031634055 |
| serial_timesteps   | 6784        |
| time_elapsed       | 245         |
| total_timesteps    | 6784        |
| value_loss         | 219.68185   |
------------------------------------
------------------------------------
| approxkl           | 0.02954871  |
| clipfrac           | 0.36132812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | -2.38e-07   |
| fps                | 28          |
| n_updates          | 54          |
| policy_entropy     | 1.1733949   |
| policy_loss        | 0.023443496 |
| serial_timesteps   | 6912        |
| time_elapsed       | 249         |
| total_timesteps    | 6912        |
| value_loss         | 179.87332   |
------------------------------------
------------------------------------
| approxkl           | 0.020784374 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | 7.99e-06    |
| fps                | 28          |
| n_updates          | 55          |
| policy_entropy     | 1.1730672   |
| policy_loss        | 0.017142076 |
| serial_timesteps   | 7040        |
| time_elapsed       | 253         |
| total_timesteps    | 7040        |
| value_loss         | 188.65169   |
------------------------------------
-------------------------------------
| approxkl           | 0.025361061  |
| clipfrac           | 0.33398438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.29e+03     |
| explained_variance | 1.76e-05     |
| fps                | 29           |
| n_updates          | 56           |
| policy_entropy     | 1.1731137    |
| policy_loss        | -0.009513314 |
| serial_timesteps   | 7168         |
| time_elapsed       | 258          |
| total_timesteps    | 7168         |
| value_loss         | 121.82114    |
-------------------------------------
An average of 123.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0063378667  |
| clipfrac           | 0.0859375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.29e+03      |
| explained_variance | -1.31e-06     |
| fps                | 29            |
| n_updates          | 57            |
| policy_entropy     | 1.1728284     |
| policy_loss        | 0.00017580506 |
| serial_timesteps   | 7296          |
| time_elapsed       | 262           |
| total_timesteps    | 7296          |
| value_loss         | 239.90019     |
--------------------------------------
------------------------------------
| approxkl           | 0.018368645 |
| clipfrac           | 0.25976562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | -2.38e-07   |
| fps                | 29          |
| n_updates          | 58          |
| policy_entropy     | 1.1719182   |
| policy_loss        | 0.032004036 |
| serial_timesteps   | 7424        |
| time_elapsed       | 267         |
| total_timesteps    | 7424        |
| value_loss         | 198.86736   |
------------------------------------
------------------------------------
| approxkl           | 0.037819978 |
| clipfrac           | 0.421875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | -1.07e-06   |
| fps                | 28          |
| n_updates          | 59          |
| policy_entropy     | 1.1710443   |
| policy_loss        | 0.032416675 |
| serial_timesteps   | 7552        |
| time_elapsed       | 271         |
| total_timesteps    | 7552        |
| value_loss         | 158.80392   |
------------------------------------
------------------------------------
| approxkl           | 0.025082557 |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.29e+03    |
| explained_variance | 2.03e-06    |
| fps                | 30          |
| n_updates          | 60          |
| policy_entropy     | 1.1706486   |
| policy_loss        | 0.01518978  |
| serial_timesteps   | 7680        |
| time_elapsed       | 275         |
| total_timesteps    | 7680        |
| value_loss         | 246.3523    |
------------------------------------
--------------------------------------
| approxkl           | 0.02453921    |
| clipfrac           | 0.31054688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.3e+03       |
| explained_variance | 4.17e-07      |
| fps                | 27            |
| n_updates          | 61            |
| policy_entropy     | 1.170786      |
| policy_loss        | -0.0029664726 |
| serial_timesteps   | 7808          |
| time_elapsed       | 280           |
| total_timesteps    | 7808          |
| value_loss         | 1538.7983     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00044453857 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.3e+03       |
| explained_variance | -5.96e-07     |
| fps                | 29            |
| n_updates          | 62            |
| policy_entropy     | 1.170754      |
| policy_loss        | 0.0025290307  |
| serial_timesteps   | 7936          |
| time_elapsed       | 284           |
| total_timesteps    | 7936          |
| value_loss         | 311.24725     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0007987929  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.3e+03       |
| explained_variance | -5.01e-06     |
| fps                | 31            |
| n_updates          | 63            |
| policy_entropy     | 1.1704452     |
| policy_loss        | -0.0025041073 |
| serial_timesteps   | 8064          |
| time_elapsed       | 289           |
| total_timesteps    | 8064          |
| value_loss         | 162.99683     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0007679365  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.3e+03       |
| explained_variance | -8.34e-07     |
| fps                | 29            |
| n_updates          | 64            |
| policy_entropy     | 1.1695973     |
| policy_loss        | -0.0013365971 |
| serial_timesteps   | 8192          |
| time_elapsed       | 293           |
| total_timesteps    | 8192          |
| value_loss         | 140.42761     |
--------------------------------------
An average of 124.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 4.08103e-05    |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.3e+03        |
| explained_variance | -5.96e-07      |
| fps                | 28             |
| n_updates          | 65             |
| policy_entropy     | 1.1685699      |
| policy_loss        | -0.00041515531 |
| serial_timesteps   | 8320           |
| time_elapsed       | 297            |
| total_timesteps    | 8320           |
| value_loss         | 116.72762      |
---------------------------------------
------------------------------------
| approxkl           | 0.019131763 |
| clipfrac           | 0.265625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.3e+03     |
| explained_variance | -2.86e-06   |
| fps                | 29          |
| n_updates          | 66          |
| policy_entropy     | 1.1675941   |
| policy_loss        | 0.025238313 |
| serial_timesteps   | 8448        |
| time_elapsed       | 302         |
| total_timesteps    | 8448        |
| value_loss         | 154.78035   |
------------------------------------
--------------------------------------
| approxkl           | 0.026520548   |
| clipfrac           | 0.32226562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.3e+03       |
| explained_variance | -1.67e-06     |
| fps                | 28            |
| n_updates          | 67            |
| policy_entropy     | 1.1674501     |
| policy_loss        | -0.0042445743 |
| serial_timesteps   | 8576          |
| time_elapsed       | 306           |
| total_timesteps    | 8576          |
| value_loss         | 244.139       |
--------------------------------------
------------------------------------
| approxkl           | 0.018572249 |
| clipfrac           | 0.265625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.3e+03     |
| explained_variance | 1.19e-07    |
| fps                | 29          |
| n_updates          | 68          |
| policy_entropy     | 1.1672417   |
| policy_loss        | 0.01639727  |
| serial_timesteps   | 8704        |
| time_elapsed       | 311         |
| total_timesteps    | 8704        |
| value_loss         | 238.80266   |
------------------------------------
------------------------------------
| approxkl           | 0.028878052 |
| clipfrac           | 0.33984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.3e+03     |
| explained_variance | -6.56e-06   |
| fps                | 29          |
| n_updates          | 69          |
| policy_entropy     | 1.1676451   |
| policy_loss        | 0.012455409 |
| serial_timesteps   | 8832        |
| time_elapsed       | 315         |
| total_timesteps    | 8832        |
| value_loss         | 157.66661   |
------------------------------------
------------------------------------
| approxkl           | 0.023904337 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.3e+03     |
| explained_variance | 2.5e-06     |
| fps                | 28          |
| n_updates          | 70          |
| policy_entropy     | 1.1671859   |
| policy_loss        | 0.035313196 |
| serial_timesteps   | 8960        |
| time_elapsed       | 319         |
| total_timesteps    | 8960        |
| value_loss         | 161.24193   |
------------------------------------
------------------------------------
| approxkl           | 0.022714674 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.3e+03     |
| explained_variance | -2.26e-06   |
| fps                | 30          |
| n_updates          | 71          |
| policy_entropy     | 1.166374    |
| policy_loss        | 0.02400639  |
| serial_timesteps   | 9088        |
| time_elapsed       | 324         |
| total_timesteps    | 9088        |
| value_loss         | 190.03154   |
------------------------------------
------------------------------------
| approxkl           | 0.017471096 |
| clipfrac           | 0.25390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.3e+03     |
| explained_variance | -1.07e-05   |
| fps                | 27          |
| n_updates          | 72          |
| policy_entropy     | 1.1658412   |
| policy_loss        | 0.026719913 |
| serial_timesteps   | 9216        |
| time_elapsed       | 328         |
| total_timesteps    | 9216        |
| value_loss         | 198.89763   |
------------------------------------
An average of 125.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.029114943 |
| clipfrac           | 0.32226562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | 5.96e-08    |
| fps                | 29          |
| n_updates          | 73          |
| policy_entropy     | 1.165874    |
| policy_loss        | 0.020994678 |
| serial_timesteps   | 9344        |
| time_elapsed       | 333         |
| total_timesteps    | 9344        |
| value_loss         | 1486.4183   |
------------------------------------
------------------------------------
| approxkl           | 0.00996783  |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | 6.56e-07    |
| fps                | 30          |
| n_updates          | 74          |
| policy_entropy     | 1.1663677   |
| policy_loss        | 0.010957686 |
| serial_timesteps   | 9472        |
| time_elapsed       | 337         |
| total_timesteps    | 9472        |
| value_loss         | 227.66652   |
------------------------------------
--------------------------------------
| approxkl           | 0.0006794747  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.31e+03      |
| explained_variance | 3.4e-06       |
| fps                | 30            |
| n_updates          | 75            |
| policy_entropy     | 1.1662675     |
| policy_loss        | -0.0044705067 |
| serial_timesteps   | 9600          |
| time_elapsed       | 341           |
| total_timesteps    | 9600          |
| value_loss         | 206.4348      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00092904764 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.31e+03      |
| explained_variance | 4.23e-06      |
| fps                | 28            |
| n_updates          | 76            |
| policy_entropy     | 1.1663677     |
| policy_loss        | -0.005229122  |
| serial_timesteps   | 9728          |
| time_elapsed       | 346           |
| total_timesteps    | 9728          |
| value_loss         | 183.69437     |
--------------------------------------
------------------------------------
| approxkl           | 0.03603834  |
| clipfrac           | 0.36523438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | -9.54e-07   |
| fps                | 29          |
| n_updates          | 77          |
| policy_entropy     | 1.1655341   |
| policy_loss        | 0.009681227 |
| serial_timesteps   | 9856        |
| time_elapsed       | 350         |
| total_timesteps    | 9856        |
| value_loss         | 223.26048   |
------------------------------------
--------------------------------------
| approxkl           | 0.024196591   |
| clipfrac           | 0.31445312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.31e+03      |
| explained_variance | -2.74e-06     |
| fps                | 33            |
| n_updates          | 78            |
| policy_entropy     | 1.1652267     |
| policy_loss        | -0.0035379708 |
| serial_timesteps   | 9984          |
| time_elapsed       | 354           |
| total_timesteps    | 9984          |
| value_loss         | 201.77986     |
--------------------------------------
------------------------------------
| approxkl           | 0.019701954 |
| clipfrac           | 0.25585938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | -1.19e-06   |
| fps                | 29          |
| n_updates          | 79          |
| policy_entropy     | 1.165908    |
| policy_loss        | 0.021950116 |
| serial_timesteps   | 10112       |
| time_elapsed       | 358         |
| total_timesteps    | 10112       |
| value_loss         | 205.35516   |
------------------------------------
-------------------------------------
| approxkl           | 0.025397995  |
| clipfrac           | 0.3125       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.31e+03     |
| explained_variance | 5.96e-07     |
| fps                | 28           |
| n_updates          | 80           |
| policy_entropy     | 1.1666332    |
| policy_loss        | 0.0051535247 |
| serial_timesteps   | 10240        |
| time_elapsed       | 363          |
| total_timesteps    | 10240        |
| value_loss         | 150.30856    |
-------------------------------------
An average of 125.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.009802301 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | -8.58e-06   |
| fps                | 28          |
| n_updates          | 81          |
| policy_entropy     | 1.1663905   |
| policy_loss        | 0.016805649 |
| serial_timesteps   | 10368       |
| time_elapsed       | 367         |
| total_timesteps    | 10368       |
| value_loss         | 50.311844   |
------------------------------------
-------------------------------------
| approxkl           | 0.028354548  |
| clipfrac           | 0.3125       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.31e+03     |
| explained_variance | -8.34e-07    |
| fps                | 30           |
| n_updates          | 82           |
| policy_entropy     | 1.1666423    |
| policy_loss        | 0.0036394657 |
| serial_timesteps   | 10496        |
| time_elapsed       | 372          |
| total_timesteps    | 10496        |
| value_loss         | 210.21211    |
-------------------------------------
------------------------------------
| approxkl           | 0.028226638 |
| clipfrac           | 0.35742188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | 1.85e-06    |
| fps                | 30          |
| n_updates          | 83          |
| policy_entropy     | 1.1665807   |
| policy_loss        | 0.006662271 |
| serial_timesteps   | 10624       |
| time_elapsed       | 376         |
| total_timesteps    | 10624       |
| value_loss         | 217.13635   |
------------------------------------
------------------------------------
| approxkl           | 0.018521663 |
| clipfrac           | 0.2578125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.31e+03    |
| explained_variance | 2.86e-06    |
| fps                | 29          |
| n_updates          | 84          |
| policy_entropy     | 1.1660187   |
| policy_loss        | 0.03539603  |
| serial_timesteps   | 10752       |
| time_elapsed       | 380         |
| total_timesteps    | 10752       |
| value_loss         | 204.21089   |
------------------------------------
------------------------------------
| approxkl           | 0.025974032 |
| clipfrac           | 0.32226562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | 1.79e-07    |
| fps                | 28          |
| n_updates          | 85          |
| policy_entropy     | 1.1652386   |
| policy_loss        | 0.015286118 |
| serial_timesteps   | 10880       |
| time_elapsed       | 384         |
| total_timesteps    | 10880       |
| value_loss         | 1542.08     |
------------------------------------
--------------------------------------
| approxkl           | 0.00051271956 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.32e+03      |
| explained_variance | -7.15e-07     |
| fps                | 26            |
| n_updates          | 86            |
| policy_entropy     | 1.1650099     |
| policy_loss        | 0.0012000615  |
| serial_timesteps   | 11008         |
| time_elapsed       | 389           |
| total_timesteps    | 11008         |
| value_loss         | 196.88089     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0006212308  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.32e+03      |
| explained_variance | -4.89e-06     |
| fps                | 28            |
| n_updates          | 87            |
| policy_entropy     | 1.1646427     |
| policy_loss        | -0.0027797963 |
| serial_timesteps   | 11136         |
| time_elapsed       | 394           |
| total_timesteps    | 11136         |
| value_loss         | 136.94485     |
--------------------------------------
------------------------------------
| approxkl           | 0.022231579 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -7.51e-06   |
| fps                | 29          |
| n_updates          | 88          |
| policy_entropy     | 1.1625972   |
| policy_loss        | 0.007314317 |
| serial_timesteps   | 11264       |
| time_elapsed       | 398         |
| total_timesteps    | 11264       |
| value_loss         | 202.09497   |
------------------------------------
An average of 126.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01834541  |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -1.07e-06   |
| fps                | 27          |
| n_updates          | 89          |
| policy_entropy     | 1.1615516   |
| policy_loss        | 0.021059398 |
| serial_timesteps   | 11392       |
| time_elapsed       | 402         |
| total_timesteps    | 11392       |
| value_loss         | 146.8192    |
------------------------------------
------------------------------------
| approxkl           | 0.020469867 |
| clipfrac           | 0.24414062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -1.19e-07   |
| fps                | 27          |
| n_updates          | 90          |
| policy_entropy     | 1.1615534   |
| policy_loss        | 0.040814634 |
| serial_timesteps   | 11520       |
| time_elapsed       | 407         |
| total_timesteps    | 11520       |
| value_loss         | 144.48833   |
------------------------------------
------------------------------------
| approxkl           | 0.040143393 |
| clipfrac           | 0.41015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -7.15e-07   |
| fps                | 27          |
| n_updates          | 91          |
| policy_entropy     | 1.1612139   |
| policy_loss        | 0.025735302 |
| serial_timesteps   | 11648       |
| time_elapsed       | 412         |
| total_timesteps    | 11648       |
| value_loss         | 154.95853   |
------------------------------------
------------------------------------
| approxkl           | 0.025131065 |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -3.58e-07   |
| fps                | 28          |
| n_updates          | 92          |
| policy_entropy     | 1.160595    |
| policy_loss        | 0.029839747 |
| serial_timesteps   | 11776       |
| time_elapsed       | 416         |
| total_timesteps    | 11776       |
| value_loss         | 162.20793   |
------------------------------------
------------------------------------
| approxkl           | 0.028568285 |
| clipfrac           | 0.33203125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | 5.19e-06    |
| fps                | 27          |
| n_updates          | 93          |
| policy_entropy     | 1.1601722   |
| policy_loss        | 0.017551856 |
| serial_timesteps   | 11904       |
| time_elapsed       | 421         |
| total_timesteps    | 11904       |
| value_loss         | 217.27873   |
------------------------------------
------------------------------------
| approxkl           | 0.026330203 |
| clipfrac           | 0.33203125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | 7.75e-07    |
| fps                | 30          |
| n_updates          | 94          |
| policy_entropy     | 1.1595837   |
| policy_loss        | 0.005275828 |
| serial_timesteps   | 12032       |
| time_elapsed       | 426         |
| total_timesteps    | 12032       |
| value_loss         | 187.21869   |
------------------------------------
------------------------------------
| approxkl           | 0.025332978 |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -1.07e-06   |
| fps                | 31          |
| n_updates          | 95          |
| policy_entropy     | 1.1593373   |
| policy_loss        | 0.007559762 |
| serial_timesteps   | 12160       |
| time_elapsed       | 430         |
| total_timesteps    | 12160       |
| value_loss         | 122.71774   |
------------------------------------
------------------------------------
| approxkl           | 0.01850106  |
| clipfrac           | 0.25976562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | 1.19e-06    |
| fps                | 28          |
| n_updates          | 96          |
| policy_entropy     | 1.1593809   |
| policy_loss        | 0.023553276 |
| serial_timesteps   | 12288       |
| time_elapsed       | 434         |
| total_timesteps    | 12288       |
| value_loss         | 134.1638    |
------------------------------------
An average of 126.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.015843915 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | 2.38e-07    |
| fps                | 28          |
| n_updates          | 97          |
| policy_entropy     | 1.1591021   |
| policy_loss        | 0.008474363 |
| serial_timesteps   | 12416       |
| time_elapsed       | 438         |
| total_timesteps    | 12416       |
| value_loss         | 1627.5698   |
------------------------------------
-------------------------------------
| approxkl           | 0.001563636  |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.32e+03     |
| explained_variance | -2.98e-06    |
| fps                | 27           |
| n_updates          | 98           |
| policy_entropy     | 1.1587951    |
| policy_loss        | -0.009117408 |
| serial_timesteps   | 12544        |
| time_elapsed       | 443          |
| total_timesteps    | 12544        |
| value_loss         | 151.76079    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0020884366   |
| clipfrac           | 0.0078125      |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.32e+03       |
| explained_variance | 1.79e-07       |
| fps                | 30             |
| n_updates          | 99             |
| policy_entropy     | 1.1585041      |
| policy_loss        | -0.00040538504 |
| serial_timesteps   | 12672          |
| time_elapsed       | 447            |
| total_timesteps    | 12672          |
| value_loss         | 201.23747      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00013295257 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.32e+03      |
| explained_variance | -2.03e-06     |
| fps                | 30            |
| n_updates          | 100           |
| policy_entropy     | 1.1580942     |
| policy_loss        | 0.0001748309  |
| serial_timesteps   | 12800         |
| time_elapsed       | 452           |
| total_timesteps    | 12800         |
| value_loss         | 235.82503     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0002101679  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.32e+03      |
| explained_variance | -2.38e-06     |
| fps                | 29            |
| n_updates          | 101           |
| policy_entropy     | 1.1578665     |
| policy_loss        | -8.747168e-05 |
| serial_timesteps   | 12928         |
| time_elapsed       | 456           |
| total_timesteps    | 12928         |
| value_loss         | 182.08104     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0003631154  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.32e+03      |
| explained_variance | 6.56e-07      |
| fps                | 29            |
| n_updates          | 102           |
| policy_entropy     | 1.1571944     |
| policy_loss        | -0.0016999927 |
| serial_timesteps   | 13056         |
| time_elapsed       | 460           |
| total_timesteps    | 13056         |
| value_loss         | 180.93416     |
--------------------------------------
------------------------------------
| approxkl           | 0.004855116 |
| clipfrac           | 0.05078125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -8.34e-07   |
| fps                | 28          |
| n_updates          | 103         |
| policy_entropy     | 1.1548272   |
| policy_loss        | 0.004841432 |
| serial_timesteps   | 13184       |
| time_elapsed       | 464         |
| total_timesteps    | 13184       |
| value_loss         | 120.93975   |
------------------------------------
An average of 127.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.027205769  |
| clipfrac           | 0.33789062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.32e+03     |
| explained_variance | -6.68e-06    |
| fps                | 28           |
| n_updates          | 104          |
| policy_entropy     | 1.1529491    |
| policy_loss        | 0.0009937444 |
| serial_timesteps   | 13312        |
| time_elapsed       | 469          |
| total_timesteps    | 13312        |
| value_loss         | 186.1876     |
-------------------------------------
------------------------------------
| approxkl           | 0.023123497 |
| clipfrac           | 0.31640625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -1.79e-06   |
| fps                | 30          |
| n_updates          | 105         |
| policy_entropy     | 1.1523299   |
| policy_loss        | 0.00612945  |
| serial_timesteps   | 13440       |
| time_elapsed       | 473         |
| total_timesteps    | 13440       |
| value_loss         | 140.12958   |
------------------------------------
------------------------------------
| approxkl           | 0.031080125 |
| clipfrac           | 0.359375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | -4.77e-07   |
| fps                | 29          |
| n_updates          | 106         |
| policy_entropy     | 1.1513143   |
| policy_loss        | 0.020671023 |
| serial_timesteps   | 13568       |
| time_elapsed       | 478         |
| total_timesteps    | 13568       |
| value_loss         | 164.19864   |
------------------------------------
--------------------------------------
| approxkl           | 0.030499961   |
| clipfrac           | 0.3359375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.32e+03      |
| explained_variance | -2.38e-07     |
| fps                | 27            |
| n_updates          | 107           |
| policy_entropy     | 1.1508994     |
| policy_loss        | -0.0030972199 |
| serial_timesteps   | 13696         |
| time_elapsed       | 482           |
| total_timesteps    | 13696         |
| value_loss         | 180.73169     |
--------------------------------------
------------------------------------
| approxkl           | 0.023374047 |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.32e+03    |
| explained_variance | 4.17e-07    |
| fps                | 26          |
| n_updates          | 108         |
| policy_entropy     | 1.1506568   |
| policy_loss        | 0.020077573 |
| serial_timesteps   | 13824       |
| time_elapsed       | 487         |
| total_timesteps    | 13824       |
| value_loss         | 203.92221   |
------------------------------------
-------------------------------------
| approxkl           | 0.014467627  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.33e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 109          |
| policy_entropy     | 1.1513699    |
| policy_loss        | -0.007822847 |
| serial_timesteps   | 13952        |
| time_elapsed       | 491          |
| total_timesteps    | 13952        |
| value_loss         | 1658.3285    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00013175502 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.33e+03      |
| explained_variance | -1.79e-06     |
| fps                | 29            |
| n_updates          | 110           |
| policy_entropy     | 1.1519963     |
| policy_loss        | 0.001457016   |
| serial_timesteps   | 14080         |
| time_elapsed       | 496           |
| total_timesteps    | 14080         |
| value_loss         | 228.5499      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0001262365  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.33e+03      |
| explained_variance | -1.55e-06     |
| fps                | 29            |
| n_updates          | 111           |
| policy_entropy     | 1.152031      |
| policy_loss        | -0.0001518894 |
| serial_timesteps   | 14208         |
| time_elapsed       | 500           |
| total_timesteps    | 14208         |
| value_loss         | 235.22523     |
--------------------------------------
An average of 128.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 7.031328e-05 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.33e+03     |
| explained_variance | 2.68e-06     |
| fps                | 28           |
| n_updates          | 112          |
| policy_entropy     | 1.1521759    |
| policy_loss        | 0.0011818698 |
| serial_timesteps   | 14336        |
| time_elapsed       | 504          |
| total_timesteps    | 14336        |
| value_loss         | 102.81437    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0053817583 |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.33e+03     |
| explained_variance | -3.34e-06    |
| fps                | 31           |
| n_updates          | 113          |
| policy_entropy     | 1.1514889    |
| policy_loss        | -0.015156487 |
| serial_timesteps   | 14464        |
| time_elapsed       | 509          |
| total_timesteps    | 14464        |
| value_loss         | 58.812374    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0015388605 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.33e+03     |
| explained_variance | -8.34e-07    |
| fps                | 27           |
| n_updates          | 114          |
| policy_entropy     | 1.1507576    |
| policy_loss        | 0.0044825035 |
| serial_timesteps   | 14592        |
| time_elapsed       | 513          |
| total_timesteps    | 14592        |
| value_loss         | 151.64473    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006830876  |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.33e+03     |
| explained_variance | 1.79e-07     |
| fps                | 30           |
| n_updates          | 115          |
| policy_entropy     | 1.149524     |
| policy_loss        | 0.0087605985 |
| serial_timesteps   | 14720        |
| time_elapsed       | 517          |
| total_timesteps    | 14720        |
| value_loss         | 205.87236    |
-------------------------------------
------------------------------------
| approxkl           | 0.04460337  |
| clipfrac           | 0.45507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.33e+03    |
| explained_variance | -7.15e-07   |
| fps                | 28          |
| n_updates          | 116         |
| policy_entropy     | 1.146847    |
| policy_loss        | 0.046808094 |
| serial_timesteps   | 14848       |
| time_elapsed       | 522         |
| total_timesteps    | 14848       |
| value_loss         | 195.88983   |
------------------------------------
------------------------------------
| approxkl           | 0.03553212  |
| clipfrac           | 0.39453125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.33e+03    |
| explained_variance | -1.19e-07   |
| fps                | 30          |
| n_updates          | 117         |
| policy_entropy     | 1.1451157   |
| policy_loss        | -0.00856226 |
| serial_timesteps   | 14976       |
| time_elapsed       | 526         |
| total_timesteps    | 14976       |
| value_loss         | 93.98726    |
------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b67ed6b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b67ed6b38>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b66bb0320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b66bb0320>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2388 samples, validate on 335 samples
Epoch 231/5000
 - 4s - loss: 0.3911 - val_loss: 0.3196
Epoch 232/5000
 - 0s - loss: 0.3911 - val_loss: 0.3196
Epoch 233/5000
 - 0s - loss: 0.3911 - val_loss: 0.3196
Epoch 234/5000
 - 0s - loss: 0.3911 - val_loss: 0.3196
Epoch 235/5000
 - 1s - loss: 0.3911 - val_loss: 0.3196
Epoch 236/5000
 - 1s - loss: 0.3911 - val_loss: 0.3196
Train on 1841 samples, validate on 335 samples
Epoch 183/5000
 - 4s - loss: 9.3028e-04 - val_loss: 0.0023
Epoch 184/5000
 - 0s - loss: 0.0010 - val_loss: 0.0026
Epoch 185/5000
 - 0s - loss: 9.9124e-04 - val_loss: 0.0027
Epoch 186/5000
 - 0s - loss: 0.0019 - val_loss: 0.0017
Epoch 187/5000
 - 0s - loss: 0.0013 - val_loss: 0.0015
Epoch 188/5000
 - 0s - loss: 0.0012 - val_loss: 0.0015
Epoch 189/5000
 - 0s - loss: 0.0012 - val_loss: 0.0015
Epoch 190/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 191/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 192/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 193/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 194/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 195/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 196/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 197/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 198/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 199/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 200/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 201/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 202/5000
 - 1s - loss: 0.0011 - val_loss: 0.0015
Epoch 203/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 204/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 205/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 206/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 207/5000
 - 1s - loss: 0.0011 - val_loss: 0.0015
Epoch 208/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 209/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 210/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 211/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 212/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 213/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Epoch 214/5000
 - 0s - loss: 0.0011 - val_loss: 0.0015
Train on 2388 samples, validate on 335 samples
Epoch 384/5000
 - 6s - loss: 0.6240 - val_loss: 0.6760
Epoch 385/5000
 - 1s - loss: 0.5087 - val_loss: 0.7247
Epoch 386/5000
 - 1s - loss: 0.4814 - val_loss: 0.7362
Epoch 387/5000
 - 1s - loss: 0.4661 - val_loss: 0.7435
Epoch 388/5000
 - 1s - loss: 0.4637 - val_loss: 0.7510
Epoch 389/5000
 - 1s - loss: 0.4617 - val_loss: 0.7579
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.017211705 |
| clipfrac           | 0.25585938  |
| explained_variance | -1.07e-06   |
| fps                | 5           |
| n_updates          | 1           |
| policy_entropy     | 1.143965    |
| policy_loss        | 0.032122962 |
| serial_timesteps   | 128         |
| time_elapsed       | 1.17e-05    |
| total_timesteps    | 128         |
| value_loss         | 212.94055   |
------------------------------------
------------------------------------
| approxkl           | 0.0315054   |
| clipfrac           | 0.33007812  |
| explained_variance | 5.96e-07    |
| fps                | 29          |
| n_updates          | 2           |
| policy_entropy     | 1.1430888   |
| policy_loss        | 0.023045525 |
| serial_timesteps   | 256         |
| time_elapsed       | 24.1        |
| total_timesteps    | 256         |
| value_loss         | 168.48334   |
------------------------------------
An average of 129.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.032336358  |
| clipfrac           | 0.33007812   |
| explained_variance | -1.91e-06    |
| fps                | 28           |
| n_updates          | 3            |
| policy_entropy     | 1.1425219    |
| policy_loss        | 0.0099918125 |
| serial_timesteps   | 384          |
| time_elapsed       | 28.4         |
| total_timesteps    | 384          |
| value_loss         | 219.97975    |
-------------------------------------
-------------------------------------
| approxkl           | 0.031238712  |
| clipfrac           | 0.34570312   |
| explained_variance | -5.96e-07    |
| fps                | 31           |
| n_updates          | 4            |
| policy_entropy     | 1.1419222    |
| policy_loss        | -0.015783451 |
| serial_timesteps   | 512          |
| time_elapsed       | 32.9         |
| total_timesteps    | 512          |
| value_loss         | 145.01749    |
-------------------------------------
------------------------------------
| approxkl           | 0.022801613 |
| clipfrac           | 0.2734375   |
| explained_variance | -1.19e-07   |
| fps                | 28          |
| n_updates          | 5           |
| policy_entropy     | 1.1410486   |
| policy_loss        | 0.019897737 |
| serial_timesteps   | 640         |
| time_elapsed       | 37          |
| total_timesteps    | 640         |
| value_loss         | 167.35466   |
------------------------------------
------------------------------------
| approxkl           | 0.013540014 |
| clipfrac           | 0.1875      |
| explained_variance | 5.36e-06    |
| fps                | 28          |
| n_updates          | 6           |
| policy_entropy     | 1.1406676   |
| policy_loss        | 0.035851948 |
| serial_timesteps   | 768         |
| time_elapsed       | 41.5        |
| total_timesteps    | 768         |
| value_loss         | 215.15683   |
------------------------------------
-------------------------------------
| approxkl           | 0.04328238   |
| clipfrac           | 0.42773438   |
| explained_variance | -5.48e-06    |
| fps                | 30           |
| n_updates          | 7            |
| policy_entropy     | 1.140169     |
| policy_loss        | -0.022313943 |
| serial_timesteps   | 896          |
| time_elapsed       | 46           |
| total_timesteps    | 896          |
| value_loss         | 175.58728    |
-------------------------------------
------------------------------------
| approxkl           | 0.027237725 |
| clipfrac           | 0.296875    |
| explained_variance | 5.96e-08    |
| fps                | 27          |
| n_updates          | 8           |
| policy_entropy     | 1.1397425   |
| policy_loss        | -0.02737948 |
| serial_timesteps   | 1024        |
| time_elapsed       | 50.2        |
| total_timesteps    | 1024        |
| value_loss         | 102.94489   |
------------------------------------
------------------------------------
| approxkl           | 0.02010258  |
| clipfrac           | 0.26953125  |
| explained_variance | -1.67e-06   |
| fps                | 28          |
| n_updates          | 9           |
| policy_entropy     | 1.1392853   |
| policy_loss        | 0.013722246 |
| serial_timesteps   | 1152        |
| time_elapsed       | 55          |
| total_timesteps    | 1152        |
| value_loss         | 136.05542   |
------------------------------------
------------------------------------
| approxkl           | 0.043638345 |
| clipfrac           | 0.38867188  |
| explained_variance | 1.79e-07    |
| fps                | 29          |
| n_updates          | 10          |
| policy_entropy     | 1.1387733   |
| policy_loss        | -0.03395323 |
| serial_timesteps   | 1280        |
| time_elapsed       | 59.5        |
| total_timesteps    | 1280        |
| value_loss         | 126.18604   |
------------------------------------
An average of 129.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.019537918 |
| clipfrac           | 0.26757812  |
| explained_variance | -2.03e-06   |
| fps                | 29          |
| n_updates          | 11          |
| policy_entropy     | 1.1385802   |
| policy_loss        | 0.007940287 |
| serial_timesteps   | 1408        |
| time_elapsed       | 63.9        |
| total_timesteps    | 1408        |
| value_loss         | 185.68079   |
------------------------------------
-------------------------------------
| approxkl           | 0.029896496  |
| clipfrac           | 0.33007812   |
| explained_variance | 1.55e-06     |
| fps                | 30           |
| n_updates          | 12           |
| policy_entropy     | 1.1386487    |
| policy_loss        | 0.0042796656 |
| serial_timesteps   | 1536         |
| time_elapsed       | 68.1         |
| total_timesteps    | 1536         |
| value_loss         | 171.11353    |
-------------------------------------
------------------------------------
| approxkl           | 0.004604203 |
| clipfrac           | 0.041015625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 13          |
| policy_entropy     | 1.1379428   |
| policy_loss        | 0.00248023  |
| serial_timesteps   | 1664        |
| time_elapsed       | 72.4        |
| total_timesteps    | 1664        |
| value_loss         | 1219.8428   |
------------------------------------
-------------------------------------
| approxkl           | 0.017205633  |
| clipfrac           | 0.25976562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | 5.36e-07     |
| fps                | 29           |
| n_updates          | 14           |
| policy_entropy     | 1.1367778    |
| policy_loss        | 0.0043642395 |
| serial_timesteps   | 1792         |
| time_elapsed       | 76.7         |
| total_timesteps    | 1792         |
| value_loss         | 167.08191    |
-------------------------------------
---------------------------------------
| approxkl           | 7.997176e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.46e+03       |
| explained_variance | -8.34e-07      |
| fps                | 27             |
| n_updates          | 15             |
| policy_entropy     | 1.1362712      |
| policy_loss        | -0.00011762034 |
| serial_timesteps   | 1920           |
| time_elapsed       | 81.1           |
| total_timesteps    | 1920           |
| value_loss         | 205.5371       |
---------------------------------------
------------------------------------
| approxkl           | 0.020783395 |
| clipfrac           | 0.24023438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | 2.38e-07    |
| fps                | 27          |
| n_updates          | 16          |
| policy_entropy     | 1.1331297   |
| policy_loss        | 0.014493712 |
| serial_timesteps   | 2048        |
| time_elapsed       | 85.7        |
| total_timesteps    | 2048        |
| value_loss         | 186.15735   |
------------------------------------
------------------------------------
| approxkl           | 0.022851486 |
| clipfrac           | 0.29296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | -1.91e-06   |
| fps                | 28          |
| n_updates          | 17          |
| policy_entropy     | 1.1313355   |
| policy_loss        | 0.02786632  |
| serial_timesteps   | 2176        |
| time_elapsed       | 90.3        |
| total_timesteps    | 2176        |
| value_loss         | 172.60335   |
------------------------------------
---------------------------------------
| approxkl           | 0.03472405     |
| clipfrac           | 0.41210938     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.46e+03       |
| explained_variance | -2.98e-06      |
| fps                | 28             |
| n_updates          | 18             |
| policy_entropy     | 1.1306987      |
| policy_loss        | -0.00053290906 |
| serial_timesteps   | 2304           |
| time_elapsed       | 94.8           |
| total_timesteps    | 2304           |
| value_loss         | 134.98065      |
---------------------------------------
An average of 130.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01751503  |
| clipfrac           | 0.25195312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | -2.38e-06   |
| fps                | 27          |
| n_updates          | 19          |
| policy_entropy     | 1.1305455   |
| policy_loss        | 0.030865414 |
| serial_timesteps   | 2432        |
| time_elapsed       | 99.4        |
| total_timesteps    | 2432        |
| value_loss         | 167.89334   |
------------------------------------
------------------------------------
| approxkl           | 0.020807868 |
| clipfrac           | 0.29101562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | 5.96e-07    |
| fps                | 29          |
| n_updates          | 20          |
| policy_entropy     | 1.1300539   |
| policy_loss        | 0.017213661 |
| serial_timesteps   | 2560        |
| time_elapsed       | 104         |
| total_timesteps    | 2560        |
| value_loss         | 194.7593    |
------------------------------------
------------------------------------
| approxkl           | 0.017842194 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | 2.15e-06    |
| fps                | 30          |
| n_updates          | 21          |
| policy_entropy     | 1.129478    |
| policy_loss        | 0.022246176 |
| serial_timesteps   | 2688        |
| time_elapsed       | 108         |
| total_timesteps    | 2688        |
| value_loss         | 155.17336   |
------------------------------------
--------------------------------------
| approxkl           | 0.03143292    |
| clipfrac           | 0.328125      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | 2.38e-07      |
| fps                | 30            |
| n_updates          | 22            |
| policy_entropy     | 1.1285758     |
| policy_loss        | 0.00023509469 |
| serial_timesteps   | 2816          |
| time_elapsed       | 113           |
| total_timesteps    | 2816          |
| value_loss         | 155.7607      |
--------------------------------------
------------------------------------
| approxkl           | 0.01999406  |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | -6.91e-06   |
| fps                | 28          |
| n_updates          | 23          |
| policy_entropy     | 1.1277456   |
| policy_loss        | 0.018776793 |
| serial_timesteps   | 2944        |
| time_elapsed       | 117         |
| total_timesteps    | 2944        |
| value_loss         | 174.9682    |
------------------------------------
------------------------------------
| approxkl           | 0.013393625 |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | 5.96e-08    |
| fps                | 26          |
| n_updates          | 24          |
| policy_entropy     | 1.1269908   |
| policy_loss        | 0.033869054 |
| serial_timesteps   | 3072        |
| time_elapsed       | 121         |
| total_timesteps    | 3072        |
| value_loss         | 146.28915   |
------------------------------------
------------------------------------
| approxkl           | 0.015737511 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -2.38e-07   |
| fps                | 28          |
| n_updates          | 25          |
| policy_entropy     | 1.1262113   |
| policy_loss        | 0.008526297 |
| serial_timesteps   | 3200        |
| time_elapsed       | 126         |
| total_timesteps    | 3200        |
| value_loss         | 1605.54     |
------------------------------------
An average of 131.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0040403605 |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | 1.55e-06     |
| fps                | 28           |
| n_updates          | 26           |
| policy_entropy     | 1.1258942    |
| policy_loss        | 0.010784754  |
| serial_timesteps   | 3328         |
| time_elapsed       | 130          |
| total_timesteps    | 3328         |
| value_loss         | 115.86741    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0041133948 |
| clipfrac           | 0.0546875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -3.58e-06    |
| fps                | 28           |
| n_updates          | 27           |
| policy_entropy     | 1.1254854    |
| policy_loss        | -0.013531258 |
| serial_timesteps   | 3456         |
| time_elapsed       | 135          |
| total_timesteps    | 3456         |
| value_loss         | 180.31639    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00022964986 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.48e+03      |
| explained_variance | 1.13e-06      |
| fps                | 28            |
| n_updates          | 28            |
| policy_entropy     | 1.1241004     |
| policy_loss        | 0.003021842   |
| serial_timesteps   | 3584          |
| time_elapsed       | 139           |
| total_timesteps    | 3584          |
| value_loss         | 214.06274     |
--------------------------------------
------------------------------------
| approxkl           | 0.028739046 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -1.79e-06   |
| fps                | 28          |
| n_updates          | 29          |
| policy_entropy     | 1.1229259   |
| policy_loss        | 0.026705395 |
| serial_timesteps   | 3712        |
| time_elapsed       | 144         |
| total_timesteps    | 3712        |
| value_loss         | 178.87373   |
------------------------------------
------------------------------------
| approxkl           | 0.021916185 |
| clipfrac           | 0.29296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 8.94e-07    |
| fps                | 28          |
| n_updates          | 30          |
| policy_entropy     | 1.1222366   |
| policy_loss        | 0.038255222 |
| serial_timesteps   | 3840        |
| time_elapsed       | 148         |
| total_timesteps    | 3840        |
| value_loss         | 183.5076    |
------------------------------------
------------------------------------
| approxkl           | 0.03598247  |
| clipfrac           | 0.3984375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -9.54e-07   |
| fps                | 30          |
| n_updates          | 31          |
| policy_entropy     | 1.1216321   |
| policy_loss        | 0.027011275 |
| serial_timesteps   | 3968        |
| time_elapsed       | 153         |
| total_timesteps    | 3968        |
| value_loss         | 156.44946   |
------------------------------------
------------------------------------
| approxkl           | 0.02683778  |
| clipfrac           | 0.31445312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 2.21e-06    |
| fps                | 27          |
| n_updates          | 32          |
| policy_entropy     | 1.1216891   |
| policy_loss        | 0.011865753 |
| serial_timesteps   | 4096        |
| time_elapsed       | 157         |
| total_timesteps    | 4096        |
| value_loss         | 167.57428   |
------------------------------------
------------------------------------
| approxkl           | 0.014808606 |
| clipfrac           | 0.21875     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -3.46e-06   |
| fps                | 26          |
| n_updates          | 33          |
| policy_entropy     | 1.1214768   |
| policy_loss        | 0.031425275 |
| serial_timesteps   | 4224        |
| time_elapsed       | 162         |
| total_timesteps    | 4224        |
| value_loss         | 134.4994    |
------------------------------------
An average of 131.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.044264715  |
| clipfrac           | 0.44335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -3.58e-06    |
| fps                | 29           |
| n_updates          | 34           |
| policy_entropy     | 1.1211689    |
| policy_loss        | 0.0021283356 |
| serial_timesteps   | 4352         |
| time_elapsed       | 166          |
| total_timesteps    | 4352         |
| value_loss         | 130.07335    |
-------------------------------------
------------------------------------
| approxkl           | 0.019662116 |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -2.38e-06   |
| fps                | 27          |
| n_updates          | 35          |
| policy_entropy     | 1.1210623   |
| policy_loss        | 0.028368589 |
| serial_timesteps   | 4480        |
| time_elapsed       | 171         |
| total_timesteps    | 4480        |
| value_loss         | 135.08562   |
------------------------------------
------------------------------------
| approxkl           | 0.024591494 |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 2.38e-07    |
| fps                | 29          |
| n_updates          | 36          |
| policy_entropy     | 1.1191413   |
| policy_loss        | 0.026888836 |
| serial_timesteps   | 4608        |
| time_elapsed       | 175         |
| total_timesteps    | 4608        |
| value_loss         | 160.9606    |
------------------------------------
------------------------------------
| approxkl           | 0.023152942 |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -1.19e-07   |
| fps                | 29          |
| n_updates          | 37          |
| policy_entropy     | 1.1180468   |
| policy_loss        | 0.023751697 |
| serial_timesteps   | 4736        |
| time_elapsed       | 180         |
| total_timesteps    | 4736        |
| value_loss         | 1782.8124   |
------------------------------------
-------------------------------------
| approxkl           | 0.0018190244 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | 3.76e-06     |
| fps                | 28           |
| n_updates          | 38           |
| policy_entropy     | 1.1180459    |
| policy_loss        | 0.0018309864 |
| serial_timesteps   | 4864         |
| time_elapsed       | 184          |
| total_timesteps    | 4864         |
| value_loss         | 179.49388    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0004623649  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.48e+03      |
| explained_variance | -5.96e-06     |
| fps                | 30            |
| n_updates          | 39            |
| policy_entropy     | 1.1176511     |
| policy_loss        | -0.0016408686 |
| serial_timesteps   | 4992          |
| time_elapsed       | 189           |
| total_timesteps    | 4992          |
| value_loss         | 162.28294     |
--------------------------------------
------------------------------------
| approxkl           | 0.019253973 |
| clipfrac           | 0.25976562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 40          |
| policy_entropy     | 1.1160959   |
| policy_loss        | 0.03944093  |
| serial_timesteps   | 5120        |
| time_elapsed       | 193         |
| total_timesteps    | 5120        |
| value_loss         | 175.6583    |
------------------------------------
------------------------------------
| approxkl           | 0.03744576  |
| clipfrac           | 0.39257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 1.19e-07    |
| fps                | 28          |
| n_updates          | 41          |
| policy_entropy     | 1.1156325   |
| policy_loss        | 0.007904787 |
| serial_timesteps   | 5248        |
| time_elapsed       | 198         |
| total_timesteps    | 5248        |
| value_loss         | 149.60954   |
------------------------------------
An average of 132.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.021164725 |
| clipfrac           | 0.26171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 3.28e-06    |
| fps                | 28          |
| n_updates          | 42          |
| policy_entropy     | 1.1159947   |
| policy_loss        | 0.021022653 |
| serial_timesteps   | 5376        |
| time_elapsed       | 202         |
| total_timesteps    | 5376        |
| value_loss         | 158.86395   |
------------------------------------
-------------------------------------
| approxkl           | 0.0329619    |
| clipfrac           | 0.35742188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -1.19e-06    |
| fps                | 27           |
| n_updates          | 43           |
| policy_entropy     | 1.1160395    |
| policy_loss        | 0.0010798145 |
| serial_timesteps   | 5504         |
| time_elapsed       | 207          |
| total_timesteps    | 5504         |
| value_loss         | 147.11218    |
-------------------------------------
------------------------------------
| approxkl           | 0.019666301 |
| clipfrac           | 0.23242188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 1.19e-07    |
| fps                | 28          |
| n_updates          | 44          |
| policy_entropy     | 1.1160654   |
| policy_loss        | 0.00584004  |
| serial_timesteps   | 5632        |
| time_elapsed       | 211         |
| total_timesteps    | 5632        |
| value_loss         | 181.98553   |
------------------------------------
------------------------------------
| approxkl           | 0.024185069 |
| clipfrac           | 0.28320312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -1.67e-06   |
| fps                | 28          |
| n_updates          | 45          |
| policy_entropy     | 1.1155959   |
| policy_loss        | 0.010352761 |
| serial_timesteps   | 5760        |
| time_elapsed       | 216         |
| total_timesteps    | 5760        |
| value_loss         | 174.37442   |
------------------------------------
------------------------------------
| approxkl           | 0.025355825 |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 1.55e-06    |
| fps                | 29          |
| n_updates          | 46          |
| policy_entropy     | 1.1147752   |
| policy_loss        | 0.026400248 |
| serial_timesteps   | 5888        |
| time_elapsed       | 220         |
| total_timesteps    | 5888        |
| value_loss         | 170.9837    |
------------------------------------
------------------------------------
| approxkl           | 0.021602817 |
| clipfrac           | 0.26171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -7.15e-07   |
| fps                | 29          |
| n_updates          | 47          |
| policy_entropy     | 1.1147037   |
| policy_loss        | 0.02848757  |
| serial_timesteps   | 6016        |
| time_elapsed       | 225         |
| total_timesteps    | 6016        |
| value_loss         | 185.13147   |
------------------------------------
------------------------------------
| approxkl           | 0.020535225 |
| clipfrac           | 0.28125     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | 2.62e-06    |
| fps                | 28          |
| n_updates          | 48          |
| policy_entropy     | 1.1141348   |
| policy_loss        | 0.02435958  |
| serial_timesteps   | 6144        |
| time_elapsed       | 229         |
| total_timesteps    | 6144        |
| value_loss         | 177.23175   |
------------------------------------
-------------------------------------
| approxkl           | 0.02576784   |
| clipfrac           | 0.29882812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | -2.38e-07    |
| fps                | 28           |
| n_updates          | 49           |
| policy_entropy     | 1.1136601    |
| policy_loss        | 0.0032222678 |
| serial_timesteps   | 6272         |
| time_elapsed       | 233          |
| total_timesteps    | 6272         |
| value_loss         | 1738.2463    |
-------------------------------------
An average of 133.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0043184427 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | -3.1e-06     |
| fps                | 25           |
| n_updates          | 50           |
| policy_entropy     | 1.1135436    |
| policy_loss        | -0.012386176 |
| serial_timesteps   | 6400         |
| time_elapsed       | 238          |
| total_timesteps    | 6400         |
| value_loss         | 114.80443    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0030649959  |
| clipfrac           | 0.029296875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.51e+03      |
| explained_variance | 3.58e-07      |
| fps                | 29            |
| n_updates          | 51            |
| policy_entropy     | 1.1133125     |
| policy_loss        | -0.0072884797 |
| serial_timesteps   | 6528          |
| time_elapsed       | 243           |
| total_timesteps    | 6528          |
| value_loss         | 116.5903      |
--------------------------------------
------------------------------------
| approxkl           | 0.009350969 |
| clipfrac           | 0.14453125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | -1.19e-07   |
| fps                | 27          |
| n_updates          | 52          |
| policy_entropy     | 1.1115608   |
| policy_loss        | 0.031295367 |
| serial_timesteps   | 6656        |
| time_elapsed       | 247         |
| total_timesteps    | 6656        |
| value_loss         | 79.773445   |
------------------------------------
------------------------------------
| approxkl           | 0.031916555 |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 5.78e-06    |
| fps                | 27          |
| n_updates          | 53          |
| policy_entropy     | 1.1101911   |
| policy_loss        | 0.026494993 |
| serial_timesteps   | 6784        |
| time_elapsed       | 252         |
| total_timesteps    | 6784        |
| value_loss         | 203.41107   |
------------------------------------
------------------------------------
| approxkl           | 0.01986938  |
| clipfrac           | 0.26953125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 1.03e-05    |
| fps                | 28          |
| n_updates          | 54          |
| policy_entropy     | 1.1092609   |
| policy_loss        | 0.005982814 |
| serial_timesteps   | 6912        |
| time_elapsed       | 256         |
| total_timesteps    | 6912        |
| value_loss         | 122.55134   |
------------------------------------
------------------------------------
| approxkl           | 0.015654266 |
| clipfrac           | 0.21679688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | -1.43e-06   |
| fps                | 27          |
| n_updates          | 55          |
| policy_entropy     | 1.1088828   |
| policy_loss        | 0.022656005 |
| serial_timesteps   | 7040        |
| time_elapsed       | 261         |
| total_timesteps    | 7040        |
| value_loss         | 232.39827   |
------------------------------------
------------------------------------
| approxkl           | 0.021738192 |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | -1.19e-07   |
| fps                | 29          |
| n_updates          | 56          |
| policy_entropy     | 1.108677    |
| policy_loss        | 0.022051282 |
| serial_timesteps   | 7168        |
| time_elapsed       | 266         |
| total_timesteps    | 7168        |
| value_loss         | 176.61613   |
------------------------------------
------------------------------------
| approxkl           | 0.0293979   |
| clipfrac           | 0.375       |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | -1.79e-06   |
| fps                | 28          |
| n_updates          | 57          |
| policy_entropy     | 1.1082356   |
| policy_loss        | 0.022968061 |
| serial_timesteps   | 7296        |
| time_elapsed       | 270         |
| total_timesteps    | 7296        |
| value_loss         | 147.22565   |
------------------------------------
An average of 133.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.03228168   |
| clipfrac           | 0.3125       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | 3.34e-06     |
| fps                | 28           |
| n_updates          | 58           |
| policy_entropy     | 1.1080712    |
| policy_loss        | -0.001919402 |
| serial_timesteps   | 7424         |
| time_elapsed       | 275          |
| total_timesteps    | 7424         |
| value_loss         | 175.81717    |
-------------------------------------
------------------------------------
| approxkl           | 0.028778667 |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 0           |
| fps                | 28          |
| n_updates          | 59          |
| policy_entropy     | 1.1085787   |
| policy_loss        | -0.0106811  |
| serial_timesteps   | 7552        |
| time_elapsed       | 279         |
| total_timesteps    | 7552        |
| value_loss         | 168.35805   |
------------------------------------
-------------------------------------
| approxkl           | 0.03028393   |
| clipfrac           | 0.34179688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | -3.1e-06     |
| fps                | 30           |
| n_updates          | 60           |
| policy_entropy     | 1.1092854    |
| policy_loss        | 0.0039979955 |
| serial_timesteps   | 7680         |
| time_elapsed       | 284          |
| total_timesteps    | 7680         |
| value_loss         | 169.15575    |
-------------------------------------
--------------------------------------
| approxkl           | 0.03859808    |
| clipfrac           | 0.38476562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.51e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 61            |
| policy_entropy     | 1.1089078     |
| policy_loss        | -0.0050793844 |
| serial_timesteps   | 7808          |
| time_elapsed       | 288           |
| total_timesteps    | 7808          |
| value_loss         | 1867.5195     |
--------------------------------------
--------------------------------------
| approxkl           | 1.8569273e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.51e+03      |
| explained_variance | 5.36e-07      |
| fps                | 26            |
| n_updates          | 62            |
| policy_entropy     | 1.1084673     |
| policy_loss        | 6.202352e-05  |
| serial_timesteps   | 7936          |
| time_elapsed       | 292           |
| total_timesteps    | 7936          |
| value_loss         | 142.6855      |
--------------------------------------
-------------------------------------
| approxkl           | 0.004200369  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | -3.58e-07    |
| fps                | 28           |
| n_updates          | 63           |
| policy_entropy     | 1.1078315    |
| policy_loss        | -0.012455944 |
| serial_timesteps   | 8064         |
| time_elapsed       | 297          |
| total_timesteps    | 8064         |
| value_loss         | 132.3221     |
-------------------------------------
------------------------------------
| approxkl           | 0.04578693  |
| clipfrac           | 0.41601562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 4.65e-06    |
| fps                | 30          |
| n_updates          | 64          |
| policy_entropy     | 1.1084496   |
| policy_loss        | 0.017570745 |
| serial_timesteps   | 8192        |
| time_elapsed       | 301         |
| total_timesteps    | 8192        |
| value_loss         | 156.37833   |
------------------------------------
An average of 134.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.021818062 |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 1.43e-06    |
| fps                | 27          |
| n_updates          | 65          |
| policy_entropy     | 1.1086094   |
| policy_loss        | 0.018199764 |
| serial_timesteps   | 8320        |
| time_elapsed       | 306         |
| total_timesteps    | 8320        |
| value_loss         | 206.59677   |
------------------------------------
------------------------------------
| approxkl           | 0.029357359 |
| clipfrac           | 0.29296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | -9.54e-07   |
| fps                | 28          |
| n_updates          | 66          |
| policy_entropy     | 1.1082969   |
| policy_loss        | 0.009273525 |
| serial_timesteps   | 8448        |
| time_elapsed       | 310         |
| total_timesteps    | 8448        |
| value_loss         | 154.9612    |
------------------------------------
--------------------------------------
| approxkl           | 0.005528902   |
| clipfrac           | 0.072265625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.51e+03      |
| explained_variance | -3.22e-06     |
| fps                | 27            |
| n_updates          | 67            |
| policy_entropy     | 1.1096488     |
| policy_loss        | -0.0033199603 |
| serial_timesteps   | 8576          |
| time_elapsed       | 315           |
| total_timesteps    | 8576          |
| value_loss         | 176.50334     |
--------------------------------------
------------------------------------
| approxkl           | 0.009880496 |
| clipfrac           | 0.15429688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 0           |
| fps                | 30          |
| n_updates          | 68          |
| policy_entropy     | 1.1094444   |
| policy_loss        | 0.0368136   |
| serial_timesteps   | 8704        |
| time_elapsed       | 319         |
| total_timesteps    | 8704        |
| value_loss         | 132.50333   |
------------------------------------
------------------------------------
| approxkl           | 0.0266026   |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 3.4e-06     |
| fps                | 28          |
| n_updates          | 69          |
| policy_entropy     | 1.1087486   |
| policy_loss        | 0.004203966 |
| serial_timesteps   | 8832        |
| time_elapsed       | 323         |
| total_timesteps    | 8832        |
| value_loss         | 152.72235   |
------------------------------------
-------------------------------------
| approxkl           | 0.018532898  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | 3.81e-06     |
| fps                | 27           |
| n_updates          | 70           |
| policy_entropy     | 1.1084795    |
| policy_loss        | 0.0042249765 |
| serial_timesteps   | 8960         |
| time_elapsed       | 328          |
| total_timesteps    | 8960         |
| value_loss         | 152.61009    |
-------------------------------------
-------------------------------------
| approxkl           | 0.036168374  |
| clipfrac           | 0.3359375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.51e+03     |
| explained_variance | -3.34e-06    |
| fps                | 29           |
| n_updates          | 71           |
| policy_entropy     | 1.1083398    |
| policy_loss        | -0.015363365 |
| serial_timesteps   | 9088         |
| time_elapsed       | 332          |
| total_timesteps    | 9088         |
| value_loss         | 109.58385    |
-------------------------------------
------------------------------------
| approxkl           | 0.011855527 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.51e+03    |
| explained_variance | 1.19e-07    |
| fps                | 30          |
| n_updates          | 72          |
| policy_entropy     | 1.1088356   |
| policy_loss        | 0.02468394  |
| serial_timesteps   | 9216        |
| time_elapsed       | 337         |
| total_timesteps    | 9216        |
| value_loss         | 181.50616   |
------------------------------------
An average of 135.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.026312567 |
| clipfrac           | 0.27734375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | -1.19e-07   |
| fps                | 27          |
| n_updates          | 73          |
| policy_entropy     | 1.108659    |
| policy_loss        | 0.009973384 |
| serial_timesteps   | 9344        |
| time_elapsed       | 341         |
| total_timesteps    | 9344        |
| value_loss         | 1828.8821   |
------------------------------------
-------------------------------------
| approxkl           | 0.0008194179 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | 2.86e-06     |
| fps                | 29           |
| n_updates          | 74           |
| policy_entropy     | 1.1085249    |
| policy_loss        | -0.003879305 |
| serial_timesteps   | 9472         |
| time_elapsed       | 346          |
| total_timesteps    | 9472         |
| value_loss         | 170.68727    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0042009815 |
| clipfrac           | 0.048828125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | 7.15e-07     |
| fps                | 29           |
| n_updates          | 75           |
| policy_entropy     | 1.1082324    |
| policy_loss        | -0.011495631 |
| serial_timesteps   | 9600         |
| time_elapsed       | 350          |
| total_timesteps    | 9600         |
| value_loss         | 117.09252    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0027654944 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | 5.36e-07     |
| fps                | 29           |
| n_updates          | 76           |
| policy_entropy     | 1.1061909    |
| policy_loss        | -0.004940815 |
| serial_timesteps   | 9728         |
| time_elapsed       | 354          |
| total_timesteps    | 9728         |
| value_loss         | 190.21169    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0050431644 |
| clipfrac           | 0.06640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | -3.58e-06    |
| fps                | 30           |
| n_updates          | 77           |
| policy_entropy     | 1.104025     |
| policy_loss        | -0.017246079 |
| serial_timesteps   | 9856         |
| time_elapsed       | 359          |
| total_timesteps    | 9856         |
| value_loss         | 102.29544    |
-------------------------------------
------------------------------------
| approxkl           | 0.003825305 |
| clipfrac           | 0.048828125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 1.13e-06    |
| fps                | 28          |
| n_updates          | 78          |
| policy_entropy     | 1.102647    |
| policy_loss        | 0.020706216 |
| serial_timesteps   | 9984        |
| time_elapsed       | 363         |
| total_timesteps    | 9984        |
| value_loss         | 110.436386  |
------------------------------------
------------------------------------
| approxkl           | 0.041750807 |
| clipfrac           | 0.37109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 2.8e-06     |
| fps                | 27          |
| n_updates          | 79          |
| policy_entropy     | 1.1010975   |
| policy_loss        | 0.033019796 |
| serial_timesteps   | 10112       |
| time_elapsed       | 367         |
| total_timesteps    | 10112       |
| value_loss         | 183.2397    |
------------------------------------
------------------------------------
| approxkl           | 0.025487246 |
| clipfrac           | 0.32226562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 3.93e-06    |
| fps                | 29          |
| n_updates          | 80          |
| policy_entropy     | 1.100807    |
| policy_loss        | 0.00832268  |
| serial_timesteps   | 10240       |
| time_elapsed       | 372         |
| total_timesteps    | 10240       |
| value_loss         | 142.00148   |
------------------------------------
An average of 135.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-----------------------------------
| approxkl           | 0.01826474 |
| clipfrac           | 0.25585938 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.52e+03   |
| explained_variance | 1.85e-06   |
| fps                | 29         |
| n_updates          | 81         |
| policy_entropy     | 1.1006516  |
| policy_loss        | 0.03325437 |
| serial_timesteps   | 10368      |
| time_elapsed       | 376        |
| total_timesteps    | 10368      |
| value_loss         | 128.68112  |
-----------------------------------
------------------------------------
| approxkl           | 0.04246652  |
| clipfrac           | 0.40234375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | -1.55e-06   |
| fps                | 27          |
| n_updates          | 82          |
| policy_entropy     | 1.0998024   |
| policy_loss        | 0.009975242 |
| serial_timesteps   | 10496       |
| time_elapsed       | 381         |
| total_timesteps    | 10496       |
| value_loss         | 151.04105   |
------------------------------------
------------------------------------
| approxkl           | 0.017635811 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | -2.74e-06   |
| fps                | 29          |
| n_updates          | 83          |
| policy_entropy     | 1.0993598   |
| policy_loss        | 0.018150846 |
| serial_timesteps   | 10624       |
| time_elapsed       | 385         |
| total_timesteps    | 10624       |
| value_loss         | 172.62357   |
------------------------------------
------------------------------------
| approxkl           | 0.025628638 |
| clipfrac           | 0.36132812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | -1.19e-07   |
| fps                | 30          |
| n_updates          | 84          |
| policy_entropy     | 1.0987312   |
| policy_loss        | 0.011902941 |
| serial_timesteps   | 10752       |
| time_elapsed       | 390         |
| total_timesteps    | 10752       |
| value_loss         | 154.12373   |
------------------------------------
-------------------------------------
| approxkl           | 0.0130061945 |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | -2.38e-07    |
| fps                | 29           |
| n_updates          | 85           |
| policy_entropy     | 1.098423     |
| policy_loss        | 0.016675731  |
| serial_timesteps   | 10880        |
| time_elapsed       | 394          |
| total_timesteps    | 10880        |
| value_loss         | 1934.4086    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0072050206 |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | 5.54e-06     |
| fps                | 29           |
| n_updates          | 86           |
| policy_entropy     | 1.0982519    |
| policy_loss        | -0.010229593 |
| serial_timesteps   | 11008        |
| time_elapsed       | 398          |
| total_timesteps    | 11008        |
| value_loss         | 104.80956    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00029464558 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.52e+03      |
| explained_variance | 5.96e-07      |
| fps                | 29            |
| n_updates          | 87            |
| policy_entropy     | 1.0979261     |
| policy_loss        | -0.0011901169 |
| serial_timesteps   | 11136         |
| time_elapsed       | 403           |
| total_timesteps    | 11136         |
| value_loss         | 87.47201      |
--------------------------------------
------------------------------------
| approxkl           | 0.010145447 |
| clipfrac           | 0.16210938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | -3.58e-07   |
| fps                | 26          |
| n_updates          | 88          |
| policy_entropy     | 1.0964892   |
| policy_loss        | 0.010651781 |
| serial_timesteps   | 11264       |
| time_elapsed       | 407         |
| total_timesteps    | 11264       |
| value_loss         | 137.4429    |
------------------------------------
An average of 136.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-----------------------------------
| approxkl           | 0.02175978 |
| clipfrac           | 0.3125     |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.52e+03   |
| explained_variance | -9.54e-07  |
| fps                | 29         |
| n_updates          | 89         |
| policy_entropy     | 1.0961213  |
| policy_loss        | 0.03617494 |
| serial_timesteps   | 11392      |
| time_elapsed       | 412        |
| total_timesteps    | 11392      |
| value_loss         | 153.39438  |
-----------------------------------
------------------------------------
| approxkl           | 0.035107262 |
| clipfrac           | 0.38671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 7.75e-07    |
| fps                | 29          |
| n_updates          | 90          |
| policy_entropy     | 1.0957693   |
| policy_loss        | 0.009431968 |
| serial_timesteps   | 11520       |
| time_elapsed       | 416         |
| total_timesteps    | 11520       |
| value_loss         | 178.00156   |
------------------------------------
-------------------------------------
| approxkl           | 0.02478344   |
| clipfrac           | 0.3125       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | 2.03e-06     |
| fps                | 29           |
| n_updates          | 91           |
| policy_entropy     | 1.0961701    |
| policy_loss        | 0.0003587387 |
| serial_timesteps   | 11648        |
| time_elapsed       | 420          |
| total_timesteps    | 11648        |
| value_loss         | 148.73395    |
-------------------------------------
------------------------------------
| approxkl           | 0.026357679 |
| clipfrac           | 0.33789062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 4.41e-06    |
| fps                | 30          |
| n_updates          | 92          |
| policy_entropy     | 1.0958841   |
| policy_loss        | 0.010628586 |
| serial_timesteps   | 11776       |
| time_elapsed       | 425         |
| total_timesteps    | 11776       |
| value_loss         | 101.47063   |
------------------------------------
------------------------------------
| approxkl           | 0.03648166  |
| clipfrac           | 0.3828125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | -1.07e-06   |
| fps                | 29          |
| n_updates          | 93          |
| policy_entropy     | 1.0946375   |
| policy_loss        | 0.016224839 |
| serial_timesteps   | 11904       |
| time_elapsed       | 429         |
| total_timesteps    | 11904       |
| value_loss         | 158.55753   |
------------------------------------
------------------------------------
| approxkl           | 0.022783926 |
| clipfrac           | 0.28710938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 2.98e-07    |
| fps                | 27          |
| n_updates          | 94          |
| policy_entropy     | 1.0944065   |
| policy_loss        | 0.011743994 |
| serial_timesteps   | 12032       |
| time_elapsed       | 433         |
| total_timesteps    | 12032       |
| value_loss         | 160.06293   |
------------------------------------
------------------------------------
| approxkl           | 0.02684288  |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.52e+03    |
| explained_variance | 3.34e-06    |
| fps                | 26          |
| n_updates          | 95          |
| policy_entropy     | 1.0944034   |
| policy_loss        | 0.011291865 |
| serial_timesteps   | 12160       |
| time_elapsed       | 438         |
| total_timesteps    | 12160       |
| value_loss         | 186.43787   |
------------------------------------
-------------------------------------
| approxkl           | 0.032547235  |
| clipfrac           | 0.34375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.52e+03     |
| explained_variance | -2.03e-06    |
| fps                | 27           |
| n_updates          | 96           |
| policy_entropy     | 1.0937955    |
| policy_loss        | -0.014785524 |
| serial_timesteps   | 12288        |
| time_elapsed       | 443          |
| total_timesteps    | 12288        |
| value_loss         | 138.09889    |
-------------------------------------
An average of 136.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.020065859 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.53e+03    |
| explained_variance | -2.38e-07   |
| fps                | 28          |
| n_updates          | 97          |
| policy_entropy     | 1.0937382   |
| policy_loss        | 0.004645408 |
| serial_timesteps   | 12416       |
| time_elapsed       | 447         |
| total_timesteps    | 12416       |
| value_loss         | 1930.7186   |
------------------------------------
-------------------------------------
| approxkl           | 0.0020051743 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.53e+03     |
| explained_variance | 1.37e-06     |
| fps                | 30           |
| n_updates          | 98           |
| policy_entropy     | 1.0938493    |
| policy_loss        | -0.005655171 |
| serial_timesteps   | 12544        |
| time_elapsed       | 452          |
| total_timesteps    | 12544        |
| value_loss         | 127.82207    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0004686425 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.53e+03     |
| explained_variance | -4.17e-06    |
| fps                | 30           |
| n_updates          | 99           |
| policy_entropy     | 1.093621     |
| policy_loss        | 0.001038095  |
| serial_timesteps   | 12672        |
| time_elapsed       | 456          |
| total_timesteps    | 12672        |
| value_loss         | 169.02675    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0008469493  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.53e+03      |
| explained_variance | -2.38e-07     |
| fps                | 28            |
| n_updates          | 100           |
| policy_entropy     | 1.0922812     |
| policy_loss        | 0.00058708584 |
| serial_timesteps   | 12800         |
| time_elapsed       | 460           |
| total_timesteps    | 12800         |
| value_loss         | 140.64017     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00018057511  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.53e+03       |
| explained_variance | 6.91e-06       |
| fps                | 27             |
| n_updates          | 101            |
| policy_entropy     | 1.0905863      |
| policy_loss        | -0.00010020216 |
| serial_timesteps   | 12928          |
| time_elapsed       | 465            |
| total_timesteps    | 12928          |
| value_loss         | 136.47891      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0058852024 |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.53e+03     |
| explained_variance | 3.34e-06     |
| fps                | 27           |
| n_updates          | 102          |
| policy_entropy     | 1.0859361    |
| policy_loss        | -0.008629279 |
| serial_timesteps   | 13056        |
| time_elapsed       | 469          |
| total_timesteps    | 13056        |
| value_loss         | 104.98501    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0006342443  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.53e+03      |
| explained_variance | 7.15e-07      |
| fps                | 28            |
| n_updates          | 103           |
| policy_entropy     | 1.0824821     |
| policy_loss        | -0.0023068185 |
| serial_timesteps   | 13184         |
| time_elapsed       | 474           |
| total_timesteps    | 13184         |
| value_loss         | 127.14082     |
--------------------------------------
-------------------------------------
| approxkl           | 0.009463308  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.53e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 104          |
| policy_entropy     | 1.0813406    |
| policy_loss        | 0.0147656575 |
| serial_timesteps   | 13312        |
| time_elapsed       | 478          |
| total_timesteps    | 13312        |
| value_loss         | 149.09766    |
-------------------------------------
An average of 137.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.026777893 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.53e+03    |
| explained_variance | -2.38e-07   |
| fps                | 29          |
| n_updates          | 105         |
| policy_entropy     | 1.0813082   |
| policy_loss        | 0.02513478  |
| serial_timesteps   | 13440       |
| time_elapsed       | 483         |
| total_timesteps    | 13440       |
| value_loss         | 150.97766   |
------------------------------------
------------------------------------
| approxkl           | 0.030530816 |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.53e+03    |
| explained_variance | -5.96e-07   |
| fps                | 29          |
| n_updates          | 106         |
| policy_entropy     | 1.0810568   |
| policy_loss        | 0.027672714 |
| serial_timesteps   | 13568       |
| time_elapsed       | 487         |
| total_timesteps    | 13568       |
| value_loss         | 130.02948   |
------------------------------------
------------------------------------
| approxkl           | 0.03541781  |
| clipfrac           | 0.37304688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.53e+03    |
| explained_variance | 3.52e-06    |
| fps                | 29          |
| n_updates          | 107         |
| policy_entropy     | 1.0807987   |
| policy_loss        | 0.006354624 |
| serial_timesteps   | 13696       |
| time_elapsed       | 492         |
| total_timesteps    | 13696       |
| value_loss         | 111.09665   |
------------------------------------
------------------------------------
| approxkl           | 0.021539606 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.53e+03    |
| explained_variance | 4.53e-06    |
| fps                | 29          |
| n_updates          | 108         |
| policy_entropy     | 1.0804511   |
| policy_loss        | 0.020085173 |
| serial_timesteps   | 13824       |
| time_elapsed       | 496         |
| total_timesteps    | 13824       |
| value_loss         | 132.91328   |
------------------------------------
------------------------------------
| approxkl           | 0.031892713 |
| clipfrac           | 0.34960938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.54e+03    |
| explained_variance | 5.96e-08    |
| fps                | 28          |
| n_updates          | 109         |
| policy_entropy     | 1.0796822   |
| policy_loss        | 0.022399615 |
| serial_timesteps   | 13952       |
| time_elapsed       | 500         |
| total_timesteps    | 13952       |
| value_loss         | 1918.4802   |
------------------------------------
--------------------------------------
| approxkl           | 0.00038469513 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.54e+03      |
| explained_variance | 5.96e-07      |
| fps                | 28            |
| n_updates          | 110           |
| policy_entropy     | 1.079335      |
| policy_loss        | 0.0003054632  |
| serial_timesteps   | 14080         |
| time_elapsed       | 505           |
| total_timesteps    | 14080         |
| value_loss         | 118.564064    |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017477763 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.54e+03      |
| explained_variance | 1.97e-06      |
| fps                | 29            |
| n_updates          | 111           |
| policy_entropy     | 1.078796      |
| policy_loss        | -0.0009844952 |
| serial_timesteps   | 14208         |
| time_elapsed       | 509           |
| total_timesteps    | 14208         |
| value_loss         | 175.17911     |
--------------------------------------
An average of 138.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.025455376 |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.54e+03    |
| explained_variance | -1.79e-06   |
| fps                | 29          |
| n_updates          | 112         |
| policy_entropy     | 1.0781009   |
| policy_loss        | 0.031546764 |
| serial_timesteps   | 14336       |
| time_elapsed       | 513         |
| total_timesteps    | 14336       |
| value_loss         | 117.14506   |
------------------------------------
------------------------------------
| approxkl           | 0.04269679  |
| clipfrac           | 0.4296875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.54e+03    |
| explained_variance | 3.58e-07    |
| fps                | 27          |
| n_updates          | 113         |
| policy_entropy     | 1.0774825   |
| policy_loss        | 0.024067808 |
| serial_timesteps   | 14464       |
| time_elapsed       | 518         |
| total_timesteps    | 14464       |
| value_loss         | 100.29712   |
------------------------------------
------------------------------------
| approxkl           | 0.04176699  |
| clipfrac           | 0.43945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.54e+03    |
| explained_variance | -7.15e-07   |
| fps                | 27          |
| n_updates          | 114         |
| policy_entropy     | 1.0774146   |
| policy_loss        | 0.004289405 |
| serial_timesteps   | 14592       |
| time_elapsed       | 522         |
| total_timesteps    | 14592       |
| value_loss         | 151.19254   |
------------------------------------
------------------------------------
| approxkl           | 0.021922123 |
| clipfrac           | 0.29296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.54e+03    |
| explained_variance | -4.41e-06   |
| fps                | 26          |
| n_updates          | 115         |
| policy_entropy     | 1.0771397   |
| policy_loss        | 0.018893579 |
| serial_timesteps   | 14720       |
| time_elapsed       | 527         |
| total_timesteps    | 14720       |
| value_loss         | 87.664604   |
------------------------------------
------------------------------------
| approxkl           | 0.04316539  |
| clipfrac           | 0.390625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.54e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 116         |
| policy_entropy     | 1.0762167   |
| policy_loss        | 0.006582155 |
| serial_timesteps   | 14848       |
| time_elapsed       | 532         |
| total_timesteps    | 14848       |
| value_loss         | 131.92184   |
------------------------------------
--------------------------------------
| approxkl           | 0.023449957   |
| clipfrac           | 0.29101562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.54e+03      |
| explained_variance | 1.19e-07      |
| fps                | 28            |
| n_updates          | 117           |
| policy_entropy     | 1.0754522     |
| policy_loss        | -0.0016224056 |
| serial_timesteps   | 14976         |
| time_elapsed       | 536           |
| total_timesteps    | 14976         |
| value_loss         | 165.60674     |
--------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b63b1e6d8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b63b1e6d8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b63aa5278>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b63aa5278>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2635 samples, validate on 333 samples
Epoch 237/5000
 - 5s - loss: 0.0235 - val_loss: 0.0247
Epoch 238/5000
 - 1s - loss: 0.0112 - val_loss: 0.0189
Epoch 239/5000
 - 1s - loss: 0.0086 - val_loss: 0.0117
Epoch 240/5000
 - 1s - loss: 0.0071 - val_loss: 0.0100
Epoch 241/5000
 - 1s - loss: 0.0065 - val_loss: 0.0092
Epoch 242/5000
 - 1s - loss: 0.0062 - val_loss: 0.0082
Epoch 243/5000
 - 1s - loss: 0.0060 - val_loss: 0.0082
Epoch 244/5000
 - 1s - loss: 0.0058 - val_loss: 0.0078
Epoch 245/5000
 - 1s - loss: 0.0056 - val_loss: 0.0077
Epoch 246/5000
 - 1s - loss: 0.0055 - val_loss: 0.0076
Epoch 247/5000
 - 1s - loss: 0.0054 - val_loss: 0.0075
Epoch 248/5000
 - 1s - loss: 0.0054 - val_loss: 0.0076
Epoch 249/5000
 - 1s - loss: 0.0044 - val_loss: 0.0031
Epoch 250/5000
 - 1s - loss: 0.0040 - val_loss: 0.0030
Epoch 251/5000
 - 1s - loss: 0.0040 - val_loss: 0.0030
Epoch 252/5000
 - 1s - loss: 0.0039 - val_loss: 0.0029
Epoch 253/5000
 - 1s - loss: 0.0039 - val_loss: 0.0029
Epoch 254/5000
 - 1s - loss: 0.0038 - val_loss: 0.0028
Epoch 255/5000
 - 1s - loss: 0.0037 - val_loss: 0.0028
Epoch 256/5000
 - 1s - loss: 0.0037 - val_loss: 0.0028
Epoch 257/5000
 - 1s - loss: 0.0037 - val_loss: 0.0028
Epoch 258/5000
 - 1s - loss: 0.0037 - val_loss: 0.0028
Epoch 259/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 260/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 261/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 262/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 263/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 264/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 265/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 266/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 267/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 268/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 269/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 270/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 271/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 272/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 273/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 274/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Epoch 275/5000
 - 1s - loss: 0.0036 - val_loss: 0.0028
Train on 2009 samples, validate on 333 samples
Epoch 215/5000
 - 5s - loss: 0.0061 - val_loss: 0.0081
Epoch 216/5000
 - 0s - loss: 0.0061 - val_loss: 0.0081
Epoch 217/5000
 - 1s - loss: 0.0061 - val_loss: 0.0081
Epoch 218/5000
 - 0s - loss: 0.0061 - val_loss: 0.0081
Epoch 219/5000
 - 1s - loss: 0.0061 - val_loss: 0.0081
Epoch 220/5000
 - 1s - loss: 0.0061 - val_loss: 0.0081
Train on 2635 samples, validate on 333 samples
Epoch 390/5000
 - 6s - loss: 0.6144 - val_loss: 0.5696
Epoch 391/5000
 - 1s - loss: 0.5378 - val_loss: 0.5607
Epoch 392/5000
 - 1s - loss: 0.5298 - val_loss: 0.5585
Epoch 393/5000
 - 1s - loss: 0.5265 - val_loss: 0.5573
Epoch 394/5000
 - 1s - loss: 0.5244 - val_loss: 0.5561
Epoch 395/5000
 - 1s - loss: 0.5235 - val_loss: 0.5555
Epoch 396/5000
 - 1s - loss: 0.5209 - val_loss: 0.5536
Epoch 397/5000
 - 1s - loss: 0.5178 - val_loss: 0.5528
Epoch 398/5000
 - 1s - loss: 0.5127 - val_loss: 0.5471
Epoch 399/5000
 - 1s - loss: 0.5000 - val_loss: 0.5404
Epoch 400/5000
 - 1s - loss: 0.4843 - val_loss: 0.5352
Epoch 401/5000
 - 1s - loss: 0.4744 - val_loss: 0.5306
Epoch 402/5000
 - 1s - loss: 0.4698 - val_loss: 0.5260
Epoch 403/5000
 - 1s - loss: 0.4673 - val_loss: 0.5219
Epoch 404/5000
 - 1s - loss: 0.4648 - val_loss: 0.5184
Epoch 405/5000
 - 1s - loss: 0.4624 - val_loss: 0.5157
Epoch 406/5000
 - 1s - loss: 0.4603 - val_loss: 0.5138
Epoch 407/5000
 - 1s - loss: 0.4587 - val_loss: 0.5123
Epoch 408/5000
 - 1s - loss: 0.4574 - val_loss: 0.5110
Epoch 409/5000
 - 1s - loss: 0.4562 - val_loss: 0.5099
Epoch 410/5000
 - 1s - loss: 0.4551 - val_loss: 0.5090
Epoch 411/5000
 - 1s - loss: 0.4541 - val_loss: 0.5084
Epoch 412/5000
 - 1s - loss: 0.4533 - val_loss: 0.5076
Epoch 413/5000
 - 1s - loss: 0.4522 - val_loss: 0.5071
Epoch 414/5000
 - 1s - loss: 0.4512 - val_loss: 0.5064
Epoch 415/5000
 - 1s - loss: 0.4507 - val_loss: 0.5056
Epoch 416/5000
 - 1s - loss: 0.4499 - val_loss: 0.5048
Epoch 417/5000
 - 1s - loss: 0.4492 - val_loss: 0.5041
Epoch 418/5000
 - 1s - loss: 0.4487 - val_loss: 0.5036
Epoch 419/5000
 - 1s - loss: 0.4482 - val_loss: 0.5031
Epoch 420/5000
 - 1s - loss: 0.4478 - val_loss: 0.5027
Epoch 421/5000
 - 1s - loss: 0.4475 - val_loss: 0.5024
Epoch 422/5000
 - 1s - loss: 0.4472 - val_loss: 0.5021
Epoch 423/5000
 - 1s - loss: 0.4469 - val_loss: 0.5018
Epoch 424/5000
 - 1s - loss: 0.4466 - val_loss: 0.5015
Epoch 425/5000
 - 1s - loss: 0.4462 - val_loss: 0.5012
Epoch 426/5000
 - 1s - loss: 0.4460 - val_loss: 0.5009
Epoch 427/5000
 - 1s - loss: 0.4458 - val_loss: 0.5005
Epoch 428/5000
 - 1s - loss: 0.4455 - val_loss: 0.5003
Epoch 429/5000
 - 1s - loss: 0.4453 - val_loss: 0.5000
Epoch 430/5000
 - 1s - loss: 0.4451 - val_loss: 0.4997
Epoch 431/5000
 - 1s - loss: 0.4453 - val_loss: 0.5001
Epoch 432/5000
 - 1s - loss: 0.4456 - val_loss: 0.4993
Epoch 433/5000
 - 1s - loss: 0.4446 - val_loss: 0.4990
Epoch 434/5000
 - 1s - loss: 0.4442 - val_loss: 0.4988
Epoch 435/5000
 - 1s - loss: 0.4440 - val_loss: 0.4986
Epoch 436/5000
 - 1s - loss: 0.4438 - val_loss: 0.4983
Epoch 437/5000
 - 1s - loss: 0.4435 - val_loss: 0.4981
Epoch 438/5000
 - 1s - loss: 0.4432 - val_loss: 0.4979
Epoch 439/5000
 - 1s - loss: 0.4429 - val_loss: 0.4977
Epoch 440/5000
 - 1s - loss: 0.4428 - val_loss: 0.4975
Epoch 441/5000
 - 1s - loss: 0.4426 - val_loss: 0.4973
Epoch 442/5000
 - 1s - loss: 0.4424 - val_loss: 0.4971
Epoch 443/5000
 - 1s - loss: 0.4423 - val_loss: 0.4969
Epoch 444/5000
 - 1s - loss: 0.4420 - val_loss: 0.4968
Epoch 445/5000
 - 1s - loss: 0.4419 - val_loss: 0.4966
Epoch 446/5000
 - 1s - loss: 0.4417 - val_loss: 0.4964
Epoch 447/5000
 - 1s - loss: 0.4416 - val_loss: 0.4962
Epoch 448/5000
 - 1s - loss: 0.4415 - val_loss: 0.4960
Epoch 449/5000
 - 1s - loss: 0.4414 - val_loss: 0.4958
Epoch 450/5000
 - 1s - loss: 0.4412 - val_loss: 0.4957
Epoch 451/5000
 - 1s - loss: 0.4411 - val_loss: 0.4955
Epoch 452/5000
 - 1s - loss: 0.4409 - val_loss: 0.4953
Epoch 453/5000
 - 1s - loss: 0.4408 - val_loss: 0.4951
Epoch 454/5000
 - 1s - loss: 0.4406 - val_loss: 0.4950
Epoch 455/5000
 - 1s - loss: 0.4405 - val_loss: 0.4948
Epoch 456/5000
 - 1s - loss: 0.4404 - val_loss: 0.4945
Epoch 457/5000
 - 1s - loss: 0.4402 - val_loss: 0.4944
Epoch 458/5000
 - 1s - loss: 0.4401 - val_loss: 0.4942
Epoch 459/5000
 - 1s - loss: 0.4400 - val_loss: 0.4940
Epoch 460/5000
 - 1s - loss: 0.4399 - val_loss: 0.4938
Epoch 461/5000
 - 1s - loss: 0.4397 - val_loss: 0.4936
Epoch 462/5000
 - 1s - loss: 0.4397 - val_loss: 0.4934
Epoch 463/5000
 - 1s - loss: 0.4396 - val_loss: 0.4932
Epoch 464/5000
 - 1s - loss: 0.4394 - val_loss: 0.4930
Epoch 465/5000
 - 1s - loss: 0.4393 - val_loss: 0.4928
Epoch 466/5000
 - 1s - loss: 0.4392 - val_loss: 0.4926
Epoch 467/5000
 - 1s - loss: 0.4390 - val_loss: 0.4924
Epoch 468/5000
 - 1s - loss: 0.4389 - val_loss: 0.4921
Epoch 469/5000
 - 1s - loss: 0.4388 - val_loss: 0.4919
Epoch 470/5000
 - 1s - loss: 0.4387 - val_loss: 0.4917
Epoch 471/5000
 - 1s - loss: 0.4386 - val_loss: 0.4915
Epoch 472/5000
 - 1s - loss: 0.4385 - val_loss: 0.4913
Epoch 473/5000
 - 1s - loss: 0.4383 - val_loss: 0.4911
Epoch 474/5000
 - 1s - loss: 0.4382 - val_loss: 0.4909
Epoch 475/5000
 - 1s - loss: 0.4382 - val_loss: 0.4906
Epoch 476/5000
 - 1s - loss: 0.4379 - val_loss: 0.4905
Epoch 477/5000
 - 1s - loss: 0.4379 - val_loss: 0.4903
Epoch 478/5000
 - 1s - loss: 0.4377 - val_loss: 0.4900
Epoch 479/5000
 - 1s - loss: 0.4375 - val_loss: 0.4898
Epoch 480/5000
 - 1s - loss: 0.4375 - val_loss: 0.4896
Epoch 481/5000
 - 1s - loss: 0.4373 - val_loss: 0.4894
Epoch 482/5000
 - 1s - loss: 0.4372 - val_loss: 0.4891
Epoch 483/5000
 - 1s - loss: 0.4370 - val_loss: 0.4889
Epoch 484/5000
 - 1s - loss: 0.4370 - val_loss: 0.4887
Epoch 485/5000
 - 1s - loss: 0.4368 - val_loss: 0.4885
Epoch 486/5000
 - 1s - loss: 0.4367 - val_loss: 0.4882
Epoch 487/5000
 - 1s - loss: 0.4367 - val_loss: 0.4879
Epoch 488/5000
 - 1s - loss: 0.4364 - val_loss: 0.4877
Epoch 489/5000
 - 1s - loss: 0.4364 - val_loss: 0.4874
Epoch 490/5000
 - 1s - loss: 0.4361 - val_loss: 0.4872
Epoch 491/5000
 - 1s - loss: 0.4361 - val_loss: 0.4870
Epoch 492/5000
 - 1s - loss: 0.4359 - val_loss: 0.4867
Epoch 493/5000
 - 1s - loss: 0.4358 - val_loss: 0.4864
Epoch 494/5000
 - 1s - loss: 0.4356 - val_loss: 0.4862
Epoch 495/5000
 - 1s - loss: 0.4356 - val_loss: 0.4859
Epoch 496/5000
 - 1s - loss: 0.4352 - val_loss: 0.4858
Epoch 497/5000
 - 1s - loss: 0.4352 - val_loss: 0.4855
Epoch 498/5000
 - 1s - loss: 0.4351 - val_loss: 0.4853
Epoch 499/5000
 - 1s - loss: 0.4350 - val_loss: 0.4850
Epoch 500/5000
 - 1s - loss: 0.4349 - val_loss: 0.4848
Epoch 501/5000
 - 1s - loss: 0.4348 - val_loss: 0.4846
Epoch 502/5000
 - 1s - loss: 0.4348 - val_loss: 0.4843
Epoch 503/5000
 - 1s - loss: 0.4344 - val_loss: 0.4842
Epoch 504/5000
 - 1s - loss: 0.4344 - val_loss: 0.4839
Epoch 505/5000
 - 1s - loss: 0.4343 - val_loss: 0.4837
Epoch 506/5000
 - 1s - loss: 0.4341 - val_loss: 0.4834
Epoch 507/5000
 - 1s - loss: 0.4340 - val_loss: 0.4832
Epoch 508/5000
 - 1s - loss: 0.4339 - val_loss: 0.4829
Epoch 509/5000
 - 1s - loss: 0.4337 - val_loss: 0.4827
Epoch 510/5000
 - 1s - loss: 0.4336 - val_loss: 0.4825
Epoch 511/5000
 - 1s - loss: 0.4334 - val_loss: 0.4823
Epoch 512/5000
 - 1s - loss: 0.4333 - val_loss: 0.4820
Epoch 513/5000
 - 1s - loss: 0.4332 - val_loss: 0.4818
Epoch 514/5000
 - 1s - loss: 0.4329 - val_loss: 0.4816
Epoch 515/5000
 - 1s - loss: 0.4329 - val_loss: 0.4813
Epoch 516/5000
 - 1s - loss: 0.4327 - val_loss: 0.4810
Epoch 517/5000
 - 1s - loss: 0.4326 - val_loss: 0.4808
Epoch 518/5000
 - 1s - loss: 0.4324 - val_loss: 0.4806
Epoch 519/5000
 - 1s - loss: 0.4323 - val_loss: 0.4803
Epoch 520/5000
 - 1s - loss: 0.4322 - val_loss: 0.4801
Epoch 521/5000
 - 1s - loss: 0.4320 - val_loss: 0.4798
Epoch 522/5000
 - 1s - loss: 0.4320 - val_loss: 0.4795
Epoch 523/5000
 - 1s - loss: 0.4317 - val_loss: 0.4792
Epoch 524/5000
 - 1s - loss: 0.4317 - val_loss: 0.4789
Epoch 525/5000
 - 1s - loss: 0.4314 - val_loss: 0.4787
Epoch 526/5000
 - 1s - loss: 0.4316 - val_loss: 0.4783
Epoch 527/5000
 - 1s - loss: 0.4313 - val_loss: 0.4780
Epoch 528/5000
 - 1s - loss: 0.4312 - val_loss: 0.4776
Epoch 529/5000
 - 1s - loss: 0.4310 - val_loss: 0.4773
Epoch 530/5000
 - 1s - loss: 0.4308 - val_loss: 0.4769
Epoch 531/5000
 - 1s - loss: 0.4306 - val_loss: 0.4766
Epoch 532/5000
 - 1s - loss: 0.4304 - val_loss: 0.4762
Epoch 533/5000
 - 1s - loss: 0.4302 - val_loss: 0.4759
Epoch 534/5000
 - 1s - loss: 0.4310 - val_loss: 0.4755
Epoch 535/5000
 - 1s - loss: 0.4294 - val_loss: 0.4752
Epoch 536/5000
 - 1s - loss: 0.4298 - val_loss: 0.4748
Epoch 537/5000
 - 1s - loss: 0.4296 - val_loss: 0.4743
Epoch 538/5000
 - 1s - loss: 0.4291 - val_loss: 0.4741
Epoch 539/5000
 - 1s - loss: 0.4293 - val_loss: 0.4736
Epoch 540/5000
 - 1s - loss: 0.4289 - val_loss: 0.4733
Epoch 541/5000
 - 1s - loss: 0.4284 - val_loss: 0.4730
Epoch 542/5000
 - 1s - loss: 0.4284 - val_loss: 0.4726
Epoch 543/5000
 - 1s - loss: 0.4285 - val_loss: 0.4721
Epoch 544/5000
 - 1s - loss: 0.4283 - val_loss: 0.4716
Epoch 545/5000
 - 1s - loss: 0.4280 - val_loss: 0.4712
Epoch 546/5000
 - 1s - loss: 0.4278 - val_loss: 0.4706
Epoch 547/5000
 - 1s - loss: 0.4276 - val_loss: 0.4702
Epoch 548/5000
 - 1s - loss: 0.4275 - val_loss: 0.4697
Epoch 549/5000
 - 1s - loss: 0.4269 - val_loss: 0.4692
Epoch 550/5000
 - 1s - loss: 0.4268 - val_loss: 0.4688
Epoch 551/5000
 - 1s - loss: 0.4265 - val_loss: 0.4683
Epoch 552/5000
 - 1s - loss: 0.4259 - val_loss: 0.4679
Epoch 553/5000
 - 1s - loss: 0.4256 - val_loss: 0.4673
Epoch 554/5000
 - 1s - loss: 0.4252 - val_loss: 0.4668
Epoch 555/5000
 - 1s - loss: 0.4248 - val_loss: 0.4664
Epoch 556/5000
 - 1s - loss: 0.4247 - val_loss: 0.4659
Epoch 557/5000
 - 1s - loss: 0.4244 - val_loss: 0.4654
Epoch 558/5000
 - 1s - loss: 0.4241 - val_loss: 0.4647
Epoch 559/5000
 - 1s - loss: 0.4237 - val_loss: 0.4642
Epoch 560/5000
 - 1s - loss: 0.4235 - val_loss: 0.4637
Epoch 561/5000
 - 1s - loss: 0.4230 - val_loss: 0.4632
Epoch 562/5000
 - 1s - loss: 0.4221 - val_loss: 0.4626
Epoch 563/5000
 - 1s - loss: 0.4225 - val_loss: 0.4614
Epoch 564/5000
 - 1s - loss: 0.4228 - val_loss: 0.4607
Epoch 565/5000
 - 1s - loss: 0.4221 - val_loss: 0.4601
Epoch 566/5000
 - 1s - loss: 0.4213 - val_loss: 0.4594
Epoch 567/5000
 - 1s - loss: 0.4211 - val_loss: 0.4588
Epoch 568/5000
 - 1s - loss: 0.4205 - val_loss: 0.4579
Epoch 569/5000
 - 1s - loss: 0.4202 - val_loss: 0.4570
Epoch 570/5000
 - 1s - loss: 0.4200 - val_loss: 0.4564
Epoch 571/5000
 - 1s - loss: 0.4194 - val_loss: 0.4558
Epoch 572/5000
 - 1s - loss: 0.4189 - val_loss: 0.4551
Epoch 573/5000
 - 1s - loss: 0.4183 - val_loss: 0.4544
Epoch 574/5000
 - 1s - loss: 0.4178 - val_loss: 0.4537
Epoch 575/5000
 - 1s - loss: 0.4172 - val_loss: 0.4526
Epoch 576/5000
 - 1s - loss: 0.4169 - val_loss: 0.4516
Epoch 577/5000
 - 1s - loss: 0.4163 - val_loss: 0.4507
Epoch 578/5000
 - 1s - loss: 0.4159 - val_loss: 0.4499
Epoch 579/5000
 - 1s - loss: 0.4152 - val_loss: 0.4491
Epoch 580/5000
 - 1s - loss: 0.4147 - val_loss: 0.4481
Epoch 581/5000
 - 1s - loss: 0.4138 - val_loss: 0.4460
Epoch 582/5000
 - 1s - loss: 0.4132 - val_loss: 0.4433
Epoch 583/5000
 - 1s - loss: 0.4123 - val_loss: 0.4391
Epoch 584/5000
 - 1s - loss: 0.4122 - val_loss: 0.4334
Epoch 585/5000
 - 1s - loss: 0.4117 - val_loss: 0.4269
Epoch 586/5000
 - 1s - loss: 0.4105 - val_loss: 0.4235
Epoch 587/5000
 - 1s - loss: 0.4122 - val_loss: 0.4205
Epoch 588/5000
 - 1s - loss: 0.4115 - val_loss: 0.4150
Epoch 589/5000
 - 1s - loss: 0.4076 - val_loss: 0.4112
Epoch 590/5000
 - 1s - loss: 0.4036 - val_loss: 0.4075
Epoch 591/5000
 - 1s - loss: 0.4002 - val_loss: 0.4055
Epoch 592/5000
 - 1s - loss: 0.3973 - val_loss: 0.4038
Epoch 593/5000
 - 1s - loss: 0.3946 - val_loss: 0.4030
Epoch 594/5000
 - 1s - loss: 0.3923 - val_loss: 0.4027
Epoch 595/5000
 - 1s - loss: 0.3902 - val_loss: 0.4030
Epoch 596/5000
 - 1s - loss: 0.3883 - val_loss: 0.4030
Epoch 597/5000
 - 1s - loss: 0.3935 - val_loss: 0.4310
Epoch 598/5000
 - 1s - loss: 0.3628 - val_loss: 0.4569
Epoch 599/5000
 - 1s - loss: 0.3592 - val_loss: 0.4630
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0030150558 |
| clipfrac           | 0.0234375    |
| explained_variance | -1.67e-06    |
| fps                | 5            |
| n_updates          | 1            |
| policy_entropy     | 1.0743008    |
| policy_loss        | -0.009591713 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.29e-05     |
| total_timesteps    | 128          |
| value_loss         | 105.60914    |
-------------------------------------
------------------------------------
| approxkl           | 0.03136836  |
| clipfrac           | 0.34570312  |
| explained_variance | 2.86e-06    |
| fps                | 28          |
| n_updates          | 2           |
| policy_entropy     | 1.073094    |
| policy_loss        | 0.029684823 |
| serial_timesteps   | 256         |
| time_elapsed       | 25.6        |
| total_timesteps    | 256         |
| value_loss         | 148.77307   |
------------------------------------
An average of 139.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.035790265  |
| clipfrac           | 0.37890625   |
| explained_variance | -7.15e-07    |
| fps                | 29           |
| n_updates          | 3            |
| policy_entropy     | 1.0728045    |
| policy_loss        | 0.0065202275 |
| serial_timesteps   | 384          |
| time_elapsed       | 30.1         |
| total_timesteps    | 384          |
| value_loss         | 118.31633    |
-------------------------------------
------------------------------------
| approxkl           | 0.004315267 |
| clipfrac           | 0.05078125  |
| explained_variance | 0           |
| fps                | 28          |
| n_updates          | 4           |
| policy_entropy     | 1.0736513   |
| policy_loss        | 0.018009555 |
| serial_timesteps   | 512         |
| time_elapsed       | 34.5        |
| total_timesteps    | 512         |
| value_loss         | 116.73877   |
------------------------------------
--------------------------------------
| approxkl           | 0.004776652   |
| clipfrac           | 0.056640625   |
| explained_variance | -1.79e-06     |
| fps                | 28            |
| n_updates          | 5             |
| policy_entropy     | 1.071231      |
| policy_loss        | -0.0034365084 |
| serial_timesteps   | 640           |
| time_elapsed       | 39            |
| total_timesteps    | 640           |
| value_loss         | 112.60125     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00025618976 |
| clipfrac           | 0.0           |
| explained_variance | -4.77e-06     |
| fps                | 27            |
| n_updates          | 6             |
| policy_entropy     | 1.0697005     |
| policy_loss        | 0.000757528   |
| serial_timesteps   | 768           |
| time_elapsed       | 43.5          |
| total_timesteps    | 768           |
| value_loss         | 173.76291     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0021536646 |
| clipfrac           | 0.017578125  |
| explained_variance | -1.19e-06    |
| fps                | 28           |
| n_updates          | 7            |
| policy_entropy     | 1.0693234    |
| policy_loss        | -0.006329428 |
| serial_timesteps   | 896          |
| time_elapsed       | 48.1         |
| total_timesteps    | 896          |
| value_loss         | 127.17765    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068583456 |
| clipfrac           | 0.08203125   |
| explained_variance | -1.19e-07    |
| fps                | 28           |
| n_updates          | 8            |
| policy_entropy     | 1.0658554    |
| policy_loss        | 0.014707093  |
| serial_timesteps   | 1024         |
| time_elapsed       | 52.5         |
| total_timesteps    | 1024         |
| value_loss         | 139.66913    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011709638  |
| clipfrac           | 0.15429688   |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 9            |
| policy_entropy     | 1.0638196    |
| policy_loss        | -0.008953272 |
| serial_timesteps   | 1152         |
| time_elapsed       | 57           |
| total_timesteps    | 1152         |
| value_loss         | 135.82481    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0010881913 |
| clipfrac           | 0.001953125  |
| explained_variance | -1.07e-06    |
| fps                | 27           |
| n_updates          | 10           |
| policy_entropy     | 1.064189     |
| policy_loss        | 0.0034697936 |
| serial_timesteps   | 1280         |
| time_elapsed       | 61.3         |
| total_timesteps    | 1280         |
| value_loss         | 160.96744    |
-------------------------------------
An average of 139.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.015877806   |
| clipfrac           | 0.1953125     |
| explained_variance | 4.17e-07      |
| fps                | 29            |
| n_updates          | 11            |
| policy_entropy     | 1.063302      |
| policy_loss        | -0.0068155066 |
| serial_timesteps   | 1408          |
| time_elapsed       | 65.9          |
| total_timesteps    | 1408          |
| value_loss         | 185.01498     |
--------------------------------------
------------------------------------
| approxkl           | 0.024764955 |
| clipfrac           | 0.265625    |
| explained_variance | 1.49e-06    |
| fps                | 29          |
| n_updates          | 12          |
| policy_entropy     | 1.0631001   |
| policy_loss        | 0.012225753 |
| serial_timesteps   | 1536        |
| time_elapsed       | 70.3        |
| total_timesteps    | 1536        |
| value_loss         | 149.40062   |
------------------------------------
--------------------------------------
| approxkl           | 0.015956448   |
| clipfrac           | 0.27148438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.66e+03      |
| explained_variance | -1.19e-07     |
| fps                | 29            |
| n_updates          | 13            |
| policy_entropy     | 1.0630233     |
| policy_loss        | -0.0068018176 |
| serial_timesteps   | 1664          |
| time_elapsed       | 74.6          |
| total_timesteps    | 1664          |
| value_loss         | 1454.6686     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0022089996 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.66e+03     |
| explained_variance | -2.38e-07    |
| fps                | 29           |
| n_updates          | 14           |
| policy_entropy     | 1.063006     |
| policy_loss        | 0.0005195644 |
| serial_timesteps   | 1792         |
| time_elapsed       | 78.9         |
| total_timesteps    | 1792         |
| value_loss         | 140.42838    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00036006654  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.66e+03       |
| explained_variance | -5.25e-06      |
| fps                | 27             |
| n_updates          | 15             |
| policy_entropy     | 1.0627509      |
| policy_loss        | -0.00054262177 |
| serial_timesteps   | 1920           |
| time_elapsed       | 83.2           |
| total_timesteps    | 1920           |
| value_loss         | 115.388756     |
---------------------------------------
---------------------------------------
| approxkl           | 0.00044794567  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.66e+03       |
| explained_variance | 3.16e-06       |
| fps                | 27             |
| n_updates          | 16             |
| policy_entropy     | 1.0585256      |
| policy_loss        | -0.00076985836 |
| serial_timesteps   | 2048           |
| time_elapsed       | 87.8           |
| total_timesteps    | 2048           |
| value_loss         | 143.54395      |
---------------------------------------
-------------------------------------
| approxkl           | 0.046893083  |
| clipfrac           | 0.43554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.66e+03     |
| explained_variance | 1.13e-06     |
| fps                | 27           |
| n_updates          | 17           |
| policy_entropy     | 1.0553005    |
| policy_loss        | -0.007139826 |
| serial_timesteps   | 2176         |
| time_elapsed       | 92.5         |
| total_timesteps    | 2176         |
| value_loss         | 128.793      |
-------------------------------------
-------------------------------------
| approxkl           | 0.031682674  |
| clipfrac           | 0.3203125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.66e+03     |
| explained_variance | 1.19e-07     |
| fps                | 27           |
| n_updates          | 18           |
| policy_entropy     | 1.0540842    |
| policy_loss        | 0.0022699712 |
| serial_timesteps   | 2304         |
| time_elapsed       | 97.1         |
| total_timesteps    | 2304         |
| value_loss         | 129.32146    |
-------------------------------------
An average of 140.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 5.735754e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.66e+03       |
| explained_variance | 0              |
| fps                | 27             |
| n_updates          | 19             |
| policy_entropy     | 1.0533595      |
| policy_loss        | -0.00044383318 |
| serial_timesteps   | 2432           |
| time_elapsed       | 102            |
| total_timesteps    | 2432           |
| value_loss         | 155.54904      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0002888279 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.66e+03     |
| explained_variance | -3.46e-06    |
| fps                | 27           |
| n_updates          | 20           |
| policy_entropy     | 1.0526806    |
| policy_loss        | 0.0011142879 |
| serial_timesteps   | 2560         |
| time_elapsed       | 106          |
| total_timesteps    | 2560         |
| value_loss         | 122.13493    |
-------------------------------------
--------------------------------------
| approxkl           | 5.234249e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.66e+03      |
| explained_variance | 0             |
| fps                | 27            |
| n_updates          | 21            |
| policy_entropy     | 1.0521191     |
| policy_loss        | 0.00031015195 |
| serial_timesteps   | 2688          |
| time_elapsed       | 111           |
| total_timesteps    | 2688          |
| value_loss         | 151.78566     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0014469859 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.66e+03     |
| explained_variance | 2.15e-06     |
| fps                | 27           |
| n_updates          | 22           |
| policy_entropy     | 1.0515904    |
| policy_loss        | -0.005828931 |
| serial_timesteps   | 2816         |
| time_elapsed       | 116          |
| total_timesteps    | 2816         |
| value_loss         | 106.30754    |
-------------------------------------
------------------------------------
| approxkl           | 0.032526944 |
| clipfrac           | 0.37695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.66e+03    |
| explained_variance | 4.23e-06    |
| fps                | 29          |
| n_updates          | 23          |
| policy_entropy     | 1.0507643   |
| policy_loss        | 0.017493982 |
| serial_timesteps   | 2944        |
| time_elapsed       | 120         |
| total_timesteps    | 2944        |
| value_loss         | 152.77327   |
------------------------------------
-------------------------------------
| approxkl           | 0.04319339   |
| clipfrac           | 0.39453125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.66e+03     |
| explained_variance | -2.62e-06    |
| fps                | 27           |
| n_updates          | 24           |
| policy_entropy     | 1.0502983    |
| policy_loss        | -0.013965787 |
| serial_timesteps   | 3072         |
| time_elapsed       | 125          |
| total_timesteps    | 3072         |
| value_loss         | 109.2849     |
-------------------------------------
--------------------------------------
| approxkl           | 0.020472046   |
| clipfrac           | 0.27734375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 0             |
| fps                | 27            |
| n_updates          | 25            |
| policy_entropy     | 1.0506283     |
| policy_loss        | -0.0058937315 |
| serial_timesteps   | 3200          |
| time_elapsed       | 129           |
| total_timesteps    | 3200          |
| value_loss         | 1942.4174     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005604871  |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | -9.54e-07    |
| fps                | 27           |
| n_updates          | 26           |
| policy_entropy     | 1.051003     |
| policy_loss        | -0.009129234 |
| serial_timesteps   | 3328         |
| time_elapsed       | 134          |
| total_timesteps    | 3328         |
| value_loss         | 102.15556    |
-------------------------------------
An average of 141.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.000115072195 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.67e+03       |
| explained_variance | -2.38e-07      |
| fps                | 28             |
| n_updates          | 27             |
| policy_entropy     | 1.0508392      |
| policy_loss        | 0.00069736247  |
| serial_timesteps   | 3456           |
| time_elapsed       | 139            |
| total_timesteps    | 3456           |
| value_loss         | 130.96281      |
---------------------------------------
------------------------------------
| approxkl           | 0.011077694 |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 6.56e-07    |
| fps                | 28          |
| n_updates          | 28          |
| policy_entropy     | 1.0487344   |
| policy_loss        | 0.018864514 |
| serial_timesteps   | 3584        |
| time_elapsed       | 143         |
| total_timesteps    | 3584        |
| value_loss         | 137.35423   |
------------------------------------
--------------------------------------
| approxkl           | 0.0032189717  |
| clipfrac           | 0.029296875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 3.4e-06       |
| fps                | 28            |
| n_updates          | 29            |
| policy_entropy     | 1.0471174     |
| policy_loss        | -0.0078954045 |
| serial_timesteps   | 3712          |
| time_elapsed       | 147           |
| total_timesteps    | 3712          |
| value_loss         | 75.14092      |
--------------------------------------
-------------------------------------
| approxkl           | 0.013499142  |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | 0            |
| fps                | 27           |
| n_updates          | 30           |
| policy_entropy     | 1.046335     |
| policy_loss        | -0.027139282 |
| serial_timesteps   | 3840         |
| time_elapsed       | 152          |
| total_timesteps    | 3840         |
| value_loss         | 105.96403    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005881898  |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | -7.15e-07    |
| fps                | 29           |
| n_updates          | 31           |
| policy_entropy     | 1.0457643    |
| policy_loss        | -0.008688011 |
| serial_timesteps   | 3968         |
| time_elapsed       | 157          |
| total_timesteps    | 3968         |
| value_loss         | 115.81293    |
-------------------------------------
---------------------------------------
| approxkl           | 3.4070734e-05  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.67e+03       |
| explained_variance | 7.75e-07       |
| fps                | 28             |
| n_updates          | 32             |
| policy_entropy     | 1.0449611      |
| policy_loss        | -5.9648068e-05 |
| serial_timesteps   | 4096           |
| time_elapsed       | 161            |
| total_timesteps    | 4096           |
| value_loss         | 149.49068      |
---------------------------------------
------------------------------------
| approxkl           | 0.016667295 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 5.66e-06    |
| fps                | 27          |
| n_updates          | 33          |
| policy_entropy     | 1.0432746   |
| policy_loss        | 0.01860932  |
| serial_timesteps   | 4224        |
| time_elapsed       | 166         |
| total_timesteps    | 4224        |
| value_loss         | 124.248085  |
------------------------------------
An average of 141.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.036325872  |
| clipfrac           | 0.4140625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | -3.58e-07    |
| fps                | 27           |
| n_updates          | 34           |
| policy_entropy     | 1.0424168    |
| policy_loss        | 0.0043324297 |
| serial_timesteps   | 4352         |
| time_elapsed       | 170          |
| total_timesteps    | 4352         |
| value_loss         | 130.98663    |
-------------------------------------
------------------------------------
| approxkl           | 0.02599281  |
| clipfrac           | 0.33789062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 3.46e-06    |
| fps                | 28          |
| n_updates          | 35          |
| policy_entropy     | 1.0420558   |
| policy_loss        | 0.025420265 |
| serial_timesteps   | 4480        |
| time_elapsed       | 175         |
| total_timesteps    | 4480        |
| value_loss         | 125.75378   |
------------------------------------
------------------------------------
| approxkl           | 0.030062452 |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 36          |
| policy_entropy     | 1.0418005   |
| policy_loss        | 0.027477048 |
| serial_timesteps   | 4608        |
| time_elapsed       | 179         |
| total_timesteps    | 4608        |
| value_loss         | 186.33061   |
------------------------------------
------------------------------------
| approxkl           | 0.023763306 |
| clipfrac           | 0.296875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | -1.19e-07   |
| fps                | 29          |
| n_updates          | 37          |
| policy_entropy     | 1.0417575   |
| policy_loss        | 0.010188041 |
| serial_timesteps   | 4736        |
| time_elapsed       | 184         |
| total_timesteps    | 4736        |
| value_loss         | 2174.4158   |
------------------------------------
--------------------------------------
| approxkl           | 0.00041588477 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | -9.54e-07     |
| fps                | 28            |
| n_updates          | 38            |
| policy_entropy     | 1.0417582     |
| policy_loss        | -0.0029160655 |
| serial_timesteps   | 4864          |
| time_elapsed       | 188           |
| total_timesteps    | 4864          |
| value_loss         | 135.04132     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0022016692  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 4.29e-06      |
| fps                | 28            |
| n_updates          | 39            |
| policy_entropy     | 1.0416627     |
| policy_loss        | -0.0036512096 |
| serial_timesteps   | 4992          |
| time_elapsed       | 193           |
| total_timesteps    | 4992          |
| value_loss         | 177.33986     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0028511826 |
| clipfrac           | 0.0234375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | 5.01e-06     |
| fps                | 26           |
| n_updates          | 40           |
| policy_entropy     | 1.041357     |
| policy_loss        | -0.007549006 |
| serial_timesteps   | 5120         |
| time_elapsed       | 197          |
| total_timesteps    | 5120         |
| value_loss         | 134.9154     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0025771488 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | -9.54e-07    |
| fps                | 27           |
| n_updates          | 41           |
| policy_entropy     | 1.0409042    |
| policy_loss        | -0.00540471  |
| serial_timesteps   | 5248         |
| time_elapsed       | 202          |
| total_timesteps    | 5248         |
| value_loss         | 134.87016    |
-------------------------------------
An average of 142.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.009340927 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | -3.58e-07   |
| fps                | 28          |
| n_updates          | 42          |
| policy_entropy     | 1.0410192   |
| policy_loss        | 0.022353992 |
| serial_timesteps   | 5376        |
| time_elapsed       | 207         |
| total_timesteps    | 5376        |
| value_loss         | 122.75894   |
------------------------------------
--------------------------------------
| approxkl           | 0.06107069    |
| clipfrac           | 0.44140625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 3.58e-07      |
| fps                | 25            |
| n_updates          | 43            |
| policy_entropy     | 1.0410826     |
| policy_loss        | -0.0074326764 |
| serial_timesteps   | 5504          |
| time_elapsed       | 211           |
| total_timesteps    | 5504          |
| value_loss         | 128.96072     |
--------------------------------------
------------------------------------
| approxkl           | 0.021332905 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | -2.38e-07   |
| fps                | 27          |
| n_updates          | 44          |
| policy_entropy     | 1.0409367   |
| policy_loss        | 0.020955201 |
| serial_timesteps   | 5632        |
| time_elapsed       | 216         |
| total_timesteps    | 5632        |
| value_loss         | 152.34819   |
------------------------------------
-----------------------------------
| approxkl           | 0.0314274  |
| clipfrac           | 0.35546875 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.67e+03   |
| explained_variance | 1.61e-06   |
| fps                | 29         |
| n_updates          | 45         |
| policy_entropy     | 1.0406053  |
| policy_loss        | 0.02520768 |
| serial_timesteps   | 5760       |
| time_elapsed       | 221        |
| total_timesteps    | 5760       |
| value_loss         | 116.590324 |
-----------------------------------
--------------------------------------
| approxkl           | 0.0015100968  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 1.19e-07      |
| fps                | 28            |
| n_updates          | 46            |
| policy_entropy     | 1.0398848     |
| policy_loss        | -0.0018460955 |
| serial_timesteps   | 5888          |
| time_elapsed       | 226           |
| total_timesteps    | 5888          |
| value_loss         | 150.84518     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0007976807  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | -2.98e-06     |
| fps                | 29            |
| n_updates          | 47            |
| policy_entropy     | 1.0387808     |
| policy_loss        | -0.0024955377 |
| serial_timesteps   | 6016          |
| time_elapsed       | 230           |
| total_timesteps    | 6016          |
| value_loss         | 90.20792      |
--------------------------------------
------------------------------------
| approxkl           | 0.031707447 |
| clipfrac           | 0.3828125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 2.98e-07    |
| fps                | 29          |
| n_updates          | 48          |
| policy_entropy     | 1.0376464   |
| policy_loss        | 0.024703557 |
| serial_timesteps   | 6144        |
| time_elapsed       | 234         |
| total_timesteps    | 6144        |
| value_loss         | 96.96387    |
------------------------------------
------------------------------------
| approxkl           | 0.023715414 |
| clipfrac           | 0.26757812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | -1.19e-07   |
| fps                | 27          |
| n_updates          | 49          |
| policy_entropy     | 1.0372598   |
| policy_loss        | 0.008846244 |
| serial_timesteps   | 6272        |
| time_elapsed       | 239         |
| total_timesteps    | 6272        |
| value_loss         | 2207.658    |
------------------------------------
An average of 143.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0034984564 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.68e+03     |
| explained_variance | 2.09e-06     |
| fps                | 28           |
| n_updates          | 50           |
| policy_entropy     | 1.037234     |
| policy_loss        | 0.010866756  |
| serial_timesteps   | 6400         |
| time_elapsed       | 244          |
| total_timesteps    | 6400         |
| value_loss         | 118.48251    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0005668428  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.68e+03      |
| explained_variance | -1.19e-06     |
| fps                | 28            |
| n_updates          | 51            |
| policy_entropy     | 1.0370532     |
| policy_loss        | 0.00031623675 |
| serial_timesteps   | 6528          |
| time_elapsed       | 248           |
| total_timesteps    | 6528          |
| value_loss         | 136.51688     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00015883529 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.68e+03      |
| explained_variance | -9.54e-07     |
| fps                | 29            |
| n_updates          | 52            |
| policy_entropy     | 1.0364066     |
| policy_loss        | -4.948757e-05 |
| serial_timesteps   | 6656          |
| time_elapsed       | 253           |
| total_timesteps    | 6656          |
| value_loss         | 155.79825     |
--------------------------------------
------------------------------------
| approxkl           | 0.018749071 |
| clipfrac           | 0.28320312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | 4.47e-06    |
| fps                | 28          |
| n_updates          | 53          |
| policy_entropy     | 1.0362071   |
| policy_loss        | 0.022991857 |
| serial_timesteps   | 6784        |
| time_elapsed       | 257         |
| total_timesteps    | 6784        |
| value_loss         | 113.808495  |
------------------------------------
------------------------------------
| approxkl           | 0.029653003 |
| clipfrac           | 0.32617188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | 2.8e-06     |
| fps                | 29          |
| n_updates          | 54          |
| policy_entropy     | 1.0360124   |
| policy_loss        | 0.017852312 |
| serial_timesteps   | 6912        |
| time_elapsed       | 261         |
| total_timesteps    | 6912        |
| value_loss         | 111.65842   |
------------------------------------
------------------------------------
| approxkl           | 0.018780079 |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | 0           |
| fps                | 26          |
| n_updates          | 55          |
| policy_entropy     | 1.0355569   |
| policy_loss        | 0.03505782  |
| serial_timesteps   | 7040        |
| time_elapsed       | 266         |
| total_timesteps    | 7040        |
| value_loss         | 124.25595   |
------------------------------------
------------------------------------
| approxkl           | 0.035165478 |
| clipfrac           | 0.41796875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | 2.98e-07    |
| fps                | 30          |
| n_updates          | 56          |
| policy_entropy     | 1.0352168   |
| policy_loss        | 0.021938255 |
| serial_timesteps   | 7168        |
| time_elapsed       | 271         |
| total_timesteps    | 7168        |
| value_loss         | 115.95522   |
------------------------------------
------------------------------------
| approxkl           | 0.013569947 |
| clipfrac           | 0.21289062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | -3.58e-07   |
| fps                | 27          |
| n_updates          | 57          |
| policy_entropy     | 1.0345675   |
| policy_loss        | 0.038861167 |
| serial_timesteps   | 7296        |
| time_elapsed       | 275         |
| total_timesteps    | 7296        |
| value_loss         | 87.80079    |
------------------------------------
An average of 143.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.042827245 |
| clipfrac           | 0.44140625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | -3.22e-06   |
| fps                | 28          |
| n_updates          | 58          |
| policy_entropy     | 1.0334119   |
| policy_loss        | 0.029097745 |
| serial_timesteps   | 7424        |
| time_elapsed       | 279         |
| total_timesteps    | 7424        |
| value_loss         | 102.56826   |
------------------------------------
------------------------------------
| approxkl           | 0.027569797 |
| clipfrac           | 0.37695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | -1.91e-06   |
| fps                | 26          |
| n_updates          | 59          |
| policy_entropy     | 1.032467    |
| policy_loss        | 0.028719787 |
| serial_timesteps   | 7552        |
| time_elapsed       | 284         |
| total_timesteps    | 7552        |
| value_loss         | 126.588974  |
------------------------------------
------------------------------------
| approxkl           | 0.028439002 |
| clipfrac           | 0.3671875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.68e+03    |
| explained_variance | -1.19e-07   |
| fps                | 28          |
| n_updates          | 60          |
| policy_entropy     | 1.0319439   |
| policy_loss        | 0.025563546 |
| serial_timesteps   | 7680        |
| time_elapsed       | 289         |
| total_timesteps    | 7680        |
| value_loss         | 129.20825   |
------------------------------------
------------------------------------
| approxkl           | 0.039274275 |
| clipfrac           | 0.421875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | 0           |
| fps                | 28          |
| n_updates          | 61          |
| policy_entropy     | 1.031594    |
| policy_loss        | 0.01939045  |
| serial_timesteps   | 7808        |
| time_elapsed       | 293         |
| total_timesteps    | 7808        |
| value_loss         | 2257.5017   |
------------------------------------
---------------------------------------
| approxkl           | 0.00019332748  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.69e+03       |
| explained_variance | 0              |
| fps                | 30             |
| n_updates          | 62             |
| policy_entropy     | 1.0313894      |
| policy_loss        | -0.00040378806 |
| serial_timesteps   | 7936           |
| time_elapsed       | 298            |
| total_timesteps    | 7936           |
| value_loss         | 121.52219      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0012247626  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.69e+03      |
| explained_variance | 8.94e-07      |
| fps                | 28            |
| n_updates          | 63            |
| policy_entropy     | 1.0310612     |
| policy_loss        | -0.0026321076 |
| serial_timesteps   | 8064          |
| time_elapsed       | 302           |
| total_timesteps    | 8064          |
| value_loss         | 132.58144     |
--------------------------------------
---------------------------------------
| approxkl           | 6.768562e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.69e+03       |
| explained_variance | -2.38e-07      |
| fps                | 28             |
| n_updates          | 64             |
| policy_entropy     | 1.0307391      |
| policy_loss        | -0.00019710767 |
| serial_timesteps   | 8192           |
| time_elapsed       | 307            |
| total_timesteps    | 8192           |
| value_loss         | 142.20508      |
---------------------------------------
------------------------------------
| approxkl           | 0.018359838 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | -1.79e-06   |
| fps                | 28          |
| n_updates          | 65          |
| policy_entropy     | 1.0295944   |
| policy_loss        | 0.015613254 |
| serial_timesteps   | 8320        |
| time_elapsed       | 311         |
| total_timesteps    | 8320        |
| value_loss         | 166.06197   |
------------------------------------
An average of 144.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.022864902 |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | 4.17e-07    |
| fps                | 27          |
| n_updates          | 66          |
| policy_entropy     | 1.0290216   |
| policy_loss        | 0.03564562  |
| serial_timesteps   | 8448        |
| time_elapsed       | 316         |
| total_timesteps    | 8448        |
| value_loss         | 101.15277   |
------------------------------------
------------------------------------
| approxkl           | 0.01725083  |
| clipfrac           | 0.23242188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | 1.61e-06    |
| fps                | 26          |
| n_updates          | 67          |
| policy_entropy     | 1.0283407   |
| policy_loss        | 0.048073012 |
| serial_timesteps   | 8576        |
| time_elapsed       | 320         |
| total_timesteps    | 8576        |
| value_loss         | 106.26014   |
------------------------------------
------------------------------------
| approxkl           | 0.058408797 |
| clipfrac           | 0.5019531   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | -1.79e-06   |
| fps                | 29          |
| n_updates          | 68          |
| policy_entropy     | 1.0272481   |
| policy_loss        | 0.04339414  |
| serial_timesteps   | 8704        |
| time_elapsed       | 325         |
| total_timesteps    | 8704        |
| value_loss         | 115.46965   |
------------------------------------
------------------------------------
| approxkl           | 0.023811605 |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | 2.98e-07    |
| fps                | 26          |
| n_updates          | 69          |
| policy_entropy     | 1.0264883   |
| policy_loss        | 0.039890707 |
| serial_timesteps   | 8832        |
| time_elapsed       | 329         |
| total_timesteps    | 8832        |
| value_loss         | 152.43425   |
------------------------------------
------------------------------------
| approxkl           | 0.039165538 |
| clipfrac           | 0.45898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | 1.85e-06    |
| fps                | 30          |
| n_updates          | 70          |
| policy_entropy     | 1.0259559   |
| policy_loss        | 0.030197784 |
| serial_timesteps   | 8960        |
| time_elapsed       | 334         |
| total_timesteps    | 8960        |
| value_loss         | 123.51422   |
------------------------------------
------------------------------------
| approxkl           | 0.039739482 |
| clipfrac           | 0.37890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | -5.72e-06   |
| fps                | 26          |
| n_updates          | 71          |
| policy_entropy     | 1.0258338   |
| policy_loss        | 0.02139891  |
| serial_timesteps   | 9088        |
| time_elapsed       | 338         |
| total_timesteps    | 9088        |
| value_loss         | 145.1722    |
------------------------------------
------------------------------------
| approxkl           | 0.022793988 |
| clipfrac           | 0.31054688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.69e+03    |
| explained_variance | -5.48e-06   |
| fps                | 26          |
| n_updates          | 72          |
| policy_entropy     | 1.0255826   |
| policy_loss        | 0.043051526 |
| serial_timesteps   | 9216        |
| time_elapsed       | 343         |
| total_timesteps    | 9216        |
| value_loss         | 140.99416   |
------------------------------------
An average of 145.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.0440311   |
| clipfrac           | 0.40820312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | 5.96e-08    |
| fps                | 26          |
| n_updates          | 73          |
| policy_entropy     | 1.0250823   |
| policy_loss        | 0.018935248 |
| serial_timesteps   | 9344        |
| time_elapsed       | 348         |
| total_timesteps    | 9344        |
| value_loss         | 2236.241    |
------------------------------------
-------------------------------------
| approxkl           | 0.011307673  |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 1.25e-06     |
| fps                | 29           |
| n_updates          | 74           |
| policy_entropy     | 1.0248616    |
| policy_loss        | -0.017909253 |
| serial_timesteps   | 9472         |
| time_elapsed       | 353          |
| total_timesteps    | 9472         |
| value_loss         | 79.46393     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0012848913 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 4.17e-06     |
| fps                | 27           |
| n_updates          | 75           |
| policy_entropy     | 1.0247008    |
| policy_loss        | -0.003100325 |
| serial_timesteps   | 9600         |
| time_elapsed       | 357          |
| total_timesteps    | 9600         |
| value_loss         | 133.99896    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00043282297 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.71e+03      |
| explained_variance | -3.81e-06     |
| fps                | 27            |
| n_updates          | 76            |
| policy_entropy     | 1.0237372     |
| policy_loss        | -0.0016067072 |
| serial_timesteps   | 9728          |
| time_elapsed       | 362           |
| total_timesteps    | 9728          |
| value_loss         | 145.10535     |
--------------------------------------
------------------------------------
| approxkl           | 0.023547962 |
| clipfrac           | 0.27734375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | -5.96e-07   |
| fps                | 29          |
| n_updates          | 77          |
| policy_entropy     | 1.0224705   |
| policy_loss        | 0.007951433 |
| serial_timesteps   | 9856        |
| time_elapsed       | 366         |
| total_timesteps    | 9856        |
| value_loss         | 143.97644   |
------------------------------------
--------------------------------------
| approxkl           | 0.036176413   |
| clipfrac           | 0.359375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.71e+03      |
| explained_variance | -2.74e-06     |
| fps                | 29            |
| n_updates          | 78            |
| policy_entropy     | 1.0217316     |
| policy_loss        | -0.0010594972 |
| serial_timesteps   | 9984          |
| time_elapsed       | 371           |
| total_timesteps    | 9984          |
| value_loss         | 117.8007      |
--------------------------------------
------------------------------------
| approxkl           | 0.028935153 |
| clipfrac           | 0.3359375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | 5.9e-06     |
| fps                | 27          |
| n_updates          | 79          |
| policy_entropy     | 1.0215571   |
| policy_loss        | 0.018960958 |
| serial_timesteps   | 10112       |
| time_elapsed       | 375         |
| total_timesteps    | 10112       |
| value_loss         | 116.664825  |
------------------------------------
------------------------------------
| approxkl           | 0.04167354  |
| clipfrac           | 0.37890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | -4.77e-07   |
| fps                | 30          |
| n_updates          | 80          |
| policy_entropy     | 1.0214106   |
| policy_loss        | 0.029313836 |
| serial_timesteps   | 10240       |
| time_elapsed       | 379         |
| total_timesteps    | 10240       |
| value_loss         | 109.78968   |
------------------------------------
An average of 145.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.04155286  |
| clipfrac           | 0.45898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | 1.19e-07    |
| fps                | 28          |
| n_updates          | 81          |
| policy_entropy     | 1.0211264   |
| policy_loss        | 0.020961244 |
| serial_timesteps   | 10368       |
| time_elapsed       | 384         |
| total_timesteps    | 10368       |
| value_loss         | 87.57188    |
------------------------------------
------------------------------------
| approxkl           | 0.023115011 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | -2.03e-06   |
| fps                | 28          |
| n_updates          | 82          |
| policy_entropy     | 1.0207961   |
| policy_loss        | 0.0386336   |
| serial_timesteps   | 10496       |
| time_elapsed       | 388         |
| total_timesteps    | 10496       |
| value_loss         | 161.78822   |
------------------------------------
------------------------------------
| approxkl           | 0.03400151  |
| clipfrac           | 0.43359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | 1.79e-06    |
| fps                | 30          |
| n_updates          | 83          |
| policy_entropy     | 1.0206541   |
| policy_loss        | 0.024019022 |
| serial_timesteps   | 10624       |
| time_elapsed       | 393         |
| total_timesteps    | 10624       |
| value_loss         | 117.478584  |
------------------------------------
------------------------------------
| approxkl           | 0.02354472  |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | -5.96e-07   |
| fps                | 26          |
| n_updates          | 84          |
| policy_entropy     | 1.0204477   |
| policy_loss        | 0.046316158 |
| serial_timesteps   | 10752       |
| time_elapsed       | 397         |
| total_timesteps    | 10752       |
| value_loss         | 144.46896   |
------------------------------------
------------------------------------
| approxkl           | 0.045177747 |
| clipfrac           | 0.421875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 0           |
| fps                | 28          |
| n_updates          | 85          |
| policy_entropy     | 1.0203835   |
| policy_loss        | 0.02101326  |
| serial_timesteps   | 10880       |
| time_elapsed       | 402         |
| total_timesteps    | 10880       |
| value_loss         | 2324.5894   |
------------------------------------
---------------------------------------
| approxkl           | 1.34544825e-05 |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.72e+03       |
| explained_variance | -1.43e-06      |
| fps                | 29             |
| n_updates          | 86             |
| policy_entropy     | 1.020387       |
| policy_loss        | -5.4836855e-05 |
| serial_timesteps   | 11008          |
| time_elapsed       | 406            |
| total_timesteps    | 11008          |
| value_loss         | 100.62987      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0041141026  |
| clipfrac           | 0.0390625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.72e+03      |
| explained_variance | -2.03e-06     |
| fps                | 28            |
| n_updates          | 87            |
| policy_entropy     | 1.0201933     |
| policy_loss        | -0.0060468856 |
| serial_timesteps   | 11136         |
| time_elapsed       | 411           |
| total_timesteps    | 11136         |
| value_loss         | 90.98945      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00079822546 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.72e+03      |
| explained_variance | -7.15e-07     |
| fps                | 28            |
| n_updates          | 88            |
| policy_entropy     | 1.0201358     |
| policy_loss        | -0.002914291  |
| serial_timesteps   | 11264         |
| time_elapsed       | 415           |
| total_timesteps    | 11264         |
| value_loss         | 135.99895     |
--------------------------------------
An average of 146.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.019316817 |
| clipfrac           | 0.26171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -3.58e-07   |
| fps                | 28          |
| n_updates          | 89          |
| policy_entropy     | 1.019576    |
| policy_loss        | 0.037053157 |
| serial_timesteps   | 11392       |
| time_elapsed       | 420         |
| total_timesteps    | 11392       |
| value_loss         | 100.64888   |
------------------------------------
------------------------------------
| approxkl           | 0.036820788 |
| clipfrac           | 0.38867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -1.07e-06   |
| fps                | 27          |
| n_updates          | 90          |
| policy_entropy     | 1.0187316   |
| policy_loss        | 0.018402088 |
| serial_timesteps   | 11520       |
| time_elapsed       | 424         |
| total_timesteps    | 11520       |
| value_loss         | 101.581505  |
------------------------------------
------------------------------------
| approxkl           | 0.014731658 |
| clipfrac           | 0.22265625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 1.79e-07    |
| fps                | 29          |
| n_updates          | 91          |
| policy_entropy     | 1.0178136   |
| policy_loss        | 0.034261063 |
| serial_timesteps   | 11648       |
| time_elapsed       | 429         |
| total_timesteps    | 11648       |
| value_loss         | 74.5747     |
------------------------------------
-------------------------------------
| approxkl           | 0.05872962   |
| clipfrac           | 0.5019531    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | -2.15e-06    |
| fps                | 30           |
| n_updates          | 92           |
| policy_entropy     | 1.0169007    |
| policy_loss        | 0.0051677576 |
| serial_timesteps   | 11776        |
| time_elapsed       | 433          |
| total_timesteps    | 11776        |
| value_loss         | 82.348854    |
-------------------------------------
------------------------------------
| approxkl           | 0.017750384 |
| clipfrac           | 0.26953125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -3.46e-06   |
| fps                | 29          |
| n_updates          | 93          |
| policy_entropy     | 1.0168276   |
| policy_loss        | 0.011100553 |
| serial_timesteps   | 11904       |
| time_elapsed       | 437         |
| total_timesteps    | 11904       |
| value_loss         | 95.95836    |
------------------------------------
------------------------------------
| approxkl           | 0.02699373  |
| clipfrac           | 0.34960938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -3.1e-06    |
| fps                | 28          |
| n_updates          | 94          |
| policy_entropy     | 1.0159465   |
| policy_loss        | 0.018655678 |
| serial_timesteps   | 12032       |
| time_elapsed       | 442         |
| total_timesteps    | 12032       |
| value_loss         | 109.708954  |
------------------------------------
------------------------------------
| approxkl           | 0.026885372 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 2.5e-06     |
| fps                | 29          |
| n_updates          | 95          |
| policy_entropy     | 1.0153997   |
| policy_loss        | 0.032586597 |
| serial_timesteps   | 12160       |
| time_elapsed       | 446         |
| total_timesteps    | 12160       |
| value_loss         | 103.9183    |
------------------------------------
------------------------------------
| approxkl           | 0.021870298 |
| clipfrac           | 0.28320312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 5.36e-07    |
| fps                | 28          |
| n_updates          | 96          |
| policy_entropy     | 1.0149522   |
| policy_loss        | 0.032868907 |
| serial_timesteps   | 12288       |
| time_elapsed       | 451         |
| total_timesteps    | 12288       |
| value_loss         | 84.04577    |
------------------------------------
An average of 146.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.030838052 |
| clipfrac           | 0.35742188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -1.19e-07   |
| fps                | 27          |
| n_updates          | 97          |
| policy_entropy     | 1.0143108   |
| policy_loss        | 0.013996946 |
| serial_timesteps   | 12416       |
| time_elapsed       | 455         |
| total_timesteps    | 12416       |
| value_loss         | 2248.8433   |
------------------------------------
--------------------------------------
| approxkl           | 0.0034406786  |
| clipfrac           | 0.037109375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.72e+03      |
| explained_variance | -8.34e-07     |
| fps                | 29            |
| n_updates          | 98            |
| policy_entropy     | 1.0140969     |
| policy_loss        | -0.0020655189 |
| serial_timesteps   | 12544         |
| time_elapsed       | 460           |
| total_timesteps    | 12544         |
| value_loss         | 145.06853     |
--------------------------------------
-------------------------------------
| approxkl           | 6.41467e-05  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | -8.34e-07    |
| fps                | 29           |
| n_updates          | 99           |
| policy_entropy     | 1.0137994    |
| policy_loss        | 0.0004006198 |
| serial_timesteps   | 12672        |
| time_elapsed       | 464          |
| total_timesteps    | 12672        |
| value_loss         | 106.21648    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00044748478  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.72e+03       |
| explained_variance | -1.19e-07      |
| fps                | 27             |
| n_updates          | 100            |
| policy_entropy     | 1.0130024      |
| policy_loss        | -0.00036234874 |
| serial_timesteps   | 12800          |
| time_elapsed       | 468            |
| total_timesteps    | 12800          |
| value_loss         | 101.779495     |
---------------------------------------
-------------------------------------
| approxkl           | 0.0018368729 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | -2.62e-06    |
| fps                | 27           |
| n_updates          | 101          |
| policy_entropy     | 1.0116485    |
| policy_loss        | -0.005159977 |
| serial_timesteps   | 12928        |
| time_elapsed       | 473          |
| total_timesteps    | 12928        |
| value_loss         | 108.36226    |
-------------------------------------
------------------------------------
| approxkl           | 0.022874132 |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 0           |
| fps                | 28          |
| n_updates          | 102         |
| policy_entropy     | 1.0088784   |
| policy_loss        | 0.03584827  |
| serial_timesteps   | 13056       |
| time_elapsed       | 478         |
| total_timesteps    | 13056       |
| value_loss         | 107.55948   |
------------------------------------
------------------------------------
| approxkl           | 0.044105075 |
| clipfrac           | 0.39648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 1.55e-06    |
| fps                | 27          |
| n_updates          | 103         |
| policy_entropy     | 1.0071536   |
| policy_loss        | 0.026938826 |
| serial_timesteps   | 13184       |
| time_elapsed       | 482         |
| total_timesteps    | 13184       |
| value_loss         | 115.42543   |
------------------------------------
------------------------------------
| approxkl           | 0.03194957  |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 3.93e-06    |
| fps                | 26          |
| n_updates          | 104         |
| policy_entropy     | 1.0066859   |
| policy_loss        | 0.022522178 |
| serial_timesteps   | 13312       |
| time_elapsed       | 487         |
| total_timesteps    | 13312       |
| value_loss         | 117.86543   |
------------------------------------
An average of 147.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.03483785  |
| clipfrac           | 0.33984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -2.38e-07   |
| fps                | 28          |
| n_updates          | 105         |
| policy_entropy     | 1.0062597   |
| policy_loss        | 0.016914714 |
| serial_timesteps   | 13440       |
| time_elapsed       | 492         |
| total_timesteps    | 13440       |
| value_loss         | 136.7752    |
------------------------------------
-------------------------------------
| approxkl           | 0.03200042   |
| clipfrac           | 0.34179688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | 4.77e-07     |
| fps                | 27           |
| n_updates          | 106          |
| policy_entropy     | 1.0060685    |
| policy_loss        | -0.006015615 |
| serial_timesteps   | 13568        |
| time_elapsed       | 496          |
| total_timesteps    | 13568        |
| value_loss         | 137.8888     |
-------------------------------------
------------------------------------
| approxkl           | 0.024570905 |
| clipfrac           | 0.30078125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -1.19e-06   |
| fps                | 28          |
| n_updates          | 107         |
| policy_entropy     | 1.005773    |
| policy_loss        | 0.009245341 |
| serial_timesteps   | 13696       |
| time_elapsed       | 501         |
| total_timesteps    | 13696       |
| value_loss         | 106.31799   |
------------------------------------
------------------------------------
| approxkl           | 0.0325561   |
| clipfrac           | 0.33984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 5.96e-08    |
| fps                | 29          |
| n_updates          | 108         |
| policy_entropy     | 1.0052618   |
| policy_loss        | 0.021952014 |
| serial_timesteps   | 13824       |
| time_elapsed       | 505         |
| total_timesteps    | 13824       |
| value_loss         | 95.90107    |
------------------------------------
------------------------------------
| approxkl           | 0.04691782  |
| clipfrac           | 0.38671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 109         |
| policy_entropy     | 1.0045111   |
| policy_loss        | 0.035078175 |
| serial_timesteps   | 13952       |
| time_elapsed       | 510         |
| total_timesteps    | 13952       |
| value_loss         | 2358.7349   |
------------------------------------
---------------------------------------
| approxkl           | 0.0014017398   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.73e+03       |
| explained_variance | -2.98e-06      |
| fps                | 29             |
| n_updates          | 110            |
| policy_entropy     | 1.004092       |
| policy_loss        | -0.00033709162 |
| serial_timesteps   | 14080          |
| time_elapsed       | 514            |
| total_timesteps    | 14080          |
| value_loss         | 123.1882       |
---------------------------------------
--------------------------------------
| approxkl           | 0.00058829464 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.73e+03      |
| explained_variance | -1.07e-06     |
| fps                | 29            |
| n_updates          | 111           |
| policy_entropy     | 1.003629      |
| policy_loss        | -0.0011065066 |
| serial_timesteps   | 14208         |
| time_elapsed       | 519           |
| total_timesteps    | 14208         |
| value_loss         | 102.98863     |
--------------------------------------
------------------------------------
| approxkl           | 0.024760067 |
| clipfrac           | 0.33398438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | -3.58e-07   |
| fps                | 29          |
| n_updates          | 112         |
| policy_entropy     | 1.0014741   |
| policy_loss        | 0.028720178 |
| serial_timesteps   | 14336       |
| time_elapsed       | 523         |
| total_timesteps    | 14336       |
| value_loss         | 97.18679    |
------------------------------------
An average of 148.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.03904184  |
| clipfrac           | 0.4609375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | -1.19e-07   |
| fps                | 26          |
| n_updates          | 113         |
| policy_entropy     | 0.9998283   |
| policy_loss        | 0.031994753 |
| serial_timesteps   | 14464       |
| time_elapsed       | 528         |
| total_timesteps    | 14464       |
| value_loss         | 95.175545   |
------------------------------------
------------------------------------
| approxkl           | 0.05393535  |
| clipfrac           | 0.48632812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 114         |
| policy_entropy     | 0.998736    |
| policy_loss        | 0.028173596 |
| serial_timesteps   | 14592       |
| time_elapsed       | 532         |
| total_timesteps    | 14592       |
| value_loss         | 115.50718   |
------------------------------------
------------------------------------
| approxkl           | 0.0345435   |
| clipfrac           | 0.38085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | 1.01e-06    |
| fps                | 27          |
| n_updates          | 115         |
| policy_entropy     | 0.9984384   |
| policy_loss        | 0.020902121 |
| serial_timesteps   | 14720       |
| time_elapsed       | 537         |
| total_timesteps    | 14720       |
| value_loss         | 99.094894   |
------------------------------------
------------------------------------
| approxkl           | 0.047271468 |
| clipfrac           | 0.390625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | 1.19e-07    |
| fps                | 26          |
| n_updates          | 116         |
| policy_entropy     | 0.99811906  |
| policy_loss        | 0.01936274  |
| serial_timesteps   | 14848       |
| time_elapsed       | 541         |
| total_timesteps    | 14848       |
| value_loss         | 117.91477   |
------------------------------------
------------------------------------
| approxkl           | 0.035575867 |
| clipfrac           | 0.3671875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.73e+03    |
| explained_variance | -2.74e-06   |
| fps                | 29          |
| n_updates          | 117         |
| policy_entropy     | 0.9978594   |
| policy_loss        | 0.013492793 |
| serial_timesteps   | 14976       |
| time_elapsed       | 546         |
| total_timesteps    | 14976       |
| value_loss         | 103.80682   |
------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b60f84748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b60f84748>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b5fc47ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b5fc47ef0>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2753 samples, validate on 332 samples
Epoch 276/5000
 - 5s - loss: 0.0740 - val_loss: 0.0048
Epoch 277/5000
 - 1s - loss: 0.0085 - val_loss: 0.0028
Epoch 278/5000
 - 1s - loss: 0.0076 - val_loss: 0.0022
Epoch 279/5000
 - 1s - loss: 0.0069 - val_loss: 0.0019
Epoch 280/5000
 - 1s - loss: 0.0064 - val_loss: 0.0018
Epoch 281/5000
 - 1s - loss: 0.0061 - val_loss: 0.0017
Epoch 282/5000
 - 1s - loss: 0.0058 - val_loss: 0.0017
Epoch 283/5000
 - 1s - loss: 0.0050 - val_loss: 0.0018
Epoch 284/5000
 - 1s - loss: 0.0050 - val_loss: 0.0018
Epoch 285/5000
 - 1s - loss: 0.0049 - val_loss: 0.0017
Epoch 286/5000
 - 1s - loss: 0.0048 - val_loss: 0.0017
Epoch 287/5000
 - 1s - loss: 0.0045 - val_loss: 0.0017
Epoch 288/5000
 - 1s - loss: 0.0044 - val_loss: 0.0016
Epoch 289/5000
 - 1s - loss: 0.0044 - val_loss: 0.0016
Epoch 290/5000
 - 1s - loss: 0.0044 - val_loss: 0.0016
Epoch 291/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 292/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 293/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 294/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 295/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 296/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 297/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 298/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 299/5000
 - 0s - loss: 0.0043 - val_loss: 0.0016
Epoch 300/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 301/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 302/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 303/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 304/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 305/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 306/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 307/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 308/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 309/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 310/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Epoch 311/5000
 - 1s - loss: 0.0043 - val_loss: 0.0016
Train on 1978 samples, validate on 332 samples
Epoch 221/5000
 - 5s - loss: 0.0065 - val_loss: 0.0034
Epoch 222/5000
 - 0s - loss: 0.0065 - val_loss: 0.0034
Epoch 223/5000
 - 0s - loss: 0.0065 - val_loss: 0.0034
Epoch 224/5000
 - 1s - loss: 0.0065 - val_loss: 0.0034
Epoch 225/5000
 - 0s - loss: 0.0065 - val_loss: 0.0034
Epoch 226/5000
 - 0s - loss: 0.0065 - val_loss: 0.0034
Train on 2753 samples, validate on 332 samples
Epoch 600/5000
 - 7s - loss: 0.6425 - val_loss: 0.7091
Epoch 601/5000
 - 1s - loss: 0.5662 - val_loss: 0.7533
Epoch 602/5000
 - 1s - loss: 0.5512 - val_loss: 0.7624
Epoch 603/5000
 - 1s - loss: 0.5398 - val_loss: 0.7684
Epoch 604/5000
 - 1s - loss: 0.5386 - val_loss: 0.7739
Epoch 605/5000
 - 1s - loss: 0.5378 - val_loss: 0.7787
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.022547968 |
| clipfrac           | 0.29101562  |
| explained_variance | -2.38e-06   |
| fps                | 4           |
| n_updates          | 1           |
| policy_entropy     | 0.99739754  |
| policy_loss        | 0.041646563 |
| serial_timesteps   | 128         |
| time_elapsed       | 1.24e-05    |
| total_timesteps    | 128         |
| value_loss         | 113.30393   |
------------------------------------
------------------------------------
| approxkl           | 0.028757222 |
| clipfrac           | 0.35546875  |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 2           |
| policy_entropy     | 0.9978981   |
| policy_loss        | 0.0049678   |
| serial_timesteps   | 256         |
| time_elapsed       | 27.2        |
| total_timesteps    | 256         |
| value_loss         | 100.40685   |
------------------------------------
An average of 149.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.013415798 |
| clipfrac           | 0.20703125  |
| explained_variance | 5.96e-07    |
| fps                | 23          |
| n_updates          | 3           |
| policy_entropy     | 0.99799776  |
| policy_loss        | 0.033375584 |
| serial_timesteps   | 384         |
| time_elapsed       | 31.8        |
| total_timesteps    | 384         |
| value_loss         | 104.293594  |
------------------------------------
------------------------------------
| approxkl           | 0.044891074 |
| clipfrac           | 0.36328125  |
| explained_variance | 7.75e-07    |
| fps                | 25          |
| n_updates          | 4           |
| policy_entropy     | 0.99757504  |
| policy_loss        | 0.006396388 |
| serial_timesteps   | 512         |
| time_elapsed       | 37.1        |
| total_timesteps    | 512         |
| value_loss         | 115.88708   |
------------------------------------
-------------------------------------
| approxkl           | 0.016848702  |
| clipfrac           | 0.23242188   |
| explained_variance | -2.5e-06     |
| fps                | 26           |
| n_updates          | 5            |
| policy_entropy     | 0.99737954   |
| policy_loss        | 0.0067628482 |
| serial_timesteps   | 640          |
| time_elapsed       | 42.1         |
| total_timesteps    | 640          |
| value_loss         | 131.30687    |
-------------------------------------
------------------------------------
| approxkl           | 0.015603122 |
| clipfrac           | 0.21484375  |
| explained_variance | -1.19e-07   |
| fps                | 27          |
| n_updates          | 6           |
| policy_entropy     | 0.9970753   |
| policy_loss        | 0.026380574 |
| serial_timesteps   | 768         |
| time_elapsed       | 46.9        |
| total_timesteps    | 768         |
| value_loss         | 128.8966    |
------------------------------------
-----------------------------------
| approxkl           | 0.03215447 |
| clipfrac           | 0.38867188 |
| explained_variance | -7.15e-07  |
| fps                | 26         |
| n_updates          | 7          |
| policy_entropy     | 0.9972799  |
| policy_loss        | 0.02520904 |
| serial_timesteps   | 896        |
| time_elapsed       | 51.6       |
| total_timesteps    | 896        |
| value_loss         | 97.755165  |
-----------------------------------
-----------------------------------
| approxkl           | 0.04432691 |
| clipfrac           | 0.38867188 |
| explained_variance | 0          |
| fps                | 26         |
| n_updates          | 8          |
| policy_entropy     | 0.9971053  |
| policy_loss        | 0.02977155 |
| serial_timesteps   | 1024       |
| time_elapsed       | 56.4       |
| total_timesteps    | 1024       |
| value_loss         | 113.94585  |
-----------------------------------
-------------------------------------
| approxkl           | 0.06161449   |
| clipfrac           | 0.53515625   |
| explained_variance | -1.19e-07    |
| fps                | 27           |
| n_updates          | 9            |
| policy_entropy     | 0.9968324    |
| policy_loss        | -0.012973828 |
| serial_timesteps   | 1152         |
| time_elapsed       | 61.2         |
| total_timesteps    | 1152         |
| value_loss         | 61.378395    |
-------------------------------------
------------------------------------
| approxkl           | 0.007595635 |
| clipfrac           | 0.119140625 |
| explained_variance | -2.38e-07   |
| fps                | 24          |
| n_updates          | 10          |
| policy_entropy     | 0.9967372   |
| policy_loss        | 0.026493557 |
| serial_timesteps   | 1280        |
| time_elapsed       | 65.8        |
| total_timesteps    | 1280        |
| value_loss         | 63.48747    |
------------------------------------
An average of 149.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-----------------------------------
| approxkl           | 0.06443174 |
| clipfrac           | 0.49609375 |
| explained_variance | -9.54e-07  |
| fps                | 25         |
| n_updates          | 11         |
| policy_entropy     | 0.99637365 |
| policy_loss        | 0.02244504 |
| serial_timesteps   | 1408       |
| time_elapsed       | 71         |
| total_timesteps    | 1408       |
| value_loss         | 102.939476 |
-----------------------------------
------------------------------------
| approxkl           | 0.038070597 |
| clipfrac           | 0.40429688  |
| explained_variance | -1.31e-06   |
| fps                | 28          |
| n_updates          | 12          |
| policy_entropy     | 0.9961816   |
| policy_loss        | 0.018104581 |
| serial_timesteps   | 1536        |
| time_elapsed       | 76.1        |
| total_timesteps    | 1536        |
| value_loss         | 83.957375   |
------------------------------------
-------------------------------------
| approxkl           | 0.01477273   |
| clipfrac           | 0.19921875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 0            |
| fps                | 24           |
| n_updates          | 13           |
| policy_entropy     | 0.99583673   |
| policy_loss        | 0.0035469665 |
| serial_timesteps   | 1664         |
| time_elapsed       | 80.6         |
| total_timesteps    | 1664         |
| value_loss         | 1748.364     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0048943907 |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 2.21e-06     |
| fps                | 27           |
| n_updates          | 14           |
| policy_entropy     | 0.9951729    |
| policy_loss        | 0.014698375  |
| serial_timesteps   | 1792         |
| time_elapsed       | 85.8         |
| total_timesteps    | 1792         |
| value_loss         | 96.80225     |
-------------------------------------
-------------------------------------
| approxkl           | 0.001216899  |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 2.38e-07     |
| fps                | 25           |
| n_updates          | 15           |
| policy_entropy     | 0.99466443   |
| policy_loss        | 0.0010764389 |
| serial_timesteps   | 1920         |
| time_elapsed       | 90.5         |
| total_timesteps    | 1920         |
| value_loss         | 115.73763    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016581331 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | -8.34e-07    |
| fps                | 26           |
| n_updates          | 16           |
| policy_entropy     | 0.9941851    |
| policy_loss        | 0.00944163   |
| serial_timesteps   | 2048         |
| time_elapsed       | 95.4         |
| total_timesteps    | 2048         |
| value_loss         | 110.909645   |
-------------------------------------
------------------------------------
| approxkl           | 0.03583383  |
| clipfrac           | 0.36328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | 7.75e-07    |
| fps                | 28          |
| n_updates          | 17          |
| policy_entropy     | 0.9936931   |
| policy_loss        | 0.040345415 |
| serial_timesteps   | 2176        |
| time_elapsed       | 100         |
| total_timesteps    | 2176        |
| value_loss         | 95.505684   |
------------------------------------
------------------------------------
| approxkl           | 0.056553543 |
| clipfrac           | 0.4375      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | 1.85e-06    |
| fps                | 28          |
| n_updates          | 18          |
| policy_entropy     | 0.99363625  |
| policy_loss        | 0.008354626 |
| serial_timesteps   | 2304        |
| time_elapsed       | 105         |
| total_timesteps    | 2304        |
| value_loss         | 41.595936   |
------------------------------------
An average of 150.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.027310228 |
| clipfrac           | 0.3046875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -3.7e-06    |
| fps                | 25          |
| n_updates          | 19          |
| policy_entropy     | 0.99409574  |
| policy_loss        | 0.036539115 |
| serial_timesteps   | 2432        |
| time_elapsed       | 109         |
| total_timesteps    | 2432        |
| value_loss         | 122.00901   |
------------------------------------
-------------------------------------
| approxkl           | 0.04635083   |
| clipfrac           | 0.41601562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 5.96e-08     |
| fps                | 27           |
| n_updates          | 20           |
| policy_entropy     | 0.994583     |
| policy_loss        | 0.0021129572 |
| serial_timesteps   | 2560         |
| time_elapsed       | 114          |
| total_timesteps    | 2560         |
| value_loss         | 40.485725    |
-------------------------------------
-----------------------------------
| approxkl           | 0.02956871 |
| clipfrac           | 0.32617188 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.78e+03   |
| explained_variance | 5.36e-07   |
| fps                | 26         |
| n_updates          | 21         |
| policy_entropy     | 0.9946719  |
| policy_loss        | 0.02876719 |
| serial_timesteps   | 2688       |
| time_elapsed       | 119        |
| total_timesteps    | 2688       |
| value_loss         | 114.14489  |
-----------------------------------
-------------------------------------
| approxkl           | 0.0326216    |
| clipfrac           | 0.36523438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | -3.22e-06    |
| fps                | 27           |
| n_updates          | 22           |
| policy_entropy     | 0.994923     |
| policy_loss        | -3.47842e-05 |
| serial_timesteps   | 2816         |
| time_elapsed       | 124          |
| total_timesteps    | 2816         |
| value_loss         | 73.24079     |
-------------------------------------
------------------------------------
| approxkl           | 0.017281005 |
| clipfrac           | 0.2578125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -3.34e-06   |
| fps                | 25          |
| n_updates          | 23          |
| policy_entropy     | 0.99485093  |
| policy_loss        | 0.026619397 |
| serial_timesteps   | 2944        |
| time_elapsed       | 128         |
| total_timesteps    | 2944        |
| value_loss         | 109.6894    |
------------------------------------
------------------------------------
| approxkl           | 0.030843755 |
| clipfrac           | 0.3515625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -5.96e-07   |
| fps                | 25          |
| n_updates          | 24          |
| policy_entropy     | 0.9942916   |
| policy_loss        | 0.021736458 |
| serial_timesteps   | 3072        |
| time_elapsed       | 133         |
| total_timesteps    | 3072        |
| value_loss         | 57.96518    |
------------------------------------
------------------------------------
| approxkl           | 0.02623668  |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 25          |
| policy_entropy     | 0.99342674  |
| policy_loss        | 0.024621643 |
| serial_timesteps   | 3200        |
| time_elapsed       | 138         |
| total_timesteps    | 3200        |
| value_loss         | 2309.892    |
------------------------------------
--------------------------------------
| approxkl           | 0.010063568   |
| clipfrac           | 0.119140625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.76e+03      |
| explained_variance | 1.19e-07      |
| fps                | 27            |
| n_updates          | 26            |
| policy_entropy     | 0.99347687    |
| policy_loss        | -0.0018091698 |
| serial_timesteps   | 3328          |
| time_elapsed       | 143           |
| total_timesteps    | 3328          |
| value_loss         | 116.5843      |
--------------------------------------
An average of 151.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0019100728  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.76e+03      |
| explained_variance | -8.34e-07     |
| fps                | 27            |
| n_updates          | 27            |
| policy_entropy     | 0.99337375    |
| policy_loss        | -0.0035913019 |
| serial_timesteps   | 3456          |
| time_elapsed       | 148           |
| total_timesteps    | 3456          |
| value_loss         | 73.62528      |
--------------------------------------
------------------------------------
| approxkl           | 0.030193407 |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | -1.19e-06   |
| fps                | 26          |
| n_updates          | 28          |
| policy_entropy     | 0.9932473   |
| policy_loss        | 0.004328532 |
| serial_timesteps   | 3584        |
| time_elapsed       | 152         |
| total_timesteps    | 3584        |
| value_loss         | 73.19725    |
------------------------------------
------------------------------------
| approxkl           | 0.0432611   |
| clipfrac           | 0.3515625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | -7.15e-07   |
| fps                | 27          |
| n_updates          | 29          |
| policy_entropy     | 0.9925712   |
| policy_loss        | 0.011215234 |
| serial_timesteps   | 3712        |
| time_elapsed       | 157         |
| total_timesteps    | 3712        |
| value_loss         | 102.04721   |
------------------------------------
------------------------------------
| approxkl           | 0.052416306 |
| clipfrac           | 0.4140625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | 6.56e-07    |
| fps                | 27          |
| n_updates          | 30          |
| policy_entropy     | 0.9920976   |
| policy_loss        | 0.008899765 |
| serial_timesteps   | 3840        |
| time_elapsed       | 162         |
| total_timesteps    | 3840        |
| value_loss         | 85.13089    |
------------------------------------
------------------------------------
| approxkl           | 0.029551344 |
| clipfrac           | 0.33984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | 4.77e-07    |
| fps                | 27          |
| n_updates          | 31          |
| policy_entropy     | 0.9920212   |
| policy_loss        | 0.014136032 |
| serial_timesteps   | 3968        |
| time_elapsed       | 167         |
| total_timesteps    | 3968        |
| value_loss         | 78.165474   |
------------------------------------
------------------------------------
| approxkl           | 0.03301602  |
| clipfrac           | 0.41015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | 1.79e-06    |
| fps                | 26          |
| n_updates          | 32          |
| policy_entropy     | 0.99159974  |
| policy_loss        | 0.035445444 |
| serial_timesteps   | 4096        |
| time_elapsed       | 171         |
| total_timesteps    | 4096        |
| value_loss         | 92.45224    |
------------------------------------
------------------------------------
| approxkl           | 0.042995773 |
| clipfrac           | 0.42578125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | -5.96e-07   |
| fps                | 26          |
| n_updates          | 33          |
| policy_entropy     | 0.99101335  |
| policy_loss        | 0.017166901 |
| serial_timesteps   | 4224        |
| time_elapsed       | 176         |
| total_timesteps    | 4224        |
| value_loss         | 99.73012    |
------------------------------------
------------------------------------
| approxkl           | 0.027420279 |
| clipfrac           | 0.34960938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | -1.91e-06   |
| fps                | 28          |
| n_updates          | 34          |
| policy_entropy     | 0.99058884  |
| policy_loss        | 0.022860099 |
| serial_timesteps   | 4352        |
| time_elapsed       | 181         |
| total_timesteps    | 4352        |
| value_loss         | 96.910065   |
------------------------------------
An average of 151.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.05218404  |
| clipfrac           | 0.46484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | 4.65e-06    |
| fps                | 25          |
| n_updates          | 35          |
| policy_entropy     | 0.9900938   |
| policy_loss        | 0.017749403 |
| serial_timesteps   | 4480        |
| time_elapsed       | 185         |
| total_timesteps    | 4480        |
| value_loss         | 93.189156   |
------------------------------------
------------------------------------
| approxkl           | 0.018051509 |
| clipfrac           | 0.29296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.76e+03    |
| explained_variance | 0           |
| fps                | 26          |
| n_updates          | 36          |
| policy_entropy     | 0.9898981   |
| policy_loss        | 0.02122581  |
| serial_timesteps   | 4608        |
| time_elapsed       | 190         |
| total_timesteps    | 4608        |
| value_loss         | 100.182625  |
------------------------------------
------------------------------------
| approxkl           | 0.019771552 |
| clipfrac           | 0.25390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 1.19e-07    |
| fps                | 26          |
| n_updates          | 37          |
| policy_entropy     | 0.98952585  |
| policy_loss        | 0.008482494 |
| serial_timesteps   | 4736        |
| time_elapsed       | 195         |
| total_timesteps    | 4736        |
| value_loss         | 2530.5183   |
------------------------------------
-------------------------------------
| approxkl           | 0.008792668  |
| clipfrac           | 0.125        |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.77e+03     |
| explained_variance | 0            |
| fps                | 26           |
| n_updates          | 38           |
| policy_entropy     | 0.9893753    |
| policy_loss        | -0.010362878 |
| serial_timesteps   | 4864         |
| time_elapsed       | 200          |
| total_timesteps    | 4864         |
| value_loss         | 72.27915     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0038407496 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.77e+03     |
| explained_variance | 5.07e-06     |
| fps                | 25           |
| n_updates          | 39           |
| policy_entropy     | 0.98890644   |
| policy_loss        | -0.009282494 |
| serial_timesteps   | 4992         |
| time_elapsed       | 205          |
| total_timesteps    | 4992         |
| value_loss         | 88.24394     |
-------------------------------------
-------------------------------------
| approxkl           | 0.00285673   |
| clipfrac           | 0.0234375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.77e+03     |
| explained_variance | 5.19e-06     |
| fps                | 26           |
| n_updates          | 40           |
| policy_entropy     | 0.98819345   |
| policy_loss        | -0.004995532 |
| serial_timesteps   | 5120         |
| time_elapsed       | 210          |
| total_timesteps    | 5120         |
| value_loss         | 95.04622     |
-------------------------------------
------------------------------------
| approxkl           | 0.02201178  |
| clipfrac           | 0.27929688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 1.19e-07    |
| fps                | 26          |
| n_updates          | 41          |
| policy_entropy     | 0.9875543   |
| policy_loss        | 0.008022896 |
| serial_timesteps   | 5248        |
| time_elapsed       | 215         |
| total_timesteps    | 5248        |
| value_loss         | 66.807465   |
------------------------------------
An average of 152.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.004992321 |
| clipfrac           | 0.0546875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 2.38e-07    |
| fps                | 26          |
| n_updates          | 42          |
| policy_entropy     | 0.98520494  |
| policy_loss        | 0.007893173 |
| serial_timesteps   | 5376        |
| time_elapsed       | 220         |
| total_timesteps    | 5376        |
| value_loss         | 62.884357   |
------------------------------------
------------------------------------
| approxkl           | 0.039504454 |
| clipfrac           | 0.40039062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | -5.96e-07   |
| fps                | 26          |
| n_updates          | 43          |
| policy_entropy     | 0.98256636  |
| policy_loss        | 0.016105521 |
| serial_timesteps   | 5504        |
| time_elapsed       | 225         |
| total_timesteps    | 5504        |
| value_loss         | 109.382195  |
------------------------------------
------------------------------------
| approxkl           | 0.03862604  |
| clipfrac           | 0.42578125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | -2.38e-07   |
| fps                | 27          |
| n_updates          | 44          |
| policy_entropy     | 0.98155224  |
| policy_loss        | 0.021334339 |
| serial_timesteps   | 5632        |
| time_elapsed       | 229         |
| total_timesteps    | 5632        |
| value_loss         | 88.6742     |
------------------------------------
------------------------------------
| approxkl           | 0.04121366  |
| clipfrac           | 0.42773438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 1.79e-06    |
| fps                | 26          |
| n_updates          | 45          |
| policy_entropy     | 0.98168707  |
| policy_loss        | 0.021299753 |
| serial_timesteps   | 5760        |
| time_elapsed       | 234         |
| total_timesteps    | 5760        |
| value_loss         | 99.77991    |
------------------------------------
------------------------------------
| approxkl           | 0.02220009  |
| clipfrac           | 0.32617188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 2.86e-06    |
| fps                | 25          |
| n_updates          | 46          |
| policy_entropy     | 0.9818535   |
| policy_loss        | 0.036769897 |
| serial_timesteps   | 5888        |
| time_elapsed       | 239         |
| total_timesteps    | 5888        |
| value_loss         | 97.58433    |
------------------------------------
------------------------------------
| approxkl           | 0.030494623 |
| clipfrac           | 0.39257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | -7.15e-07   |
| fps                | 25          |
| n_updates          | 47          |
| policy_entropy     | 0.9818624   |
| policy_loss        | 0.027877463 |
| serial_timesteps   | 6016        |
| time_elapsed       | 244         |
| total_timesteps    | 6016        |
| value_loss         | 99.58517    |
------------------------------------
-----------------------------------
| approxkl           | 0.05361179 |
| clipfrac           | 0.51171875 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.77e+03   |
| explained_variance | -4.77e-07  |
| fps                | 26         |
| n_updates          | 48         |
| policy_entropy     | 0.98177904 |
| policy_loss        | 0.02231057 |
| serial_timesteps   | 6144       |
| time_elapsed       | 249        |
| total_timesteps    | 6144       |
| value_loss         | 76.429855  |
-----------------------------------
--------------------------------------
| approxkl           | 0.025538884   |
| clipfrac           | 0.33203125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.78e+03      |
| explained_variance | 1.19e-07      |
| fps                | 25            |
| n_updates          | 49            |
| policy_entropy     | 0.98214746    |
| policy_loss        | -0.0036757838 |
| serial_timesteps   | 6272          |
| time_elapsed       | 254           |
| total_timesteps    | 6272          |
| value_loss         | 2714.0188     |
--------------------------------------
An average of 153.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.004242863  |
| clipfrac           | 0.0546875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 2.86e-06     |
| fps                | 26           |
| n_updates          | 50           |
| policy_entropy     | 0.9821672    |
| policy_loss        | -0.008113889 |
| serial_timesteps   | 6400         |
| time_elapsed       | 259          |
| total_timesteps    | 6400         |
| value_loss         | 90.59865     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0009256265  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.78e+03      |
| explained_variance | -2.38e-07     |
| fps                | 26            |
| n_updates          | 51            |
| policy_entropy     | 0.9819659     |
| policy_loss        | -0.0017553996 |
| serial_timesteps   | 6528          |
| time_elapsed       | 264           |
| total_timesteps    | 6528          |
| value_loss         | 94.071205     |
--------------------------------------
------------------------------------
| approxkl           | 0.028134488 |
| clipfrac           | 0.35351562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -4.77e-07   |
| fps                | 26          |
| n_updates          | 52          |
| policy_entropy     | 0.98119706  |
| policy_loss        | 0.014863875 |
| serial_timesteps   | 6656        |
| time_elapsed       | 269         |
| total_timesteps    | 6656        |
| value_loss         | 99.25868    |
------------------------------------
------------------------------------
| approxkl           | 0.05428632  |
| clipfrac           | 0.42382812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | 9.54e-07    |
| fps                | 26          |
| n_updates          | 53          |
| policy_entropy     | 0.980785    |
| policy_loss        | 0.011790704 |
| serial_timesteps   | 6784        |
| time_elapsed       | 273         |
| total_timesteps    | 6784        |
| value_loss         | 75.41275    |
------------------------------------
------------------------------------
| approxkl           | 0.0166583   |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -1.19e-06   |
| fps                | 26          |
| n_updates          | 54          |
| policy_entropy     | 0.98047924  |
| policy_loss        | 0.031493872 |
| serial_timesteps   | 6912        |
| time_elapsed       | 278         |
| total_timesteps    | 6912        |
| value_loss         | 97.92739    |
------------------------------------
------------------------------------
| approxkl           | 0.030314824 |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -1.07e-06   |
| fps                | 27          |
| n_updates          | 55          |
| policy_entropy     | 0.9797165   |
| policy_loss        | 0.0346092   |
| serial_timesteps   | 7040        |
| time_elapsed       | 283         |
| total_timesteps    | 7040        |
| value_loss         | 116.697334  |
------------------------------------
-------------------------------------
| approxkl           | 0.034772612  |
| clipfrac           | 0.39257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 0            |
| fps                | 27           |
| n_updates          | 56           |
| policy_entropy     | 0.9794203    |
| policy_loss        | 0.0083775325 |
| serial_timesteps   | 7168         |
| time_elapsed       | 288          |
| total_timesteps    | 7168         |
| value_loss         | 77.09575     |
-------------------------------------
------------------------------------
| approxkl           | 0.026972618 |
| clipfrac           | 0.3359375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | 3.28e-06    |
| fps                | 26          |
| n_updates          | 57          |
| policy_entropy     | 0.97936827  |
| policy_loss        | 0.01774349  |
| serial_timesteps   | 7296        |
| time_elapsed       | 292         |
| total_timesteps    | 7296        |
| value_loss         | 96.93059    |
------------------------------------
An average of 153.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.03188884   |
| clipfrac           | 0.32226562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.78e+03     |
| explained_variance | 6.97e-06     |
| fps                | 25           |
| n_updates          | 58           |
| policy_entropy     | 0.9791139    |
| policy_loss        | 0.0032943967 |
| serial_timesteps   | 7424         |
| time_elapsed       | 297          |
| total_timesteps    | 7424         |
| value_loss         | 81.76074     |
-------------------------------------
------------------------------------
| approxkl           | 0.020333901 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -1.55e-06   |
| fps                | 25          |
| n_updates          | 59          |
| policy_entropy     | 0.97869885  |
| policy_loss        | 0.016581947 |
| serial_timesteps   | 7552        |
| time_elapsed       | 302         |
| total_timesteps    | 7552        |
| value_loss         | 115.954666  |
------------------------------------
------------------------------------
| approxkl           | 0.02309045  |
| clipfrac           | 0.30078125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.78e+03    |
| explained_variance | -1.79e-06   |
| fps                | 26          |
| n_updates          | 60          |
| policy_entropy     | 0.97824085  |
| policy_loss        | 0.026434172 |
| serial_timesteps   | 7680        |
| time_elapsed       | 307         |
| total_timesteps    | 7680        |
| value_loss         | 92.536194   |
------------------------------------
------------------------------------
| approxkl           | 0.047084715 |
| clipfrac           | 0.4140625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 61          |
| policy_entropy     | 0.9779875   |
| policy_loss        | 0.022366855 |
| serial_timesteps   | 7808        |
| time_elapsed       | 312         |
| total_timesteps    | 7808        |
| value_loss         | 2651.3818   |
------------------------------------
--------------------------------------
| approxkl           | 0.00041699017 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.81e+03      |
| explained_variance | 1.67e-06      |
| fps                | 27            |
| n_updates          | 62            |
| policy_entropy     | 0.97806406    |
| policy_loss        | -0.0014031142 |
| serial_timesteps   | 7936          |
| time_elapsed       | 317           |
| total_timesteps    | 7936          |
| value_loss         | 82.618        |
--------------------------------------
--------------------------------------
| approxkl           | 0.0027562515  |
| clipfrac           | 0.02734375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.81e+03      |
| explained_variance | 5.36e-07      |
| fps                | 28            |
| n_updates          | 63            |
| policy_entropy     | 0.9777888     |
| policy_loss        | -0.0059791123 |
| serial_timesteps   | 8064          |
| time_elapsed       | 322           |
| total_timesteps    | 8064          |
| value_loss         | 84.710556     |
--------------------------------------
------------------------------------
| approxkl           | 0.00461317  |
| clipfrac           | 0.041015625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | -4.65e-06   |
| fps                | 26          |
| n_updates          | 64          |
| policy_entropy     | 0.9757882   |
| policy_loss        | 0.010939572 |
| serial_timesteps   | 8192        |
| time_elapsed       | 326         |
| total_timesteps    | 8192        |
| value_loss         | 97.225716   |
------------------------------------
------------------------------------
| approxkl           | 0.024279144 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | -1.31e-06   |
| fps                | 26          |
| n_updates          | 65          |
| policy_entropy     | 0.9734616   |
| policy_loss        | 0.035947487 |
| serial_timesteps   | 8320        |
| time_elapsed       | 331         |
| total_timesteps    | 8320        |
| value_loss         | 91.84162    |
------------------------------------
An average of 154.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.03399439  |
| clipfrac           | 0.37304688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | 5.96e-07    |
| fps                | 26          |
| n_updates          | 66          |
| policy_entropy     | 0.9716284   |
| policy_loss        | 0.030673068 |
| serial_timesteps   | 8448        |
| time_elapsed       | 336         |
| total_timesteps    | 8448        |
| value_loss         | 72.996895   |
------------------------------------
------------------------------------
| approxkl           | 0.045731373 |
| clipfrac           | 0.39453125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | 3.1e-06     |
| fps                | 24          |
| n_updates          | 67          |
| policy_entropy     | 0.96998334  |
| policy_loss        | 0.02814123  |
| serial_timesteps   | 8576        |
| time_elapsed       | 341         |
| total_timesteps    | 8576        |
| value_loss         | 122.008316  |
------------------------------------
------------------------------------
| approxkl           | 0.039288893 |
| clipfrac           | 0.40820312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | -9.54e-07   |
| fps                | 25          |
| n_updates          | 68          |
| policy_entropy     | 0.9692269   |
| policy_loss        | 0.008573582 |
| serial_timesteps   | 8704        |
| time_elapsed       | 346         |
| total_timesteps    | 8704        |
| value_loss         | 89.63229    |
------------------------------------
------------------------------------
| approxkl           | 0.025633534 |
| clipfrac           | 0.34570312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | -9.54e-07   |
| fps                | 27          |
| n_updates          | 69          |
| policy_entropy     | 0.96899456  |
| policy_loss        | 0.025434926 |
| serial_timesteps   | 8832        |
| time_elapsed       | 351         |
| total_timesteps    | 8832        |
| value_loss         | 82.86565    |
------------------------------------
------------------------------------
| approxkl           | 0.040071424 |
| clipfrac           | 0.41210938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | -4.77e-07   |
| fps                | 25          |
| n_updates          | 70          |
| policy_entropy     | 0.9685796   |
| policy_loss        | 0.027867826 |
| serial_timesteps   | 8960        |
| time_elapsed       | 356         |
| total_timesteps    | 8960        |
| value_loss         | 87.12148    |
------------------------------------
------------------------------------
| approxkl           | 0.039937235 |
| clipfrac           | 0.4375      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | -1.07e-06   |
| fps                | 25          |
| n_updates          | 71          |
| policy_entropy     | 0.9679079   |
| policy_loss        | 0.012232829 |
| serial_timesteps   | 9088        |
| time_elapsed       | 361         |
| total_timesteps    | 9088        |
| value_loss         | 66.80954    |
------------------------------------
------------------------------------
| approxkl           | 0.016458275 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.81e+03    |
| explained_variance | 2.38e-07    |
| fps                | 28          |
| n_updates          | 72          |
| policy_entropy     | 0.9673855   |
| policy_loss        | 0.035462547 |
| serial_timesteps   | 9216        |
| time_elapsed       | 366         |
| total_timesteps    | 9216        |
| value_loss         | 80.798355   |
------------------------------------
------------------------------------
| approxkl           | 0.058254585 |
| clipfrac           | 0.45898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.82e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 73          |
| policy_entropy     | 0.96566725  |
| policy_loss        | 0.060274996 |
| serial_timesteps   | 9344        |
| time_elapsed       | 370         |
| total_timesteps    | 9344        |
| value_loss         | 2787.7534   |
------------------------------------
An average of 155.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.016137298  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.82e+03     |
| explained_variance | -1.19e-07    |
| fps                | 27           |
| n_updates          | 74           |
| policy_entropy     | 0.9646248    |
| policy_loss        | -0.017481793 |
| serial_timesteps   | 9472         |
| time_elapsed       | 375          |
| total_timesteps    | 9472         |
| value_loss         | 56.152687    |
-------------------------------------
-------------------------------------
| approxkl           | 0.001683255  |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.82e+03     |
| explained_variance | 9.06e-06     |
| fps                | 28           |
| n_updates          | 75           |
| policy_entropy     | 0.9640104    |
| policy_loss        | -0.003640389 |
| serial_timesteps   | 9600         |
| time_elapsed       | 380          |
| total_timesteps    | 9600         |
| value_loss         | 84.60976     |
-------------------------------------
-------------------------------------
| approxkl           | 0.010038478  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.82e+03     |
| explained_variance | 2.38e-06     |
| fps                | 24           |
| n_updates          | 76           |
| policy_entropy     | 0.9619281    |
| policy_loss        | -0.007785583 |
| serial_timesteps   | 9728         |
| time_elapsed       | 384          |
| total_timesteps    | 9728         |
| value_loss         | 87.55067     |
-------------------------------------
------------------------------------
| approxkl           | 0.012267891 |
| clipfrac           | 0.20898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.82e+03    |
| explained_variance | -1.43e-06   |
| fps                | 27          |
| n_updates          | 77          |
| policy_entropy     | 0.9597403   |
| policy_loss        | 0.023248982 |
| serial_timesteps   | 9856        |
| time_elapsed       | 390         |
| total_timesteps    | 9856        |
| value_loss         | 96.15056    |
------------------------------------
------------------------------------
| approxkl           | 0.030077312 |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.82e+03    |
| explained_variance | 2.38e-07    |
| fps                | 27          |
| n_updates          | 78          |
| policy_entropy     | 0.95862216  |
| policy_loss        | 0.01284715  |
| serial_timesteps   | 9984        |
| time_elapsed       | 394         |
| total_timesteps    | 9984        |
| value_loss         | 120.71306   |
------------------------------------
-------------------------------------
| approxkl           | 0.036194734  |
| clipfrac           | 0.34960938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.82e+03     |
| explained_variance | 5.36e-07     |
| fps                | 26           |
| n_updates          | 79           |
| policy_entropy     | 0.9581773    |
| policy_loss        | -0.010160915 |
| serial_timesteps   | 10112        |
| time_elapsed       | 399          |
| total_timesteps    | 10112        |
| value_loss         | 88.86894     |
-------------------------------------
-------------------------------------
| approxkl           | 0.037645735  |
| clipfrac           | 0.34570312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.82e+03     |
| explained_variance | 8.46e-06     |
| fps                | 27           |
| n_updates          | 80           |
| policy_entropy     | 0.9586053    |
| policy_loss        | 0.0002731774 |
| serial_timesteps   | 10240        |
| time_elapsed       | 404          |
| total_timesteps    | 10240        |
| value_loss         | 99.03056     |
-------------------------------------
An average of 155.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.051232558  |
| clipfrac           | 0.48632812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.82e+03     |
| explained_variance | -2.26e-06    |
| fps                | 24           |
| n_updates          | 81           |
| policy_entropy     | 0.95927465   |
| policy_loss        | -0.009202728 |
| serial_timesteps   | 10368        |
| time_elapsed       | 409          |
| total_timesteps    | 10368        |
| value_loss         | 46.319004    |
-------------------------------------
------------------------------------
| approxkl           | 0.014931828 |
| clipfrac           | 0.21875     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.82e+03    |
| explained_variance | -3.58e-07   |
| fps                | 27          |
| n_updates          | 82          |
| policy_entropy     | 0.9592564   |
| policy_loss        | 0.03002709  |
| serial_timesteps   | 10496       |
| time_elapsed       | 414         |
| total_timesteps    | 10496       |
| value_loss         | 67.00159    |
------------------------------------
------------------------------------
| approxkl           | 0.0602315   |
| clipfrac           | 0.5097656   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.82e+03    |
| explained_variance | 1.19e-07    |
| fps                | 27          |
| n_updates          | 83          |
| policy_entropy     | 0.95882124  |
| policy_loss        | 0.024280077 |
| serial_timesteps   | 10624       |
| time_elapsed       | 419         |
| total_timesteps    | 10624       |
| value_loss         | 63.340977   |
------------------------------------
------------------------------------
| approxkl           | 0.031983968 |
| clipfrac           | 0.34570312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.82e+03    |
| explained_variance | 1.85e-06    |
| fps                | 27          |
| n_updates          | 84          |
| policy_entropy     | 0.9577274   |
| policy_loss        | 0.042359695 |
| serial_timesteps   | 10752       |
| time_elapsed       | 423         |
| total_timesteps    | 10752       |
| value_loss         | 88.36568    |
------------------------------------
------------------------------------
| approxkl           | 0.04374498  |
| clipfrac           | 0.39648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | -1.19e-07   |
| fps                | 25          |
| n_updates          | 85          |
| policy_entropy     | 0.95590204  |
| policy_loss        | 0.008596821 |
| serial_timesteps   | 10880       |
| time_elapsed       | 428         |
| total_timesteps    | 10880       |
| value_loss         | 2678.0215   |
------------------------------------
--------------------------------------
| approxkl           | 0.00038205602 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.83e+03      |
| explained_variance | 0             |
| fps                | 27            |
| n_updates          | 86            |
| policy_entropy     | 0.9551581     |
| policy_loss        | 0.0002832783  |
| serial_timesteps   | 11008         |
| time_elapsed       | 433           |
| total_timesteps    | 11008         |
| value_loss         | 82.16618      |
--------------------------------------
--------------------------------------
| approxkl           | 2.1133517e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.83e+03      |
| explained_variance | 4.17e-07      |
| fps                | 27            |
| n_updates          | 87            |
| policy_entropy     | 0.95460963    |
| policy_loss        | -8.139503e-05 |
| serial_timesteps   | 11136         |
| time_elapsed       | 437           |
| total_timesteps    | 11136         |
| value_loss         | 70.2836       |
--------------------------------------
------------------------------------
| approxkl           | 0.004960527 |
| clipfrac           | 0.060546875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 88          |
| policy_entropy     | 0.95065445  |
| policy_loss        | 0.009893376 |
| serial_timesteps   | 11264       |
| time_elapsed       | 442         |
| total_timesteps    | 11264       |
| value_loss         | 64.071045   |
------------------------------------
An average of 156.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.040107615 |
| clipfrac           | 0.43554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 89          |
| policy_entropy     | 0.94758534  |
| policy_loss        | 0.007941106 |
| serial_timesteps   | 11392       |
| time_elapsed       | 447         |
| total_timesteps    | 11392       |
| value_loss         | 50.079178   |
------------------------------------
------------------------------------
| approxkl           | 0.022819642 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 5.36e-07    |
| fps                | 28          |
| n_updates          | 90          |
| policy_entropy     | 0.9457379   |
| policy_loss        | 0.050129294 |
| serial_timesteps   | 11520       |
| time_elapsed       | 451         |
| total_timesteps    | 11520       |
| value_loss         | 88.72104    |
------------------------------------
-------------------------------------
| approxkl           | 0.010600598  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.83e+03     |
| explained_variance | -4.77e-06    |
| fps                | 27           |
| n_updates          | 91           |
| policy_entropy     | 0.9446886    |
| policy_loss        | -0.014480114 |
| serial_timesteps   | 11648        |
| time_elapsed       | 456          |
| total_timesteps    | 11648        |
| value_loss         | 75.9701      |
-------------------------------------
------------------------------------
| approxkl           | 0.021453988 |
| clipfrac           | 0.25195312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 92          |
| policy_entropy     | 0.94278723  |
| policy_loss        | 0.019781308 |
| serial_timesteps   | 11776       |
| time_elapsed       | 461         |
| total_timesteps    | 11776       |
| value_loss         | 85.83781    |
------------------------------------
------------------------------------
| approxkl           | 0.032166675 |
| clipfrac           | 0.390625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 5.96e-08    |
| fps                | 25          |
| n_updates          | 93          |
| policy_entropy     | 0.9420761   |
| policy_loss        | 0.011277614 |
| serial_timesteps   | 11904       |
| time_elapsed       | 466         |
| total_timesteps    | 11904       |
| value_loss         | 66.026245   |
------------------------------------
------------------------------------
| approxkl           | 0.013582369 |
| clipfrac           | 0.19726562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | -2.38e-07   |
| fps                | 28          |
| n_updates          | 94          |
| policy_entropy     | 0.9420843   |
| policy_loss        | 0.027756726 |
| serial_timesteps   | 12032       |
| time_elapsed       | 471         |
| total_timesteps    | 12032       |
| value_loss         | 66.87566    |
------------------------------------
------------------------------------
| approxkl           | 0.029026125 |
| clipfrac           | 0.33789062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | -8.34e-07   |
| fps                | 26          |
| n_updates          | 95          |
| policy_entropy     | 0.9396361   |
| policy_loss        | -0.02483594 |
| serial_timesteps   | 12160       |
| time_elapsed       | 475         |
| total_timesteps    | 12160       |
| value_loss         | 49.49524    |
------------------------------------
-------------------------------------
| approxkl           | 0.033366837  |
| clipfrac           | 0.359375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.83e+03     |
| explained_variance | 1.13e-06     |
| fps                | 26           |
| n_updates          | 96           |
| policy_entropy     | 0.93791074   |
| policy_loss        | -0.004293535 |
| serial_timesteps   | 12288        |
| time_elapsed       | 480          |
| total_timesteps    | 12288        |
| value_loss         | 77.697266    |
-------------------------------------
An average of 157.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.033652972 |
| clipfrac           | 0.38476562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 1.19e-07    |
| fps                | 29          |
| n_updates          | 97          |
| policy_entropy     | 0.937736    |
| policy_loss        | 0.03970989  |
| serial_timesteps   | 12416       |
| time_elapsed       | 485         |
| total_timesteps    | 12416       |
| value_loss         | 2783.7576   |
------------------------------------
-------------------------------------
| approxkl           | 0.0066151028 |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.83e+03     |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 98           |
| policy_entropy     | 0.9376527    |
| policy_loss        | -0.010280336 |
| serial_timesteps   | 12544        |
| time_elapsed       | 489          |
| total_timesteps    | 12544        |
| value_loss         | 76.85269     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00028371363 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.83e+03      |
| explained_variance | -5.96e-07     |
| fps                | 27            |
| n_updates          | 99            |
| policy_entropy     | 0.9374098     |
| policy_loss        | 0.00043190108 |
| serial_timesteps   | 12672         |
| time_elapsed       | 494           |
| total_timesteps    | 12672         |
| value_loss         | 71.553345     |
--------------------------------------
---------------------------------------
| approxkl           | 6.202355e-05   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.83e+03       |
| explained_variance | -3.58e-07      |
| fps                | 27             |
| n_updates          | 100            |
| policy_entropy     | 0.9364733      |
| policy_loss        | -0.00024781178 |
| serial_timesteps   | 12800          |
| time_elapsed       | 499            |
| total_timesteps    | 12800          |
| value_loss         | 61.280746      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0032137923 |
| clipfrac           | 0.029296875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.83e+03     |
| explained_variance | -1.31e-06    |
| fps                | 27           |
| n_updates          | 101          |
| policy_entropy     | 0.9352222    |
| policy_loss        | -0.003777256 |
| serial_timesteps   | 12928        |
| time_elapsed       | 504          |
| total_timesteps    | 12928        |
| value_loss         | 79.51472     |
-------------------------------------
---------------------------------------
| approxkl           | 0.00029262766  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.83e+03       |
| explained_variance | -1.19e-07      |
| fps                | 27             |
| n_updates          | 102            |
| policy_entropy     | 0.9342724      |
| policy_loss        | -0.00065467926 |
| serial_timesteps   | 13056          |
| time_elapsed       | 508            |
| total_timesteps    | 13056          |
| value_loss         | 106.22192      |
---------------------------------------
-------------------------------------
| approxkl           | 0.010006079  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.83e+03     |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 103          |
| policy_entropy     | 0.93298316   |
| policy_loss        | -0.011955756 |
| serial_timesteps   | 13184        |
| time_elapsed       | 513          |
| total_timesteps    | 13184        |
| value_loss         | 69.805275    |
-------------------------------------
------------------------------------
| approxkl           | 0.026198514 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | -9.54e-07   |
| fps                | 25          |
| n_updates          | 104         |
| policy_entropy     | 0.93196034  |
| policy_loss        | 0.01572863  |
| serial_timesteps   | 13312       |
| time_elapsed       | 518         |
| total_timesteps    | 13312       |
| value_loss         | 107.92302   |
------------------------------------
An average of 157.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.022495808 |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | -1.31e-06   |
| fps                | 27          |
| n_updates          | 105         |
| policy_entropy     | 0.9314077   |
| policy_loss        | 0.022914834 |
| serial_timesteps   | 13440       |
| time_elapsed       | 523         |
| total_timesteps    | 13440       |
| value_loss         | 61.89856    |
------------------------------------
------------------------------------
| approxkl           | 0.031004691 |
| clipfrac           | 0.40234375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | 0           |
| fps                | 26          |
| n_updates          | 106         |
| policy_entropy     | 0.9307013   |
| policy_loss        | 0.04157805  |
| serial_timesteps   | 13568       |
| time_elapsed       | 527         |
| total_timesteps    | 13568       |
| value_loss         | 69.74102    |
------------------------------------
-------------------------------------
| approxkl           | 0.019581754  |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.83e+03     |
| explained_variance | 3.58e-07     |
| fps                | 25           |
| n_updates          | 107          |
| policy_entropy     | 0.9296099    |
| policy_loss        | -0.017772209 |
| serial_timesteps   | 13696        |
| time_elapsed       | 532          |
| total_timesteps    | 13696        |
| value_loss         | 63.562904    |
-------------------------------------
------------------------------------
| approxkl           | 0.015865134 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.83e+03    |
| explained_variance | -1.19e-07   |
| fps                | 25          |
| n_updates          | 108         |
| policy_entropy     | 0.9284351   |
| policy_loss        | 0.032424495 |
| serial_timesteps   | 13824       |
| time_elapsed       | 537         |
| total_timesteps    | 13824       |
| value_loss         | 86.188805   |
------------------------------------
-------------------------------------
| approxkl           | 0.0046114717 |
| clipfrac           | 0.048828125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.84e+03     |
| explained_variance | 1.19e-07     |
| fps                | 25           |
| n_updates          | 109          |
| policy_entropy     | 0.92889565   |
| policy_loss        | -0.005112713 |
| serial_timesteps   | 13952        |
| time_elapsed       | 542          |
| total_timesteps    | 13952        |
| value_loss         | 2934.7915    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0013696135  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | -9.54e-07     |
| fps                | 27            |
| n_updates          | 110           |
| policy_entropy     | 0.9291963     |
| policy_loss        | -0.0038408593 |
| serial_timesteps   | 14080         |
| time_elapsed       | 547           |
| total_timesteps    | 14080         |
| value_loss         | 81.28438      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0015302867  |
| clipfrac           | 0.005859375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | 4.05e-06      |
| fps                | 25            |
| n_updates          | 111           |
| policy_entropy     | 0.9289708     |
| policy_loss        | -0.0010718696 |
| serial_timesteps   | 14208         |
| time_elapsed       | 552           |
| total_timesteps    | 14208         |
| value_loss         | 81.37969      |
--------------------------------------
-------------------------------------
| approxkl           | 0.007457968  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.84e+03     |
| explained_variance | 1.73e-06     |
| fps                | 28           |
| n_updates          | 112          |
| policy_entropy     | 0.92839247   |
| policy_loss        | -0.007178566 |
| serial_timesteps   | 14336        |
| time_elapsed       | 557          |
| total_timesteps    | 14336        |
| value_loss         | 62.90326     |
-------------------------------------
An average of 158.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00070271536 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | -2.26e-06     |
| fps                | 28            |
| n_updates          | 113           |
| policy_entropy     | 0.92810947    |
| policy_loss        | -0.0009906259 |
| serial_timesteps   | 14464         |
| time_elapsed       | 562           |
| total_timesteps    | 14464         |
| value_loss         | 71.85419      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00016264469 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | -4.77e-07     |
| fps                | 27            |
| n_updates          | 114           |
| policy_entropy     | 0.9277175     |
| policy_loss        | 0.00062809093 |
| serial_timesteps   | 14592         |
| time_elapsed       | 566           |
| total_timesteps    | 14592         |
| value_loss         | 100.21794     |
--------------------------------------
--------------------------------------
| approxkl           | 4.002689e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | 3.58e-07      |
| fps                | 26            |
| n_updates          | 115           |
| policy_entropy     | 0.92718       |
| policy_loss        | 0.00031978055 |
| serial_timesteps   | 14720         |
| time_elapsed       | 571           |
| total_timesteps    | 14720         |
| value_loss         | 59.726276     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018635642 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | -1.19e-07     |
| fps                | 28            |
| n_updates          | 116           |
| policy_entropy     | 0.9262907     |
| policy_loss        | 0.0005908498  |
| serial_timesteps   | 14848         |
| time_elapsed       | 575           |
| total_timesteps    | 14848         |
| value_loss         | 79.288925     |
--------------------------------------
--------------------------------------
| approxkl           | 0.000956163   |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.84e+03      |
| explained_variance | -1.19e-07     |
| fps                | 27            |
| n_updates          | 117           |
| policy_entropy     | 0.92491615    |
| policy_loss        | -0.0030739028 |
| serial_timesteps   | 14976         |
| time_elapsed       | 580           |
| total_timesteps    | 14976         |
| value_loss         | 57.80537      |
--------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b5cccf2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b5cccf2b0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b5cccf3c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b5cccf3c8>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2762 samples, validate on 336 samples
Epoch 312/5000
 - 6s - loss: 0.3801 - val_loss: 0.3840
Epoch 313/5000
 - 1s - loss: 0.3801 - val_loss: 0.3840
Epoch 314/5000
 - 1s - loss: 0.3801 - val_loss: 0.3840
Epoch 315/5000
 - 1s - loss: 0.3801 - val_loss: 0.3840
Epoch 316/5000
 - 1s - loss: 0.3801 - val_loss: 0.3840
Epoch 317/5000
 - 1s - loss: 0.3801 - val_loss: 0.3840
Train on 1857 samples, validate on 336 samples
Epoch 227/5000
 - 5s - loss: 0.0064 - val_loss: 0.0031
Epoch 228/5000
 - 0s - loss: 0.0064 - val_loss: 0.0031
Epoch 229/5000
 - 1s - loss: 0.0064 - val_loss: 0.0031
Epoch 230/5000
 - 1s - loss: 0.0064 - val_loss: 0.0031
Epoch 231/5000
 - 0s - loss: 0.0064 - val_loss: 0.0031
Epoch 232/5000
 - 0s - loss: 0.0064 - val_loss: 0.0031
Train on 2762 samples, validate on 336 samples
Epoch 606/5000
 - 7s - loss: 0.6394 - val_loss: 0.8939
Epoch 607/5000
 - 1s - loss: 0.5735 - val_loss: 0.9851
Epoch 608/5000
 - 1s - loss: 0.5609 - val_loss: 1.0007
Epoch 609/5000
 - 1s - loss: 0.5481 - val_loss: 1.0174
Epoch 610/5000
 - 1s - loss: 0.5463 - val_loss: 1.0320
Epoch 611/5000
 - 1s - loss: 0.5449 - val_loss: 1.0444
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0064949756 |
| clipfrac           | 0.080078125  |
| explained_variance | 1.49e-06     |
| fps                | 4            |
| n_updates          | 1            |
| policy_entropy     | 0.92362887   |
| policy_loss        | -0.007982037 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.31e-05     |
| total_timesteps    | 128          |
| value_loss         | 76.96696     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0012691505  |
| clipfrac           | 0.00390625    |
| explained_variance | -8.7e-06      |
| fps                | 26            |
| n_updates          | 2             |
| policy_entropy     | 0.9224386     |
| policy_loss        | -0.0042973785 |
| serial_timesteps   | 256           |
| time_elapsed       | 29            |
| total_timesteps    | 256           |
| value_loss         | 55.241222     |
--------------------------------------
--------------------------------------
| approxkl           | 0.004408802   |
| clipfrac           | 0.060546875   |
| explained_variance | -4.29e-06     |
| fps                | 27            |
| n_updates          | 3             |
| policy_entropy     | 0.92142856    |
| policy_loss        | -0.0051184185 |
| serial_timesteps   | 384           |
| time_elapsed       | 33.9          |
| total_timesteps    | 384           |
| value_loss         | 63.551636     |
--------------------------------------
An average of 159.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.017134588 |
| clipfrac           | 0.2421875   |
| explained_variance | -1.07e-06   |
| fps                | 23          |
| n_updates          | 4           |
| policy_entropy     | 0.91982836  |
| policy_loss        | 0.008423323 |
| serial_timesteps   | 512         |
| time_elapsed       | 38.5        |
| total_timesteps    | 512         |
| value_loss         | 76.16231    |
------------------------------------
--------------------------------------
| approxkl           | 0.0041138646  |
| clipfrac           | 0.0390625     |
| explained_variance | 1.79e-07      |
| fps                | 27            |
| n_updates          | 5             |
| policy_entropy     | 0.918568      |
| policy_loss        | -0.0006827628 |
| serial_timesteps   | 640           |
| time_elapsed       | 43.9          |
| total_timesteps    | 640           |
| value_loss         | 75.51372      |
--------------------------------------
------------------------------------
| approxkl           | 0.026611445 |
| clipfrac           | 0.35742188  |
| explained_variance | -2.38e-07   |
| fps                | 26          |
| n_updates          | 6           |
| policy_entropy     | 0.91749394  |
| policy_loss        | 0.020112224 |
| serial_timesteps   | 768         |
| time_elapsed       | 48.6        |
| total_timesteps    | 768         |
| value_loss         | 66.172264   |
------------------------------------
-------------------------------------
| approxkl           | 0.043817848  |
| clipfrac           | 0.40039062   |
| explained_variance | -3.58e-07    |
| fps                | 23           |
| n_updates          | 7            |
| policy_entropy     | 0.91696703   |
| policy_loss        | 0.0005824021 |
| serial_timesteps   | 896          |
| time_elapsed       | 53.5         |
| total_timesteps    | 896          |
| value_loss         | 99.604546    |
-------------------------------------
--------------------------------------
| approxkl           | 0.031327095   |
| clipfrac           | 0.40820312    |
| explained_variance | -5.96e-07     |
| fps                | 25            |
| n_updates          | 8             |
| policy_entropy     | 0.9171024     |
| policy_loss        | 0.00023835013 |
| serial_timesteps   | 1024          |
| time_elapsed       | 58.8          |
| total_timesteps    | 1024          |
| value_loss         | 66.20762      |
--------------------------------------
------------------------------------
| approxkl           | 0.030442104 |
| clipfrac           | 0.3671875   |
| explained_variance | -9.54e-07   |
| fps                | 24          |
| n_updates          | 9           |
| policy_entropy     | 0.916978    |
| policy_loss        | 0.022179633 |
| serial_timesteps   | 1152        |
| time_elapsed       | 63.9        |
| total_timesteps    | 1152        |
| value_loss         | 82.715805   |
------------------------------------
------------------------------------
| approxkl           | 0.045805346 |
| clipfrac           | 0.37304688  |
| explained_variance | -3.58e-07   |
| fps                | 27          |
| n_updates          | 10          |
| policy_entropy     | 0.91672814  |
| policy_loss        | 0.019853763 |
| serial_timesteps   | 1280        |
| time_elapsed       | 69.1        |
| total_timesteps    | 1280        |
| value_loss         | 56.8565     |
------------------------------------
An average of 159.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.036668114 |
| clipfrac           | 0.39257812  |
| explained_variance | -5.96e-07   |
| fps                | 23          |
| n_updates          | 11          |
| policy_entropy     | 0.91656905  |
| policy_loss        | 0.03320751  |
| serial_timesteps   | 1408        |
| time_elapsed       | 73.7        |
| total_timesteps    | 1408        |
| value_loss         | 69.70697    |
------------------------------------
-----------------------------------
| approxkl           | 0.04400336 |
| clipfrac           | 0.43945312 |
| explained_variance | -3.58e-06  |
| fps                | 25         |
| n_updates          | 12         |
| policy_entropy     | 0.9163486  |
| policy_loss        | 0.0354781  |
| serial_timesteps   | 1536       |
| time_elapsed       | 79.1       |
| total_timesteps    | 1536       |
| value_loss         | 62.49585   |
-----------------------------------
------------------------------------
| approxkl           | 0.011051187 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.95e+03    |
| explained_variance | -1.19e-07   |
| fps                | 25          |
| n_updates          | 13          |
| policy_entropy     | 0.9155099   |
| policy_loss        | 0.004606502 |
| serial_timesteps   | 1664        |
| time_elapsed       | 84          |
| total_timesteps    | 1664        |
| value_loss         | 2015.209    |
------------------------------------
---------------------------------------
| approxkl           | 0.0012707897   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.95e+03       |
| explained_variance | -7.15e-07      |
| fps                | 26             |
| n_updates          | 14             |
| policy_entropy     | 0.91458005     |
| policy_loss        | -4.2523257e-05 |
| serial_timesteps   | 1792           |
| time_elapsed       | 89.1           |
| total_timesteps    | 1792           |
| value_loss         | 59.925674      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0046368265  |
| clipfrac           | 0.04296875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.95e+03      |
| explained_variance | 5.96e-08      |
| fps                | 24            |
| n_updates          | 15            |
| policy_entropy     | 0.91391695    |
| policy_loss        | -0.0010409551 |
| serial_timesteps   | 1920          |
| time_elapsed       | 94            |
| total_timesteps    | 1920          |
| value_loss         | 60.01024      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00062070956 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.95e+03      |
| explained_variance | 8.34e-07      |
| fps                | 26            |
| n_updates          | 16            |
| policy_entropy     | 0.9121983     |
| policy_loss        | 0.0029364042  |
| serial_timesteps   | 2048          |
| time_elapsed       | 99.2          |
| total_timesteps    | 2048          |
| value_loss         | 48.12724      |
--------------------------------------
------------------------------------
| approxkl           | 0.004797915 |
| clipfrac           | 0.076171875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.95e+03    |
| explained_variance | 1.79e-07    |
| fps                | 27          |
| n_updates          | 17          |
| policy_entropy     | 0.9102022   |
| policy_loss        | 0.010718297 |
| serial_timesteps   | 2176        |
| time_elapsed       | 104         |
| total_timesteps    | 2176        |
| value_loss         | 49.837776   |
------------------------------------
--------------------------------------
| approxkl           | 0.04159996    |
| clipfrac           | 0.421875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.95e+03      |
| explained_variance | 1.91e-06      |
| fps                | 27            |
| n_updates          | 18            |
| policy_entropy     | 0.90945697    |
| policy_loss        | -0.0073600174 |
| serial_timesteps   | 2304          |
| time_elapsed       | 109           |
| total_timesteps    | 2304          |
| value_loss         | 12.840369     |
--------------------------------------
An average of 160.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.007400634  |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.95e+03     |
| explained_variance | 3.1e-06      |
| fps                | 26           |
| n_updates          | 19           |
| policy_entropy     | 0.90718114   |
| policy_loss        | 0.0032968018 |
| serial_timesteps   | 2432         |
| time_elapsed       | 113          |
| total_timesteps    | 2432         |
| value_loss         | 51.946697    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0029618097 |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.95e+03     |
| explained_variance | -1.19e-07    |
| fps                | 26           |
| n_updates          | 20           |
| policy_entropy     | 0.90449214   |
| policy_loss        | 0.005786114  |
| serial_timesteps   | 2560         |
| time_elapsed       | 118          |
| total_timesteps    | 2560         |
| value_loss         | 48.395866    |
-------------------------------------
--------------------------------------
| approxkl           | 0.003788763   |
| clipfrac           | 0.041015625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.95e+03      |
| explained_variance | 5.01e-06      |
| fps                | 24            |
| n_updates          | 21            |
| policy_entropy     | 0.9032321     |
| policy_loss        | -0.0065209707 |
| serial_timesteps   | 2688          |
| time_elapsed       | 123           |
| total_timesteps    | 2688          |
| value_loss         | 41.84744      |
--------------------------------------
-------------------------------------
| approxkl           | 0.011731961  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.95e+03     |
| explained_variance | -5.96e-07    |
| fps                | 25           |
| n_updates          | 22           |
| policy_entropy     | 0.90236      |
| policy_loss        | -0.007048595 |
| serial_timesteps   | 2816         |
| time_elapsed       | 128          |
| total_timesteps    | 2816         |
| value_loss         | 53.738094    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0014421333 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.95e+03     |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 23           |
| policy_entropy     | 0.90137386   |
| policy_loss        | -0.003219314 |
| serial_timesteps   | 2944         |
| time_elapsed       | 133          |
| total_timesteps    | 2944         |
| value_loss         | 59.120457    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0025899177 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.95e+03     |
| explained_variance | 1.13e-06     |
| fps                | 25           |
| n_updates          | 24           |
| policy_entropy     | 0.8996657    |
| policy_loss        | -0.0078114   |
| serial_timesteps   | 3072         |
| time_elapsed       | 138          |
| total_timesteps    | 3072         |
| value_loss         | 67.27172     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0071608545 |
| clipfrac           | 0.103515625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.87e+03     |
| explained_variance | 1.19e-07     |
| fps                | 26           |
| n_updates          | 25           |
| policy_entropy     | 0.89798933   |
| policy_loss        | -0.005183997 |
| serial_timesteps   | 3200         |
| time_elapsed       | 144          |
| total_timesteps    | 3200         |
| value_loss         | 2675.5986    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014355346  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.87e+03     |
| explained_variance | -2.15e-06    |
| fps                | 25           |
| n_updates          | 26           |
| policy_entropy     | 0.8972829    |
| policy_loss        | -0.011171635 |
| serial_timesteps   | 3328         |
| time_elapsed       | 148          |
| total_timesteps    | 3328         |
| value_loss         | 31.361393    |
-------------------------------------
An average of 161.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.008389957  |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.87e+03     |
| explained_variance | 3.28e-06     |
| fps                | 24           |
| n_updates          | 27           |
| policy_entropy     | 0.8967203    |
| policy_loss        | -0.007814305 |
| serial_timesteps   | 3456         |
| time_elapsed       | 153          |
| total_timesteps    | 3456         |
| value_loss         | 73.77492     |
-------------------------------------
------------------------------------
| approxkl           | 0.026982062 |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.87e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 28          |
| policy_entropy     | 0.89617676  |
| policy_loss        | 0.01663766  |
| serial_timesteps   | 3584        |
| time_elapsed       | 159         |
| total_timesteps    | 3584        |
| value_loss         | 92.55797    |
------------------------------------
------------------------------------
| approxkl           | 0.036185086 |
| clipfrac           | 0.3671875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.87e+03    |
| explained_variance | -5.96e-07   |
| fps                | 25          |
| n_updates          | 29          |
| policy_entropy     | 0.8957055   |
| policy_loss        | 0.016263688 |
| serial_timesteps   | 3712        |
| time_elapsed       | 164         |
| total_timesteps    | 3712        |
| value_loss         | 76.26656    |
------------------------------------
------------------------------------
| approxkl           | 0.04942915  |
| clipfrac           | 0.41796875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.87e+03    |
| explained_variance | -1.19e-07   |
| fps                | 25          |
| n_updates          | 30          |
| policy_entropy     | 0.8951331   |
| policy_loss        | 0.016276516 |
| serial_timesteps   | 3840        |
| time_elapsed       | 169         |
| total_timesteps    | 3840        |
| value_loss         | 74.468475   |
------------------------------------
------------------------------------
| approxkl           | 0.038104914 |
| clipfrac           | 0.40429688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.87e+03    |
| explained_variance | 1.91e-06    |
| fps                | 26          |
| n_updates          | 31          |
| policy_entropy     | 0.89490515  |
| policy_loss        | 0.007562773 |
| serial_timesteps   | 3968        |
| time_elapsed       | 174         |
| total_timesteps    | 3968        |
| value_loss         | 62.30984    |
------------------------------------
------------------------------------
| approxkl           | 0.003922806 |
| clipfrac           | 0.04296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.87e+03    |
| explained_variance | -2.38e-07   |
| fps                | 25          |
| n_updates          | 32          |
| policy_entropy     | 0.8943693   |
| policy_loss        | 0.008120124 |
| serial_timesteps   | 4096        |
| time_elapsed       | 179         |
| total_timesteps    | 4096        |
| value_loss         | 70.26302    |
------------------------------------
-------------------------------------
| approxkl           | 0.006552034  |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.87e+03     |
| explained_variance | -9.54e-07    |
| fps                | 24           |
| n_updates          | 33           |
| policy_entropy     | 0.8933327    |
| policy_loss        | -0.001585515 |
| serial_timesteps   | 4224         |
| time_elapsed       | 184          |
| total_timesteps    | 4224         |
| value_loss         | 66.36467     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0030290864  |
| clipfrac           | 0.029296875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.87e+03      |
| explained_variance | 1.07e-06      |
| fps                | 25            |
| n_updates          | 34            |
| policy_entropy     | 0.89211404    |
| policy_loss        | -0.0050226003 |
| serial_timesteps   | 4352          |
| time_elapsed       | 189           |
| total_timesteps    | 4352          |
| value_loss         | 66.59148      |
--------------------------------------
An average of 161.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0012601403  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.87e+03      |
| explained_variance | -1.19e-07     |
| fps                | 25            |
| n_updates          | 35            |
| policy_entropy     | 0.8911496     |
| policy_loss        | -0.0023375268 |
| serial_timesteps   | 4480          |
| time_elapsed       | 194           |
| total_timesteps    | 4480          |
| value_loss         | 79.46903      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0094714565 |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.87e+03     |
| explained_variance | 2.38e-07     |
| fps                | 26           |
| n_updates          | 36           |
| policy_entropy     | 0.89080185   |
| policy_loss        | -0.014708941 |
| serial_timesteps   | 4608         |
| time_elapsed       | 199          |
| total_timesteps    | 4608         |
| value_loss         | 63.782303    |
-------------------------------------
------------------------------------
| approxkl           | 0.024038479 |
| clipfrac           | 0.27539062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | 1.79e-07    |
| fps                | 25          |
| n_updates          | 37          |
| policy_entropy     | 0.8906777   |
| policy_loss        | 0.01035969  |
| serial_timesteps   | 4736        |
| time_elapsed       | 204         |
| total_timesteps    | 4736        |
| value_loss         | 2911.6252   |
------------------------------------
--------------------------------------
| approxkl           | 0.0003007437  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 1.85e-05      |
| fps                | 24            |
| n_updates          | 38            |
| policy_entropy     | 0.8907171     |
| policy_loss        | -0.0012250108 |
| serial_timesteps   | 4864          |
| time_elapsed       | 209           |
| total_timesteps    | 4864          |
| value_loss         | 82.65789      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00026819573 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 1.37e-05      |
| fps                | 24            |
| n_updates          | 39            |
| policy_entropy     | 0.8905082     |
| policy_loss        | 0.000608188   |
| serial_timesteps   | 4992          |
| time_elapsed       | 214           |
| total_timesteps    | 4992          |
| value_loss         | 64.27478      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0010692074 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | -9.54e-07    |
| fps                | 23           |
| n_updates          | 40           |
| policy_entropy     | 0.8894997    |
| policy_loss        | 0.000333664  |
| serial_timesteps   | 5120         |
| time_elapsed       | 219          |
| total_timesteps    | 5120         |
| value_loss         | 63.508686    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0070780073 |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | 2.98e-07     |
| fps                | 24           |
| n_updates          | 41           |
| policy_entropy     | 0.8871254    |
| policy_loss        | 0.012197396  |
| serial_timesteps   | 5248         |
| time_elapsed       | 225          |
| total_timesteps    | 5248         |
| value_loss         | 64.42976     |
-------------------------------------
------------------------------------
| approxkl           | 0.003339558 |
| clipfrac           | 0.029296875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 42          |
| policy_entropy     | 0.88537544  |
| policy_loss        | 0.005235771 |
| serial_timesteps   | 5376        |
| time_elapsed       | 230         |
| total_timesteps    | 5376        |
| value_loss         | 82.83637    |
------------------------------------
An average of 162.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.010241395 |
| clipfrac           | 0.12695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | 2.68e-06    |
| fps                | 25          |
| n_updates          | 43          |
| policy_entropy     | 0.88432735  |
| policy_loss        | 0.02450124  |
| serial_timesteps   | 5504        |
| time_elapsed       | 235         |
| total_timesteps    | 5504        |
| value_loss         | 63.1136     |
------------------------------------
------------------------------------
| approxkl           | 0.044537738 |
| clipfrac           | 0.39257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | -1.19e-07   |
| fps                | 24          |
| n_updates          | 44          |
| policy_entropy     | 0.8832107   |
| policy_loss        | 0.018245155 |
| serial_timesteps   | 5632        |
| time_elapsed       | 240         |
| total_timesteps    | 5632        |
| value_loss         | 70.40521    |
------------------------------------
------------------------------------
| approxkl           | 0.020232232 |
| clipfrac           | 0.28710938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | -5.48e-06   |
| fps                | 26          |
| n_updates          | 45          |
| policy_entropy     | 0.88252175  |
| policy_loss        | 0.015387705 |
| serial_timesteps   | 5760        |
| time_elapsed       | 245         |
| total_timesteps    | 5760        |
| value_loss         | 59.534885   |
------------------------------------
--------------------------------------
| approxkl           | 0.0048462767  |
| clipfrac           | 0.05078125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 5.96e-08      |
| fps                | 26            |
| n_updates          | 46            |
| policy_entropy     | 0.8814669     |
| policy_loss        | -0.0010646293 |
| serial_timesteps   | 5888          |
| time_elapsed       | 250           |
| total_timesteps    | 5888          |
| value_loss         | 77.22717      |
--------------------------------------
--------------------------------------
| approxkl           | 0.001084891   |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 2.5e-06       |
| fps                | 27            |
| n_updates          | 47            |
| policy_entropy     | 0.8802819     |
| policy_loss        | -0.0037535077 |
| serial_timesteps   | 6016          |
| time_elapsed       | 255           |
| total_timesteps    | 6016          |
| value_loss         | 51.889076     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0052043675  |
| clipfrac           | 0.052734375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 1.31e-06      |
| fps                | 25            |
| n_updates          | 48            |
| policy_entropy     | 0.87742394    |
| policy_loss        | -0.0022817934 |
| serial_timesteps   | 6144          |
| time_elapsed       | 259           |
| total_timesteps    | 6144          |
| value_loss         | 67.97453      |
--------------------------------------
--------------------------------------
| approxkl           | 1.945284e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | 5.96e-08      |
| fps                | 25            |
| n_updates          | 49            |
| policy_entropy     | 0.87569314    |
| policy_loss        | 0.00037614594 |
| serial_timesteps   | 6272          |
| time_elapsed       | 264           |
| total_timesteps    | 6272          |
| value_loss         | 3082.9412     |
--------------------------------------
An average of 163.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.008568531   |
| clipfrac           | 0.125         |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | -3.58e-07     |
| fps                | 24            |
| n_updates          | 50            |
| policy_entropy     | 0.8750296     |
| policy_loss        | -0.0088262325 |
| serial_timesteps   | 6400          |
| time_elapsed       | 269           |
| total_timesteps    | 6400          |
| value_loss         | 45.969646     |
--------------------------------------
--------------------------------------
| approxkl           | 0.002780815   |
| clipfrac           | 0.01953125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | -5.96e-07     |
| fps                | 25            |
| n_updates          | 51            |
| policy_entropy     | 0.8742897     |
| policy_loss        | -0.0038617547 |
| serial_timesteps   | 6528          |
| time_elapsed       | 274           |
| total_timesteps    | 6528          |
| value_loss         | 57.094017     |
--------------------------------------
------------------------------------
| approxkl           | 0.008817399 |
| clipfrac           | 0.12109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -1.19e-06   |
| fps                | 27          |
| n_updates          | 52          |
| policy_entropy     | 0.8728082   |
| policy_loss        | 0.01865998  |
| serial_timesteps   | 6656        |
| time_elapsed       | 279         |
| total_timesteps    | 6656        |
| value_loss         | 68.25043    |
------------------------------------
------------------------------------
| approxkl           | 0.036156856 |
| clipfrac           | 0.38867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -2.38e-07   |
| fps                | 25          |
| n_updates          | 53          |
| policy_entropy     | 0.8719039   |
| policy_loss        | 0.019274073 |
| serial_timesteps   | 6784        |
| time_elapsed       | 284         |
| total_timesteps    | 6784        |
| value_loss         | 56.913265   |
------------------------------------
-------------------------------------
| approxkl           | 0.016189687  |
| clipfrac           | 0.20117188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.93e+03     |
| explained_variance | 8.4e-06      |
| fps                | 24           |
| n_updates          | 54           |
| policy_entropy     | 0.8717372    |
| policy_loss        | -0.019649409 |
| serial_timesteps   | 6912         |
| time_elapsed       | 289          |
| total_timesteps    | 6912         |
| value_loss         | 28.717873    |
-------------------------------------
------------------------------------
| approxkl           | 0.017002024 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -5.96e-07   |
| fps                | 24          |
| n_updates          | 55          |
| policy_entropy     | 0.87151283  |
| policy_loss        | 0.010871698 |
| serial_timesteps   | 7040        |
| time_elapsed       | 294         |
| total_timesteps    | 7040        |
| value_loss         | 80.71916    |
------------------------------------
---------------------------------------
| approxkl           | 0.0010759734   |
| clipfrac           | 0.001953125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.93e+03       |
| explained_variance | 1.31e-06       |
| fps                | 25             |
| n_updates          | 56             |
| policy_entropy     | 0.87114143     |
| policy_loss        | -0.00025391066 |
| serial_timesteps   | 7168           |
| time_elapsed       | 299            |
| total_timesteps    | 7168           |
| value_loss         | 79.15719       |
---------------------------------------
-------------------------------------
| approxkl           | 0.04293736   |
| clipfrac           | 0.421875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.93e+03     |
| explained_variance | 4.77e-07     |
| fps                | 25           |
| n_updates          | 57           |
| policy_entropy     | 0.8712078    |
| policy_loss        | -0.013887483 |
| serial_timesteps   | 7296         |
| time_elapsed       | 304          |
| total_timesteps    | 7296         |
| value_loss         | 56.341255    |
-------------------------------------
An average of 163.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.03819998   |
| clipfrac           | 0.43554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.93e+03     |
| explained_variance | -5.84e-06    |
| fps                | 26           |
| n_updates          | 58           |
| policy_entropy     | 0.87091917   |
| policy_loss        | 0.0070131775 |
| serial_timesteps   | 7424         |
| time_elapsed       | 309          |
| total_timesteps    | 7424         |
| value_loss         | 43.197227    |
-------------------------------------
------------------------------------
| approxkl           | 0.026985181 |
| clipfrac           | 0.37890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -3.58e-07   |
| fps                | 26          |
| n_updates          | 59          |
| policy_entropy     | 0.8705891   |
| policy_loss        | 0.035436317 |
| serial_timesteps   | 7552        |
| time_elapsed       | 314         |
| total_timesteps    | 7552        |
| value_loss         | 66.11876    |
------------------------------------
------------------------------------
| approxkl           | 0.023011904 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -7.15e-07   |
| fps                | 24          |
| n_updates          | 60          |
| policy_entropy     | 0.87053186  |
| policy_loss        | 0.02916963  |
| serial_timesteps   | 7680        |
| time_elapsed       | 319         |
| total_timesteps    | 7680        |
| value_loss         | 50.446495   |
------------------------------------
------------------------------------
| approxkl           | 0.08466899  |
| clipfrac           | 0.57421875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 1.19e-07    |
| fps                | 25          |
| n_updates          | 61          |
| policy_entropy     | 0.8690375   |
| policy_loss        | 0.033852622 |
| serial_timesteps   | 7808        |
| time_elapsed       | 324         |
| total_timesteps    | 7808        |
| value_loss         | 3188.6357   |
------------------------------------
-------------------------------------
| approxkl           | 0.021160651  |
| clipfrac           | 0.25390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | 1.79e-07     |
| fps                | 25           |
| n_updates          | 62           |
| policy_entropy     | 0.8679053    |
| policy_loss        | -0.021261783 |
| serial_timesteps   | 7936         |
| time_elapsed       | 330          |
| total_timesteps    | 7936         |
| value_loss         | 8.349002     |
-------------------------------------
-------------------------------------
| approxkl           | 0.041724447  |
| clipfrac           | 0.33203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | 1.19e-06     |
| fps                | 24           |
| n_updates          | 63           |
| policy_entropy     | 0.86683315   |
| policy_loss        | -0.019186366 |
| serial_timesteps   | 8064         |
| time_elapsed       | 335          |
| total_timesteps    | 8064         |
| value_loss         | 7.1623106    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01152023   |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | 2.38e-07     |
| fps                | 25           |
| n_updates          | 64           |
| policy_entropy     | 0.8664986    |
| policy_loss        | 0.0075672604 |
| serial_timesteps   | 8192         |
| time_elapsed       | 340          |
| total_timesteps    | 8192         |
| value_loss         | 14.590626    |
-------------------------------------
-------------------------------------
| approxkl           | 0.020433709  |
| clipfrac           | 0.26171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | 0            |
| fps                | 25           |
| n_updates          | 65           |
| policy_entropy     | 0.8658497    |
| policy_loss        | -0.030126177 |
| serial_timesteps   | 8320         |
| time_elapsed       | 345          |
| total_timesteps    | 8320         |
| value_loss         | 37.167892    |
-------------------------------------
An average of 164.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0013890975  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.94e+03      |
| explained_variance | -8.34e-07     |
| fps                | 24            |
| n_updates          | 66            |
| policy_entropy     | 0.8656239     |
| policy_loss        | -0.0028385983 |
| serial_timesteps   | 8448          |
| time_elapsed       | 350           |
| total_timesteps    | 8448          |
| value_loss         | 45.95234      |
--------------------------------------
-------------------------------------
| approxkl           | 0.005488144  |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | -2.38e-06    |
| fps                | 24           |
| n_updates          | 67           |
| policy_entropy     | 0.863586     |
| policy_loss        | -0.008224633 |
| serial_timesteps   | 8576         |
| time_elapsed       | 355          |
| total_timesteps    | 8576         |
| value_loss         | 39.823982    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0032465737  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.94e+03      |
| explained_variance | 4.17e-07      |
| fps                | 25            |
| n_updates          | 68            |
| policy_entropy     | 0.86223483    |
| policy_loss        | -0.0021307617 |
| serial_timesteps   | 8704          |
| time_elapsed       | 360           |
| total_timesteps    | 8704          |
| value_loss         | 59.480892     |
--------------------------------------
------------------------------------
| approxkl           | 0.009854925 |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 1.79e-07    |
| fps                | 25          |
| n_updates          | 69          |
| policy_entropy     | 0.8617125   |
| policy_loss        | 0.023887508 |
| serial_timesteps   | 8832        |
| time_elapsed       | 365         |
| total_timesteps    | 8832        |
| value_loss         | 74.16835    |
------------------------------------
------------------------------------
| approxkl           | 0.044898577 |
| clipfrac           | 0.41015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 1.13e-06    |
| fps                | 26          |
| n_updates          | 70          |
| policy_entropy     | 0.86131495  |
| policy_loss        | 0.018215925 |
| serial_timesteps   | 8960        |
| time_elapsed       | 370         |
| total_timesteps    | 8960        |
| value_loss         | 60.075447   |
------------------------------------
------------------------------------
| approxkl           | 0.04525071  |
| clipfrac           | 0.4453125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | -3.58e-07   |
| fps                | 27          |
| n_updates          | 71          |
| policy_entropy     | 0.8612017   |
| policy_loss        | 0.010342039 |
| serial_timesteps   | 9088        |
| time_elapsed       | 375         |
| total_timesteps    | 9088        |
| value_loss         | 54.54849    |
------------------------------------
------------------------------------
| approxkl           | 0.026109602 |
| clipfrac           | 0.31640625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 3.52e-06    |
| fps                | 26          |
| n_updates          | 72          |
| policy_entropy     | 0.8610205   |
| policy_loss        | 0.010882905 |
| serial_timesteps   | 9216        |
| time_elapsed       | 380         |
| total_timesteps    | 9216        |
| value_loss         | 26.382345   |
------------------------------------
-------------------------------------
| approxkl           | 0.0072137495 |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.9e+03      |
| explained_variance | 0            |
| fps                | 24           |
| n_updates          | 73           |
| policy_entropy     | 0.86103845   |
| policy_loss        | 0.0048935567 |
| serial_timesteps   | 9344         |
| time_elapsed       | 385          |
| total_timesteps    | 9344         |
| value_loss         | 3201.844     |
-------------------------------------
An average of 165.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00065899437 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.9e+03       |
| explained_variance | 2.92e-06      |
| fps                | 25            |
| n_updates          | 74            |
| policy_entropy     | 0.8610906     |
| policy_loss        | -0.0006112362 |
| serial_timesteps   | 9472          |
| time_elapsed       | 390           |
| total_timesteps    | 9472          |
| value_loss         | 50.148422     |
--------------------------------------
-------------------------------------
| approxkl           | 0.004268642  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.9e+03      |
| explained_variance | 8.94e-07     |
| fps                | 25           |
| n_updates          | 75           |
| policy_entropy     | 0.86072105   |
| policy_loss        | -0.010102029 |
| serial_timesteps   | 9600         |
| time_elapsed       | 395          |
| total_timesteps    | 9600         |
| value_loss         | 40.734863    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00037305302 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.9e+03       |
| explained_variance | -6.08e-06     |
| fps                | 25            |
| n_updates          | 76            |
| policy_entropy     | 0.86007595    |
| policy_loss        | -0.001812411  |
| serial_timesteps   | 9728          |
| time_elapsed       | 400           |
| total_timesteps    | 9728          |
| value_loss         | 57.122875     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0066330004 |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.9e+03      |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 77           |
| policy_entropy     | 0.8595572    |
| policy_loss        | -0.009480902 |
| serial_timesteps   | 9856         |
| time_elapsed       | 405          |
| total_timesteps    | 9856         |
| value_loss         | 81.4621      |
-------------------------------------
--------------------------------------
| approxkl           | 0.007541908   |
| clipfrac           | 0.10546875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.9e+03       |
| explained_variance | 1.79e-07      |
| fps                | 26            |
| n_updates          | 78            |
| policy_entropy     | 0.8590719     |
| policy_loss        | -0.0068235453 |
| serial_timesteps   | 9984          |
| time_elapsed       | 410           |
| total_timesteps    | 9984          |
| value_loss         | 45.168682     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0065875584 |
| clipfrac           | 0.087890625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.9e+03      |
| explained_variance | -1.19e-07    |
| fps                | 24           |
| n_updates          | 79           |
| policy_entropy     | 0.8583166    |
| policy_loss        | 0.01628848   |
| serial_timesteps   | 10112        |
| time_elapsed       | 415          |
| total_timesteps    | 10112        |
| value_loss         | 41.084805    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077049327 |
| clipfrac           | 0.099609375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.9e+03      |
| explained_variance | 1.31e-06     |
| fps                | 24           |
| n_updates          | 80           |
| policy_entropy     | 0.85714126   |
| policy_loss        | 0.0060188957 |
| serial_timesteps   | 10240        |
| time_elapsed       | 420          |
| total_timesteps    | 10240        |
| value_loss         | 70.82748     |
-------------------------------------
------------------------------------
| approxkl           | 0.004047016 |
| clipfrac           | 0.0546875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.9e+03     |
| explained_variance | 2.38e-07    |
| fps                | 25          |
| n_updates          | 81          |
| policy_entropy     | 0.8555075   |
| policy_loss        | 0.01012946  |
| serial_timesteps   | 10368       |
| time_elapsed       | 425         |
| total_timesteps    | 10368       |
| value_loss         | 58.36287    |
------------------------------------
An average of 165.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0022247764  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.9e+03       |
| explained_variance | -9.54e-07     |
| fps                | 25            |
| n_updates          | 82            |
| policy_entropy     | 0.8508278     |
| policy_loss        | -0.0007026701 |
| serial_timesteps   | 10496         |
| time_elapsed       | 430           |
| total_timesteps    | 10496         |
| value_loss         | 66.43102      |
--------------------------------------
------------------------------------
| approxkl           | 0.007579596 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.9e+03     |
| explained_variance | -1.19e-07   |
| fps                | 24          |
| n_updates          | 83          |
| policy_entropy     | 0.8473019   |
| policy_loss        | 0.008719001 |
| serial_timesteps   | 10624       |
| time_elapsed       | 435         |
| total_timesteps    | 10624       |
| value_loss         | 60.187706   |
------------------------------------
--------------------------------------
| approxkl           | 0.0018117991  |
| clipfrac           | 0.015625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.9e+03       |
| explained_variance | 4.89e-06      |
| fps                | 25            |
| n_updates          | 84            |
| policy_entropy     | 0.8456591     |
| policy_loss        | -0.0015710758 |
| serial_timesteps   | 10752         |
| time_elapsed       | 440           |
| total_timesteps    | 10752         |
| value_loss         | 56.470364     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00023876151 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 1.19e-07      |
| fps                | 27            |
| n_updates          | 85            |
| policy_entropy     | 0.8444322     |
| policy_loss        | 0.0017341648  |
| serial_timesteps   | 10880         |
| time_elapsed       | 446           |
| total_timesteps    | 10880         |
| value_loss         | 3189.7598     |
--------------------------------------
-------------------------------------
| approxkl           | 0.003847288  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 86           |
| policy_entropy     | 0.84388304   |
| policy_loss        | -0.008858556 |
| serial_timesteps   | 11008        |
| time_elapsed       | 450          |
| total_timesteps    | 11008        |
| value_loss         | 88.47015     |
-------------------------------------
-------------------------------------
| approxkl           | 0.002058487  |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | 1.19e-07     |
| fps                | 26           |
| n_updates          | 87           |
| policy_entropy     | 0.8435173    |
| policy_loss        | -0.005256785 |
| serial_timesteps   | 11136        |
| time_elapsed       | 455          |
| total_timesteps    | 11136        |
| value_loss         | 49.012264    |
-------------------------------------
------------------------------------
| approxkl           | 0.009667911 |
| clipfrac           | 0.15039062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | 7.15e-07    |
| fps                | 26          |
| n_updates          | 88          |
| policy_entropy     | 0.84309644  |
| policy_loss        | 0.013000695 |
| serial_timesteps   | 11264       |
| time_elapsed       | 460         |
| total_timesteps    | 11264       |
| value_loss         | 51.420593   |
------------------------------------
An average of 166.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0038186617 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | 1.19e-07     |
| fps                | 24           |
| n_updates          | 89           |
| policy_entropy     | 0.84251225   |
| policy_loss        | 0.0035186855 |
| serial_timesteps   | 11392        |
| time_elapsed       | 465          |
| total_timesteps    | 11392        |
| value_loss         | 53.036316    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005954695  |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | 3.7e-06      |
| fps                | 26           |
| n_updates          | 90           |
| policy_entropy     | 0.84158856   |
| policy_loss        | -0.006619553 |
| serial_timesteps   | 11520        |
| time_elapsed       | 470          |
| total_timesteps    | 11520        |
| value_loss         | 44.52859     |
-------------------------------------
------------------------------------
| approxkl           | 0.013392201 |
| clipfrac           | 0.19335938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | -1.43e-06   |
| fps                | 25          |
| n_updates          | 91          |
| policy_entropy     | 0.84097606  |
| policy_loss        | 0.007026823 |
| serial_timesteps   | 11648       |
| time_elapsed       | 475         |
| total_timesteps    | 11648       |
| value_loss         | 38.585903   |
------------------------------------
-------------------------------------
| approxkl           | 0.0011094685 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | 0            |
| fps                | 25           |
| n_updates          | 92           |
| policy_entropy     | 0.83942837   |
| policy_loss        | 0.0011020126 |
| serial_timesteps   | 11776        |
| time_elapsed       | 480          |
| total_timesteps    | 11776        |
| value_loss         | 44.949287    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010578857  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.91e+03     |
| explained_variance | -7.15e-07    |
| fps                | 24           |
| n_updates          | 93           |
| policy_entropy     | 0.83830357   |
| policy_loss        | -0.012532388 |
| serial_timesteps   | 11904        |
| time_elapsed       | 485          |
| total_timesteps    | 11904        |
| value_loss         | 55.776558    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00048922666 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | -1.79e-06     |
| fps                | 25            |
| n_updates          | 94            |
| policy_entropy     | 0.8377309     |
| policy_loss        | 0.00090505136 |
| serial_timesteps   | 12032         |
| time_elapsed       | 490           |
| total_timesteps    | 12032         |
| value_loss         | 44.332176     |
--------------------------------------
------------------------------------
| approxkl           | 0.008473106 |
| clipfrac           | 0.115234375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.91e+03    |
| explained_variance | -9.54e-07   |
| fps                | 24          |
| n_updates          | 95          |
| policy_entropy     | 0.8379215   |
| policy_loss        | 0.004723613 |
| serial_timesteps   | 12160       |
| time_elapsed       | 495         |
| total_timesteps    | 12160       |
| value_loss         | 52.67005    |
------------------------------------
--------------------------------------
| approxkl           | 0.0050713317  |
| clipfrac           | 0.072265625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.91e+03      |
| explained_variance | 4.17e-07      |
| fps                | 24            |
| n_updates          | 96            |
| policy_entropy     | 0.8373925     |
| policy_loss        | -0.0024003962 |
| serial_timesteps   | 12288         |
| time_elapsed       | 501           |
| total_timesteps    | 12288         |
| value_loss         | 54.233673     |
--------------------------------------
An average of 167.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.012099282 |
| clipfrac           | 0.19726562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 97          |
| policy_entropy     | 0.83628654  |
| policy_loss        | 0.019324865 |
| serial_timesteps   | 12416       |
| time_elapsed       | 506         |
| total_timesteps    | 12416       |
| value_loss         | 3302.945    |
------------------------------------
--------------------------------------
| approxkl           | 0.005196453   |
| clipfrac           | 0.0703125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | 0             |
| fps                | 24            |
| n_updates          | 98            |
| policy_entropy     | 0.8357123     |
| policy_loss        | -0.0025569946 |
| serial_timesteps   | 12544         |
| time_elapsed       | 511           |
| total_timesteps    | 12544         |
| value_loss         | 54.059677     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005855722  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | 8.34e-07      |
| fps                | 25            |
| n_updates          | 99            |
| policy_entropy     | 0.8353394     |
| policy_loss        | -0.0019514582 |
| serial_timesteps   | 12672         |
| time_elapsed       | 516           |
| total_timesteps    | 12672         |
| value_loss         | 75.11652      |
--------------------------------------
-------------------------------------
| approxkl           | 0.018759433  |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.93e+03     |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 100          |
| policy_entropy     | 0.8350265    |
| policy_loss        | 0.0046279174 |
| serial_timesteps   | 12800        |
| time_elapsed       | 521          |
| total_timesteps    | 12800        |
| value_loss         | 34.76914     |
-------------------------------------
------------------------------------
| approxkl           | 0.03042874  |
| clipfrac           | 0.3515625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | 5.96e-08    |
| fps                | 23          |
| n_updates          | 101         |
| policy_entropy     | 0.8344802   |
| policy_loss        | 0.028238092 |
| serial_timesteps   | 12928       |
| time_elapsed       | 526         |
| total_timesteps    | 12928       |
| value_loss         | 50.976784   |
------------------------------------
--------------------------------------
| approxkl           | 0.01159705    |
| clipfrac           | 0.18554688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | 0             |
| fps                | 24            |
| n_updates          | 102           |
| policy_entropy     | 0.8337587     |
| policy_loss        | -0.0069733323 |
| serial_timesteps   | 13056         |
| time_elapsed       | 531           |
| total_timesteps    | 13056         |
| value_loss         | 61.79337      |
--------------------------------------
------------------------------------
| approxkl           | 0.01692217  |
| clipfrac           | 0.25390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -1.67e-06   |
| fps                | 25          |
| n_updates          | 103         |
| policy_entropy     | 0.83354115  |
| policy_loss        | 0.012908004 |
| serial_timesteps   | 13184       |
| time_elapsed       | 536         |
| total_timesteps    | 13184       |
| value_loss         | 41.734737   |
------------------------------------
-------------------------------------
| approxkl           | 0.0027630562 |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.93e+03     |
| explained_variance | 4.17e-07     |
| fps                | 26           |
| n_updates          | 104          |
| policy_entropy     | 0.83326566   |
| policy_loss        | 0.003682889  |
| serial_timesteps   | 13312        |
| time_elapsed       | 541          |
| total_timesteps    | 13312        |
| value_loss         | 79.445946    |
-------------------------------------
An average of 167.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.002991018   |
| clipfrac           | 0.0234375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.93e+03      |
| explained_variance | -4.77e-07     |
| fps                | 26            |
| n_updates          | 105           |
| policy_entropy     | 0.8327478     |
| policy_loss        | -0.0055264584 |
| serial_timesteps   | 13440         |
| time_elapsed       | 546           |
| total_timesteps    | 13440         |
| value_loss         | 40.802765     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01087624   |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.93e+03     |
| explained_variance | -2.38e-07    |
| fps                | 26           |
| n_updates          | 106          |
| policy_entropy     | 0.83176357   |
| policy_loss        | -0.011642812 |
| serial_timesteps   | 13568        |
| time_elapsed       | 551          |
| total_timesteps    | 13568        |
| value_loss         | 49.334663    |
-------------------------------------
------------------------------------
| approxkl           | 0.033369023 |
| clipfrac           | 0.4453125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | -2.38e-06   |
| fps                | 24          |
| n_updates          | 107         |
| policy_entropy     | 0.8304541   |
| policy_loss        | 0.011901404 |
| serial_timesteps   | 13696       |
| time_elapsed       | 556         |
| total_timesteps    | 13696       |
| value_loss         | 51.343716   |
------------------------------------
------------------------------------
| approxkl           | 0.036477856 |
| clipfrac           | 0.4609375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.93e+03    |
| explained_variance | 3.46e-06    |
| fps                | 25          |
| n_updates          | 108         |
| policy_entropy     | 0.8296638   |
| policy_loss        | 0.008265713 |
| serial_timesteps   | 13824       |
| time_elapsed       | 561         |
| total_timesteps    | 13824       |
| value_loss         | 31.932993   |
------------------------------------
------------------------------------
| approxkl           | 0.093934104 |
| clipfrac           | 0.546875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | -1.19e-07   |
| fps                | 23          |
| n_updates          | 109         |
| policy_entropy     | 0.82920265  |
| policy_loss        | 0.014278941 |
| serial_timesteps   | 13952       |
| time_elapsed       | 566         |
| total_timesteps    | 13952       |
| value_loss         | 3315.783    |
------------------------------------
--------------------------------------
| approxkl           | 0.0047990824  |
| clipfrac           | 0.0625        |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.94e+03      |
| explained_variance | 2.98e-07      |
| fps                | 25            |
| n_updates          | 110           |
| policy_entropy     | 0.82886285    |
| policy_loss        | -0.0059470865 |
| serial_timesteps   | 14080         |
| time_elapsed       | 572           |
| total_timesteps    | 14080         |
| value_loss         | 21.991833     |
--------------------------------------
-------------------------------------
| approxkl           | 0.015338308  |
| clipfrac           | 0.20898438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | -8.34e-07    |
| fps                | 25           |
| n_updates          | 111          |
| policy_entropy     | 0.8282759    |
| policy_loss        | -0.019451216 |
| serial_timesteps   | 14208        |
| time_elapsed       | 577          |
| total_timesteps    | 14208        |
| value_loss         | 20.197315    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0048241573 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.94e+03     |
| explained_variance | -1.43e-06    |
| fps                | 25           |
| n_updates          | 112          |
| policy_entropy     | 0.8277225    |
| policy_loss        | 0.008577461  |
| serial_timesteps   | 14336        |
| time_elapsed       | 582          |
| total_timesteps    | 14336        |
| value_loss         | 54.220562    |
-------------------------------------
An average of 168.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.052917156 |
| clipfrac           | 0.5         |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | -1.79e-06   |
| fps                | 25          |
| n_updates          | 113         |
| policy_entropy     | 0.82711744  |
| policy_loss        | 0.024400683 |
| serial_timesteps   | 14464       |
| time_elapsed       | 587         |
| total_timesteps    | 14464       |
| value_loss         | 55.771587   |
------------------------------------
------------------------------------
| approxkl           | 0.037790585 |
| clipfrac           | 0.38671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 0           |
| fps                | 26          |
| n_updates          | 114         |
| policy_entropy     | 0.8265684   |
| policy_loss        | 0.027616864 |
| serial_timesteps   | 14592       |
| time_elapsed       | 592         |
| total_timesteps    | 14592       |
| value_loss         | 53.000088   |
------------------------------------
------------------------------------
| approxkl           | 0.060937643 |
| clipfrac           | 0.5078125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 0           |
| fps                | 25          |
| n_updates          | 115         |
| policy_entropy     | 0.8259704   |
| policy_loss        | 0.01942301  |
| serial_timesteps   | 14720       |
| time_elapsed       | 597         |
| total_timesteps    | 14720       |
| value_loss         | 52.097477   |
------------------------------------
------------------------------------
| approxkl           | 0.04547483  |
| clipfrac           | 0.45898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | -1.19e-07   |
| fps                | 24          |
| n_updates          | 116         |
| policy_entropy     | 0.82592416  |
| policy_loss        | 0.006966056 |
| serial_timesteps   | 14848       |
| time_elapsed       | 602         |
| total_timesteps    | 14848       |
| value_loss         | 49.754337   |
------------------------------------
------------------------------------
| approxkl           | 0.018503211 |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.94e+03    |
| explained_variance | 2.26e-06    |
| fps                | 25          |
| n_updates          | 117         |
| policy_entropy     | 0.82565624  |
| policy_loss        | 0.035583384 |
| serial_timesteps   | 14976       |
| time_elapsed       | 607         |
| total_timesteps    | 14976       |
| value_loss         | 40.038673   |
------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b58dfa4a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b58dfa4a8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b58d77a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b58d77a90>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2949 samples, validate on 150 samples
Epoch 318/5000
 - 6s - loss: 0.3974 - val_loss: 0.5247
Epoch 319/5000
 - 1s - loss: 0.3974 - val_loss: 0.5247
Epoch 320/5000
 - 1s - loss: 0.3974 - val_loss: 0.5247
Epoch 321/5000
 - 1s - loss: 0.3974 - val_loss: 0.5247
Epoch 322/5000
 - 1s - loss: 0.3974 - val_loss: 0.5247
Epoch 323/5000
 - 1s - loss: 0.3974 - val_loss: 0.5247
Train on 1896 samples, validate on 150 samples
Epoch 233/5000
 - 6s - loss: 0.0052 - val_loss: 0.0028
Epoch 234/5000
 - 0s - loss: 0.0052 - val_loss: 0.0028
Epoch 235/5000
 - 1s - loss: 0.0052 - val_loss: 0.0028
Epoch 236/5000
 - 0s - loss: 0.0052 - val_loss: 0.0028
Epoch 237/5000
 - 0s - loss: 0.0052 - val_loss: 0.0028
Epoch 238/5000
 - 0s - loss: 0.0052 - val_loss: 0.0028
Train on 2949 samples, validate on 150 samples
Epoch 612/5000
 - 7s - loss: 0.6858 - val_loss: 0.6754
Epoch 613/5000
 - 1s - loss: 0.6665 - val_loss: 0.6721
Epoch 614/5000
 - 1s - loss: 0.6547 - val_loss: 0.6723
Epoch 615/5000
 - 1s - loss: 0.6500 - val_loss: 0.6713
Epoch 616/5000
 - 1s - loss: 0.6480 - val_loss: 0.6696
Epoch 617/5000
 - 1s - loss: 0.6442 - val_loss: 0.6650
Epoch 618/5000
 - 1s - loss: 0.6382 - val_loss: 0.6584
Epoch 619/5000
 - 1s - loss: 0.6231 - val_loss: 0.6486
Epoch 620/5000
 - 1s - loss: 0.6012 - val_loss: 0.6428
Epoch 621/5000
 - 1s - loss: 0.5867 - val_loss: 0.6283
Epoch 622/5000
 - 1s - loss: 0.5682 - val_loss: 0.6180
Epoch 623/5000
 - 1s - loss: 0.5609 - val_loss: 0.6086
Epoch 624/5000
 - 1s - loss: 0.5553 - val_loss: 0.6011
Epoch 625/5000
 - 1s - loss: 0.5502 - val_loss: 0.5963
Epoch 626/5000
 - 1s - loss: 0.5468 - val_loss: 0.5920
Epoch 627/5000
 - 1s - loss: 0.5439 - val_loss: 0.5896
Epoch 628/5000
 - 1s - loss: 0.5421 - val_loss: 0.5857
Epoch 629/5000
 - 1s - loss: 0.5399 - val_loss: 0.5834
Epoch 630/5000
 - 1s - loss: 0.5382 - val_loss: 0.5816
Epoch 631/5000
 - 1s - loss: 0.5366 - val_loss: 0.5796
Epoch 632/5000
 - 1s - loss: 0.5349 - val_loss: 0.5780
Epoch 633/5000
 - 1s - loss: 0.5332 - val_loss: 0.5766
Epoch 634/5000
 - 1s - loss: 0.5319 - val_loss: 0.5764
Epoch 635/5000
 - 1s - loss: 0.5316 - val_loss: 0.5758
Epoch 636/5000
 - 1s - loss: 0.5306 - val_loss: 0.5749
Epoch 637/5000
 - 1s - loss: 0.5296 - val_loss: 0.5737
Epoch 638/5000
 - 1s - loss: 0.5283 - val_loss: 0.5729
Epoch 639/5000
 - 1s - loss: 0.5273 - val_loss: 0.5723
Epoch 640/5000
 - 1s - loss: 0.5267 - val_loss: 0.5718
Epoch 641/5000
 - 1s - loss: 0.5260 - val_loss: 0.5713
Epoch 642/5000
 - 1s - loss: 0.5256 - val_loss: 0.5708
Epoch 643/5000
 - 1s - loss: 0.5248 - val_loss: 0.5693
Epoch 644/5000
 - 1s - loss: 0.5234 - val_loss: 0.5690
Epoch 645/5000
 - 1s - loss: 0.5228 - val_loss: 0.5689
Epoch 646/5000
 - 1s - loss: 0.5223 - val_loss: 0.5686
Epoch 647/5000
 - 1s - loss: 0.5217 - val_loss: 0.5678
Epoch 648/5000
 - 1s - loss: 0.5207 - val_loss: 0.5673
Epoch 649/5000
 - 1s - loss: 0.5198 - val_loss: 0.5671
Epoch 650/5000
 - 1s - loss: 0.5192 - val_loss: 0.5667
Epoch 651/5000
 - 1s - loss: 0.5184 - val_loss: 0.5665
Epoch 652/5000
 - 1s - loss: 0.5175 - val_loss: 0.5665
Epoch 653/5000
 - 1s - loss: 0.5169 - val_loss: 0.5666
Epoch 654/5000
 - 1s - loss: 0.5094 - val_loss: 0.5537
Epoch 655/5000
 - 1s - loss: 0.4999 - val_loss: 0.5436
Epoch 656/5000
 - 1s - loss: 0.4941 - val_loss: 0.5367
Epoch 657/5000
 - 1s - loss: 0.4906 - val_loss: 0.5322
Epoch 658/5000
 - 1s - loss: 0.4887 - val_loss: 0.5291
Epoch 659/5000
 - 1s - loss: 0.4876 - val_loss: 0.5270
Epoch 660/5000
 - 1s - loss: 0.4868 - val_loss: 0.5256
Epoch 661/5000
 - 1s - loss: 0.4863 - val_loss: 0.5247
Epoch 662/5000
 - 1s - loss: 0.4860 - val_loss: 0.5241
Epoch 663/5000
 - 1s - loss: 0.4858 - val_loss: 0.5235
Epoch 664/5000
 - 1s - loss: 0.4856 - val_loss: 0.5232
Epoch 665/5000
 - 1s - loss: 0.4854 - val_loss: 0.5230
Epoch 666/5000
 - 1s - loss: 0.4852 - val_loss: 0.5228
Epoch 667/5000
 - 1s - loss: 0.4850 - val_loss: 0.5227
Epoch 668/5000
 - 1s - loss: 0.4849 - val_loss: 0.5226
Epoch 669/5000
 - 1s - loss: 0.4848 - val_loss: 0.5225
Epoch 670/5000
 - 1s - loss: 0.4846 - val_loss: 0.5224
Epoch 671/5000
 - 1s - loss: 0.4845 - val_loss: 0.5223
Epoch 672/5000
 - 1s - loss: 0.4843 - val_loss: 0.5222
Epoch 673/5000
 - 1s - loss: 0.4842 - val_loss: 0.5221
Epoch 674/5000
 - 1s - loss: 0.4840 - val_loss: 0.5220
Epoch 675/5000
 - 1s - loss: 0.4839 - val_loss: 0.5219
Epoch 676/5000
 - 1s - loss: 0.4837 - val_loss: 0.5218
Epoch 677/5000
 - 1s - loss: 0.4836 - val_loss: 0.5217
Epoch 678/5000
 - 1s - loss: 0.4834 - val_loss: 0.5217
Epoch 679/5000
 - 1s - loss: 0.4833 - val_loss: 0.5216
Epoch 680/5000
 - 1s - loss: 0.4831 - val_loss: 0.5215
Epoch 681/5000
 - 1s - loss: 0.4829 - val_loss: 0.5215
Epoch 682/5000
 - 1s - loss: 0.4828 - val_loss: 0.5214
Epoch 683/5000
 - 1s - loss: 0.4827 - val_loss: 0.5214
Epoch 684/5000
 - 1s - loss: 0.4796 - val_loss: 0.5213
Epoch 685/5000
 - 1s - loss: 0.4796 - val_loss: 0.5212
Epoch 686/5000
 - 1s - loss: 0.4795 - val_loss: 0.5211
Epoch 687/5000
 - 1s - loss: 0.4795 - val_loss: 0.5210
Epoch 688/5000
 - 1s - loss: 0.4795 - val_loss: 0.5208
Epoch 689/5000
 - 1s - loss: 0.4794 - val_loss: 0.5207
Epoch 690/5000
 - 1s - loss: 0.4794 - val_loss: 0.5207
Epoch 691/5000
 - 1s - loss: 0.4794 - val_loss: 0.5206
Epoch 692/5000
 - 1s - loss: 0.4794 - val_loss: 0.5205
Epoch 693/5000
 - 1s - loss: 0.4793 - val_loss: 0.5204
Epoch 694/5000
 - 1s - loss: 0.4793 - val_loss: 0.5203
Epoch 695/5000
 - 1s - loss: 0.4793 - val_loss: 0.5203
Epoch 696/5000
 - 1s - loss: 0.4792 - val_loss: 0.5202
Epoch 697/5000
 - 1s - loss: 0.4792 - val_loss: 0.5201
Epoch 698/5000
 - 1s - loss: 0.4792 - val_loss: 0.5200
Epoch 699/5000
 - 1s - loss: 0.4792 - val_loss: 0.5200
Epoch 700/5000
 - 1s - loss: 0.4792 - val_loss: 0.5199
Epoch 701/5000
 - 1s - loss: 0.4791 - val_loss: 0.5199
Epoch 702/5000
 - 1s - loss: 0.4791 - val_loss: 0.5198
Epoch 703/5000
 - 1s - loss: 0.4791 - val_loss: 0.5198
Epoch 704/5000
 - 1s - loss: 0.4791 - val_loss: 0.5197
Epoch 705/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 706/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 707/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 708/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 709/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 710/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 711/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 712/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 713/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 714/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 715/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 716/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
Epoch 717/5000
 - 1s - loss: 0.4787 - val_loss: 0.5197
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0065976162 |
| clipfrac           | 0.095703125  |
| explained_variance | -8.11e-06    |
| fps                | 4            |
| n_updates          | 1            |
| policy_entropy     | 0.824552     |
| policy_loss        | 0.0072331615 |
| serial_timesteps   | 128          |
| time_elapsed       | 2.43e-05     |
| total_timesteps    | 128          |
| value_loss         | 45.64295     |
-------------------------------------
------------------------------------
| approxkl           | 0.020813417 |
| clipfrac           | 0.2890625   |
| explained_variance | -5.96e-07   |
| fps                | 33          |
| n_updates          | 2           |
| policy_entropy     | 0.8234212   |
| policy_loss        | 0.03200288  |
| serial_timesteps   | 256         |
| time_elapsed       | 29.2        |
| total_timesteps    | 256         |
| value_loss         | 56.027546   |
------------------------------------
------------------------------------
| approxkl           | 0.021693468 |
| clipfrac           | 0.265625    |
| explained_variance | 1.19e-07    |
| fps                | 33          |
| n_updates          | 3           |
| policy_entropy     | 0.82168406  |
| policy_loss        | 0.03762374  |
| serial_timesteps   | 384         |
| time_elapsed       | 33          |
| total_timesteps    | 384         |
| value_loss         | 49.645203   |
------------------------------------
An average of 169.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.040243134 |
| clipfrac           | 0.42382812  |
| explained_variance | 1.19e-07    |
| fps                | 35          |
| n_updates          | 4           |
| policy_entropy     | 0.82071114  |
| policy_loss        | 0.02525668  |
| serial_timesteps   | 512         |
| time_elapsed       | 36.9        |
| total_timesteps    | 512         |
| value_loss         | 49.63805    |
------------------------------------
--------------------------------------
| approxkl           | 0.05649884    |
| clipfrac           | 0.43554688    |
| explained_variance | -4.77e-07     |
| fps                | 31            |
| n_updates          | 5             |
| policy_entropy     | 0.8203957     |
| policy_loss        | -0.0013604716 |
| serial_timesteps   | 640           |
| time_elapsed       | 40.5          |
| total_timesteps    | 640           |
| value_loss         | 73.18656      |
--------------------------------------
--------------------------------------
| approxkl           | 0.026652182   |
| clipfrac           | 0.34765625    |
| explained_variance | 0             |
| fps                | 31            |
| n_updates          | 6             |
| policy_entropy     | 0.8201558     |
| policy_loss        | -9.421399e-05 |
| serial_timesteps   | 768           |
| time_elapsed       | 44.6          |
| total_timesteps    | 768           |
| value_loss         | 38.137573     |
--------------------------------------
------------------------------------
| approxkl           | 0.015080749 |
| clipfrac           | 0.21484375  |
| explained_variance | -1.07e-06   |
| fps                | 31          |
| n_updates          | 7           |
| policy_entropy     | 0.8200531   |
| policy_loss        | 0.027881017 |
| serial_timesteps   | 896         |
| time_elapsed       | 48.6        |
| total_timesteps    | 896         |
| value_loss         | 50.730366   |
------------------------------------
------------------------------------
| approxkl           | 0.043005235 |
| clipfrac           | 0.43945312  |
| explained_variance | 4.17e-07    |
| fps                | 33          |
| n_updates          | 8           |
| policy_entropy     | 0.8190674   |
| policy_loss        | 0.037991773 |
| serial_timesteps   | 1024        |
| time_elapsed       | 52.7        |
| total_timesteps    | 1024        |
| value_loss         | 52.981705   |
------------------------------------
------------------------------------
| approxkl           | 0.0538774   |
| clipfrac           | 0.44726562  |
| explained_variance | 0           |
| fps                | 32          |
| n_updates          | 9           |
| policy_entropy     | 0.81844735  |
| policy_loss        | 0.046405748 |
| serial_timesteps   | 1152        |
| time_elapsed       | 56.5        |
| total_timesteps    | 1152        |
| value_loss         | 47.42137    |
------------------------------------
------------------------------------
| approxkl           | 0.058675118 |
| clipfrac           | 0.45703125  |
| explained_variance | 2.38e-07    |
| fps                | 31          |
| n_updates          | 10          |
| policy_entropy     | 0.81825864  |
| policy_loss        | 0.027579607 |
| serial_timesteps   | 1280        |
| time_elapsed       | 60.4        |
| total_timesteps    | 1280        |
| value_loss         | 42.715492   |
------------------------------------
------------------------------------
| approxkl           | 0.03137643  |
| clipfrac           | 0.33007812  |
| explained_variance | -4.77e-07   |
| fps                | 32          |
| n_updates          | 11          |
| policy_entropy     | 0.8175038   |
| policy_loss        | 0.048473615 |
| serial_timesteps   | 1408        |
| time_elapsed       | 64.5        |
| total_timesteps    | 1408        |
| value_loss         | 61.33734    |
------------------------------------
An average of 169.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.026089564 |
| clipfrac           | 0.33007812  |
| explained_variance | -1.19e-07   |
| fps                | 32          |
| n_updates          | 12          |
| policy_entropy     | 0.8159679   |
| policy_loss        | 0.032408036 |
| serial_timesteps   | 1536        |
| time_elapsed       | 68.4        |
| total_timesteps    | 1536        |
| value_loss         | 40.15248    |
------------------------------------
------------------------------------
| approxkl           | 0.05574573  |
| clipfrac           | 0.48046875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.09e+03    |
| explained_variance | 0           |
| fps                | 31          |
| n_updates          | 13          |
| policy_entropy     | 0.8147564   |
| policy_loss        | 0.024913793 |
| serial_timesteps   | 1664        |
| time_elapsed       | 72.4        |
| total_timesteps    | 1664        |
| value_loss         | 2290.4783   |
------------------------------------
-------------------------------------
| approxkl           | 0.03866351   |
| clipfrac           | 0.39453125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.09e+03     |
| explained_variance | -1.91e-06    |
| fps                | 31           |
| n_updates          | 14           |
| policy_entropy     | 0.81449383   |
| policy_loss        | 0.0064378553 |
| serial_timesteps   | 1792         |
| time_elapsed       | 76.4         |
| total_timesteps    | 1792         |
| value_loss         | 37.240524    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0011106235 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.09e+03     |
| explained_variance | 1.97e-06     |
| fps                | 33           |
| n_updates          | 15           |
| policy_entropy     | 0.8143121    |
| policy_loss        | 0.0052704653 |
| serial_timesteps   | 1920         |
| time_elapsed       | 80.5         |
| total_timesteps    | 1920         |
| value_loss         | 43.695236    |
-------------------------------------
-------------------------------------
| approxkl           | 0.031084737  |
| clipfrac           | 0.35742188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.09e+03     |
| explained_variance | 1.07e-06     |
| fps                | 32           |
| n_updates          | 16           |
| policy_entropy     | 0.81380874   |
| policy_loss        | -0.026785865 |
| serial_timesteps   | 2048         |
| time_elapsed       | 84.3         |
| total_timesteps    | 2048         |
| value_loss         | 14.7646055   |
-------------------------------------
-------------------------------------
| approxkl           | 0.002442664  |
| clipfrac           | 0.025390625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.09e+03     |
| explained_variance | -3.58e-07    |
| fps                | 32           |
| n_updates          | 17           |
| policy_entropy     | 0.81269234   |
| policy_loss        | 0.0032770503 |
| serial_timesteps   | 2176         |
| time_elapsed       | 88.2         |
| total_timesteps    | 2176         |
| value_loss         | 38.569134    |
-------------------------------------
------------------------------------
| approxkl           | 0.027854137 |
| clipfrac           | 0.32421875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.09e+03    |
| explained_variance | -2.38e-07   |
| fps                | 30          |
| n_updates          | 18          |
| policy_entropy     | 0.81179726  |
| policy_loss        | 0.03109252  |
| serial_timesteps   | 2304        |
| time_elapsed       | 92.2        |
| total_timesteps    | 2304        |
| value_loss         | 35.141743   |
------------------------------------
An average of 170.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.057723947 |
| clipfrac           | 0.42773438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.09e+03    |
| explained_variance | -1.67e-06   |
| fps                | 31          |
| n_updates          | 19          |
| policy_entropy     | 0.8109896   |
| policy_loss        | 0.045724962 |
| serial_timesteps   | 2432        |
| time_elapsed       | 96.3        |
| total_timesteps    | 2432        |
| value_loss         | 42.83601    |
------------------------------------
------------------------------------
| approxkl           | 0.045015942 |
| clipfrac           | 0.4375      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.09e+03    |
| explained_variance | -1.79e-06   |
| fps                | 32          |
| n_updates          | 20          |
| policy_entropy     | 0.81038284  |
| policy_loss        | 0.034872595 |
| serial_timesteps   | 2560        |
| time_elapsed       | 100         |
| total_timesteps    | 2560        |
| value_loss         | 43.640907   |
------------------------------------
------------------------------------
| approxkl           | 0.0804942   |
| clipfrac           | 0.49804688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.09e+03    |
| explained_variance | 0           |
| fps                | 34          |
| n_updates          | 21          |
| policy_entropy     | 0.81026936  |
| policy_loss        | 0.015582314 |
| serial_timesteps   | 2688        |
| time_elapsed       | 104         |
| total_timesteps    | 2688        |
| value_loss         | 49.21257    |
------------------------------------
--------------------------------------
| approxkl           | 0.06417547    |
| clipfrac           | 0.453125      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.09e+03      |
| explained_variance | 2.38e-07      |
| fps                | 32            |
| n_updates          | 22            |
| policy_entropy     | 0.8103348     |
| policy_loss        | -0.0071402895 |
| serial_timesteps   | 2816          |
| time_elapsed       | 108           |
| total_timesteps    | 2816          |
| value_loss         | 41.945896     |
--------------------------------------
--------------------------------------
| approxkl           | 0.027685847   |
| clipfrac           | 0.33007812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.09e+03      |
| explained_variance | -8.34e-07     |
| fps                | 32            |
| n_updates          | 23            |
| policy_entropy     | 0.8102828     |
| policy_loss        | 0.00083595514 |
| serial_timesteps   | 2944          |
| time_elapsed       | 112           |
| total_timesteps    | 2944          |
| value_loss         | 45.000996     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0009246056  |
| clipfrac           | 0.0078125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.09e+03      |
| explained_variance | 4.77e-07      |
| fps                | 32            |
| n_updates          | 24            |
| policy_entropy     | 0.8107528     |
| policy_loss        | -0.0026804656 |
| serial_timesteps   | 3072          |
| time_elapsed       | 116           |
| total_timesteps    | 3072          |
| value_loss         | 58.53569      |
--------------------------------------
------------------------------------
| approxkl           | 0.015575635 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | 1.79e-07    |
| fps                | 33          |
| n_updates          | 25          |
| policy_entropy     | 0.81073105  |
| policy_loss        | 0.0148113   |
| serial_timesteps   | 3200        |
| time_elapsed       | 120         |
| total_timesteps    | 3200        |
| value_loss         | 3127.412    |
------------------------------------
-------------------------------------
| approxkl           | 0.004262709  |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 26           |
| policy_entropy     | 0.8104577    |
| policy_loss        | -0.007251842 |
| serial_timesteps   | 3328         |
| time_elapsed       | 124          |
| total_timesteps    | 3328         |
| value_loss         | 44.260334    |
-------------------------------------
An average of 171.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0011742573  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | 2.56e-06      |
| fps                | 30            |
| n_updates          | 27            |
| policy_entropy     | 0.81012285    |
| policy_loss        | 0.00067839085 |
| serial_timesteps   | 3456          |
| time_elapsed       | 128           |
| total_timesteps    | 3456          |
| value_loss         | 54.869255     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0034700518 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | 2.15e-06     |
| fps                | 34           |
| n_updates          | 28           |
| policy_entropy     | 0.8095332    |
| policy_loss        | 0.0111623965 |
| serial_timesteps   | 3584         |
| time_elapsed       | 132          |
| total_timesteps    | 3584         |
| value_loss         | 33.30796     |
-------------------------------------
--------------------------------------
| approxkl           | 0.018014254   |
| clipfrac           | 0.24023438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | -1.55e-06     |
| fps                | 32            |
| n_updates          | 29            |
| policy_entropy     | 0.80840796    |
| policy_loss        | -0.0013075279 |
| serial_timesteps   | 3712          |
| time_elapsed       | 136           |
| total_timesteps    | 3712          |
| value_loss         | 32.94159      |
--------------------------------------
-------------------------------------
| approxkl           | 0.019769978  |
| clipfrac           | 0.24023438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | -1.19e-07    |
| fps                | 34           |
| n_updates          | 30           |
| policy_entropy     | 0.8065454    |
| policy_loss        | -0.003525663 |
| serial_timesteps   | 3840         |
| time_elapsed       | 140          |
| total_timesteps    | 3840         |
| value_loss         | 48.373184    |
-------------------------------------
-------------------------------------
| approxkl           | 0.026979282  |
| clipfrac           | 0.34960938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | 4.17e-07     |
| fps                | 31           |
| n_updates          | 31           |
| policy_entropy     | 0.8052879    |
| policy_loss        | 0.0044147857 |
| serial_timesteps   | 3968         |
| time_elapsed       | 143          |
| total_timesteps    | 3968         |
| value_loss         | 45.251637    |
-------------------------------------
------------------------------------
| approxkl           | 0.011529007 |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | -2.38e-07   |
| fps                | 33          |
| n_updates          | 32          |
| policy_entropy     | 0.8044105   |
| policy_loss        | 0.021987256 |
| serial_timesteps   | 4096        |
| time_elapsed       | 147         |
| total_timesteps    | 4096        |
| value_loss         | 30.176453   |
------------------------------------
-------------------------------------
| approxkl           | 0.009987999  |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | 7.69e-06     |
| fps                | 31           |
| n_updates          | 33           |
| policy_entropy     | 0.8033297    |
| policy_loss        | -0.004557571 |
| serial_timesteps   | 4224         |
| time_elapsed       | 151          |
| total_timesteps    | 4224         |
| value_loss         | 21.892273    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0058936393  |
| clipfrac           | 0.0703125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | -4.53e-06     |
| fps                | 32            |
| n_updates          | 34            |
| policy_entropy     | 0.80210537    |
| policy_loss        | 0.00041998085 |
| serial_timesteps   | 4352          |
| time_elapsed       | 155           |
| total_timesteps    | 4352          |
| value_loss         | 25.574635     |
--------------------------------------
An average of 171.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.003011724   |
| clipfrac           | 0.0390625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | -3.81e-06     |
| fps                | 32            |
| n_updates          | 35            |
| policy_entropy     | 0.80039144    |
| policy_loss        | -0.0033437754 |
| serial_timesteps   | 4480          |
| time_elapsed       | 159           |
| total_timesteps    | 4480          |
| value_loss         | 49.743134     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0019715168  |
| clipfrac           | 0.017578125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | 1.67e-06      |
| fps                | 31            |
| n_updates          | 36            |
| policy_entropy     | 0.7992453     |
| policy_loss        | 0.00040578982 |
| serial_timesteps   | 4608          |
| time_elapsed       | 163           |
| total_timesteps    | 4608          |
| value_loss         | 43.38331      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0012873512 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 37           |
| policy_entropy     | 0.7987137    |
| policy_loss        | -0.002182231 |
| serial_timesteps   | 4736         |
| time_elapsed       | 167          |
| total_timesteps    | 4736         |
| value_loss         | 3380.4692    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0027581756  |
| clipfrac           | 0.0234375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 38            |
| policy_entropy     | 0.7985444     |
| policy_loss        | -0.0011785477 |
| serial_timesteps   | 4864          |
| time_elapsed       | 171           |
| total_timesteps    | 4864          |
| value_loss         | 45.376465     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00018424602 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | -1.19e-07     |
| fps                | 33            |
| n_updates          | 39            |
| policy_entropy     | 0.7982818     |
| policy_loss        | 0.00014655327 |
| serial_timesteps   | 4992          |
| time_elapsed       | 175           |
| total_timesteps    | 4992          |
| value_loss         | 52.5097       |
--------------------------------------
------------------------------------
| approxkl           | 0.007133373 |
| clipfrac           | 0.09765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | -9.54e-07   |
| fps                | 33          |
| n_updates          | 40          |
| policy_entropy     | 0.79771286  |
| policy_loss        | 0.007822396 |
| serial_timesteps   | 5120        |
| time_elapsed       | 179         |
| total_timesteps    | 5120        |
| value_loss         | 41.035057   |
------------------------------------
-------------------------------------
| approxkl           | 0.012652394  |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.07e+03     |
| explained_variance | 7.75e-07     |
| fps                | 33           |
| n_updates          | 41           |
| policy_entropy     | 0.7965719    |
| policy_loss        | 0.0078035854 |
| serial_timesteps   | 5248         |
| time_elapsed       | 183          |
| total_timesteps    | 5248         |
| value_loss         | 43.079155    |
-------------------------------------
------------------------------------
| approxkl           | 0.031470932 |
| clipfrac           | 0.37109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | 2.38e-06    |
| fps                | 32          |
| n_updates          | 42          |
| policy_entropy     | 0.79572767  |
| policy_loss        | 0.017504929 |
| serial_timesteps   | 5376        |
| time_elapsed       | 187         |
| total_timesteps    | 5376        |
| value_loss         | 53.566204   |
------------------------------------
An average of 172.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01274128  |
| clipfrac           | 0.19335938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | 1.13e-06    |
| fps                | 34          |
| n_updates          | 43          |
| policy_entropy     | 0.79636526  |
| policy_loss        | 0.022904709 |
| serial_timesteps   | 5504        |
| time_elapsed       | 191         |
| total_timesteps    | 5504        |
| value_loss         | 60.15828    |
------------------------------------
------------------------------------
| approxkl           | 0.023225455 |
| clipfrac           | 0.31445312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | 5.96e-08    |
| fps                | 32          |
| n_updates          | 44          |
| policy_entropy     | 0.79645663  |
| policy_loss        | 0.020819355 |
| serial_timesteps   | 5632        |
| time_elapsed       | 195         |
| total_timesteps    | 5632        |
| value_loss         | 40.579453   |
------------------------------------
--------------------------------------
| approxkl           | 0.0079902215  |
| clipfrac           | 0.107421875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.07e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 45            |
| policy_entropy     | 0.79534733    |
| policy_loss        | -0.0013911807 |
| serial_timesteps   | 5760          |
| time_elapsed       | 199           |
| total_timesteps    | 5760          |
| value_loss         | 47.90308      |
--------------------------------------
------------------------------------
| approxkl           | 0.017914644 |
| clipfrac           | 0.23828125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | -1.67e-06   |
| fps                | 34          |
| n_updates          | 46          |
| policy_entropy     | 0.794237    |
| policy_loss        | 0.016982215 |
| serial_timesteps   | 5888        |
| time_elapsed       | 202         |
| total_timesteps    | 5888        |
| value_loss         | 46.00879    |
------------------------------------
------------------------------------
| approxkl           | 0.019057846 |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | -9.54e-07   |
| fps                | 32          |
| n_updates          | 47          |
| policy_entropy     | 0.7934912   |
| policy_loss        | 0.02098823  |
| serial_timesteps   | 6016        |
| time_elapsed       | 206         |
| total_timesteps    | 6016        |
| value_loss         | 49.66308    |
------------------------------------
------------------------------------
| approxkl           | 0.02072323  |
| clipfrac           | 0.27539062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.07e+03    |
| explained_variance | -2.38e-07   |
| fps                | 34          |
| n_updates          | 48          |
| policy_entropy     | 0.7917524   |
| policy_loss        | 0.039277863 |
| serial_timesteps   | 6144        |
| time_elapsed       | 210         |
| total_timesteps    | 6144        |
| value_loss         | 46.736195   |
------------------------------------
------------------------------------
| approxkl           | 0.009968644 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | 5.96e-08    |
| fps                | 32          |
| n_updates          | 49          |
| policy_entropy     | 0.78998697  |
| policy_loss        | 0.013686156 |
| serial_timesteps   | 6272        |
| time_elapsed       | 214         |
| total_timesteps    | 6272        |
| value_loss         | 3602.0608   |
------------------------------------
--------------------------------------
| approxkl           | 0.0008651925  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | -1.19e-07     |
| fps                | 33            |
| n_updates          | 50            |
| policy_entropy     | 0.7892192     |
| policy_loss        | -0.0014651703 |
| serial_timesteps   | 6400          |
| time_elapsed       | 218           |
| total_timesteps    | 6400          |
| value_loss         | 46.636242     |
--------------------------------------
An average of 173.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0034570165  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | 2.98e-07      |
| fps                | 32            |
| n_updates          | 51            |
| policy_entropy     | 0.7882936     |
| policy_loss        | 0.00027851877 |
| serial_timesteps   | 6528          |
| time_elapsed       | 222           |
| total_timesteps    | 6528          |
| value_loss         | 38.67578      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0076746927 |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -2.62e-06    |
| fps                | 30           |
| n_updates          | 52           |
| policy_entropy     | 0.78738946   |
| policy_loss        | -0.012255803 |
| serial_timesteps   | 6656         |
| time_elapsed       | 226          |
| total_timesteps    | 6656         |
| value_loss         | 39.507458    |
-------------------------------------
-------------------------------------
| approxkl           | 0.004491167  |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | 1.61e-06     |
| fps                | 32           |
| n_updates          | 53           |
| policy_entropy     | 0.7865782    |
| policy_loss        | 0.0036081513 |
| serial_timesteps   | 6784         |
| time_elapsed       | 230          |
| total_timesteps    | 6784         |
| value_loss         | 33.62176     |
-------------------------------------
--------------------------------------
| approxkl           | 0.021257946   |
| clipfrac           | 0.29296875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | -8.34e-07     |
| fps                | 32            |
| n_updates          | 54            |
| policy_entropy     | 0.78494155    |
| policy_loss        | -0.0016408926 |
| serial_timesteps   | 6912          |
| time_elapsed       | 234           |
| total_timesteps    | 6912          |
| value_loss         | 35.18506      |
--------------------------------------
------------------------------------
| approxkl           | 0.012480583 |
| clipfrac           | 0.17578125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | 4.77e-07    |
| fps                | 32          |
| n_updates          | 55          |
| policy_entropy     | 0.7839254   |
| policy_loss        | 0.01848372  |
| serial_timesteps   | 7040        |
| time_elapsed       | 238         |
| total_timesteps    | 7040        |
| value_loss         | 31.622784   |
------------------------------------
--------------------------------------
| approxkl           | 0.015792845   |
| clipfrac           | 0.23828125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | 5.96e-08      |
| fps                | 33            |
| n_updates          | 56            |
| policy_entropy     | 0.7829021     |
| policy_loss        | -0.0066407947 |
| serial_timesteps   | 7168          |
| time_elapsed       | 242           |
| total_timesteps    | 7168          |
| value_loss         | 39.500126     |
--------------------------------------
--------------------------------------
| approxkl           | 0.002034041   |
| clipfrac           | 0.021484375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | 1.19e-07      |
| fps                | 30            |
| n_updates          | 57            |
| policy_entropy     | 0.7812176     |
| policy_loss        | -0.0026284354 |
| serial_timesteps   | 7296          |
| time_elapsed       | 245           |
| total_timesteps    | 7296          |
| value_loss         | 48.548332     |
--------------------------------------
An average of 173.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.016219132  |
| clipfrac           | 0.20898438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 58           |
| policy_entropy     | 0.7786886    |
| policy_loss        | -0.019411437 |
| serial_timesteps   | 7424         |
| time_elapsed       | 250          |
| total_timesteps    | 7424         |
| value_loss         | 47.242596    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03607098   |
| clipfrac           | 0.37304688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -3.58e-07    |
| fps                | 31           |
| n_updates          | 59           |
| policy_entropy     | 0.7767749    |
| policy_loss        | 0.0072495025 |
| serial_timesteps   | 7552         |
| time_elapsed       | 254          |
| total_timesteps    | 7552         |
| value_loss         | 39.031467    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006374735   |
| clipfrac           | 0.08984375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | 7.75e-07      |
| fps                | 32            |
| n_updates          | 60            |
| policy_entropy     | 0.7758107     |
| policy_loss        | -0.0033685248 |
| serial_timesteps   | 7680          |
| time_elapsed       | 258           |
| total_timesteps    | 7680          |
| value_loss         | 38.851044     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005783944  |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 61           |
| policy_entropy     | 0.7751275    |
| policy_loss        | -0.007640302 |
| serial_timesteps   | 7808         |
| time_elapsed       | 262          |
| total_timesteps    | 7808         |
| value_loss         | 3640.4258    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0037056846 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -9.54e-07    |
| fps                | 33           |
| n_updates          | 62           |
| policy_entropy     | 0.77496904   |
| policy_loss        | -0.005406977 |
| serial_timesteps   | 7936         |
| time_elapsed       | 266          |
| total_timesteps    | 7936         |
| value_loss         | 45.6106      |
-------------------------------------
--------------------------------------
| approxkl           | 0.002915038   |
| clipfrac           | 0.025390625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | -4.77e-07     |
| fps                | 33            |
| n_updates          | 63            |
| policy_entropy     | 0.7746149     |
| policy_loss        | -0.0015576624 |
| serial_timesteps   | 8064          |
| time_elapsed       | 270           |
| total_timesteps    | 8064          |
| value_loss         | 31.545778     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0025112242 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | 0            |
| fps                | 33           |
| n_updates          | 64           |
| policy_entropy     | 0.77397823   |
| policy_loss        | -0.003733139 |
| serial_timesteps   | 8192         |
| time_elapsed       | 273          |
| total_timesteps    | 8192         |
| value_loss         | 34.995457    |
-------------------------------------
------------------------------------
| approxkl           | 0.009714113 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | -2.38e-07   |
| fps                | 32          |
| n_updates          | 65          |
| policy_entropy     | 0.77296966  |
| policy_loss        | -0.01042786 |
| serial_timesteps   | 8320        |
| time_elapsed       | 277         |
| total_timesteps    | 8320        |
| value_loss         | 29.82759    |
------------------------------------
An average of 174.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.018172482 |
| clipfrac           | 0.23632812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | -4.77e-07   |
| fps                | 33          |
| n_updates          | 66          |
| policy_entropy     | 0.77169925  |
| policy_loss        | 0.00842907  |
| serial_timesteps   | 8448        |
| time_elapsed       | 281         |
| total_timesteps    | 8448        |
| value_loss         | 32.595417   |
------------------------------------
--------------------------------------
| approxkl           | 0.00055683387 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | 0             |
| fps                | 31            |
| n_updates          | 67            |
| policy_entropy     | 0.77048975    |
| policy_loss        | 0.0016219582  |
| serial_timesteps   | 8576          |
| time_elapsed       | 285           |
| total_timesteps    | 8576          |
| value_loss         | 33.050915     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0008930679 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | 0            |
| fps                | 27           |
| n_updates          | 68           |
| policy_entropy     | 0.7680042    |
| policy_loss        | 0.0005851827 |
| serial_timesteps   | 8704         |
| time_elapsed       | 289          |
| total_timesteps    | 8704         |
| value_loss         | 44.02178     |
-------------------------------------
---------------------------------------
| approxkl           | 0.00029084674  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.11e+03       |
| explained_variance | 4.77e-07       |
| fps                | 32             |
| n_updates          | 69             |
| policy_entropy     | 0.7658684      |
| policy_loss        | -0.00020255195 |
| serial_timesteps   | 8832           |
| time_elapsed       | 294            |
| total_timesteps    | 8832           |
| value_loss         | 31.614992      |
---------------------------------------
-------------------------------------
| approxkl           | 0.077028364  |
| clipfrac           | 0.5253906    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 70           |
| policy_entropy     | 0.7642865    |
| policy_loss        | -0.033624254 |
| serial_timesteps   | 8960         |
| time_elapsed       | 298          |
| total_timesteps    | 8960         |
| value_loss         | 13.43148     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063004387 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | 4.29e-06     |
| fps                | 31           |
| n_updates          | 71           |
| policy_entropy     | 0.76389045   |
| policy_loss        | 0.014450903  |
| serial_timesteps   | 9088         |
| time_elapsed       | 302          |
| total_timesteps    | 9088         |
| value_loss         | 29.058416    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073371273 |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -1.31e-06    |
| fps                | 33           |
| n_updates          | 72           |
| policy_entropy     | 0.7635568    |
| policy_loss        | 0.0072691827 |
| serial_timesteps   | 9216         |
| time_elapsed       | 306          |
| total_timesteps    | 9216         |
| value_loss         | 34.23109     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0031601405 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 73           |
| policy_entropy     | 0.76126903   |
| policy_loss        | 0.0008161799 |
| serial_timesteps   | 9344         |
| time_elapsed       | 310          |
| total_timesteps    | 9344         |
| value_loss         | 3746.537     |
-------------------------------------
An average of 175.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00011397213 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | -1.07e-06     |
| fps                | 31            |
| n_updates          | 74            |
| policy_entropy     | 0.7599746     |
| policy_loss        | 0.0002727341  |
| serial_timesteps   | 9472          |
| time_elapsed       | 314           |
| total_timesteps    | 9472          |
| value_loss         | 48.895863     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00043752228 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.11e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 75            |
| policy_entropy     | 0.75924534    |
| policy_loss        | -9.145716e-05 |
| serial_timesteps   | 9600          |
| time_elapsed       | 318           |
| total_timesteps    | 9600          |
| value_loss         | 32.51395      |
--------------------------------------
---------------------------------------
| approxkl           | 0.028216643    |
| clipfrac           | 0.34179688     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.11e+03       |
| explained_variance | -5.96e-07      |
| fps                | 34             |
| n_updates          | 76             |
| policy_entropy     | 0.75760996     |
| policy_loss        | -0.00076639093 |
| serial_timesteps   | 9728           |
| time_elapsed       | 322            |
| total_timesteps    | 9728           |
| value_loss         | 45.825813      |
---------------------------------------
------------------------------------
| approxkl           | 0.01678201  |
| clipfrac           | 0.23046875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | 2.38e-07    |
| fps                | 32          |
| n_updates          | 77          |
| policy_entropy     | 0.75634813  |
| policy_loss        | 0.021573666 |
| serial_timesteps   | 9856        |
| time_elapsed       | 326         |
| total_timesteps    | 9856        |
| value_loss         | 35.674927   |
------------------------------------
-------------------------------------
| approxkl           | 0.0027649659 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -1.07e-06    |
| fps                | 32           |
| n_updates          | 78           |
| policy_entropy     | 0.75425816   |
| policy_loss        | 0.0051138783 |
| serial_timesteps   | 9984         |
| time_elapsed       | 330          |
| total_timesteps    | 9984         |
| value_loss         | 40.189922    |
-------------------------------------
-------------------------------------
| approxkl           | 0.047303915  |
| clipfrac           | 0.44140625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | 0            |
| fps                | 33           |
| n_updates          | 79           |
| policy_entropy     | 0.75302386   |
| policy_loss        | -0.003455871 |
| serial_timesteps   | 10112        |
| time_elapsed       | 334          |
| total_timesteps    | 10112        |
| value_loss         | 40.72396     |
-------------------------------------
------------------------------------
| approxkl           | 0.018623497 |
| clipfrac           | 0.22851562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | -1.19e-07   |
| fps                | 34          |
| n_updates          | 80          |
| policy_entropy     | 0.75253636  |
| policy_loss        | 0.021199849 |
| serial_timesteps   | 10240       |
| time_elapsed       | 337         |
| total_timesteps    | 10240       |
| value_loss         | 30.874632   |
------------------------------------
-------------------------------------
| approxkl           | 0.008174025  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 81           |
| policy_entropy     | 0.75180113   |
| policy_loss        | -0.003913277 |
| serial_timesteps   | 10368        |
| time_elapsed       | 341          |
| total_timesteps    | 10368        |
| value_loss         | 40.83299     |
-------------------------------------
An average of 175.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.060354788 |
| clipfrac           | 0.5019531   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | -1.19e-07   |
| fps                | 32          |
| n_updates          | 82          |
| policy_entropy     | 0.7509838   |
| policy_loss        | 0.010305116 |
| serial_timesteps   | 10496       |
| time_elapsed       | 345         |
| total_timesteps    | 10496       |
| value_loss         | 32.261932   |
------------------------------------
------------------------------------
| approxkl           | 0.02473539  |
| clipfrac           | 0.32421875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.11e+03    |
| explained_variance | 2.38e-07    |
| fps                | 30          |
| n_updates          | 83          |
| policy_entropy     | 0.7506585   |
| policy_loss        | 0.022938492 |
| serial_timesteps   | 10624       |
| time_elapsed       | 349         |
| total_timesteps    | 10624       |
| value_loss         | 26.11257    |
------------------------------------
-------------------------------------
| approxkl           | 0.001578373  |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.11e+03     |
| explained_variance | -5.96e-07    |
| fps                | 33           |
| n_updates          | 84           |
| policy_entropy     | 0.7496228    |
| policy_loss        | 0.0058021494 |
| serial_timesteps   | 10752        |
| time_elapsed       | 353          |
| total_timesteps    | 10752        |
| value_loss         | 46.57187     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0022830626  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 85            |
| policy_entropy     | 0.74808073    |
| policy_loss        | -0.0042595584 |
| serial_timesteps   | 10880         |
| time_elapsed       | 357           |
| total_timesteps    | 10880         |
| value_loss         | 3828.0806     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0043386277  |
| clipfrac           | 0.05078125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | 2.38e-07      |
| fps                | 31            |
| n_updates          | 86            |
| policy_entropy     | 0.7472067     |
| policy_loss        | -0.0029174732 |
| serial_timesteps   | 11008         |
| time_elapsed       | 361           |
| total_timesteps    | 11008         |
| value_loss         | 33.24229      |
--------------------------------------
------------------------------------
| approxkl           | 0.024752878 |
| clipfrac           | 0.29101562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.13e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 87          |
| policy_entropy     | 0.7464572   |
| policy_loss        | -0.02122627 |
| serial_timesteps   | 11136       |
| time_elapsed       | 365         |
| total_timesteps    | 11136       |
| value_loss         | 27.919287   |
------------------------------------
-------------------------------------
| approxkl           | 0.0057822256 |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | -3.34e-06    |
| fps                | 32           |
| n_updates          | 88           |
| policy_entropy     | 0.74593616   |
| policy_loss        | 0.004424     |
| serial_timesteps   | 11264        |
| time_elapsed       | 370          |
| total_timesteps    | 11264        |
| value_loss         | 25.134989    |
-------------------------------------
-------------------------------------
| approxkl           | 0.019518249  |
| clipfrac           | 0.24804688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 5.96e-07     |
| fps                | 31           |
| n_updates          | 89           |
| policy_entropy     | 0.7436624    |
| policy_loss        | -0.013721751 |
| serial_timesteps   | 11392        |
| time_elapsed       | 374          |
| total_timesteps    | 11392        |
| value_loss         | 35.743473    |
-------------------------------------
An average of 176.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.006007574  |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | -3.58e-07    |
| fps                | 31           |
| n_updates          | 90           |
| policy_entropy     | 0.7407404    |
| policy_loss        | -0.006927264 |
| serial_timesteps   | 11520        |
| time_elapsed       | 378          |
| total_timesteps    | 11520        |
| value_loss         | 35.55182     |
-------------------------------------
-------------------------------------
| approxkl           | 0.01776332   |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 1.85e-06     |
| fps                | 33           |
| n_updates          | 91           |
| policy_entropy     | 0.7387242    |
| policy_loss        | 0.0140168285 |
| serial_timesteps   | 11648        |
| time_elapsed       | 382          |
| total_timesteps    | 11648        |
| value_loss         | 34.51232     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0043670293 |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | -7.87e-06    |
| fps                | 31           |
| n_updates          | 92           |
| policy_entropy     | 0.7376149    |
| policy_loss        | -0.005266222 |
| serial_timesteps   | 11776        |
| time_elapsed       | 385          |
| total_timesteps    | 11776        |
| value_loss         | 36.354923    |
-------------------------------------
--------------------------------------
| approxkl           | 9.862772e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | 0             |
| fps                | 34            |
| n_updates          | 93            |
| policy_entropy     | 0.7366292     |
| policy_loss        | 0.00067346194 |
| serial_timesteps   | 11904         |
| time_elapsed       | 389           |
| total_timesteps    | 11904         |
| value_loss         | 34.25782      |
--------------------------------------
------------------------------------
| approxkl           | 0.013589962 |
| clipfrac           | 0.2109375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.13e+03    |
| explained_variance | -1.31e-06   |
| fps                | 31          |
| n_updates          | 94          |
| policy_entropy     | 0.7354259   |
| policy_loss        | 0.008004887 |
| serial_timesteps   | 12032       |
| time_elapsed       | 393         |
| total_timesteps    | 12032       |
| value_loss         | 27.451733   |
------------------------------------
-------------------------------------
| approxkl           | 0.0058483626 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 5.66e-06     |
| fps                | 31           |
| n_updates          | 95           |
| policy_entropy     | 0.73412067   |
| policy_loss        | 0.0048859436 |
| serial_timesteps   | 12160        |
| time_elapsed       | 397          |
| total_timesteps    | 12160        |
| value_loss         | 38.2914      |
-------------------------------------
-------------------------------------
| approxkl           | 0.0010315271 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 1.49e-06     |
| fps                | 33           |
| n_updates          | 96           |
| policy_entropy     | 0.7326289    |
| policy_loss        | -0.004363661 |
| serial_timesteps   | 12288        |
| time_elapsed       | 401          |
| total_timesteps    | 12288        |
| value_loss         | 33.552094    |
-------------------------------------
An average of 177.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.00034777855  |
| clipfrac           | 0.001953125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.13e+03       |
| explained_variance | 0              |
| fps                | 31             |
| n_updates          | 97             |
| policy_entropy     | 0.73143816     |
| policy_loss        | -0.00091724284 |
| serial_timesteps   | 12416          |
| time_elapsed       | 405            |
| total_timesteps    | 12416          |
| value_loss         | 3801.1533      |
---------------------------------------
-------------------------------------
| approxkl           | 0.009951072  |
| clipfrac           | 0.1796875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | -1.91e-06    |
| fps                | 31           |
| n_updates          | 98           |
| policy_entropy     | 0.7310206    |
| policy_loss        | -0.014128524 |
| serial_timesteps   | 12544        |
| time_elapsed       | 409          |
| total_timesteps    | 12544        |
| value_loss         | 33.064735    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004514555   |
| clipfrac           | 0.048828125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 99            |
| policy_entropy     | 0.73055506    |
| policy_loss        | -0.0025116852 |
| serial_timesteps   | 12672         |
| time_elapsed       | 413           |
| total_timesteps    | 12672         |
| value_loss         | 42.84535      |
--------------------------------------
--------------------------------------
| approxkl           | 0.010524341   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | 1.97e-06      |
| fps                | 33            |
| n_updates          | 100           |
| policy_entropy     | 0.7293921     |
| policy_loss        | -0.0040322375 |
| serial_timesteps   | 12800         |
| time_elapsed       | 418           |
| total_timesteps    | 12800         |
| value_loss         | 27.641302     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0048446767  |
| clipfrac           | 0.060546875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | 1.37e-06      |
| fps                | 33            |
| n_updates          | 101           |
| policy_entropy     | 0.72828645    |
| policy_loss        | -0.0020127464 |
| serial_timesteps   | 12928         |
| time_elapsed       | 421           |
| total_timesteps    | 12928         |
| value_loss         | 25.270376     |
--------------------------------------
------------------------------------
| approxkl           | 0.007832862 |
| clipfrac           | 0.13085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.13e+03    |
| explained_variance | 0           |
| fps                | 33          |
| n_updates          | 102         |
| policy_entropy     | 0.72590923  |
| policy_loss        | 0.013820079 |
| serial_timesteps   | 13056       |
| time_elapsed       | 425         |
| total_timesteps    | 13056       |
| value_loss         | 35.18352    |
------------------------------------
-------------------------------------
| approxkl           | 0.017410154  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 1.79e-07     |
| fps                | 34           |
| n_updates          | 103          |
| policy_entropy     | 0.7229369    |
| policy_loss        | -0.008656604 |
| serial_timesteps   | 13184        |
| time_elapsed       | 429          |
| total_timesteps    | 13184        |
| value_loss         | 32.135914    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0085614575 |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 104          |
| policy_entropy     | 0.7209035    |
| policy_loss        | -0.00750768  |
| serial_timesteps   | 13312        |
| time_elapsed       | 433          |
| total_timesteps    | 13312        |
| value_loss         | 34.71909     |
-------------------------------------
An average of 177.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.012148599 |
| clipfrac           | 0.14648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.13e+03    |
| explained_variance | -3.58e-07   |
| fps                | 31          |
| n_updates          | 105         |
| policy_entropy     | 0.71954674  |
| policy_loss        | 0.018919885 |
| serial_timesteps   | 13440       |
| time_elapsed       | 437         |
| total_timesteps    | 13440       |
| value_loss         | 31.157969   |
------------------------------------
-------------------------------------
| approxkl           | 0.0022392643 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.13e+03     |
| explained_variance | 4.47e-06     |
| fps                | 31           |
| n_updates          | 106          |
| policy_entropy     | 0.71786803   |
| policy_loss        | 0.0034714402 |
| serial_timesteps   | 13568        |
| time_elapsed       | 441          |
| total_timesteps    | 13568        |
| value_loss         | 21.989462    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008165921   |
| clipfrac           | 0.125         |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | 2.38e-07      |
| fps                | 32            |
| n_updates          | 107           |
| policy_entropy     | 0.71631205    |
| policy_loss        | -0.0055435766 |
| serial_timesteps   | 13696         |
| time_elapsed       | 445           |
| total_timesteps    | 13696         |
| value_loss         | 33.35961      |
--------------------------------------
--------------------------------------
| approxkl           | 0.006327424   |
| clipfrac           | 0.087890625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.13e+03      |
| explained_variance | -1.79e-06     |
| fps                | 32            |
| n_updates          | 108           |
| policy_entropy     | 0.7156428     |
| policy_loss        | -0.0004705661 |
| serial_timesteps   | 13824         |
| time_elapsed       | 449           |
| total_timesteps    | 13824         |
| value_loss         | 33.135094     |
--------------------------------------
------------------------------------
| approxkl           | 0.046147306 |
| clipfrac           | 0.4296875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.14e+03    |
| explained_variance | 1.79e-07    |
| fps                | 33          |
| n_updates          | 109         |
| policy_entropy     | 0.7153036   |
| policy_loss        | 0.038202226 |
| serial_timesteps   | 13952       |
| time_elapsed       | 453         |
| total_timesteps    | 13952       |
| value_loss         | 3966.5671   |
------------------------------------
-------------------------------------
| approxkl           | 0.014851562  |
| clipfrac           | 0.21484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.14e+03     |
| explained_variance | 1.19e-07     |
| fps                | 31           |
| n_updates          | 110          |
| policy_entropy     | 0.7150649    |
| policy_loss        | -0.013025818 |
| serial_timesteps   | 14080        |
| time_elapsed       | 457          |
| total_timesteps    | 14080        |
| value_loss         | 25.680485    |
-------------------------------------
-------------------------------------
| approxkl           | 0.022641148  |
| clipfrac           | 0.24414062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.14e+03     |
| explained_variance | 2.38e-07     |
| fps                | 32           |
| n_updates          | 111          |
| policy_entropy     | 0.7147091    |
| policy_loss        | -0.015947798 |
| serial_timesteps   | 14208        |
| time_elapsed       | 461          |
| total_timesteps    | 14208        |
| value_loss         | 17.706583    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0046260776 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.14e+03     |
| explained_variance | 4.77e-07     |
| fps                | 32           |
| n_updates          | 112          |
| policy_entropy     | 0.71421605   |
| policy_loss        | 0.0029151784 |
| serial_timesteps   | 14336        |
| time_elapsed       | 465          |
| total_timesteps    | 14336        |
| value_loss         | 22.459393    |
-------------------------------------
An average of 178.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.003449461   |
| clipfrac           | 0.0546875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.14e+03      |
| explained_variance | 3.52e-06      |
| fps                | 30            |
| n_updates          | 113           |
| policy_entropy     | 0.7129702     |
| policy_loss        | 0.00086986064 |
| serial_timesteps   | 14464         |
| time_elapsed       | 469           |
| total_timesteps    | 14464         |
| value_loss         | 27.430079     |
--------------------------------------
--------------------------------------
| approxkl           | 0.021972923   |
| clipfrac           | 0.28320312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.14e+03      |
| explained_variance | -1.55e-06     |
| fps                | 33            |
| n_updates          | 114           |
| policy_entropy     | 0.71158355    |
| policy_loss        | -0.0023839138 |
| serial_timesteps   | 14592         |
| time_elapsed       | 473           |
| total_timesteps    | 14592         |
| value_loss         | 23.181314     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0013317488 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.14e+03     |
| explained_variance | -3.34e-06    |
| fps                | 33           |
| n_updates          | 115          |
| policy_entropy     | 0.7106361    |
| policy_loss        | 0.0013505802 |
| serial_timesteps   | 14720        |
| time_elapsed       | 477          |
| total_timesteps    | 14720        |
| value_loss         | 41.404892    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0036506406  |
| clipfrac           | 0.033203125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.14e+03      |
| explained_variance | -1.31e-06     |
| fps                | 31            |
| n_updates          | 116           |
| policy_entropy     | 0.7093713     |
| policy_loss        | -0.0020379932 |
| serial_timesteps   | 14848         |
| time_elapsed       | 480           |
| total_timesteps    | 14848         |
| value_loss         | 28.275253     |
--------------------------------------
------------------------------------
| approxkl           | 0.010251359 |
| clipfrac           | 0.15039062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.14e+03    |
| explained_variance | 1.37e-06    |
| fps                | 34          |
| n_updates          | 117         |
| policy_entropy     | 0.70742714  |
| policy_loss        | 0.020129776 |
| serial_timesteps   | 14976       |
| time_elapsed       | 485         |
| total_timesteps    | 14976       |
| value_loss         | 28.991734   |
------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b56d992e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b56d992e8>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b54f38ef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b54f38ef0>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2790 samples, validate on 327 samples
Epoch 324/5000
 - 6s - loss: 0.0611 - val_loss: 0.0153
Epoch 325/5000
 - 1s - loss: 0.0114 - val_loss: 0.0130
Epoch 326/5000
 - 1s - loss: 0.0090 - val_loss: 0.0100
Epoch 327/5000
 - 1s - loss: 0.0071 - val_loss: 0.0078
Epoch 328/5000
 - 1s - loss: 0.0061 - val_loss: 0.0070
Epoch 329/5000
 - 1s - loss: 0.0057 - val_loss: 0.0065
Epoch 330/5000
 - 1s - loss: 0.0054 - val_loss: 0.0062
Epoch 331/5000
 - 1s - loss: 0.0052 - val_loss: 0.0059
Epoch 332/5000
 - 1s - loss: 0.0051 - val_loss: 0.0058
Epoch 333/5000
 - 1s - loss: 0.0050 - val_loss: 0.0056
Epoch 334/5000
 - 1s - loss: 0.0049 - val_loss: 0.0055
Epoch 335/5000
 - 1s - loss: 0.0049 - val_loss: 0.0054
Epoch 336/5000
 - 1s - loss: 0.0048 - val_loss: 0.0053
Epoch 337/5000
 - 1s - loss: 0.0048 - val_loss: 0.0052
Epoch 338/5000
 - 1s - loss: 0.0047 - val_loss: 0.0052
Epoch 339/5000
 - 1s - loss: 0.0047 - val_loss: 0.0051
Epoch 340/5000
 - 1s - loss: 0.0041 - val_loss: 0.0053
Epoch 341/5000
 - 1s - loss: 0.0040 - val_loss: 0.0053
Epoch 342/5000
 - 1s - loss: 0.0040 - val_loss: 0.0052
Epoch 343/5000
 - 1s - loss: 0.0039 - val_loss: 0.0051
Epoch 344/5000
 - 1s - loss: 0.0037 - val_loss: 0.0051
Epoch 345/5000
 - 1s - loss: 0.0037 - val_loss: 0.0050
Epoch 346/5000
 - 1s - loss: 0.0036 - val_loss: 0.0050
Epoch 347/5000
 - 1s - loss: 0.0036 - val_loss: 0.0050
Epoch 348/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 349/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 350/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 351/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 352/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 353/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 354/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 355/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 356/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 357/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 358/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 359/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 360/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 361/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 362/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 363/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 364/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 365/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 366/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 367/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 368/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 369/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Epoch 370/5000
 - 1s - loss: 0.0036 - val_loss: 0.0049
Train on 1771 samples, validate on 327 samples
Epoch 239/5000
 - 6s - loss: 0.0015 - val_loss: 0.0020
Epoch 240/5000
 - 0s - loss: 0.0014 - val_loss: 0.0017
Epoch 241/5000
 - 0s - loss: 0.0013 - val_loss: 0.0015
Epoch 242/5000
 - 0s - loss: 0.0013 - val_loss: 0.0014
Epoch 243/5000
 - 1s - loss: 0.0013 - val_loss: 0.0012
Epoch 244/5000
 - 1s - loss: 0.0013 - val_loss: 0.0011
Epoch 245/5000
 - 0s - loss: 0.0012 - val_loss: 9.9003e-04
Epoch 246/5000
 - 0s - loss: 0.0012 - val_loss: 9.1755e-04
Epoch 247/5000
 - 0s - loss: 0.0012 - val_loss: 8.6433e-04
Epoch 248/5000
 - 0s - loss: 0.0012 - val_loss: 8.2734e-04
Epoch 249/5000
 - 1s - loss: 0.0010 - val_loss: 9.8256e-04
Epoch 250/5000
 - 0s - loss: 0.0010 - val_loss: 0.0010
Epoch 251/5000
 - 0s - loss: 0.0010 - val_loss: 0.0011
Epoch 252/5000
 - 0s - loss: 0.0010 - val_loss: 0.0011
Epoch 253/5000
 - 0s - loss: 9.7943e-04 - val_loss: 0.0011
Train on 2790 samples, validate on 327 samples
Epoch 718/5000
 - 8s - loss: 0.6870 - val_loss: 0.5775
Epoch 719/5000
 - 1s - loss: 0.6728 - val_loss: 0.5284
Epoch 720/5000
 - 1s - loss: 0.6672 - val_loss: 0.5103
Epoch 721/5000
 - 1s - loss: 0.6651 - val_loss: 0.5017
Epoch 722/5000
 - 1s - loss: 0.6634 - val_loss: 0.5013
Epoch 723/5000
 - 1s - loss: 0.6620 - val_loss: 0.5011
Epoch 724/5000
 - 1s - loss: 0.6596 - val_loss: 0.5016
Epoch 725/5000
 - 1s - loss: 0.6520 - val_loss: 0.5180
Epoch 726/5000
 - 1s - loss: 0.6341 - val_loss: 0.4983
Epoch 727/5000
 - 1s - loss: 0.6267 - val_loss: 0.4842
Epoch 728/5000
 - 1s - loss: 0.6196 - val_loss: 0.4751
Epoch 729/5000
 - 1s - loss: 0.6127 - val_loss: 0.4674
Epoch 730/5000
 - 1s - loss: 0.6061 - val_loss: 0.4602
Epoch 731/5000
 - 1s - loss: 0.5995 - val_loss: 0.4536
Epoch 732/5000
 - 1s - loss: 0.5933 - val_loss: 0.4472
Epoch 733/5000
 - 1s - loss: 0.5873 - val_loss: 0.4416
Epoch 734/5000
 - 1s - loss: 0.5812 - val_loss: 0.4372
Epoch 735/5000
 - 1s - loss: 0.5755 - val_loss: 0.4336
Epoch 736/5000
 - 1s - loss: 0.5700 - val_loss: 0.4307
Epoch 737/5000
 - 1s - loss: 0.5653 - val_loss: 0.4281
Epoch 738/5000
 - 1s - loss: 0.5609 - val_loss: 0.4265
Epoch 739/5000
 - 1s - loss: 0.5569 - val_loss: 0.4264
Epoch 740/5000
 - 1s - loss: 0.5528 - val_loss: 0.4281
Epoch 741/5000
 - 1s - loss: 0.5491 - val_loss: 0.4302
Epoch 742/5000
 - 1s - loss: 0.5437 - val_loss: 0.4294
Epoch 743/5000
 - 1s - loss: 0.5433 - val_loss: 0.4285
Epoch 744/5000
 - 1s - loss: 0.5430 - val_loss: 0.4276
setting environment to train mode..... 

Training Started... 

--------------------------------------
| approxkl           | 0.0086576175  |
| clipfrac           | 0.13671875    |
| explained_variance | 0             |
| fps                | 4             |
| n_updates          | 1             |
| policy_entropy     | 0.70620406    |
| policy_loss        | -0.0046912148 |
| serial_timesteps   | 128           |
| time_elapsed       | 1.19e-05      |
| total_timesteps    | 128           |
| value_loss         | 49.81758      |
--------------------------------------
------------------------------------
| approxkl           | 0.008299982 |
| clipfrac           | 0.1171875   |
| explained_variance | -7.15e-07   |
| fps                | 30          |
| n_updates          | 2           |
| policy_entropy     | 0.7055932   |
| policy_loss        | 0.00863292  |
| serial_timesteps   | 256         |
| time_elapsed       | 31.1        |
| total_timesteps    | 256         |
| value_loss         | 33.59865    |
------------------------------------
------------------------------------
| approxkl           | 0.013944243 |
| clipfrac           | 0.16992188  |
| explained_variance | 2.98e-07    |
| fps                | 32          |
| n_updates          | 3           |
| policy_entropy     | 0.70458925  |
| policy_loss        | 0.00606269  |
| serial_timesteps   | 384         |
| time_elapsed       | 35.3        |
| total_timesteps    | 384         |
| value_loss         | 27.678785   |
------------------------------------
An average of 179.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.010597132 |
| clipfrac           | 0.1640625   |
| explained_variance | -3.58e-07   |
| fps                | 32          |
| n_updates          | 4           |
| policy_entropy     | 0.70377815  |
| policy_loss        | -0.01019482 |
| serial_timesteps   | 512         |
| time_elapsed       | 39.3        |
| total_timesteps    | 512         |
| value_loss         | 30.26854    |
------------------------------------
-------------------------------------
| approxkl           | 0.008912453  |
| clipfrac           | 0.12695312   |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 5            |
| policy_entropy     | 0.7033121    |
| policy_loss        | -0.008958441 |
| serial_timesteps   | 640          |
| time_elapsed       | 43.2         |
| total_timesteps    | 640          |
| value_loss         | 31.661362    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0064240443  |
| clipfrac           | 0.08984375    |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 6             |
| policy_entropy     | 0.7025165     |
| policy_loss        | -0.0018396527 |
| serial_timesteps   | 768           |
| time_elapsed       | 47.5          |
| total_timesteps    | 768           |
| value_loss         | 23.620602     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0069476278 |
| clipfrac           | 0.103515625  |
| explained_variance | -1.67e-06    |
| fps                | 31           |
| n_updates          | 7            |
| policy_entropy     | 0.70208895   |
| policy_loss        | -0.008206841 |
| serial_timesteps   | 896          |
| time_elapsed       | 51.6         |
| total_timesteps    | 896          |
| value_loss         | 31.08145     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0036535722 |
| clipfrac           | 0.041015625  |
| explained_variance | -9.54e-07    |
| fps                | 32           |
| n_updates          | 8            |
| policy_entropy     | 0.70118976   |
| policy_loss        | 0.0045024483 |
| serial_timesteps   | 1024         |
| time_elapsed       | 55.6         |
| total_timesteps    | 1024         |
| value_loss         | 21.42504     |
-------------------------------------
-------------------------------------
| approxkl           | 0.026347924  |
| clipfrac           | 0.29882812   |
| explained_variance | -2.38e-07    |
| fps                | 34           |
| n_updates          | 9            |
| policy_entropy     | 0.69960636   |
| policy_loss        | 0.0063207364 |
| serial_timesteps   | 1152         |
| time_elapsed       | 59.5         |
| total_timesteps    | 1152         |
| value_loss         | 20.782078    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0054805917  |
| clipfrac           | 0.0703125     |
| explained_variance | -1.67e-06     |
| fps                | 31            |
| n_updates          | 10            |
| policy_entropy     | 0.69899374    |
| policy_loss        | 0.00066253997 |
| serial_timesteps   | 1280          |
| time_elapsed       | 63.3          |
| total_timesteps    | 1280          |
| value_loss         | 13.359378     |
--------------------------------------
------------------------------------
| approxkl           | 0.006209689 |
| clipfrac           | 0.0703125   |
| explained_variance | 1.19e-07    |
| fps                | 29          |
| n_updates          | 11          |
| policy_entropy     | 0.6991125   |
| policy_loss        | -0.00532753 |
| serial_timesteps   | 1408        |
| time_elapsed       | 67.4        |
| total_timesteps    | 1408        |
| value_loss         | 67.948555   |
------------------------------------
An average of 179.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0013995109 |
| clipfrac           | 0.005859375  |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 12           |
| policy_entropy     | 0.6987632    |
| policy_loss        | 0.0024539286 |
| serial_timesteps   | 1536         |
| time_elapsed       | 71.7         |
| total_timesteps    | 1536         |
| value_loss         | 37.603386    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0001884472  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 13            |
| policy_entropy     | 0.6962654     |
| policy_loss        | 0.00010677916 |
| serial_timesteps   | 1664          |
| time_elapsed       | 75.9          |
| total_timesteps    | 1664          |
| value_loss         | 2892.529      |
--------------------------------------
-------------------------------------
| approxkl           | 0.013505543  |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.57e+03     |
| explained_variance | -1.43e-06    |
| fps                | 29           |
| n_updates          | 14           |
| policy_entropy     | 0.69480634   |
| policy_loss        | -0.020290602 |
| serial_timesteps   | 1792         |
| time_elapsed       | 80.2         |
| total_timesteps    | 1792         |
| value_loss         | 28.29938     |
-------------------------------------
-------------------------------------
| approxkl           | 0.007698359  |
| clipfrac           | 0.095703125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.57e+03     |
| explained_variance | -3.58e-07    |
| fps                | 29           |
| n_updates          | 15           |
| policy_entropy     | 0.69346106   |
| policy_loss        | -0.005387143 |
| serial_timesteps   | 1920         |
| time_elapsed       | 84.6         |
| total_timesteps    | 1920         |
| value_loss         | 36.16602     |
-------------------------------------
-------------------------------------
| approxkl           | 0.003086043  |
| clipfrac           | 0.0390625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.57e+03     |
| explained_variance | -3.58e-07    |
| fps                | 29           |
| n_updates          | 16           |
| policy_entropy     | 0.69182956   |
| policy_loss        | -0.003041355 |
| serial_timesteps   | 2048         |
| time_elapsed       | 88.9         |
| total_timesteps    | 2048         |
| value_loss         | 27.067467    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008378865   |
| clipfrac           | 0.13085938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 17            |
| policy_entropy     | 0.6916643     |
| policy_loss        | -0.0028594683 |
| serial_timesteps   | 2176          |
| time_elapsed       | 93.3          |
| total_timesteps    | 2176          |
| value_loss         | 92.04897      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0052884305  |
| clipfrac           | 0.083984375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 18            |
| policy_entropy     | 0.69108194    |
| policy_loss        | -0.0036772229 |
| serial_timesteps   | 2304          |
| time_elapsed       | 97.5          |
| total_timesteps    | 2304          |
| value_loss         | 44.1755       |
--------------------------------------
-------------------------------------
| approxkl           | 0.0055983528 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.57e+03     |
| explained_variance | -8.34e-07    |
| fps                | 28           |
| n_updates          | 19           |
| policy_entropy     | 0.6907035    |
| policy_loss        | 0.003968231  |
| serial_timesteps   | 2432         |
| time_elapsed       | 102          |
| total_timesteps    | 2432         |
| value_loss         | 66.908066    |
-------------------------------------
An average of 180.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0030820859  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | -3.58e-07     |
| fps                | 29            |
| n_updates          | 20            |
| policy_entropy     | 0.6903241     |
| policy_loss        | 0.00014276605 |
| serial_timesteps   | 2560          |
| time_elapsed       | 106           |
| total_timesteps    | 2560          |
| value_loss         | 101.78641     |
--------------------------------------
-------------------------------------
| approxkl           | 0.006128572  |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.57e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 21           |
| policy_entropy     | 0.6900028    |
| policy_loss        | -0.002213134 |
| serial_timesteps   | 2688         |
| time_elapsed       | 111          |
| total_timesteps    | 2688         |
| value_loss         | 25.008345    |
-------------------------------------
--------------------------------------
| approxkl           | 0.020048223   |
| clipfrac           | 0.29101562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | -9.54e-07     |
| fps                | 30            |
| n_updates          | 22            |
| policy_entropy     | 0.68928117    |
| policy_loss        | -0.0123301195 |
| serial_timesteps   | 2816          |
| time_elapsed       | 115           |
| total_timesteps    | 2816          |
| value_loss         | 21.229702     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0013978358  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | -3.58e-07     |
| fps                | 31            |
| n_updates          | 23            |
| policy_entropy     | 0.68794817    |
| policy_loss        | 0.00033295748 |
| serial_timesteps   | 2944          |
| time_elapsed       | 119           |
| total_timesteps    | 2944          |
| value_loss         | 39.661766     |
--------------------------------------
--------------------------------------
| approxkl           | 0.007862226   |
| clipfrac           | 0.091796875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.57e+03      |
| explained_variance | 1.19e-07      |
| fps                | 31            |
| n_updates          | 24            |
| policy_entropy     | 0.68533516    |
| policy_loss        | -0.0058536017 |
| serial_timesteps   | 3072          |
| time_elapsed       | 123           |
| total_timesteps    | 3072          |
| value_loss         | 38.25148      |
--------------------------------------
--------------------------------------
| approxkl           | 0.00088513456 |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.37e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 25            |
| policy_entropy     | 0.68459064    |
| policy_loss        | 0.004169703   |
| serial_timesteps   | 3200          |
| time_elapsed       | 127           |
| total_timesteps    | 3200          |
| value_loss         | 3678.495      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0029085837 |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.37e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 26           |
| policy_entropy     | 0.68414164   |
| policy_loss        | 0.0030502893 |
| serial_timesteps   | 3328         |
| time_elapsed       | 131          |
| total_timesteps    | 3328         |
| value_loss         | 22.095272    |
-------------------------------------
An average of 181.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.008862996 |
| clipfrac           | 0.12109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.37e+03    |
| explained_variance | -9.54e-07   |
| fps                | 31          |
| n_updates          | 27          |
| policy_entropy     | 0.68255025  |
| policy_loss        | -0.00576175 |
| serial_timesteps   | 3456        |
| time_elapsed       | 135         |
| total_timesteps    | 3456        |
| value_loss         | 17.596588   |
------------------------------------
-------------------------------------
| approxkl           | 0.009478085  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.37e+03     |
| explained_variance | 5.36e-07     |
| fps                | 30           |
| n_updates          | 28           |
| policy_entropy     | 0.68126535   |
| policy_loss        | -0.009314988 |
| serial_timesteps   | 3584         |
| time_elapsed       | 139          |
| total_timesteps    | 3584         |
| value_loss         | 26.548971    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0010641535  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.37e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 29            |
| policy_entropy     | 0.6802827     |
| policy_loss        | -0.0017165866 |
| serial_timesteps   | 3712          |
| time_elapsed       | 143           |
| total_timesteps    | 3712          |
| value_loss         | 33.846313     |
--------------------------------------
-------------------------------------
| approxkl           | 0.00812984   |
| clipfrac           | 0.12109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.37e+03     |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 30           |
| policy_entropy     | 0.6788171    |
| policy_loss        | -0.006394067 |
| serial_timesteps   | 3840         |
| time_elapsed       | 147          |
| total_timesteps    | 3840         |
| value_loss         | 46.528877    |
-------------------------------------
------------------------------------
| approxkl           | 0.004117769 |
| clipfrac           | 0.0546875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.37e+03    |
| explained_variance | -1.55e-06   |
| fps                | 30          |
| n_updates          | 31          |
| policy_entropy     | 0.67807287  |
| policy_loss        | 0.004582815 |
| serial_timesteps   | 3968        |
| time_elapsed       | 152         |
| total_timesteps    | 3968        |
| value_loss         | 52.115967   |
------------------------------------
-------------------------------------
| approxkl           | 0.0011997431 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.37e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 32           |
| policy_entropy     | 0.67688525   |
| policy_loss        | 0.0031373776 |
| serial_timesteps   | 4096         |
| time_elapsed       | 156          |
| total_timesteps    | 4096         |
| value_loss         | 49.045097    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0010062628 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.37e+03     |
| explained_variance | -7.15e-07    |
| fps                | 29           |
| n_updates          | 33           |
| policy_entropy     | 0.674288     |
| policy_loss        | 0.0013428095 |
| serial_timesteps   | 4224         |
| time_elapsed       | 160          |
| total_timesteps    | 4224         |
| value_loss         | 43.50591     |
-------------------------------------
------------------------------------
| approxkl           | 0.007856561 |
| clipfrac           | 0.10546875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.37e+03    |
| explained_variance | -4.05e-06   |
| fps                | 32          |
| n_updates          | 34          |
| policy_entropy     | 0.67109877  |
| policy_loss        | -0.00737993 |
| serial_timesteps   | 4352        |
| time_elapsed       | 164         |
| total_timesteps    | 4352        |
| value_loss         | 12.342561   |
------------------------------------
An average of 181.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.010288224 |
| clipfrac           | 0.14648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.37e+03    |
| explained_variance | -1.19e-07   |
| fps                | 28          |
| n_updates          | 35          |
| policy_entropy     | 0.66949344  |
| policy_loss        | 0.009946628 |
| serial_timesteps   | 4480        |
| time_elapsed       | 168         |
| total_timesteps    | 4480        |
| value_loss         | 69.86521    |
------------------------------------
-------------------------------------
| approxkl           | 0.012397392  |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.37e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 36           |
| policy_entropy     | 0.66854775   |
| policy_loss        | -0.002080811 |
| serial_timesteps   | 4608         |
| time_elapsed       | 173          |
| total_timesteps    | 4608         |
| value_loss         | 42.521744    |
-------------------------------------
------------------------------------
| approxkl           | 0.013534944 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.41e+03    |
| explained_variance | 5.96e-08    |
| fps                | 31          |
| n_updates          | 37          |
| policy_entropy     | 0.6678861   |
| policy_loss        | 0.01754302  |
| serial_timesteps   | 4736        |
| time_elapsed       | 177         |
| total_timesteps    | 4736        |
| value_loss         | 3802.8206   |
------------------------------------
-------------------------------------
| approxkl           | 0.017755255  |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 38           |
| policy_entropy     | 0.6676245    |
| policy_loss        | 0.0043744138 |
| serial_timesteps   | 4864         |
| time_elapsed       | 181          |
| total_timesteps    | 4864         |
| value_loss         | 72.515114    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0048200116  |
| clipfrac           | 0.060546875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.41e+03      |
| explained_variance | -1.79e-06     |
| fps                | 28            |
| n_updates          | 39            |
| policy_entropy     | 0.6670496     |
| policy_loss        | -0.0025371998 |
| serial_timesteps   | 4992          |
| time_elapsed       | 186           |
| total_timesteps    | 4992          |
| value_loss         | 13.110802     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0061551724  |
| clipfrac           | 0.08984375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.41e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 40            |
| policy_entropy     | 0.666658      |
| policy_loss        | -0.0034623824 |
| serial_timesteps   | 5120          |
| time_elapsed       | 190           |
| total_timesteps    | 5120          |
| value_loss         | 23.354502     |
--------------------------------------
-------------------------------------
| approxkl           | 0.007979853  |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | -1.43e-06    |
| fps                | 32           |
| n_updates          | 41           |
| policy_entropy     | 0.66605985   |
| policy_loss        | -0.008893743 |
| serial_timesteps   | 5248         |
| time_elapsed       | 194          |
| total_timesteps    | 5248         |
| value_loss         | 25.301748    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01352664   |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | -9.54e-07    |
| fps                | 31           |
| n_updates          | 42           |
| policy_entropy     | 0.6652729    |
| policy_loss        | 0.0018478374 |
| serial_timesteps   | 5376         |
| time_elapsed       | 198          |
| total_timesteps    | 5376         |
| value_loss         | 34.04651     |
-------------------------------------
An average of 182.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.01165158   |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | -8.34e-07    |
| fps                | 31           |
| n_updates          | 43           |
| policy_entropy     | 0.66329426   |
| policy_loss        | 0.0022554344 |
| serial_timesteps   | 5504         |
| time_elapsed       | 202          |
| total_timesteps    | 5504         |
| value_loss         | 16.796602    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0024386533 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | -3.34e-06    |
| fps                | 30           |
| n_updates          | 44           |
| policy_entropy     | 0.66183054   |
| policy_loss        | 0.0012365025 |
| serial_timesteps   | 5632         |
| time_elapsed       | 206          |
| total_timesteps    | 5632         |
| value_loss         | 29.730057    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00039269167 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.41e+03      |
| explained_variance | -2.38e-07     |
| fps                | 30            |
| n_updates          | 45            |
| policy_entropy     | 0.6604576     |
| policy_loss        | 0.0031196019  |
| serial_timesteps   | 5760          |
| time_elapsed       | 210           |
| total_timesteps    | 5760          |
| value_loss         | 19.228514     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0030416315 |
| clipfrac           | 0.037109375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 46           |
| policy_entropy     | 0.6583969    |
| policy_loss        | 0.001882528  |
| serial_timesteps   | 5888         |
| time_elapsed       | 215          |
| total_timesteps    | 5888         |
| value_loss         | 43.874943    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005973873   |
| clipfrac           | 0.078125      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.41e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 47            |
| policy_entropy     | 0.6561259     |
| policy_loss        | -0.0051211007 |
| serial_timesteps   | 6016          |
| time_elapsed       | 219           |
| total_timesteps    | 6016          |
| value_loss         | 29.352888     |
--------------------------------------
-------------------------------------
| approxkl           | 0.003260749  |
| clipfrac           | 0.0234375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.41e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 48           |
| policy_entropy     | 0.65281254   |
| policy_loss        | 0.0021362721 |
| serial_timesteps   | 6144         |
| time_elapsed       | 223          |
| total_timesteps    | 6144         |
| value_loss         | 29.979713    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0001299529  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | 0             |
| fps                | 28            |
| n_updates          | 49            |
| policy_entropy     | 0.6486703     |
| policy_loss        | -0.0019057264 |
| serial_timesteps   | 6272          |
| time_elapsed       | 227           |
| total_timesteps    | 6272          |
| value_loss         | 4223.542      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0069872728 |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 50           |
| policy_entropy     | 0.6472122    |
| policy_loss        | -0.001850852 |
| serial_timesteps   | 6400         |
| time_elapsed       | 232          |
| total_timesteps    | 6400         |
| value_loss         | 52.7926      |
-------------------------------------
An average of 183.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0032845847  |
| clipfrac           | 0.044921875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | -2.15e-06     |
| fps                | 30            |
| n_updates          | 51            |
| policy_entropy     | 0.64544404    |
| policy_loss        | -0.0028050258 |
| serial_timesteps   | 6528          |
| time_elapsed       | 236           |
| total_timesteps    | 6528          |
| value_loss         | 18.305363     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0054927687 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -2.38e-07    |
| fps                | 31           |
| n_updates          | 52           |
| policy_entropy     | 0.6451508    |
| policy_loss        | 0.0015603149 |
| serial_timesteps   | 6656         |
| time_elapsed       | 240          |
| total_timesteps    | 6656         |
| value_loss         | 37.1639      |
-------------------------------------
------------------------------------
| approxkl           | 0.021660218 |
| clipfrac           | 0.29101562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | -1.19e-07   |
| fps                | 29          |
| n_updates          | 53          |
| policy_entropy     | 0.645777    |
| policy_loss        | 0.00553866  |
| serial_timesteps   | 6784        |
| time_elapsed       | 244         |
| total_timesteps    | 6784        |
| value_loss         | 85.18159    |
------------------------------------
-------------------------------------
| approxkl           | 0.02379896   |
| clipfrac           | 0.28710938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -8.34e-07    |
| fps                | 29           |
| n_updates          | 54           |
| policy_entropy     | 0.6461286    |
| policy_loss        | -0.012165254 |
| serial_timesteps   | 6912         |
| time_elapsed       | 248          |
| total_timesteps    | 6912         |
| value_loss         | 18.209887    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005228319  |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 55           |
| policy_entropy     | 0.6458364    |
| policy_loss        | 0.0010004656 |
| serial_timesteps   | 7040         |
| time_elapsed       | 253          |
| total_timesteps    | 7040         |
| value_loss         | 31.290117    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076254127 |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | 0            |
| fps                | 27           |
| n_updates          | 56           |
| policy_entropy     | 0.6448348    |
| policy_loss        | -0.005994932 |
| serial_timesteps   | 7168         |
| time_elapsed       | 257          |
| total_timesteps    | 7168         |
| value_loss         | 93.63022     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0019305281 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -9.54e-07    |
| fps                | 29           |
| n_updates          | 57           |
| policy_entropy     | 0.6448688    |
| policy_loss        | 0.0011364643 |
| serial_timesteps   | 7296         |
| time_elapsed       | 262          |
| total_timesteps    | 7296         |
| value_loss         | 20.81074     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0054137902 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | 6.56e-07     |
| fps                | 29           |
| n_updates          | 58           |
| policy_entropy     | 0.6451235    |
| policy_loss        | 0.0004009034 |
| serial_timesteps   | 7424         |
| time_elapsed       | 266          |
| total_timesteps    | 7424         |
| value_loss         | 21.00091     |
-------------------------------------
An average of 183.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.003016408 |
| clipfrac           | 0.03125     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | -1.19e-07   |
| fps                | 34          |
| n_updates          | 59          |
| policy_entropy     | 0.6446372   |
| policy_loss        | 0.001246264 |
| serial_timesteps   | 7552        |
| time_elapsed       | 270         |
| total_timesteps    | 7552        |
| value_loss         | 36.935574   |
------------------------------------
--------------------------------------
| approxkl           | 0.0081111975  |
| clipfrac           | 0.12695312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 60            |
| policy_entropy     | 0.64426285    |
| policy_loss        | -0.0055641313 |
| serial_timesteps   | 7680          |
| time_elapsed       | 274           |
| total_timesteps    | 7680          |
| value_loss         | 29.29514      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008870281  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 61           |
| policy_entropy     | 0.64408296   |
| policy_loss        | -0.003914579 |
| serial_timesteps   | 7808         |
| time_elapsed       | 278          |
| total_timesteps    | 7808         |
| value_loss         | 3935.6445    |
-------------------------------------
-------------------------------------
| approxkl           | 0.020983607  |
| clipfrac           | 0.28125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | -8.34e-07    |
| fps                | 32           |
| n_updates          | 62           |
| policy_entropy     | 0.6439686    |
| policy_loss        | -0.019340616 |
| serial_timesteps   | 7936         |
| time_elapsed       | 282          |
| total_timesteps    | 7936         |
| value_loss         | 22.237068    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0037782297 |
| clipfrac           | 0.041015625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | 1.19e-07     |
| fps                | 31           |
| n_updates          | 63           |
| policy_entropy     | 0.6436542    |
| policy_loss        | 0.0012055819 |
| serial_timesteps   | 8064         |
| time_elapsed       | 286          |
| total_timesteps    | 8064         |
| value_loss         | 24.062933    |
-------------------------------------
--------------------------------------
| approxkl           | 0.010799361   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.45e+03      |
| explained_variance | 5.96e-08      |
| fps                | 30            |
| n_updates          | 64            |
| policy_entropy     | 0.64268106    |
| policy_loss        | -0.0067008147 |
| serial_timesteps   | 8192          |
| time_elapsed       | 290           |
| total_timesteps    | 8192          |
| value_loss         | 21.278465     |
--------------------------------------
--------------------------------------
| approxkl           | 0.007257573   |
| clipfrac           | 0.107421875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.45e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 65            |
| policy_entropy     | 0.6422589     |
| policy_loss        | -0.0010581098 |
| serial_timesteps   | 8320          |
| time_elapsed       | 294           |
| total_timesteps    | 8320          |
| value_loss         | 16.17321      |
--------------------------------------
An average of 184.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.01125376   |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 66           |
| policy_entropy     | 0.64187294   |
| policy_loss        | -0.003575679 |
| serial_timesteps   | 8448         |
| time_elapsed       | 298          |
| total_timesteps    | 8448         |
| value_loss         | 41.46501     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0052651586  |
| clipfrac           | 0.064453125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.45e+03      |
| explained_variance | -1.19e-07     |
| fps                | 29            |
| n_updates          | 67            |
| policy_entropy     | 0.64176       |
| policy_loss        | -0.0028114938 |
| serial_timesteps   | 8576          |
| time_elapsed       | 302           |
| total_timesteps    | 8576          |
| value_loss         | 51.05277      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0039201686 |
| clipfrac           | 0.041015625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | -9.54e-07    |
| fps                | 29           |
| n_updates          | 68           |
| policy_entropy     | 0.6413874    |
| policy_loss        | -0.002966595 |
| serial_timesteps   | 8704         |
| time_elapsed       | 307          |
| total_timesteps    | 8704         |
| value_loss         | 68.04837     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0018171943  |
| clipfrac           | 0.01953125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.45e+03      |
| explained_variance | -1.31e-06     |
| fps                | 31            |
| n_updates          | 69            |
| policy_entropy     | 0.640922      |
| policy_loss        | 1.3242476e-05 |
| serial_timesteps   | 8832          |
| time_elapsed       | 311           |
| total_timesteps    | 8832          |
| value_loss         | 21.929724     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0018682402  |
| clipfrac           | 0.02734375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.45e+03      |
| explained_variance | -2.38e-07     |
| fps                | 30            |
| n_updates          | 70            |
| policy_entropy     | 0.6403062     |
| policy_loss        | -0.0002201848 |
| serial_timesteps   | 8960          |
| time_elapsed       | 315           |
| total_timesteps    | 8960          |
| value_loss         | 64.3676       |
--------------------------------------
-------------------------------------
| approxkl           | 0.0035064286 |
| clipfrac           | 0.041015625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | 1.19e-07     |
| fps                | 31           |
| n_updates          | 71           |
| policy_entropy     | 0.6395692    |
| policy_loss        | -0.003925927 |
| serial_timesteps   | 9088         |
| time_elapsed       | 319          |
| total_timesteps    | 9088         |
| value_loss         | 98.92753     |
-------------------------------------
-------------------------------------
| approxkl           | 0.003420831  |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.45e+03     |
| explained_variance | -1.19e-07    |
| fps                | 27           |
| n_updates          | 72           |
| policy_entropy     | 0.6383971    |
| policy_loss        | 0.0025239256 |
| serial_timesteps   | 9216         |
| time_elapsed       | 324          |
| total_timesteps    | 9216         |
| value_loss         | 8.924662     |
-------------------------------------
--------------------------------------
| approxkl           | 0.002213063   |
| clipfrac           | 0.01953125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 73            |
| policy_entropy     | 0.63714546    |
| policy_loss        | -0.0024848555 |
| serial_timesteps   | 9344          |
| time_elapsed       | 328           |
| total_timesteps    | 9344          |
| value_loss         | 4164.7275     |
--------------------------------------
An average of 185.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-----------------------------------
| approxkl           | 0.02570386 |
| clipfrac           | 0.29101562 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 5.46e+03   |
| explained_variance | -3.58e-07  |
| fps                | 29         |
| n_updates          | 74         |
| policy_entropy     | 0.6366861  |
| policy_loss        | -0.0160611 |
| serial_timesteps   | 9472       |
| time_elapsed       | 333        |
| total_timesteps    | 9472       |
| value_loss         | 47.946075  |
-----------------------------------
------------------------------------
| approxkl           | 0.00295812  |
| clipfrac           | 0.033203125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | -2.38e-07   |
| fps                | 29          |
| n_updates          | 75          |
| policy_entropy     | 0.63580304  |
| policy_loss        | 0.002105601 |
| serial_timesteps   | 9600        |
| time_elapsed       | 337         |
| total_timesteps    | 9600        |
| value_loss         | 52.463047   |
------------------------------------
---------------------------------------
| approxkl           | 0.003055667    |
| clipfrac           | 0.033203125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.46e+03       |
| explained_variance | 0              |
| fps                | 27             |
| n_updates          | 76             |
| policy_entropy     | 0.6343318      |
| policy_loss        | -0.00024621421 |
| serial_timesteps   | 9728           |
| time_elapsed       | 341            |
| total_timesteps    | 9728           |
| value_loss         | 16.469868      |
---------------------------------------
--------------------------------------
| approxkl           | 0.013151921   |
| clipfrac           | 0.17578125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | 1.31e-06      |
| fps                | 31            |
| n_updates          | 77            |
| policy_entropy     | 0.63386416    |
| policy_loss        | -0.0044297758 |
| serial_timesteps   | 9856          |
| time_elapsed       | 346           |
| total_timesteps    | 9856          |
| value_loss         | 17.827475     |
--------------------------------------
-------------------------------------
| approxkl           | 0.010717723  |
| clipfrac           | 0.15234375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 78           |
| policy_entropy     | 0.63371384   |
| policy_loss        | -0.009932311 |
| serial_timesteps   | 9984         |
| time_elapsed       | 350          |
| total_timesteps    | 9984         |
| value_loss         | 19.786123    |
-------------------------------------
-------------------------------------
| approxkl           | 0.004812603  |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -1.19e-07    |
| fps                | 33           |
| n_updates          | 79           |
| policy_entropy     | 0.6341144    |
| policy_loss        | 0.0009038184 |
| serial_timesteps   | 10112        |
| time_elapsed       | 354          |
| total_timesteps    | 10112        |
| value_loss         | 16.933685    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0016241512  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | 5.96e-07      |
| fps                | 30            |
| n_updates          | 80            |
| policy_entropy     | 0.63364816    |
| policy_loss        | 0.00030642725 |
| serial_timesteps   | 10240         |
| time_elapsed       | 358           |
| total_timesteps    | 10240         |
| value_loss         | 21.161242     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0009564244 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | 5.96e-08     |
| fps                | 32           |
| n_updates          | 81           |
| policy_entropy     | 0.63134116   |
| policy_loss        | 0.002556944  |
| serial_timesteps   | 10368        |
| time_elapsed       | 362          |
| total_timesteps    | 10368        |
| value_loss         | 27.605793    |
-------------------------------------
An average of 185.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.021853736  |
| clipfrac           | 0.29296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.46e+03     |
| explained_variance | -1.07e-06    |
| fps                | 31           |
| n_updates          | 82           |
| policy_entropy     | 0.6281007    |
| policy_loss        | -0.014580749 |
| serial_timesteps   | 10496        |
| time_elapsed       | 366          |
| total_timesteps    | 10496        |
| value_loss         | 19.025362    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004186033   |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.46e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 83            |
| policy_entropy     | 0.6266191     |
| policy_loss        | -0.0036106668 |
| serial_timesteps   | 10624         |
| time_elapsed       | 370           |
| total_timesteps    | 10624         |
| value_loss         | 30.286205     |
--------------------------------------
------------------------------------
| approxkl           | 0.019743215 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.46e+03    |
| explained_variance | 1.19e-07    |
| fps                | 32          |
| n_updates          | 84          |
| policy_entropy     | 0.62590617  |
| policy_loss        | 0.007767506 |
| serial_timesteps   | 10752       |
| time_elapsed       | 374         |
| total_timesteps    | 10752       |
| value_loss         | 38.106655   |
------------------------------------
------------------------------------
| approxkl           | 0.06581898  |
| clipfrac           | 0.47460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.49e+03    |
| explained_variance | -1.19e-07   |
| fps                | 30          |
| n_updates          | 85          |
| policy_entropy     | 0.6262377   |
| policy_loss        | 0.052793622 |
| serial_timesteps   | 10880       |
| time_elapsed       | 378         |
| total_timesteps    | 10880       |
| value_loss         | 3965.6526   |
------------------------------------
--------------------------------------
| approxkl           | 0.00051436294 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | -4.77e-07     |
| fps                | 30            |
| n_updates          | 86            |
| policy_entropy     | 0.6264006     |
| policy_loss        | 0.00084972405 |
| serial_timesteps   | 11008         |
| time_elapsed       | 382           |
| total_timesteps    | 11008         |
| value_loss         | 68.49473      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008986957  |
| clipfrac           | 0.12109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.49e+03     |
| explained_variance | 5.96e-08     |
| fps                | 32           |
| n_updates          | 87           |
| policy_entropy     | 0.62682503   |
| policy_loss        | 0.0070594857 |
| serial_timesteps   | 11136        |
| time_elapsed       | 387          |
| total_timesteps    | 11136        |
| value_loss         | 23.542723    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0038127596  |
| clipfrac           | 0.048828125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | -5.96e-07     |
| fps                | 32            |
| n_updates          | 88            |
| policy_entropy     | 0.62709486    |
| policy_loss        | 0.00048047974 |
| serial_timesteps   | 11264         |
| time_elapsed       | 390           |
| total_timesteps    | 11264         |
| value_loss         | 54.625282     |
--------------------------------------
-------------------------------------
| approxkl           | 0.03783      |
| clipfrac           | 0.33789062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.49e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 89           |
| policy_entropy     | 0.6259544    |
| policy_loss        | -0.016961403 |
| serial_timesteps   | 11392        |
| time_elapsed       | 394          |
| total_timesteps    | 11392        |
| value_loss         | 16.724474    |
-------------------------------------
An average of 186.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.058323607 |
| clipfrac           | 0.42578125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.49e+03    |
| explained_variance | -3.58e-07   |
| fps                | 29          |
| n_updates          | 90          |
| policy_entropy     | 0.62646693  |
| policy_loss        | 0.013518966 |
| serial_timesteps   | 11520       |
| time_elapsed       | 398         |
| total_timesteps    | 11520       |
| value_loss         | 83.145775   |
------------------------------------
--------------------------------------
| approxkl           | 0.016269272   |
| clipfrac           | 0.19335938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 91            |
| policy_entropy     | 0.62709075    |
| policy_loss        | -0.0072651217 |
| serial_timesteps   | 11648         |
| time_elapsed       | 403           |
| total_timesteps    | 11648         |
| value_loss         | 19.714327     |
--------------------------------------
-------------------------------------
| approxkl           | 0.013226141  |
| clipfrac           | 0.21289062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.49e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 92           |
| policy_entropy     | 0.62841344   |
| policy_loss        | -0.013008875 |
| serial_timesteps   | 11776        |
| time_elapsed       | 407          |
| total_timesteps    | 11776        |
| value_loss         | 47.34319     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0076552248  |
| clipfrac           | 0.119140625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | 2.38e-07      |
| fps                | 30            |
| n_updates          | 93            |
| policy_entropy     | 0.6286654     |
| policy_loss        | -0.0026255748 |
| serial_timesteps   | 11904         |
| time_elapsed       | 412           |
| total_timesteps    | 11904         |
| value_loss         | 58.27433      |
--------------------------------------
------------------------------------
| approxkl           | 0.006905017 |
| clipfrac           | 0.111328125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.49e+03    |
| explained_variance | -8.34e-07   |
| fps                | 31          |
| n_updates          | 94          |
| policy_entropy     | 0.62915206  |
| policy_loss        | 0.001303249 |
| serial_timesteps   | 12032       |
| time_elapsed       | 416         |
| total_timesteps    | 12032       |
| value_loss         | 16.606787   |
------------------------------------
------------------------------------
| approxkl           | 0.011737881 |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.49e+03    |
| explained_variance | -1.79e-06   |
| fps                | 31          |
| n_updates          | 95          |
| policy_entropy     | 0.6294594   |
| policy_loss        | 0.014087977 |
| serial_timesteps   | 12160       |
| time_elapsed       | 420         |
| total_timesteps    | 12160       |
| value_loss         | 35.611023   |
------------------------------------
------------------------------------
| approxkl           | 0.024285642 |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.49e+03    |
| explained_variance | 5.96e-08    |
| fps                | 31          |
| n_updates          | 96          |
| policy_entropy     | 0.62953836  |
| policy_loss        | -0.01158995 |
| serial_timesteps   | 12288       |
| time_elapsed       | 424         |
| total_timesteps    | 12288       |
| value_loss         | 23.206928   |
------------------------------------
------------------------------------
| approxkl           | 0.056950785 |
| clipfrac           | 0.4296875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.48e+03    |
| explained_variance | -1.19e-07   |
| fps                | 32          |
| n_updates          | 97          |
| policy_entropy     | 0.6298812   |
| policy_loss        | 0.020597678 |
| serial_timesteps   | 12416       |
| time_elapsed       | 428         |
| total_timesteps    | 12416       |
| value_loss         | 4131.502    |
------------------------------------
An average of 187.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.008308275  |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | 1.19e-07     |
| fps                | 31           |
| n_updates          | 98           |
| policy_entropy     | 0.62998194   |
| policy_loss        | -0.010048347 |
| serial_timesteps   | 12544        |
| time_elapsed       | 432          |
| total_timesteps    | 12544        |
| value_loss         | 29.333492    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005049599  |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -2.38e-07    |
| fps                | 34           |
| n_updates          | 99           |
| policy_entropy     | 0.62962574   |
| policy_loss        | -0.005538745 |
| serial_timesteps   | 12672        |
| time_elapsed       | 436          |
| total_timesteps    | 12672        |
| value_loss         | 29.464674    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0058675692 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 100          |
| policy_entropy     | 0.6289932    |
| policy_loss        | -0.002289347 |
| serial_timesteps   | 12800        |
| time_elapsed       | 440          |
| total_timesteps    | 12800        |
| value_loss         | 30.225683    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008584153  |
| clipfrac           | 0.14453125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -2.38e-07    |
| fps                | 31           |
| n_updates          | 101          |
| policy_entropy     | 0.62887913   |
| policy_loss        | 0.0048716334 |
| serial_timesteps   | 12928        |
| time_elapsed       | 444          |
| total_timesteps    | 12928        |
| value_loss         | 41.932327    |
-------------------------------------
-------------------------------------
| approxkl           | 0.06271772   |
| clipfrac           | 0.35351562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 102          |
| policy_entropy     | 0.6287168    |
| policy_loss        | 0.0147985555 |
| serial_timesteps   | 13056        |
| time_elapsed       | 448          |
| total_timesteps    | 13056        |
| value_loss         | 22.335262    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0068658404   |
| clipfrac           | 0.09765625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.48e+03       |
| explained_variance | 0              |
| fps                | 32             |
| n_updates          | 103            |
| policy_entropy     | 0.6284269      |
| policy_loss        | -0.00029220735 |
| serial_timesteps   | 13184          |
| time_elapsed       | 452            |
| total_timesteps    | 13184          |
| value_loss         | 47.809883      |
---------------------------------------
---------------------------------------
| approxkl           | 0.00093516445  |
| clipfrac           | 0.005859375    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.48e+03       |
| explained_variance | -4.77e-07      |
| fps                | 30             |
| n_updates          | 104            |
| policy_entropy     | 0.62845486     |
| policy_loss        | -0.00076024747 |
| serial_timesteps   | 13312          |
| time_elapsed       | 456            |
| total_timesteps    | 13312          |
| value_loss         | 61.541267      |
---------------------------------------
An average of 187.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.012594145  |
| clipfrac           | 0.19921875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 105          |
| policy_entropy     | 0.6287097    |
| policy_loss        | -0.009039641 |
| serial_timesteps   | 13440        |
| time_elapsed       | 460          |
| total_timesteps    | 13440        |
| value_loss         | 35.538864    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007587573  |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 106          |
| policy_entropy     | 0.6286918    |
| policy_loss        | -0.005363416 |
| serial_timesteps   | 13568        |
| time_elapsed       | 464          |
| total_timesteps    | 13568        |
| value_loss         | 46.031506    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00025451437 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.48e+03      |
| explained_variance | -2.86e-06     |
| fps                | 32            |
| n_updates          | 107           |
| policy_entropy     | 0.6290015     |
| policy_loss        | 0.0008998208  |
| serial_timesteps   | 13696         |
| time_elapsed       | 469           |
| total_timesteps    | 13696         |
| value_loss         | 21.110174     |
--------------------------------------
-------------------------------------
| approxkl           | 0.009413582  |
| clipfrac           | 0.1640625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.48e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 108          |
| policy_entropy     | 0.62899965   |
| policy_loss        | -0.006093963 |
| serial_timesteps   | 13824        |
| time_elapsed       | 473          |
| total_timesteps    | 13824        |
| value_loss         | 79.251884    |
-------------------------------------
---------------------------------------
| approxkl           | 0.009390893    |
| clipfrac           | 0.1171875      |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.49e+03       |
| explained_variance | 0              |
| fps                | 29             |
| n_updates          | 109            |
| policy_entropy     | 0.62914026     |
| policy_loss        | -0.00080331514 |
| serial_timesteps   | 13952          |
| time_elapsed       | 477            |
| total_timesteps    | 13952          |
| value_loss         | 4032.8613      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0028671245 |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.49e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 110          |
| policy_entropy     | 0.6292925    |
| policy_loss        | 0.0008941846 |
| serial_timesteps   | 14080        |
| time_elapsed       | 481          |
| total_timesteps    | 14080        |
| value_loss         | 48.337845    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0038418123 |
| clipfrac           | 0.048828125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.49e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 111          |
| policy_entropy     | 0.62866896   |
| policy_loss        | 0.0049822573 |
| serial_timesteps   | 14208        |
| time_elapsed       | 485          |
| total_timesteps    | 14208        |
| value_loss         | 63.633266    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0007773497  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | -2.26e-06     |
| fps                | 30            |
| n_updates          | 112           |
| policy_entropy     | 0.62766457    |
| policy_loss        | -0.0002596249 |
| serial_timesteps   | 14336         |
| time_elapsed       | 489           |
| total_timesteps    | 14336         |
| value_loss         | 22.1577       |
--------------------------------------
An average of 188.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0022053376  |
| clipfrac           | 0.015625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 113           |
| policy_entropy     | 0.62673724    |
| policy_loss        | -0.0016443053 |
| serial_timesteps   | 14464         |
| time_elapsed       | 494           |
| total_timesteps    | 14464         |
| value_loss         | 25.162867     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0021601706  |
| clipfrac           | 0.013671875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | 1.19e-07      |
| fps                | 30            |
| n_updates          | 114           |
| policy_entropy     | 0.6257018     |
| policy_loss        | -0.0013915423 |
| serial_timesteps   | 14592         |
| time_elapsed       | 498           |
| total_timesteps    | 14592         |
| value_loss         | 31.471296     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0039051853  |
| clipfrac           | 0.048828125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | -1.19e-07     |
| fps                | 31            |
| n_updates          | 115           |
| policy_entropy     | 0.6237688     |
| policy_loss        | 0.00031744083 |
| serial_timesteps   | 14720         |
| time_elapsed       | 502           |
| total_timesteps    | 14720         |
| value_loss         | 24.162888     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0069590877  |
| clipfrac           | 0.09765625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.49e+03      |
| explained_variance | 5.96e-08      |
| fps                | 32            |
| n_updates          | 116           |
| policy_entropy     | 0.6219818     |
| policy_loss        | -0.0026165217 |
| serial_timesteps   | 14848         |
| time_elapsed       | 506           |
| total_timesteps    | 14848         |
| value_loss         | 34.526066     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0022494644 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.49e+03     |
| explained_variance | 0            |
| fps                | 32           |
| n_updates          | 117          |
| policy_entropy     | 0.6212793    |
| policy_loss        | 0.0022172208 |
| serial_timesteps   | 14976        |
| time_elapsed       | 510          |
| total_timesteps    | 14976        |
| value_loss         | 44.247795    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b54b70d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b54b70d30>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b510ee240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b510ee240>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2798 samples, validate on 336 samples
Epoch 371/5000
 - 7s - loss: 0.0603 - val_loss: 0.0132
Epoch 372/5000
 - 1s - loss: 0.0116 - val_loss: 0.0085
Epoch 373/5000
 - 1s - loss: 0.0077 - val_loss: 0.0083
Epoch 374/5000
 - 1s - loss: 0.0068 - val_loss: 0.0085
Epoch 375/5000
 - 1s - loss: 0.0065 - val_loss: 0.0086
Epoch 376/5000
 - 1s - loss: 0.0050 - val_loss: 0.0049
Epoch 377/5000
 - 1s - loss: 0.0048 - val_loss: 0.0050
Epoch 378/5000
 - 1s - loss: 0.0047 - val_loss: 0.0051
Epoch 379/5000
 - 1s - loss: 0.0046 - val_loss: 0.0051
Epoch 380/5000
 - 1s - loss: 0.0042 - val_loss: 0.0052
Epoch 381/5000
 - 1s - loss: 0.0042 - val_loss: 0.0053
Train on 1697 samples, validate on 336 samples
Epoch 254/5000
 - 6s - loss: 0.0014 - val_loss: 0.0013
Epoch 255/5000
 - 0s - loss: 0.0014 - val_loss: 0.0013
Epoch 256/5000
 - 0s - loss: 0.0013 - val_loss: 0.0014
Epoch 257/5000
 - 1s - loss: 0.0010 - val_loss: 0.0013
Epoch 258/5000
 - 0s - loss: 0.0010 - val_loss: 0.0013
Epoch 259/5000
 - 0s - loss: 0.0010 - val_loss: 0.0012
Epoch 260/5000
 - 1s - loss: 9.9421e-04 - val_loss: 0.0012
Epoch 261/5000
 - 1s - loss: 9.6213e-04 - val_loss: 0.0012
Epoch 262/5000
 - 0s - loss: 9.6101e-04 - val_loss: 0.0012
Epoch 263/5000
 - 1s - loss: 9.5991e-04 - val_loss: 0.0012
Epoch 264/5000
 - 0s - loss: 9.5887e-04 - val_loss: 0.0012
Epoch 265/5000
 - 0s - loss: 9.5530e-04 - val_loss: 0.0012
Epoch 266/5000
 - 1s - loss: 9.5519e-04 - val_loss: 0.0012
Epoch 267/5000
 - 1s - loss: 9.5508e-04 - val_loss: 0.0012
Epoch 268/5000
 - 1s - loss: 9.5498e-04 - val_loss: 0.0012
Epoch 269/5000
 - 1s - loss: 9.5460e-04 - val_loss: 0.0012
Epoch 270/5000
 - 1s - loss: 9.5459e-04 - val_loss: 0.0012
Epoch 271/5000
 - 1s - loss: 9.5458e-04 - val_loss: 0.0012
Epoch 272/5000
 - 0s - loss: 9.5457e-04 - val_loss: 0.0012
Epoch 273/5000
 - 1s - loss: 9.5453e-04 - val_loss: 0.0012
Epoch 274/5000
 - 1s - loss: 9.5453e-04 - val_loss: 0.0012
Epoch 275/5000
 - 1s - loss: 9.5453e-04 - val_loss: 0.0012
Epoch 276/5000
 - 0s - loss: 9.5453e-04 - val_loss: 0.0012
Epoch 277/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 278/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 279/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 280/5000
 - 1s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 281/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 282/5000
 - 1s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 283/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 284/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Epoch 285/5000
 - 0s - loss: 9.5452e-04 - val_loss: 0.0012
Train on 2798 samples, validate on 336 samples
Epoch 745/5000
 - 8s - loss: 0.6819 - val_loss: 0.6521
Epoch 746/5000
 - 1s - loss: 0.6676 - val_loss: 0.6393
Epoch 747/5000
 - 1s - loss: 0.6628 - val_loss: 0.6322
Epoch 748/5000
 - 1s - loss: 0.6607 - val_loss: 0.6295
Epoch 749/5000
 - 1s - loss: 0.6593 - val_loss: 0.6272
Epoch 750/5000
 - 1s - loss: 0.6573 - val_loss: 0.6235
Epoch 751/5000
 - 1s - loss: 0.6544 - val_loss: 0.6106
Epoch 752/5000
 - 1s - loss: 0.6426 - val_loss: 0.6084
Epoch 753/5000
 - 1s - loss: 0.6180 - val_loss: 0.6040
Epoch 754/5000
 - 1s - loss: 0.6004 - val_loss: 0.5937
Epoch 755/5000
 - 1s - loss: 0.5817 - val_loss: 0.5777
Epoch 756/5000
 - 1s - loss: 0.5705 - val_loss: 0.5689
Epoch 757/5000
 - 1s - loss: 0.5625 - val_loss: 0.5655
Epoch 758/5000
 - 1s - loss: 0.5567 - val_loss: 0.5598
Epoch 759/5000
 - 1s - loss: 0.5514 - val_loss: 0.5532
Epoch 760/5000
 - 1s - loss: 0.5483 - val_loss: 0.5485
Epoch 761/5000
 - 1s - loss: 0.5443 - val_loss: 0.5428
Epoch 762/5000
 - 1s - loss: 0.5419 - val_loss: 0.5392
Epoch 763/5000
 - 1s - loss: 0.5395 - val_loss: 0.5345
Epoch 764/5000
 - 1s - loss: 0.5374 - val_loss: 0.5306
Epoch 765/5000
 - 1s - loss: 0.5351 - val_loss: 0.5260
Epoch 766/5000
 - 1s - loss: 0.5332 - val_loss: 0.5227
Epoch 767/5000
 - 1s - loss: 0.5312 - val_loss: 0.5186
Epoch 768/5000
 - 1s - loss: 0.5293 - val_loss: 0.5157
Epoch 769/5000
 - 1s - loss: 0.5276 - val_loss: 0.5133
Epoch 770/5000
 - 1s - loss: 0.5253 - val_loss: 0.5100
Epoch 771/5000
 - 1s - loss: 0.5234 - val_loss: 0.5087
Epoch 772/5000
 - 1s - loss: 0.5214 - val_loss: 0.5045
Epoch 773/5000
 - 1s - loss: 0.5191 - val_loss: 0.5034
Epoch 774/5000
 - 1s - loss: 0.5170 - val_loss: 0.4977
Epoch 775/5000
 - 1s - loss: 0.5146 - val_loss: 0.4992
Epoch 776/5000
 - 1s - loss: 0.5124 - val_loss: 0.4973
Epoch 777/5000
 - 1s - loss: 0.5096 - val_loss: 0.4920
Epoch 778/5000
 - 1s - loss: 0.5051 - val_loss: 0.4863
Epoch 779/5000
 - 1s - loss: 0.5001 - val_loss: 0.4798
Epoch 780/5000
 - 1s - loss: 0.4948 - val_loss: 0.4733
Epoch 781/5000
 - 1s - loss: 0.4899 - val_loss: 0.4675
Epoch 782/5000
 - 1s - loss: 0.4842 - val_loss: 0.4579
Epoch 783/5000
 - 1s - loss: 0.4782 - val_loss: 0.4479
Epoch 784/5000
 - 1s - loss: 0.4726 - val_loss: 0.4380
Epoch 785/5000
 - 1s - loss: 0.4674 - val_loss: 0.4307
Epoch 786/5000
 - 1s - loss: 0.4635 - val_loss: 0.4244
Epoch 787/5000
 - 1s - loss: 0.4599 - val_loss: 0.4181
Epoch 788/5000
 - 1s - loss: 0.4552 - val_loss: 0.4111
Epoch 789/5000
 - 1s - loss: 0.4514 - val_loss: 0.4067
Epoch 790/5000
 - 1s - loss: 0.4489 - val_loss: 0.4024
Epoch 791/5000
 - 1s - loss: 0.4466 - val_loss: 0.3988
Epoch 792/5000
 - 1s - loss: 0.4445 - val_loss: 0.3961
Epoch 793/5000
 - 1s - loss: 0.4413 - val_loss: 0.3903
Epoch 794/5000
 - 1s - loss: 0.4385 - val_loss: 0.3858
Epoch 795/5000
 - 1s - loss: 0.4369 - val_loss: 0.3811
Epoch 796/5000
 - 1s - loss: 0.4352 - val_loss: 0.3779
Epoch 797/5000
 - 1s - loss: 0.4318 - val_loss: 0.3714
Epoch 798/5000
 - 1s - loss: 0.4290 - val_loss: 0.3655
Epoch 799/5000
 - 1s - loss: 0.4259 - val_loss: 0.3582
Epoch 800/5000
 - 1s - loss: 0.4242 - val_loss: 0.3560
Epoch 801/5000
 - 1s - loss: 0.4230 - val_loss: 0.3526
Epoch 802/5000
 - 1s - loss: 0.4212 - val_loss: 0.3493
Epoch 803/5000
 - 1s - loss: 0.4191 - val_loss: 0.3454
Epoch 804/5000
 - 1s - loss: 0.4169 - val_loss: 0.3400
Epoch 805/5000
 - 1s - loss: 0.4162 - val_loss: 0.3386
Epoch 806/5000
 - 1s - loss: 0.4153 - val_loss: 0.3362
Epoch 807/5000
 - 1s - loss: 0.4136 - val_loss: 0.3341
Epoch 808/5000
 - 1s - loss: 0.4129 - val_loss: 0.3342
Epoch 809/5000
 - 1s - loss: 0.4130 - val_loss: 0.3350
Epoch 810/5000
 - 1s - loss: 0.4077 - val_loss: 0.3055
Epoch 811/5000
 - 1s - loss: 0.3940 - val_loss: 0.2967
Epoch 812/5000
 - 1s - loss: 0.3901 - val_loss: 0.2910
Epoch 813/5000
 - 1s - loss: 0.3880 - val_loss: 0.2882
Epoch 814/5000
 - 1s - loss: 0.3871 - val_loss: 0.2867
Epoch 815/5000
 - 1s - loss: 0.3864 - val_loss: 0.2857
Epoch 816/5000
 - 1s - loss: 0.3859 - val_loss: 0.2849
Epoch 817/5000
 - 1s - loss: 0.3855 - val_loss: 0.2842
Epoch 818/5000
 - 1s - loss: 0.3852 - val_loss: 0.2834
Epoch 819/5000
 - 1s - loss: 0.3847 - val_loss: 0.2832
Epoch 820/5000
 - 1s - loss: 0.3844 - val_loss: 0.2831
Epoch 821/5000
 - 1s - loss: 0.3842 - val_loss: 0.2830
Epoch 822/5000
 - 1s - loss: 0.3839 - val_loss: 0.2830
Epoch 823/5000
 - 1s - loss: 0.3839 - val_loss: 0.2829
Epoch 824/5000
 - 1s - loss: 0.3836 - val_loss: 0.2830
Epoch 825/5000
 - 1s - loss: 0.3835 - val_loss: 0.2830
Epoch 826/5000
 - 1s - loss: 0.3774 - val_loss: 0.2823
Epoch 827/5000
 - 1s - loss: 0.3771 - val_loss: 0.2817
Epoch 828/5000
 - 1s - loss: 0.3769 - val_loss: 0.2811
Epoch 829/5000
 - 1s - loss: 0.3767 - val_loss: 0.2806
Epoch 830/5000
 - 1s - loss: 0.3766 - val_loss: 0.2801
Epoch 831/5000
 - 1s - loss: 0.3765 - val_loss: 0.2797
Epoch 832/5000
 - 1s - loss: 0.3763 - val_loss: 0.2792
Epoch 833/5000
 - 1s - loss: 0.3762 - val_loss: 0.2789
Epoch 834/5000
 - 1s - loss: 0.3761 - val_loss: 0.2785
Epoch 835/5000
 - 1s - loss: 0.3761 - val_loss: 0.2781
Epoch 836/5000
 - 1s - loss: 0.3760 - val_loss: 0.2779
Epoch 837/5000
 - 1s - loss: 0.3759 - val_loss: 0.2776
Epoch 838/5000
 - 1s - loss: 0.3759 - val_loss: 0.2773
Epoch 839/5000
 - 1s - loss: 0.3758 - val_loss: 0.2771
Epoch 840/5000
 - 1s - loss: 0.3758 - val_loss: 0.2769
Epoch 841/5000
 - 1s - loss: 0.3758 - val_loss: 0.2767
Epoch 842/5000
 - 1s - loss: 0.3757 - val_loss: 0.2765
Epoch 843/5000
 - 1s - loss: 0.3757 - val_loss: 0.2763
Epoch 844/5000
 - 1s - loss: 0.3756 - val_loss: 0.2762
Epoch 845/5000
 - 1s - loss: 0.3756 - val_loss: 0.2761
Epoch 846/5000
 - 1s - loss: 0.3756 - val_loss: 0.2759
Epoch 847/5000
 - 1s - loss: 0.3756 - val_loss: 0.2758
Epoch 848/5000
 - 1s - loss: 0.3755 - val_loss: 0.2757
Epoch 849/5000
 - 1s - loss: 0.3755 - val_loss: 0.2757
Epoch 850/5000
 - 1s - loss: 0.3755 - val_loss: 0.2756
Epoch 851/5000
 - 1s - loss: 0.3755 - val_loss: 0.2755
Epoch 852/5000
 - 1s - loss: 0.3755 - val_loss: 0.2754
Epoch 853/5000
 - 1s - loss: 0.3754 - val_loss: 0.2754
Epoch 854/5000
 - 1s - loss: 0.3754 - val_loss: 0.2753
Epoch 855/5000
 - 1s - loss: 0.3754 - val_loss: 0.2752
Epoch 856/5000
 - 1s - loss: 0.3754 - val_loss: 0.2752
Epoch 857/5000
 - 1s - loss: 0.3754 - val_loss: 0.2751
Epoch 858/5000
 - 1s - loss: 0.3754 - val_loss: 0.2751
Epoch 859/5000
 - 1s - loss: 0.3754 - val_loss: 0.2750
Epoch 860/5000
 - 1s - loss: 0.3753 - val_loss: 0.2750
Epoch 861/5000
 - 1s - loss: 0.3753 - val_loss: 0.2749
Epoch 862/5000
 - 1s - loss: 0.3746 - val_loss: 0.2749
Epoch 863/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 864/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 865/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 866/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 867/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 868/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 869/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 870/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 871/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 872/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 873/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
Epoch 874/5000
 - 1s - loss: 0.3745 - val_loss: 0.2749
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0055783605 |
| clipfrac           | 0.076171875  |
| explained_variance | 1.55e-06     |
| fps                | 5            |
| n_updates          | 1            |
| policy_entropy     | 0.6193677    |
| policy_loss        | 0.0064814407 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.29e-05     |
| total_timesteps    | 128          |
| value_loss         | 21.848667    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005522309  |
| clipfrac           | 0.07421875   |
| explained_variance | 1.79e-07     |
| fps                | 30           |
| n_updates          | 2            |
| policy_entropy     | 0.617932     |
| policy_loss        | 0.0037072916 |
| serial_timesteps   | 256          |
| time_elapsed       | 23.2         |
| total_timesteps    | 256          |
| value_loss         | 30.866476    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0060879863  |
| clipfrac           | 0.091796875   |
| explained_variance | -1.19e-07     |
| fps                | 31            |
| n_updates          | 3             |
| policy_entropy     | 0.6163405     |
| policy_loss        | -0.0024526063 |
| serial_timesteps   | 384           |
| time_elapsed       | 27.4          |
| total_timesteps    | 384           |
| value_loss         | 47.619434     |
--------------------------------------
An average of 189.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0007115281 |
| clipfrac           | 0.0          |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 4            |
| policy_entropy     | 0.61508936   |
| policy_loss        | 0.0009004036 |
| serial_timesteps   | 512          |
| time_elapsed       | 31.5         |
| total_timesteps    | 512          |
| value_loss         | 44.10656     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0031333384 |
| clipfrac           | 0.033203125  |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 5            |
| policy_entropy     | 0.6142069    |
| policy_loss        | 0.0013001647 |
| serial_timesteps   | 640          |
| time_elapsed       | 35.6         |
| total_timesteps    | 640          |
| value_loss         | 41.16823     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0059697386 |
| clipfrac           | 0.0859375    |
| explained_variance | 1.55e-06     |
| fps                | 33           |
| n_updates          | 6            |
| policy_entropy     | 0.6110637    |
| policy_loss        | 0.0067973062 |
| serial_timesteps   | 768          |
| time_elapsed       | 39.6         |
| total_timesteps    | 768          |
| value_loss         | 32.271664    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004386076   |
| clipfrac           | 0.056640625   |
| explained_variance | -1.19e-07     |
| fps                | 31            |
| n_updates          | 7             |
| policy_entropy     | 0.60891926    |
| policy_loss        | -0.0011319568 |
| serial_timesteps   | 896           |
| time_elapsed       | 43.5          |
| total_timesteps    | 896           |
| value_loss         | 35.283623     |
--------------------------------------
--------------------------------------
| approxkl           | 0.010388568   |
| clipfrac           | 0.16210938    |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 8             |
| policy_entropy     | 0.6073197     |
| policy_loss        | -0.0076660123 |
| serial_timesteps   | 1024          |
| time_elapsed       | 47.5          |
| total_timesteps    | 1024          |
| value_loss         | 39.331665     |
--------------------------------------
-------------------------------------
| approxkl           | 0.004177427  |
| clipfrac           | 0.048828125  |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 9            |
| policy_entropy     | 0.60595775   |
| policy_loss        | 0.0066630905 |
| serial_timesteps   | 1152         |
| time_elapsed       | 51.8         |
| total_timesteps    | 1152         |
| value_loss         | 34.4087      |
-------------------------------------
------------------------------------
| approxkl           | 0.016299132 |
| clipfrac           | 0.2578125   |
| explained_variance | 2.38e-07    |
| fps                | 29          |
| n_updates          | 10          |
| policy_entropy     | 0.60471016  |
| policy_loss        | -0.00601098 |
| serial_timesteps   | 1280        |
| time_elapsed       | 56.2        |
| total_timesteps    | 1280        |
| value_loss         | 34.79601    |
------------------------------------
-------------------------------------
| approxkl           | 0.000710482  |
| clipfrac           | 0.001953125  |
| explained_variance | -2.98e-06    |
| fps                | 32           |
| n_updates          | 11           |
| policy_entropy     | 0.6040755    |
| policy_loss        | 0.0014560244 |
| serial_timesteps   | 1408         |
| time_elapsed       | 60.5         |
| total_timesteps    | 1408         |
| value_loss         | 48.556625    |
-------------------------------------
An average of 189.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0015853177 |
| clipfrac           | 0.0078125    |
| explained_variance | -5.96e-07    |
| fps                | 30           |
| n_updates          | 12           |
| policy_entropy     | 0.60375017   |
| policy_loss        | 0.0033622587 |
| serial_timesteps   | 1536         |
| time_elapsed       | 64.4         |
| total_timesteps    | 1536         |
| value_loss         | 48.767776    |
-------------------------------------
------------------------------------
| approxkl           | 0.012504596 |
| clipfrac           | 0.16992188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 13          |
| policy_entropy     | 0.603159    |
| policy_loss        | -0.00776732 |
| serial_timesteps   | 1664        |
| time_elapsed       | 68.5        |
| total_timesteps    | 1664        |
| value_loss         | 2658.4956   |
------------------------------------
-------------------------------------
| approxkl           | 0.01662519   |
| clipfrac           | 0.21484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 5.96e-08     |
| fps                | 31           |
| n_updates          | 14           |
| policy_entropy     | 0.6025433    |
| policy_loss        | -0.005731963 |
| serial_timesteps   | 1792         |
| time_elapsed       | 72.8         |
| total_timesteps    | 1792         |
| value_loss         | 31.45374     |
-------------------------------------
-------------------------------------
| approxkl           | 0.008366186  |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -4.65e-06    |
| fps                | 32           |
| n_updates          | 15           |
| policy_entropy     | 0.60192955   |
| policy_loss        | -0.007712618 |
| serial_timesteps   | 1920         |
| time_elapsed       | 76.9         |
| total_timesteps    | 1920         |
| value_loss         | 24.27827     |
-------------------------------------
--------------------------------------
| approxkl           | 0.00026705497 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 16            |
| policy_entropy     | 0.60098946    |
| policy_loss        | 1.349696e-05  |
| serial_timesteps   | 2048          |
| time_elapsed       | 80.9          |
| total_timesteps    | 2048          |
| value_loss         | 24.089626     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0018955617 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -2.38e-06    |
| fps                | 31           |
| n_updates          | 17           |
| policy_entropy     | 0.59955966   |
| policy_loss        | 0.004784277  |
| serial_timesteps   | 2176         |
| time_elapsed       | 84.8         |
| total_timesteps    | 2176         |
| value_loss         | 34.22306     |
-------------------------------------
--------------------------------------
| approxkl           | 0.007632622   |
| clipfrac           | 0.107421875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 1.49e-06      |
| fps                | 30            |
| n_updates          | 18            |
| policy_entropy     | 0.5977101     |
| policy_loss        | -0.0014396267 |
| serial_timesteps   | 2304          |
| time_elapsed       | 88.9          |
| total_timesteps    | 2304          |
| value_loss         | 45.506485     |
--------------------------------------
-------------------------------------
| approxkl           | 0.02341621   |
| clipfrac           | 0.27734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 7.99e-06     |
| fps                | 30           |
| n_updates          | 19           |
| policy_entropy     | 0.59574074   |
| policy_loss        | 0.0006605992 |
| serial_timesteps   | 2432         |
| time_elapsed       | 93.1         |
| total_timesteps    | 2432         |
| value_loss         | 19.110493    |
-------------------------------------
An average of 190.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0035950267  |
| clipfrac           | 0.044921875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | -7.15e-07     |
| fps                | 31            |
| n_updates          | 20            |
| policy_entropy     | 0.59249264    |
| policy_loss        | -0.0038890513 |
| serial_timesteps   | 2560          |
| time_elapsed       | 97.3          |
| total_timesteps    | 2560          |
| value_loss         | 37.823425     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0009881177   |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.36e+03       |
| explained_variance | 0              |
| fps                | 29             |
| n_updates          | 21             |
| policy_entropy     | 0.59019715     |
| policy_loss        | -2.5048386e-05 |
| serial_timesteps   | 2688           |
| time_elapsed       | 101            |
| total_timesteps    | 2688           |
| value_loss         | 40.145363      |
---------------------------------------
--------------------------------------
| approxkl           | 0.0018658643  |
| clipfrac           | 0.015625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 1.19e-07      |
| fps                | 31            |
| n_updates          | 22            |
| policy_entropy     | 0.58859605    |
| policy_loss        | -0.0025331408 |
| serial_timesteps   | 2816          |
| time_elapsed       | 106           |
| total_timesteps    | 2816          |
| value_loss         | 35.634315     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0013240587 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -2.38e-06    |
| fps                | 32           |
| n_updates          | 23           |
| policy_entropy     | 0.58747035   |
| policy_loss        | 0.0017628997 |
| serial_timesteps   | 2944         |
| time_elapsed       | 110          |
| total_timesteps    | 2944         |
| value_loss         | 19.022934    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005545995  |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -5.96e-07    |
| fps                | 31           |
| n_updates          | 24           |
| policy_entropy     | 0.5836397    |
| policy_loss        | 0.0002474269 |
| serial_timesteps   | 3072         |
| time_elapsed       | 114          |
| total_timesteps    | 3072         |
| value_loss         | 32.98409     |
-------------------------------------
------------------------------------
| approxkl           | 0.042733453 |
| clipfrac           | 0.4453125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.34e+03    |
| explained_variance | -1.19e-07   |
| fps                | 31          |
| n_updates          | 25          |
| policy_entropy     | 0.5810931   |
| policy_loss        | 0.028174343 |
| serial_timesteps   | 3200        |
| time_elapsed       | 118         |
| total_timesteps    | 3200        |
| value_loss         | 3629.4846   |
------------------------------------
-------------------------------------
| approxkl           | 0.014951235  |
| clipfrac           | 0.22070312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.34e+03     |
| explained_variance | 0            |
| fps                | 32           |
| n_updates          | 26           |
| policy_entropy     | 0.5805378    |
| policy_loss        | -0.011580988 |
| serial_timesteps   | 3328         |
| time_elapsed       | 122          |
| total_timesteps    | 3328         |
| value_loss         | 28.180475    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006542098  |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.34e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 27           |
| policy_entropy     | 0.58010525   |
| policy_loss        | -0.005646457 |
| serial_timesteps   | 3456         |
| time_elapsed       | 126          |
| total_timesteps    | 3456         |
| value_loss         | 26.490133    |
-------------------------------------
An average of 191.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.006790377 |
| clipfrac           | 0.08203125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.34e+03    |
| explained_variance | 5.96e-08    |
| fps                | 31          |
| n_updates          | 28          |
| policy_entropy     | 0.57853246  |
| policy_loss        | 0.007472409 |
| serial_timesteps   | 3584        |
| time_elapsed       | 130         |
| total_timesteps    | 3584        |
| value_loss         | 26.609608   |
------------------------------------
--------------------------------------
| approxkl           | 0.010624282   |
| clipfrac           | 0.16015625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.34e+03      |
| explained_variance | 3.22e-06      |
| fps                | 32            |
| n_updates          | 29            |
| policy_entropy     | 0.576209      |
| policy_loss        | -0.0028784901 |
| serial_timesteps   | 3712          |
| time_elapsed       | 134           |
| total_timesteps    | 3712          |
| value_loss         | 22.78161      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0059308168 |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.34e+03     |
| explained_variance | -3.58e-07    |
| fps                | 30           |
| n_updates          | 30           |
| policy_entropy     | 0.5743896    |
| policy_loss        | 0.009603528  |
| serial_timesteps   | 3840         |
| time_elapsed       | 138          |
| total_timesteps    | 3840         |
| value_loss         | 29.67139     |
-------------------------------------
--------------------------------------
| approxkl           | 0.009643637   |
| clipfrac           | 0.14453125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.34e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 31            |
| policy_entropy     | 0.57349783    |
| policy_loss        | -0.0001139245 |
| serial_timesteps   | 3968          |
| time_elapsed       | 142           |
| total_timesteps    | 3968          |
| value_loss         | 45.412216     |
--------------------------------------
------------------------------------
| approxkl           | 0.018226687 |
| clipfrac           | 0.25585938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.34e+03    |
| explained_variance | -1.31e-06   |
| fps                | 33          |
| n_updates          | 32          |
| policy_entropy     | 0.5723687   |
| policy_loss        | 0.022808734 |
| serial_timesteps   | 4096        |
| time_elapsed       | 146         |
| total_timesteps    | 4096        |
| value_loss         | 33.629097   |
------------------------------------
-------------------------------------
| approxkl           | 0.0025593545 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.34e+03     |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 33           |
| policy_entropy     | 0.5714456    |
| policy_loss        | 0.0041727973 |
| serial_timesteps   | 4224         |
| time_elapsed       | 150          |
| total_timesteps    | 4224         |
| value_loss         | 37.078312    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006808038  |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.34e+03     |
| explained_variance | 5.96e-08     |
| fps                | 31           |
| n_updates          | 34           |
| policy_entropy     | 0.5704537    |
| policy_loss        | 0.0025318505 |
| serial_timesteps   | 4352         |
| time_elapsed       | 154          |
| total_timesteps    | 4352         |
| value_loss         | 48.279152    |
-------------------------------------
An average of 191.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.00806656   |
| clipfrac           | 0.125        |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.34e+03     |
| explained_variance | 0            |
| fps                | 34           |
| n_updates          | 35           |
| policy_entropy     | 0.56958604   |
| policy_loss        | 0.0033258102 |
| serial_timesteps   | 4480         |
| time_elapsed       | 158          |
| total_timesteps    | 4480         |
| value_loss         | 41.38308     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0016085485  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.34e+03      |
| explained_variance | 6.56e-07      |
| fps                | 32            |
| n_updates          | 36            |
| policy_entropy     | 0.5685983     |
| policy_loss        | 0.00047404878 |
| serial_timesteps   | 4608          |
| time_elapsed       | 162           |
| total_timesteps    | 4608          |
| value_loss         | 36.917816     |
--------------------------------------
--------------------------------------
| approxkl           | 0.009482845   |
| clipfrac           | 0.13867188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 37            |
| policy_entropy     | 0.5672369     |
| policy_loss        | -0.0044475626 |
| serial_timesteps   | 4736          |
| time_elapsed       | 166           |
| total_timesteps    | 4736          |
| value_loss         | 3961.6345     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00083178113 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 38            |
| policy_entropy     | 0.5666847     |
| policy_loss        | -0.0010921431 |
| serial_timesteps   | 4864          |
| time_elapsed       | 170           |
| total_timesteps    | 4864          |
| value_loss         | 36.126335     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00015312248 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | -1.07e-06     |
| fps                | 31            |
| n_updates          | 39            |
| policy_entropy     | 0.5661621     |
| policy_loss        | 0.00052199047 |
| serial_timesteps   | 4992          |
| time_elapsed       | 174           |
| total_timesteps    | 4992          |
| value_loss         | 24.110838     |
--------------------------------------
--------------------------------------
| approxkl           | 0.020763826   |
| clipfrac           | 0.26757812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 40            |
| policy_entropy     | 0.56521755    |
| policy_loss        | -0.0027645482 |
| serial_timesteps   | 5120          |
| time_elapsed       | 178           |
| total_timesteps    | 5120          |
| value_loss         | 27.007542     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0057639843 |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 4.17e-07     |
| fps                | 31           |
| n_updates          | 41           |
| policy_entropy     | 0.5634239    |
| policy_loss        | 0.00471817   |
| serial_timesteps   | 5248         |
| time_elapsed       | 182          |
| total_timesteps    | 5248         |
| value_loss         | 27.558367    |
-------------------------------------
------------------------------------
| approxkl           | 0.015825007 |
| clipfrac           | 0.2265625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | 0           |
| fps                | 32          |
| n_updates          | 42          |
| policy_entropy     | 0.5617261   |
| policy_loss        | 0.025729872 |
| serial_timesteps   | 5376        |
| time_elapsed       | 187         |
| total_timesteps    | 5376        |
| value_loss         | 34.629025   |
------------------------------------
An average of 192.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.017122468 |
| clipfrac           | 0.21875     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | -3.58e-07   |
| fps                | 31          |
| n_updates          | 43          |
| policy_entropy     | 0.56038284  |
| policy_loss        | 0.025103988 |
| serial_timesteps   | 5504        |
| time_elapsed       | 191         |
| total_timesteps    | 5504        |
| value_loss         | 47.58726    |
------------------------------------
-------------------------------------
| approxkl           | 0.012375525  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -2.38e-07    |
| fps                | 31           |
| n_updates          | 44           |
| policy_entropy     | 0.55917346   |
| policy_loss        | 0.0045944676 |
| serial_timesteps   | 5632         |
| time_elapsed       | 195          |
| total_timesteps    | 5632         |
| value_loss         | 37.370995    |
-------------------------------------
------------------------------------
| approxkl           | 0.021809522 |
| clipfrac           | 0.26953125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | 5.96e-08    |
| fps                | 30          |
| n_updates          | 45          |
| policy_entropy     | 0.5584156   |
| policy_loss        | 0.02797583  |
| serial_timesteps   | 5760        |
| time_elapsed       | 199         |
| total_timesteps    | 5760        |
| value_loss         | 36.88734    |
------------------------------------
--------------------------------------
| approxkl           | 0.022394657   |
| clipfrac           | 0.24414062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | -2.38e-07     |
| fps                | 32            |
| n_updates          | 46            |
| policy_entropy     | 0.5580433     |
| policy_loss        | -0.0063297413 |
| serial_timesteps   | 5888          |
| time_elapsed       | 203           |
| total_timesteps    | 5888          |
| value_loss         | 36.480183     |
--------------------------------------
--------------------------------------
| approxkl           | 0.04150154    |
| clipfrac           | 0.38085938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 5.96e-08      |
| fps                | 30            |
| n_updates          | 47            |
| policy_entropy     | 0.5576185     |
| policy_loss        | -0.0010562101 |
| serial_timesteps   | 6016          |
| time_elapsed       | 207           |
| total_timesteps    | 6016          |
| value_loss         | 12.039747     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0031656083 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 2.5e-06      |
| fps                | 31           |
| n_updates          | 48           |
| policy_entropy     | 0.55690515   |
| policy_loss        | 0.0027921728 |
| serial_timesteps   | 6144         |
| time_elapsed       | 211          |
| total_timesteps    | 6144         |
| value_loss         | 14.324268    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009043114  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 49           |
| policy_entropy     | 0.55666924   |
| policy_loss        | -0.015551485 |
| serial_timesteps   | 6272         |
| time_elapsed       | 215          |
| total_timesteps    | 6272         |
| value_loss         | 4259.7495    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004813217   |
| clipfrac           | 0.0625        |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | -3.58e-07     |
| fps                | 30            |
| n_updates          | 50            |
| policy_entropy     | 0.55657643    |
| policy_loss        | -0.0021080351 |
| serial_timesteps   | 6400          |
| time_elapsed       | 219           |
| total_timesteps    | 6400          |
| value_loss         | 30.262495     |
--------------------------------------
An average of 193.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.02945998   |
| clipfrac           | 0.328125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 51           |
| policy_entropy     | 0.55606574   |
| policy_loss        | -0.017453132 |
| serial_timesteps   | 6528         |
| time_elapsed       | 223          |
| total_timesteps    | 6528         |
| value_loss         | 13.4425      |
-------------------------------------
--------------------------------------
| approxkl           | 0.012746176   |
| clipfrac           | 0.19921875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 52            |
| policy_entropy     | 0.55523145    |
| policy_loss        | -0.0062202835 |
| serial_timesteps   | 6656          |
| time_elapsed       | 228           |
| total_timesteps    | 6656          |
| value_loss         | 30.480778     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0060266913 |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 53           |
| policy_entropy     | 0.5544854    |
| policy_loss        | -0.004486527 |
| serial_timesteps   | 6784         |
| time_elapsed       | 232          |
| total_timesteps    | 6784         |
| value_loss         | 29.399837    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0035275521 |
| clipfrac           | 0.041015625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 5.01e-06     |
| fps                | 32           |
| n_updates          | 54           |
| policy_entropy     | 0.5524772    |
| policy_loss        | 0.0033398885 |
| serial_timesteps   | 6912         |
| time_elapsed       | 236          |
| total_timesteps    | 6912         |
| value_loss         | 29.380161    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011581307  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -5.96e-07    |
| fps                | 32           |
| n_updates          | 55           |
| policy_entropy     | 0.5506396    |
| policy_loss        | -0.012348777 |
| serial_timesteps   | 7040         |
| time_elapsed       | 240          |
| total_timesteps    | 7040         |
| value_loss         | 33.35333     |
-------------------------------------
-------------------------------------
| approxkl           | 0.01997614   |
| clipfrac           | 0.2578125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -8.34e-07    |
| fps                | 29           |
| n_updates          | 56           |
| policy_entropy     | 0.5497396    |
| policy_loss        | 0.0018295243 |
| serial_timesteps   | 7168         |
| time_elapsed       | 244          |
| total_timesteps    | 7168         |
| value_loss         | 24.661402    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0027056113 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 57           |
| policy_entropy     | 0.54728866   |
| policy_loss        | 0.004479536  |
| serial_timesteps   | 7296         |
| time_elapsed       | 248          |
| total_timesteps    | 7296         |
| value_loss         | 30.38909     |
-------------------------------------
-------------------------------------
| approxkl           | 0.011561903  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 1.19e-07     |
| fps                | 29           |
| n_updates          | 58           |
| policy_entropy     | 0.54482865   |
| policy_loss        | -0.009163069 |
| serial_timesteps   | 7424         |
| time_elapsed       | 252          |
| total_timesteps    | 7424         |
| value_loss         | 12.105915    |
-------------------------------------
An average of 193.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.012554694   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 3.16e-06      |
| fps                | 29            |
| n_updates          | 59            |
| policy_entropy     | 0.54359716    |
| policy_loss        | -0.0033322368 |
| serial_timesteps   | 7552          |
| time_elapsed       | 257           |
| total_timesteps    | 7552          |
| value_loss         | 29.185917     |
--------------------------------------
------------------------------------
| approxkl           | 0.008187985 |
| clipfrac           | 0.0859375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | -1.43e-06   |
| fps                | 32          |
| n_updates          | 60          |
| policy_entropy     | 0.5431996   |
| policy_loss        | 0.009743938 |
| serial_timesteps   | 7680        |
| time_elapsed       | 261         |
| total_timesteps    | 7680        |
| value_loss         | 34.102303   |
------------------------------------
-------------------------------------
| approxkl           | 0.0039304425 |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 1.19e-07     |
| fps                | 32           |
| n_updates          | 61           |
| policy_entropy     | 0.5423495    |
| policy_loss        | 0.007841376  |
| serial_timesteps   | 7808         |
| time_elapsed       | 265          |
| total_timesteps    | 7808         |
| value_loss         | 4232.928     |
-------------------------------------
-------------------------------------
| approxkl           | 0.009732623  |
| clipfrac           | 0.1328125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -2.62e-06    |
| fps                | 31           |
| n_updates          | 62           |
| policy_entropy     | 0.5418589    |
| policy_loss        | -0.006907703 |
| serial_timesteps   | 7936         |
| time_elapsed       | 269          |
| total_timesteps    | 7936         |
| value_loss         | 34.881855    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0042325915  |
| clipfrac           | 0.046875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | -1.19e-07     |
| fps                | 33            |
| n_updates          | 63            |
| policy_entropy     | 0.5415491     |
| policy_loss        | -0.0030964147 |
| serial_timesteps   | 8064          |
| time_elapsed       | 273           |
| total_timesteps    | 8064          |
| value_loss         | 32.954845     |
--------------------------------------
--------------------------------------
| approxkl           | 0.005293645   |
| clipfrac           | 0.064453125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | -1.31e-06     |
| fps                | 33            |
| n_updates          | 64            |
| policy_entropy     | 0.54092234    |
| policy_loss        | -0.0025018267 |
| serial_timesteps   | 8192          |
| time_elapsed       | 277           |
| total_timesteps    | 8192          |
| value_loss         | 21.103477     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0070947283  |
| clipfrac           | 0.083984375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 6.56e-07      |
| fps                | 30            |
| n_updates          | 65            |
| policy_entropy     | 0.5401652     |
| policy_loss        | -0.0016706707 |
| serial_timesteps   | 8320          |
| time_elapsed       | 281           |
| total_timesteps    | 8320          |
| value_loss         | 10.514405     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012896907  |
| clipfrac           | 0.20703125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -1.19e-06    |
| fps                | 32           |
| n_updates          | 66           |
| policy_entropy     | 0.5393704    |
| policy_loss        | -0.009258054 |
| serial_timesteps   | 8448         |
| time_elapsed       | 285          |
| total_timesteps    | 8448         |
| value_loss         | 23.88911     |
-------------------------------------
An average of 194.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.014053133  |
| clipfrac           | 0.21289062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | -2.38e-06    |
| fps                | 31           |
| n_updates          | 67           |
| policy_entropy     | 0.5383939    |
| policy_loss        | -0.011893603 |
| serial_timesteps   | 8576         |
| time_elapsed       | 289          |
| total_timesteps    | 8576         |
| value_loss         | 18.112183    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0142223155 |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.36e+03     |
| explained_variance | 7.75e-07     |
| fps                | 31           |
| n_updates          | 68           |
| policy_entropy     | 0.53730416   |
| policy_loss        | 0.010985408  |
| serial_timesteps   | 8704         |
| time_elapsed       | 293          |
| total_timesteps    | 8704         |
| value_loss         | 29.397171    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004692479   |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.36e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 69            |
| policy_entropy     | 0.53594965    |
| policy_loss        | 0.00039977906 |
| serial_timesteps   | 8832          |
| time_elapsed       | 297           |
| total_timesteps    | 8832          |
| value_loss         | 36.444477     |
--------------------------------------
------------------------------------
| approxkl           | 0.010779984 |
| clipfrac           | 0.14453125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | 1.19e-07    |
| fps                | 30          |
| n_updates          | 70          |
| policy_entropy     | 0.534892    |
| policy_loss        | 0.006193112 |
| serial_timesteps   | 8960        |
| time_elapsed       | 301         |
| total_timesteps    | 8960        |
| value_loss         | 30.415186   |
------------------------------------
------------------------------------
| approxkl           | 0.026731241 |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | 0           |
| fps                | 30          |
| n_updates          | 71          |
| policy_entropy     | 0.5339886   |
| policy_loss        | 0.011913429 |
| serial_timesteps   | 9088        |
| time_elapsed       | 305         |
| total_timesteps    | 9088        |
| value_loss         | 29.272806   |
------------------------------------
------------------------------------
| approxkl           | 0.025735518 |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.36e+03    |
| explained_variance | 5.84e-06    |
| fps                | 31          |
| n_updates          | 72          |
| policy_entropy     | 0.53269607  |
| policy_loss        | 0.019204488 |
| serial_timesteps   | 9216        |
| time_elapsed       | 309         |
| total_timesteps    | 9216        |
| value_loss         | 18.461113   |
------------------------------------
--------------------------------------
| approxkl           | 0.0065908805  |
| clipfrac           | 0.083984375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.37e+03      |
| explained_variance | -1.19e-07     |
| fps                | 31            |
| n_updates          | 73            |
| policy_entropy     | 0.5316025     |
| policy_loss        | -0.0017406717 |
| serial_timesteps   | 9344          |
| time_elapsed       | 313           |
| total_timesteps    | 9344          |
| value_loss         | 4299.957      |
--------------------------------------
An average of 195.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.020401992  |
| clipfrac           | 0.26367188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | -5.96e-06    |
| fps                | 32           |
| n_updates          | 74           |
| policy_entropy     | 0.5311937    |
| policy_loss        | -0.007665603 |
| serial_timesteps   | 9472         |
| time_elapsed       | 317          |
| total_timesteps    | 9472         |
| value_loss         | 17.93564     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0009276081 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | -2.5e-06     |
| fps                | 32           |
| n_updates          | 75           |
| policy_entropy     | 0.531052     |
| policy_loss        | 0.00253289   |
| serial_timesteps   | 9600         |
| time_elapsed       | 321          |
| total_timesteps    | 9600         |
| value_loss         | 29.815136    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008329917  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 2.38e-07     |
| fps                | 30           |
| n_updates          | 76           |
| policy_entropy     | 0.5305834    |
| policy_loss        | -0.004991785 |
| serial_timesteps   | 9728         |
| time_elapsed       | 325          |
| total_timesteps    | 9728         |
| value_loss         | 19.48557     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0133133475 |
| clipfrac           | 0.2109375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 77           |
| policy_entropy     | 0.5298371    |
| policy_loss        | -0.016053148 |
| serial_timesteps   | 9856         |
| time_elapsed       | 330          |
| total_timesteps    | 9856         |
| value_loss         | 19.230152    |
-------------------------------------
-------------------------------------
| approxkl           | 0.029081794  |
| clipfrac           | 0.37890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | -3.58e-07    |
| fps                | 31           |
| n_updates          | 78           |
| policy_entropy     | 0.5293358    |
| policy_loss        | -0.007098903 |
| serial_timesteps   | 9984         |
| time_elapsed       | 334          |
| total_timesteps    | 9984         |
| value_loss         | 28.897776    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01781088   |
| clipfrac           | 0.2578125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 79           |
| policy_entropy     | 0.52919203   |
| policy_loss        | -0.014763604 |
| serial_timesteps   | 10112        |
| time_elapsed       | 338          |
| total_timesteps    | 10112        |
| value_loss         | 33.40553     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0036954666 |
| clipfrac           | 0.041015625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 5.96e-08     |
| fps                | 32           |
| n_updates          | 80           |
| policy_entropy     | 0.52840155   |
| policy_loss        | 0.0026365095 |
| serial_timesteps   | 10240        |
| time_elapsed       | 342          |
| total_timesteps    | 10240        |
| value_loss         | 24.818945    |
-------------------------------------
-------------------------------------
| approxkl           | 0.016683498  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 81           |
| policy_entropy     | 0.52730006   |
| policy_loss        | -0.010513106 |
| serial_timesteps   | 10368        |
| time_elapsed       | 346          |
| total_timesteps    | 10368        |
| value_loss         | 26.500122    |
-------------------------------------
An average of 195.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.0027525276   |
| clipfrac           | 0.029296875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.37e+03       |
| explained_variance | 5.96e-08       |
| fps                | 29             |
| n_updates          | 82             |
| policy_entropy     | 0.5265573      |
| policy_loss        | -0.00027681421 |
| serial_timesteps   | 10496          |
| time_elapsed       | 350            |
| total_timesteps    | 10496          |
| value_loss         | 18.775227      |
---------------------------------------
--------------------------------------
| approxkl           | 0.009221087   |
| clipfrac           | 0.14648438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.37e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 83            |
| policy_entropy     | 0.52533185    |
| policy_loss        | -0.0010572695 |
| serial_timesteps   | 10624         |
| time_elapsed       | 355           |
| total_timesteps    | 10624         |
| value_loss         | 15.266768     |
--------------------------------------
-------------------------------------
| approxkl           | 0.021467902  |
| clipfrac           | 0.26757812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 6.32e-06     |
| fps                | 32           |
| n_updates          | 84           |
| policy_entropy     | 0.5234599    |
| policy_loss        | -0.015819933 |
| serial_timesteps   | 10752        |
| time_elapsed       | 359          |
| total_timesteps    | 10752        |
| value_loss         | 21.679792    |
-------------------------------------
------------------------------------
| approxkl           | 0.05145948  |
| clipfrac           | 0.390625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.37e+03    |
| explained_variance | -1.19e-07   |
| fps                | 30          |
| n_updates          | 85          |
| policy_entropy     | 0.5226002   |
| policy_loss        | 0.046538245 |
| serial_timesteps   | 10880       |
| time_elapsed       | 363         |
| total_timesteps    | 10880       |
| value_loss         | 4426.298    |
------------------------------------
--------------------------------------
| approxkl           | 0.013617537   |
| clipfrac           | 0.18554688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.37e+03      |
| explained_variance | -1.43e-06     |
| fps                | 29            |
| n_updates          | 86            |
| policy_entropy     | 0.52232033    |
| policy_loss        | -0.0077297213 |
| serial_timesteps   | 11008         |
| time_elapsed       | 367           |
| total_timesteps    | 11008         |
| value_loss         | 11.263868     |
--------------------------------------
-------------------------------------
| approxkl           | 0.010005986  |
| clipfrac           | 0.1640625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 1.79e-07     |
| fps                | 31           |
| n_updates          | 87           |
| policy_entropy     | 0.5218218    |
| policy_loss        | -0.008600233 |
| serial_timesteps   | 11136        |
| time_elapsed       | 371          |
| total_timesteps    | 11136        |
| value_loss         | 30.289713    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0140593955   |
| clipfrac           | 0.17578125     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.37e+03       |
| explained_variance | 8.94e-07       |
| fps                | 31             |
| n_updates          | 88             |
| policy_entropy     | 0.5213264      |
| policy_loss        | -0.00029753055 |
| serial_timesteps   | 11264          |
| time_elapsed       | 375            |
| total_timesteps    | 11264          |
| value_loss         | 29.15458       |
---------------------------------------
------------------------------------
| approxkl           | 0.0347204   |
| clipfrac           | 0.32421875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.37e+03    |
| explained_variance | -4.77e-07   |
| fps                | 33          |
| n_updates          | 89          |
| policy_entropy     | 0.5200056   |
| policy_loss        | 0.026556313 |
| serial_timesteps   | 11392       |
| time_elapsed       | 379         |
| total_timesteps    | 11392       |
| value_loss         | 23.33052    |
------------------------------------
An average of 196.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.008004953  |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 1.19e-07     |
| fps                | 29           |
| n_updates          | 90           |
| policy_entropy     | 0.518744     |
| policy_loss        | -0.002753284 |
| serial_timesteps   | 11520        |
| time_elapsed       | 383          |
| total_timesteps    | 11520        |
| value_loss         | 23.07957     |
-------------------------------------
-------------------------------------
| approxkl           | 0.015032192  |
| clipfrac           | 0.19140625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 4.77e-06     |
| fps                | 32           |
| n_updates          | 91           |
| policy_entropy     | 0.5178088    |
| policy_loss        | -0.008016978 |
| serial_timesteps   | 11648        |
| time_elapsed       | 388          |
| total_timesteps    | 11648        |
| value_loss         | 25.94018     |
-------------------------------------
------------------------------------
| approxkl           | 0.014630558 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.37e+03    |
| explained_variance | 1.31e-06    |
| fps                | 30          |
| n_updates          | 92          |
| policy_entropy     | 0.5172261   |
| policy_loss        | 0.01969     |
| serial_timesteps   | 11776       |
| time_elapsed       | 392         |
| total_timesteps    | 11776       |
| value_loss         | 28.410477   |
------------------------------------
--------------------------------------
| approxkl           | 0.012047107   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.37e+03      |
| explained_variance | -3.1e-06      |
| fps                | 30            |
| n_updates          | 93            |
| policy_entropy     | 0.5166649     |
| policy_loss        | -0.0018632631 |
| serial_timesteps   | 11904         |
| time_elapsed       | 396           |
| total_timesteps    | 11904         |
| value_loss         | 28.421967     |
--------------------------------------
-----------------------------------
| approxkl           | 0.00704107 |
| clipfrac           | 0.109375   |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 6.37e+03   |
| explained_variance | -5.48e-06  |
| fps                | 31         |
| n_updates          | 94         |
| policy_entropy     | 0.5151328  |
| policy_loss        | -0.0053852 |
| serial_timesteps   | 12032      |
| time_elapsed       | 400        |
| total_timesteps    | 12032      |
| value_loss         | 23.016891  |
-----------------------------------
-------------------------------------
| approxkl           | 0.010743181  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.37e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 95           |
| policy_entropy     | 0.513673     |
| policy_loss        | 0.0068279603 |
| serial_timesteps   | 12160        |
| time_elapsed       | 404          |
| total_timesteps    | 12160        |
| value_loss         | 17.543869    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00014385741 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.37e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 96            |
| policy_entropy     | 0.51258177    |
| policy_loss        | 0.0012913651  |
| serial_timesteps   | 12288         |
| time_elapsed       | 408           |
| total_timesteps    | 12288         |
| value_loss         | 19.694117     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00040537957 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.38e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 97            |
| policy_entropy     | 0.51071787    |
| policy_loss        | -0.0016554721 |
| serial_timesteps   | 12416         |
| time_elapsed       | 412           |
| total_timesteps    | 12416         |
| value_loss         | 4435.2847     |
--------------------------------------
An average of 197.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0074847788 |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.38e+03     |
| explained_variance | 2.38e-07     |
| fps                | 30           |
| n_updates          | 98           |
| policy_entropy     | 0.5094653    |
| policy_loss        | -0.0068036   |
| serial_timesteps   | 12544        |
| time_elapsed       | 416          |
| total_timesteps    | 12544        |
| value_loss         | 23.216915    |
-------------------------------------
--------------------------------------
| approxkl           | 0.007830857   |
| clipfrac           | 0.1171875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.38e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 99            |
| policy_entropy     | 0.50855917    |
| policy_loss        | -0.0068449206 |
| serial_timesteps   | 12672         |
| time_elapsed       | 421           |
| total_timesteps    | 12672         |
| value_loss         | 13.624273     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0045343335 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.38e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 100          |
| policy_entropy     | 0.5077246    |
| policy_loss        | 0.0020605854 |
| serial_timesteps   | 12800        |
| time_elapsed       | 425          |
| total_timesteps    | 12800        |
| value_loss         | 19.061813    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008847458   |
| clipfrac           | 0.1015625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.38e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 101           |
| policy_entropy     | 0.5065475     |
| policy_loss        | -0.0061277067 |
| serial_timesteps   | 12928         |
| time_elapsed       | 429           |
| total_timesteps    | 12928         |
| value_loss         | 29.862963     |
--------------------------------------
------------------------------------
| approxkl           | 0.01688186  |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.38e+03    |
| explained_variance | 1.19e-05    |
| fps                | 29          |
| n_updates          | 102         |
| policy_entropy     | 0.50533825  |
| policy_loss        | -0.01280888 |
| serial_timesteps   | 13056       |
| time_elapsed       | 433         |
| total_timesteps    | 13056       |
| value_loss         | 10.832671   |
------------------------------------
--------------------------------------
| approxkl           | 0.00979141    |
| clipfrac           | 0.15625       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.38e+03      |
| explained_variance | 2.38e-07      |
| fps                | 33            |
| n_updates          | 103           |
| policy_entropy     | 0.5039531     |
| policy_loss        | -0.0021732333 |
| serial_timesteps   | 13184         |
| time_elapsed       | 437           |
| total_timesteps    | 13184         |
| value_loss         | 24.518145     |
--------------------------------------
-------------------------------------
| approxkl           | 0.022751935  |
| clipfrac           | 0.3046875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.38e+03     |
| explained_variance | -7.39e-06    |
| fps                | 32           |
| n_updates          | 104          |
| policy_entropy     | 0.5028899    |
| policy_loss        | -0.010473211 |
| serial_timesteps   | 13312        |
| time_elapsed       | 441          |
| total_timesteps    | 13312        |
| value_loss         | 23.161102    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009931056  |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.38e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 105          |
| policy_entropy     | 0.50035155   |
| policy_loss        | -0.009069676 |
| serial_timesteps   | 13440        |
| time_elapsed       | 445          |
| total_timesteps    | 13440        |
| value_loss         | 19.118406    |
-------------------------------------
An average of 197.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00040348864 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.38e+03      |
| explained_variance | 0             |
| fps                | 31            |
| n_updates          | 106           |
| policy_entropy     | 0.49840966    |
| policy_loss        | -0.0014312981 |
| serial_timesteps   | 13568         |
| time_elapsed       | 449           |
| total_timesteps    | 13568         |
| value_loss         | 27.364092     |
--------------------------------------
------------------------------------
| approxkl           | 0.007813075 |
| clipfrac           | 0.111328125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.38e+03    |
| explained_variance | -3.58e-07   |
| fps                | 31          |
| n_updates          | 107         |
| policy_entropy     | 0.49749425  |
| policy_loss        | 0.01579088  |
| serial_timesteps   | 13696       |
| time_elapsed       | 453         |
| total_timesteps    | 13696       |
| value_loss         | 21.572601   |
------------------------------------
---------------------------------------
| approxkl           | 0.0025932982   |
| clipfrac           | 0.029296875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.38e+03       |
| explained_variance | 0              |
| fps                | 32             |
| n_updates          | 108            |
| policy_entropy     | 0.49697182     |
| policy_loss        | -0.00021993555 |
| serial_timesteps   | 13824          |
| time_elapsed       | 457            |
| total_timesteps    | 13824          |
| value_loss         | 18.07007       |
---------------------------------------
-------------------------------------
| approxkl           | 0.00606097   |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.39e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 109          |
| policy_entropy     | 0.49596632   |
| policy_loss        | -0.013625893 |
| serial_timesteps   | 13952        |
| time_elapsed       | 461          |
| total_timesteps    | 13952        |
| value_loss         | 4558.625     |
-------------------------------------
--------------------------------------
| approxkl           | 0.010845983   |
| clipfrac           | 0.16796875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.39e+03      |
| explained_variance | -3.58e-07     |
| fps                | 30            |
| n_updates          | 110           |
| policy_entropy     | 0.4953325     |
| policy_loss        | -0.0027246892 |
| serial_timesteps   | 14080         |
| time_elapsed       | 465           |
| total_timesteps    | 14080         |
| value_loss         | 18.704102     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01695202   |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.39e+03     |
| explained_variance | 9.54e-07     |
| fps                | 30           |
| n_updates          | 111          |
| policy_entropy     | 0.4948357    |
| policy_loss        | -0.009884263 |
| serial_timesteps   | 14208        |
| time_elapsed       | 470          |
| total_timesteps    | 14208        |
| value_loss         | 21.675203    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015066285  |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.39e+03     |
| explained_variance | -9.54e-07    |
| fps                | 31           |
| n_updates          | 112          |
| policy_entropy     | 0.49324453   |
| policy_loss        | -0.001408458 |
| serial_timesteps   | 14336        |
| time_elapsed       | 474          |
| total_timesteps    | 14336        |
| value_loss         | 9.971611     |
-------------------------------------
An average of 198.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.010475412 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.39e+03    |
| explained_variance | -1.19e-07   |
| fps                | 30          |
| n_updates          | 113         |
| policy_entropy     | 0.49120423  |
| policy_loss        | 0.010029928 |
| serial_timesteps   | 14464       |
| time_elapsed       | 478         |
| total_timesteps    | 14464       |
| value_loss         | 21.56036    |
------------------------------------
--------------------------------------
| approxkl           | 0.005189897   |
| clipfrac           | 0.068359375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.39e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 114           |
| policy_entropy     | 0.4898435     |
| policy_loss        | -0.0018608351 |
| serial_timesteps   | 14592         |
| time_elapsed       | 482           |
| total_timesteps    | 14592         |
| value_loss         | 23.198114     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0054981224 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.39e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 115          |
| policy_entropy     | 0.4886233    |
| policy_loss        | 0.00423068   |
| serial_timesteps   | 14720        |
| time_elapsed       | 486          |
| total_timesteps    | 14720        |
| value_loss         | 21.126884    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0012396682 |
| clipfrac           | 0.009765625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.39e+03     |
| explained_variance | 1.37e-06     |
| fps                | 30           |
| n_updates          | 116          |
| policy_entropy     | 0.487196     |
| policy_loss        | 0.0038187904 |
| serial_timesteps   | 14848        |
| time_elapsed       | 491          |
| total_timesteps    | 14848        |
| value_loss         | 22.926174    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010572152  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.39e+03     |
| explained_variance | -2.38e-07    |
| fps                | 30           |
| n_updates          | 117          |
| policy_entropy     | 0.4849541    |
| policy_loss        | -0.008668567 |
| serial_timesteps   | 14976        |
| time_elapsed       | 495          |
| total_timesteps    | 14976        |
| value_loss         | 26.003412    |
-------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b4e167400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b4e167400>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b4d2a3cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b4d2a3cf8>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2807 samples, validate on 336 samples
Epoch 382/5000
 - 7s - loss: 0.4116 - val_loss: 0.4652
Epoch 383/5000
 - 1s - loss: 0.4116 - val_loss: 0.4652
Epoch 384/5000
 - 1s - loss: 0.4116 - val_loss: 0.4652
Epoch 385/5000
 - 1s - loss: 0.4116 - val_loss: 0.4652
Epoch 386/5000
 - 1s - loss: 0.4116 - val_loss: 0.4652
Epoch 387/5000
 - 1s - loss: 0.4116 - val_loss: 0.4652
Train on 1742 samples, validate on 336 samples
Epoch 286/5000
 - 7s - loss: 0.0052 - val_loss: 0.0047
Epoch 287/5000
 - 1s - loss: 0.0052 - val_loss: 0.0047
Epoch 288/5000
 - 0s - loss: 0.0052 - val_loss: 0.0047
Epoch 289/5000
 - 0s - loss: 0.0052 - val_loss: 0.0047
Epoch 290/5000
 - 0s - loss: 0.0052 - val_loss: 0.0047
Epoch 291/5000
 - 1s - loss: 0.0052 - val_loss: 0.0047
Train on 2807 samples, validate on 336 samples
Epoch 875/5000
 - 8s - loss: 0.6827 - val_loss: 0.6539
Epoch 876/5000
 - 1s - loss: 0.6630 - val_loss: 0.6296
Epoch 877/5000
 - 1s - loss: 0.6562 - val_loss: 0.6218
Epoch 878/5000
 - 1s - loss: 0.6527 - val_loss: 0.6169
Epoch 879/5000
 - 1s - loss: 0.6484 - val_loss: 0.6092
Epoch 880/5000
 - 1s - loss: 0.6411 - val_loss: 0.5892
Epoch 881/5000
 - 1s - loss: 0.6254 - val_loss: 0.5636
Epoch 882/5000
 - 1s - loss: 0.6065 - val_loss: 0.5565
Epoch 883/5000
 - 1s - loss: 0.5954 - val_loss: 0.5570
Epoch 884/5000
 - 1s - loss: 0.5881 - val_loss: 0.5477
Epoch 885/5000
 - 1s - loss: 0.5797 - val_loss: 0.5422
Epoch 886/5000
 - 1s - loss: 0.5727 - val_loss: 0.5292
Epoch 887/5000
 - 1s - loss: 0.5680 - val_loss: 0.5195
Epoch 888/5000
 - 1s - loss: 0.5642 - val_loss: 0.5140
Epoch 889/5000
 - 1s - loss: 0.5614 - val_loss: 0.5096
Epoch 890/5000
 - 1s - loss: 0.5577 - val_loss: 0.5030
Epoch 891/5000
 - 1s - loss: 0.5549 - val_loss: 0.4982
Epoch 892/5000
 - 1s - loss: 0.5521 - val_loss: 0.4932
Epoch 893/5000
 - 1s - loss: 0.5497 - val_loss: 0.4897
Epoch 894/5000
 - 1s - loss: 0.5471 - val_loss: 0.4851
Epoch 895/5000
 - 1s - loss: 0.5449 - val_loss: 0.4817
Epoch 896/5000
 - 1s - loss: 0.5431 - val_loss: 0.4801
Epoch 897/5000
 - 1s - loss: 0.5407 - val_loss: 0.4759
Epoch 898/5000
 - 1s - loss: 0.5384 - val_loss: 0.4719
Epoch 899/5000
 - 1s - loss: 0.5365 - val_loss: 0.4693
Epoch 900/5000
 - 1s - loss: 0.5344 - val_loss: 0.4664
Epoch 901/5000
 - 1s - loss: 0.5328 - val_loss: 0.4644
Epoch 902/5000
 - 1s - loss: 0.5302 - val_loss: 0.4611
Epoch 903/5000
 - 1s - loss: 0.5284 - val_loss: 0.4585
Epoch 904/5000
 - 1s - loss: 0.5266 - val_loss: 0.4566
Epoch 905/5000
 - 1s - loss: 0.5248 - val_loss: 0.4539
Epoch 906/5000
 - 1s - loss: 0.5233 - val_loss: 0.4528
Epoch 907/5000
 - 1s - loss: 0.5208 - val_loss: 0.4502
Epoch 908/5000
 - 1s - loss: 0.5185 - val_loss: 0.4473
Epoch 909/5000
 - 1s - loss: 0.5165 - val_loss: 0.4447
Epoch 910/5000
 - 1s - loss: 0.5152 - val_loss: 0.4432
Epoch 911/5000
 - 1s - loss: 0.5136 - val_loss: 0.4416
Epoch 912/5000
 - 1s - loss: 0.5104 - val_loss: 0.4379
Epoch 913/5000
 - 1s - loss: 0.5082 - val_loss: 0.4353
Epoch 914/5000
 - 1s - loss: 0.5065 - val_loss: 0.4341
Epoch 915/5000
 - 1s - loss: 0.5042 - val_loss: 0.4315
Epoch 916/5000
 - 1s - loss: 0.5011 - val_loss: 0.4280
Epoch 917/5000
 - 1s - loss: 0.4980 - val_loss: 0.4233
Epoch 918/5000
 - 1s - loss: 0.4945 - val_loss: 0.4186
Epoch 919/5000
 - 1s - loss: 0.4914 - val_loss: 0.4150
Epoch 920/5000
 - 1s - loss: 0.4884 - val_loss: 0.4102
Epoch 921/5000
 - 1s - loss: 0.4853 - val_loss: 0.4063
Epoch 922/5000
 - 1s - loss: 0.4818 - val_loss: 0.4014
Epoch 923/5000
 - 1s - loss: 0.4782 - val_loss: 0.3972
Epoch 924/5000
 - 1s - loss: 0.4742 - val_loss: 0.3928
Epoch 925/5000
 - 1s - loss: 0.4708 - val_loss: 0.3889
Epoch 926/5000
 - 1s - loss: 0.4675 - val_loss: 0.3862
Epoch 927/5000
 - 1s - loss: 0.4645 - val_loss: 0.3829
Epoch 928/5000
 - 1s - loss: 0.4614 - val_loss: 0.3804
Epoch 929/5000
 - 1s - loss: 0.4579 - val_loss: 0.3765
Epoch 930/5000
 - 1s - loss: 0.4549 - val_loss: 0.3726
Epoch 931/5000
 - 1s - loss: 0.4521 - val_loss: 0.3692
Epoch 932/5000
 - 1s - loss: 0.4501 - val_loss: 0.3666
Epoch 933/5000
 - 1s - loss: 0.4488 - val_loss: 0.3657
Epoch 934/5000
 - 1s - loss: 0.4476 - val_loss: 0.3646
Epoch 935/5000
 - 1s - loss: 0.4465 - val_loss: 0.3645
Epoch 936/5000
 - 1s - loss: 0.4433 - val_loss: 0.3607
Epoch 937/5000
 - 1s - loss: 0.4404 - val_loss: 0.3578
Epoch 938/5000
 - 1s - loss: 0.4381 - val_loss: 0.3558
Epoch 939/5000
 - 1s - loss: 0.4358 - val_loss: 0.3544
Epoch 940/5000
 - 1s - loss: 0.4334 - val_loss: 0.3525
Epoch 941/5000
 - 1s - loss: 0.4310 - val_loss: 0.3503
Epoch 942/5000
 - 1s - loss: 0.4283 - val_loss: 0.3467
Epoch 943/5000
 - 1s - loss: 0.4281 - val_loss: 0.3454
Epoch 944/5000
 - 1s - loss: 0.4278 - val_loss: 0.3434
Epoch 945/5000
 - 1s - loss: 0.4262 - val_loss: 0.3406
Epoch 946/5000
 - 1s - loss: 0.4251 - val_loss: 0.3389
Epoch 947/5000
 - 1s - loss: 0.4232 - val_loss: 0.3381
Epoch 948/5000
 - 1s - loss: 0.4216 - val_loss: 0.3378
Epoch 949/5000
 - 1s - loss: 0.4198 - val_loss: 0.3360
Epoch 950/5000
 - 1s - loss: 0.4179 - val_loss: 0.3358
Epoch 951/5000
 - 1s - loss: 0.4167 - val_loss: 0.3348
Epoch 952/5000
 - 1s - loss: 0.4150 - val_loss: 0.3292
Epoch 953/5000
 - 1s - loss: 0.4150 - val_loss: 0.3310
Epoch 954/5000
 - 1s - loss: 0.4161 - val_loss: 0.3328
Epoch 955/5000
 - 1s - loss: 0.3910 - val_loss: 0.3241
Epoch 956/5000
 - 1s - loss: 0.3881 - val_loss: 0.3198
Epoch 957/5000
 - 1s - loss: 0.3865 - val_loss: 0.3170
Epoch 958/5000
 - 1s - loss: 0.3852 - val_loss: 0.3158
Epoch 959/5000
 - 1s - loss: 0.3843 - val_loss: 0.3152
Epoch 960/5000
 - 1s - loss: 0.3838 - val_loss: 0.3150
Epoch 961/5000
 - 1s - loss: 0.3836 - val_loss: 0.3150
Epoch 962/5000
 - 1s - loss: 0.3833 - val_loss: 0.3152
Epoch 963/5000
 - 1s - loss: 0.3769 - val_loss: 0.3149
Epoch 964/5000
 - 1s - loss: 0.3768 - val_loss: 0.3147
Epoch 965/5000
 - 1s - loss: 0.3767 - val_loss: 0.3144
Epoch 966/5000
 - 1s - loss: 0.3766 - val_loss: 0.3142
Epoch 967/5000
 - 1s - loss: 0.3765 - val_loss: 0.3139
Epoch 968/5000
 - 1s - loss: 0.3764 - val_loss: 0.3137
Epoch 969/5000
 - 1s - loss: 0.3763 - val_loss: 0.3135
Epoch 970/5000
 - 1s - loss: 0.3762 - val_loss: 0.3133
Epoch 971/5000
 - 1s - loss: 0.3762 - val_loss: 0.3132
Epoch 972/5000
 - 1s - loss: 0.3761 - val_loss: 0.3130
Epoch 973/5000
 - 1s - loss: 0.3760 - val_loss: 0.3128
Epoch 974/5000
 - 1s - loss: 0.3760 - val_loss: 0.3127
Epoch 975/5000
 - 1s - loss: 0.3759 - val_loss: 0.3125
Epoch 976/5000
 - 1s - loss: 0.3758 - val_loss: 0.3124
Epoch 977/5000
 - 1s - loss: 0.3758 - val_loss: 0.3122
Epoch 978/5000
 - 1s - loss: 0.3757 - val_loss: 0.3121
Epoch 979/5000
 - 1s - loss: 0.3757 - val_loss: 0.3120
Epoch 980/5000
 - 1s - loss: 0.3756 - val_loss: 0.3118
Epoch 981/5000
 - 1s - loss: 0.3756 - val_loss: 0.3117
Epoch 982/5000
 - 1s - loss: 0.3755 - val_loss: 0.3115
Epoch 983/5000
 - 1s - loss: 0.3755 - val_loss: 0.3114
Epoch 984/5000
 - 1s - loss: 0.3754 - val_loss: 0.3113
Epoch 985/5000
 - 1s - loss: 0.3754 - val_loss: 0.3111
Epoch 986/5000
 - 1s - loss: 0.3753 - val_loss: 0.3110
Epoch 987/5000
 - 1s - loss: 0.3753 - val_loss: 0.3109
Epoch 988/5000
 - 1s - loss: 0.3752 - val_loss: 0.3109
Epoch 989/5000
 - 1s - loss: 0.3752 - val_loss: 0.3108
Epoch 990/5000
 - 1s - loss: 0.3752 - val_loss: 0.3107
Epoch 991/5000
 - 1s - loss: 0.3751 - val_loss: 0.3107
Epoch 992/5000
 - 1s - loss: 0.3751 - val_loss: 0.3106
Epoch 993/5000
 - 1s - loss: 0.3750 - val_loss: 0.3105
Epoch 994/5000
 - 1s - loss: 0.3750 - val_loss: 0.3105
Epoch 995/5000
 - 1s - loss: 0.3750 - val_loss: 0.3104
Epoch 996/5000
 - 1s - loss: 0.3749 - val_loss: 0.3104
Epoch 997/5000
 - 1s - loss: 0.3749 - val_loss: 0.3103
Epoch 998/5000
 - 1s - loss: 0.3749 - val_loss: 0.3103
Epoch 999/5000
 - 1s - loss: 0.3742 - val_loss: 0.3103
Epoch 1000/5000
 - 1s - loss: 0.3742 - val_loss: 0.3103
Epoch 1001/5000
 - 1s - loss: 0.3742 - val_loss: 0.3103
Epoch 1002/5000
 - 1s - loss: 0.3742 - val_loss: 0.3103
Epoch 1003/5000
 - 1s - loss: 0.3742 - val_loss: 0.3103
Epoch 1004/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1005/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1006/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1007/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1008/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1009/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1010/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1011/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
Epoch 1012/5000
 - 1s - loss: 0.3741 - val_loss: 0.3103
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.009690579 |
| clipfrac           | 0.13671875  |
| explained_variance | 0           |
| fps                | 5           |
| n_updates          | 1           |
| policy_entropy     | 0.48308134  |
| policy_loss        | 0.008675965 |
| serial_timesteps   | 128         |
| time_elapsed       | 1.29e-05    |
| total_timesteps    | 128         |
| value_loss         | 23.632805   |
------------------------------------
--------------------------------------
| approxkl           | 0.003497884   |
| clipfrac           | 0.0390625     |
| explained_variance | -2.86e-06     |
| fps                | 29            |
| n_updates          | 2             |
| policy_entropy     | 0.48178482    |
| policy_loss        | -0.0007251672 |
| serial_timesteps   | 256           |
| time_elapsed       | 24.3          |
| total_timesteps    | 256           |
| value_loss         | 23.025843     |
--------------------------------------
-------------------------------------
| approxkl           | 0.004079972  |
| clipfrac           | 0.048828125  |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 3            |
| policy_entropy     | 0.48060644   |
| policy_loss        | 0.0034774656 |
| serial_timesteps   | 384          |
| time_elapsed       | 28.7         |
| total_timesteps    | 384          |
| value_loss         | 22.33034     |
-------------------------------------
An average of 199.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.007967038  |
| clipfrac           | 0.107421875  |
| explained_variance | -2.38e-07    |
| fps                | 27           |
| n_updates          | 4            |
| policy_entropy     | 0.4793291    |
| policy_loss        | 0.0019769866 |
| serial_timesteps   | 512          |
| time_elapsed       | 32.7         |
| total_timesteps    | 512          |
| value_loss         | 25.816162    |
-------------------------------------
-------------------------------------
| approxkl           | 0.013545953  |
| clipfrac           | 0.17773438   |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 5            |
| policy_entropy     | 0.47705176   |
| policy_loss        | -0.006592237 |
| serial_timesteps   | 640          |
| time_elapsed       | 37.3         |
| total_timesteps    | 640          |
| value_loss         | 14.066452    |
-------------------------------------
--------------------------------------
| approxkl           | 0.01228391    |
| clipfrac           | 0.17773438    |
| explained_variance | -1.07e-06     |
| fps                | 29            |
| n_updates          | 6             |
| policy_entropy     | 0.47508806    |
| policy_loss        | -0.0017838215 |
| serial_timesteps   | 768           |
| time_elapsed       | 41.6          |
| total_timesteps    | 768           |
| value_loss         | 13.74454      |
--------------------------------------
------------------------------------
| approxkl           | 0.012220669 |
| clipfrac           | 0.16210938  |
| explained_variance | 0           |
| fps                | 28          |
| n_updates          | 7           |
| policy_entropy     | 0.47365364  |
| policy_loss        | 0.008586438 |
| serial_timesteps   | 896         |
| time_elapsed       | 46          |
| total_timesteps    | 896         |
| value_loss         | 13.655906   |
------------------------------------
-------------------------------------
| approxkl           | 0.013133972  |
| clipfrac           | 0.18945312   |
| explained_variance | -7.15e-07    |
| fps                | 8            |
| n_updates          | 8            |
| policy_entropy     | 0.47250718   |
| policy_loss        | -0.016444549 |
| serial_timesteps   | 1024         |
| time_elapsed       | 50.4         |
| total_timesteps    | 1024         |
| value_loss         | 10.229355    |
-------------------------------------
-------------------------------------
| approxkl           | 0.029663475  |
| clipfrac           | 0.32226562   |
| explained_variance | 4.17e-07     |
| fps                | 31           |
| n_updates          | 9            |
| policy_entropy     | 0.47105482   |
| policy_loss        | -0.019824047 |
| serial_timesteps   | 1152         |
| time_elapsed       | 64.9         |
| total_timesteps    | 1152         |
| value_loss         | 7.9644628    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009112254  |
| clipfrac           | 0.15039062   |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 10           |
| policy_entropy     | 0.4699549    |
| policy_loss        | -0.007338565 |
| serial_timesteps   | 1280         |
| time_elapsed       | 68.9         |
| total_timesteps    | 1280         |
| value_loss         | 14.52423     |
-------------------------------------
------------------------------------
| approxkl           | 0.022809766 |
| clipfrac           | 0.265625    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 11          |
| policy_entropy     | 0.46885127  |
| policy_loss        | 0.003144617 |
| serial_timesteps   | 1408        |
| time_elapsed       | 73          |
| total_timesteps    | 1408        |
| value_loss         | 25.010553   |
------------------------------------
An average of 199.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.012823881  |
| clipfrac           | 0.16992188   |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 12           |
| policy_entropy     | 0.4678759    |
| policy_loss        | -0.008450552 |
| serial_timesteps   | 1536         |
| time_elapsed       | 77.3         |
| total_timesteps    | 1536         |
| value_loss         | 13.634607    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03174322   |
| clipfrac           | 0.26367188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 13           |
| policy_entropy     | 0.4652323    |
| policy_loss        | -0.005630971 |
| serial_timesteps   | 1664         |
| time_elapsed       | 81.7         |
| total_timesteps    | 1664         |
| value_loss         | 2988.4546    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023179494  |
| clipfrac           | 0.25390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 14           |
| policy_entropy     | 0.4636526    |
| policy_loss        | -0.012184501 |
| serial_timesteps   | 1792         |
| time_elapsed       | 85.8         |
| total_timesteps    | 1792         |
| value_loss         | 11.950728    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0028882993 |
| clipfrac           | 0.029296875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | 7.15e-07     |
| fps                | 29           |
| n_updates          | 15           |
| policy_entropy     | 0.4628958    |
| policy_loss        | -0.002933994 |
| serial_timesteps   | 1920         |
| time_elapsed       | 90.2         |
| total_timesteps    | 1920         |
| value_loss         | 24.55682     |
-------------------------------------
-------------------------------------
| approxkl           | 0.016719487  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | -9.54e-07    |
| fps                | 30           |
| n_updates          | 16           |
| policy_entropy     | 0.46081996   |
| policy_loss        | -0.002804053 |
| serial_timesteps   | 2048         |
| time_elapsed       | 94.5         |
| total_timesteps    | 2048         |
| value_loss         | 11.3213415   |
-------------------------------------
-------------------------------------
| approxkl           | 0.07172208   |
| clipfrac           | 0.49414062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | -6.2e-06     |
| fps                | 32           |
| n_updates          | 17           |
| policy_entropy     | 0.4588419    |
| policy_loss        | -0.036471136 |
| serial_timesteps   | 2176         |
| time_elapsed       | 98.8         |
| total_timesteps    | 2176         |
| value_loss         | 8.034648     |
-------------------------------------
-------------------------------------
| approxkl           | 0.015271784  |
| clipfrac           | 0.18164062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | -5.84e-06    |
| fps                | 31           |
| n_updates          | 18           |
| policy_entropy     | 0.4583332    |
| policy_loss        | 0.0033342033 |
| serial_timesteps   | 2304         |
| time_elapsed       | 103          |
| total_timesteps    | 2304         |
| value_loss         | 12.285866    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010056464  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | 1.79e-07     |
| fps                | 30           |
| n_updates          | 19           |
| policy_entropy     | 0.45774993   |
| policy_loss        | 0.0133523755 |
| serial_timesteps   | 2432         |
| time_elapsed       | 107          |
| total_timesteps    | 2432         |
| value_loss         | 15.679622    |
-------------------------------------
An average of 200.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0007873696 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | -4.77e-07    |
| fps                | 30           |
| n_updates          | 20           |
| policy_entropy     | 0.4567783    |
| policy_loss        | 0.0014026957 |
| serial_timesteps   | 2560         |
| time_elapsed       | 111          |
| total_timesteps    | 2560         |
| value_loss         | 13.829263    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006180531  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | -2.38e-07    |
| fps                | 28           |
| n_updates          | 21           |
| policy_entropy     | 0.45593187   |
| policy_loss        | 0.0012011228 |
| serial_timesteps   | 2688         |
| time_elapsed       | 115          |
| total_timesteps    | 2688         |
| value_loss         | 17.79538     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0015733752  |
| clipfrac           | 0.00390625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.43e+03      |
| explained_variance | -2.86e-06     |
| fps                | 30            |
| n_updates          | 22            |
| policy_entropy     | 0.4540527     |
| policy_loss        | -0.0010416604 |
| serial_timesteps   | 2816          |
| time_elapsed       | 120           |
| total_timesteps    | 2816          |
| value_loss         | 19.484175     |
--------------------------------------
------------------------------------
| approxkl           | 0.009486821 |
| clipfrac           | 0.13671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.43e+03    |
| explained_variance | -4.77e-07   |
| fps                | 29          |
| n_updates          | 23          |
| policy_entropy     | 0.45217934  |
| policy_loss        | 0.010427442 |
| serial_timesteps   | 2944        |
| time_elapsed       | 124         |
| total_timesteps    | 2944        |
| value_loss         | 23.605457   |
------------------------------------
-------------------------------------
| approxkl           | 0.0106952945 |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.43e+03     |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 24           |
| policy_entropy     | 0.45069343   |
| policy_loss        | 0.009991737  |
| serial_timesteps   | 3072         |
| time_elapsed       | 128          |
| total_timesteps    | 3072         |
| value_loss         | 10.890558    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006184357  |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 25           |
| policy_entropy     | 0.44940037   |
| policy_loss        | 0.0028954358 |
| serial_timesteps   | 3200         |
| time_elapsed       | 133          |
| total_timesteps    | 3200         |
| value_loss         | 4124.1187    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0058165006  |
| clipfrac           | 0.087890625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.44e+03      |
| explained_variance | 4.77e-07      |
| fps                | 30            |
| n_updates          | 26            |
| policy_entropy     | 0.44883865    |
| policy_loss        | -0.0070957188 |
| serial_timesteps   | 3328          |
| time_elapsed       | 137           |
| total_timesteps    | 3328          |
| value_loss         | 16.492756     |
--------------------------------------
--------------------------------------
| approxkl           | 0.010338116   |
| clipfrac           | 0.1484375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.44e+03      |
| explained_variance | 1.67e-06      |
| fps                | 32            |
| n_updates          | 27            |
| policy_entropy     | 0.44827133    |
| policy_loss        | -0.0046744784 |
| serial_timesteps   | 3456          |
| time_elapsed       | 141           |
| total_timesteps    | 3456          |
| value_loss         | 8.192879      |
--------------------------------------
An average of 201.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.010437643  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | -1.31e-06    |
| fps                | 30           |
| n_updates          | 28           |
| policy_entropy     | 0.4465389    |
| policy_loss        | 0.0033123712 |
| serial_timesteps   | 3584         |
| time_elapsed       | 145          |
| total_timesteps    | 3584         |
| value_loss         | 8.4951935    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0047770077 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | -2.38e-07    |
| fps                | 29           |
| n_updates          | 29           |
| policy_entropy     | 0.4449507    |
| policy_loss        | -0.002787579 |
| serial_timesteps   | 3712         |
| time_elapsed       | 149          |
| total_timesteps    | 3712         |
| value_loss         | 22.168282    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0020986954  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.44e+03      |
| explained_variance | 0             |
| fps                | 32            |
| n_updates          | 30            |
| policy_entropy     | 0.44367528    |
| policy_loss        | -0.0008981748 |
| serial_timesteps   | 3840          |
| time_elapsed       | 154           |
| total_timesteps    | 3840          |
| value_loss         | 14.522277     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011139878  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | -1.07e-06    |
| fps                | 30           |
| n_updates          | 31           |
| policy_entropy     | 0.4418977    |
| policy_loss        | -0.004790061 |
| serial_timesteps   | 3968         |
| time_elapsed       | 158          |
| total_timesteps    | 3968         |
| value_loss         | 22.032154    |
-------------------------------------
-------------------------------------
| approxkl           | 0.012982784  |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 32           |
| policy_entropy     | 0.44043073   |
| policy_loss        | -0.006744536 |
| serial_timesteps   | 4096         |
| time_elapsed       | 162          |
| total_timesteps    | 4096         |
| value_loss         | 20.4586      |
-------------------------------------
-------------------------------------
| approxkl           | 0.003316701  |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | -2.62e-06    |
| fps                | 30           |
| n_updates          | 33           |
| policy_entropy     | 0.43948027   |
| policy_loss        | 0.0055471254 |
| serial_timesteps   | 4224         |
| time_elapsed       | 166          |
| total_timesteps    | 4224         |
| value_loss         | 20.343792    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007835451  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | 4.17e-07     |
| fps                | 28           |
| n_updates          | 34           |
| policy_entropy     | 0.43829143   |
| policy_loss        | 0.0060284864 |
| serial_timesteps   | 4352         |
| time_elapsed       | 170          |
| total_timesteps    | 4352         |
| value_loss         | 21.804546    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015359706  |
| clipfrac           | 0.2109375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | -5.72e-06    |
| fps                | 29           |
| n_updates          | 35           |
| policy_entropy     | 0.43608114   |
| policy_loss        | -0.011301862 |
| serial_timesteps   | 4480         |
| time_elapsed       | 175          |
| total_timesteps    | 4480         |
| value_loss         | 15.974725    |
-------------------------------------
An average of 201.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.003980848  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.44e+03     |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 36           |
| policy_entropy     | 0.43429452   |
| policy_loss        | 0.0015072773 |
| serial_timesteps   | 4608         |
| time_elapsed       | 179          |
| total_timesteps    | 4608         |
| value_loss         | 18.033924    |
-------------------------------------
------------------------------------
| approxkl           | 0.07857943  |
| clipfrac           | 0.51171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.46e+03    |
| explained_variance | -2.38e-07   |
| fps                | 29          |
| n_updates          | 37          |
| policy_entropy     | 0.43349227  |
| policy_loss        | 0.013277508 |
| serial_timesteps   | 4736        |
| time_elapsed       | 183         |
| total_timesteps    | 4736        |
| value_loss         | 4610.8037   |
------------------------------------
-------------------------------------
| approxkl           | 0.0010588472 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.46e+03     |
| explained_variance | -1.19e-07    |
| fps                | 31           |
| n_updates          | 38           |
| policy_entropy     | 0.43302178   |
| policy_loss        | 0.000829746  |
| serial_timesteps   | 4864         |
| time_elapsed       | 188          |
| total_timesteps    | 4864         |
| value_loss         | 11.324943    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006571227   |
| clipfrac           | 0.099609375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.46e+03      |
| explained_variance | -1.31e-06     |
| fps                | 29            |
| n_updates          | 39            |
| policy_entropy     | 0.43195075    |
| policy_loss        | -0.0045329416 |
| serial_timesteps   | 4992          |
| time_elapsed       | 192           |
| total_timesteps    | 4992          |
| value_loss         | 13.370662     |
--------------------------------------
-------------------------------------
| approxkl           | 0.013441971  |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.46e+03     |
| explained_variance | -2.38e-07    |
| fps                | 29           |
| n_updates          | 40           |
| policy_entropy     | 0.43068838   |
| policy_loss        | -0.009803329 |
| serial_timesteps   | 5120         |
| time_elapsed       | 196          |
| total_timesteps    | 5120         |
| value_loss         | 15.921915    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0047636246  |
| clipfrac           | 0.060546875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.46e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 41            |
| policy_entropy     | 0.42970473    |
| policy_loss        | -0.0012837279 |
| serial_timesteps   | 5248          |
| time_elapsed       | 200           |
| total_timesteps    | 5248          |
| value_loss         | 13.889525     |
--------------------------------------
------------------------------------
| approxkl           | 0.012853976 |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.46e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 42          |
| policy_entropy     | 0.42859885  |
| policy_loss        | 0.009246071 |
| serial_timesteps   | 5376        |
| time_elapsed       | 205         |
| total_timesteps    | 5376        |
| value_loss         | 14.1030245  |
------------------------------------
An average of 202.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0062079625 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.46e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 43           |
| policy_entropy     | 0.42699194   |
| policy_loss        | 0.0054101706 |
| serial_timesteps   | 5504         |
| time_elapsed       | 209          |
| total_timesteps    | 5504         |
| value_loss         | 10.412193    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006232372  |
| clipfrac           | 0.103515625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.46e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 44           |
| policy_entropy     | 0.42575708   |
| policy_loss        | -0.004840766 |
| serial_timesteps   | 5632         |
| time_elapsed       | 213          |
| total_timesteps    | 5632         |
| value_loss         | 12.544056    |
-------------------------------------
------------------------------------
| approxkl           | 0.023753637 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.46e+03    |
| explained_variance | 6.56e-07    |
| fps                | 30          |
| n_updates          | 45          |
| policy_entropy     | 0.4252015   |
| policy_loss        | -0.02083725 |
| serial_timesteps   | 5760        |
| time_elapsed       | 217         |
| total_timesteps    | 5760        |
| value_loss         | 7.4337115   |
------------------------------------
-------------------------------------
| approxkl           | 0.019433616  |
| clipfrac           | 0.22265625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.46e+03     |
| explained_variance | -1.55e-06    |
| fps                | 28           |
| n_updates          | 46           |
| policy_entropy     | 0.4249576    |
| policy_loss        | -0.004416806 |
| serial_timesteps   | 5888         |
| time_elapsed       | 222          |
| total_timesteps    | 5888         |
| value_loss         | 17.305845    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0027956744 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.46e+03     |
| explained_variance | 3.4e-06      |
| fps                | 29           |
| n_updates          | 47           |
| policy_entropy     | 0.42406896   |
| policy_loss        | 0.0016426293 |
| serial_timesteps   | 6016         |
| time_elapsed       | 226          |
| total_timesteps    | 6016         |
| value_loss         | 12.760149    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005709943   |
| clipfrac           | 0.08203125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.46e+03      |
| explained_variance | 2.98e-07      |
| fps                | 31            |
| n_updates          | 48            |
| policy_entropy     | 0.4226892     |
| policy_loss        | -0.0008053129 |
| serial_timesteps   | 6144          |
| time_elapsed       | 231           |
| total_timesteps    | 6144          |
| value_loss         | 20.321081     |
--------------------------------------
------------------------------------
| approxkl           | 0.015367984 |
| clipfrac           | 0.203125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.47e+03    |
| explained_variance | 0           |
| fps                | 33          |
| n_updates          | 49          |
| policy_entropy     | 0.42126873  |
| policy_loss        | 0.035485435 |
| serial_timesteps   | 6272        |
| time_elapsed       | 235         |
| total_timesteps    | 6272        |
| value_loss         | 4791.3975   |
------------------------------------
-------------------------------------
| approxkl           | 0.012387499  |
| clipfrac           | 0.16992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.47e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 50           |
| policy_entropy     | 0.42045906   |
| policy_loss        | -0.015107067 |
| serial_timesteps   | 6400         |
| time_elapsed       | 238          |
| total_timesteps    | 6400         |
| value_loss         | 13.749927    |
-------------------------------------
An average of 203.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.009641237   |
| clipfrac           | 0.14648438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.47e+03      |
| explained_variance | 5.96e-07      |
| fps                | 30            |
| n_updates          | 51            |
| policy_entropy     | 0.41978842    |
| policy_loss        | -0.0050397953 |
| serial_timesteps   | 6528          |
| time_elapsed       | 243           |
| total_timesteps    | 6528          |
| value_loss         | 15.623427     |
--------------------------------------
------------------------------------
| approxkl           | 0.011399945 |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.47e+03    |
| explained_variance | -3.58e-07   |
| fps                | 28          |
| n_updates          | 52          |
| policy_entropy     | 0.4188274   |
| policy_loss        | 0.012526663 |
| serial_timesteps   | 6656        |
| time_elapsed       | 247         |
| total_timesteps    | 6656        |
| value_loss         | 12.192022   |
------------------------------------
------------------------------------
| approxkl           | 0.012471574 |
| clipfrac           | 0.16210938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.47e+03    |
| explained_variance | 2.15e-06    |
| fps                | 30          |
| n_updates          | 53          |
| policy_entropy     | 0.4174919   |
| policy_loss        | 0.017049111 |
| serial_timesteps   | 6784        |
| time_elapsed       | 251         |
| total_timesteps    | 6784        |
| value_loss         | 20.754362   |
------------------------------------
-------------------------------------
| approxkl           | 0.013230572  |
| clipfrac           | 0.1796875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.47e+03     |
| explained_variance | -5.96e-07    |
| fps                | 30           |
| n_updates          | 54           |
| policy_entropy     | 0.41579854   |
| policy_loss        | -0.002381478 |
| serial_timesteps   | 6912         |
| time_elapsed       | 256          |
| total_timesteps    | 6912         |
| value_loss         | 14.957765    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005994765   |
| clipfrac           | 0.09375       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.47e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 55            |
| policy_entropy     | 0.4144677     |
| policy_loss        | -0.0026265215 |
| serial_timesteps   | 7040          |
| time_elapsed       | 260           |
| total_timesteps    | 7040          |
| value_loss         | 19.169046     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011003242  |
| clipfrac           | 0.16601562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.47e+03     |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 56           |
| policy_entropy     | 0.41257104   |
| policy_loss        | -0.017844979 |
| serial_timesteps   | 7168         |
| time_elapsed       | 264          |
| total_timesteps    | 7168         |
| value_loss         | 4.7432923    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0020578103 |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.47e+03     |
| explained_variance | -8.34e-07    |
| fps                | 31           |
| n_updates          | 57           |
| policy_entropy     | 0.41036218   |
| policy_loss        | 0.0016372195 |
| serial_timesteps   | 7296         |
| time_elapsed       | 268          |
| total_timesteps    | 7296         |
| value_loss         | 9.45552      |
-------------------------------------
------------------------------------
| approxkl           | 0.006236106 |
| clipfrac           | 0.080078125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.47e+03    |
| explained_variance | 5.96e-06    |
| fps                | 30          |
| n_updates          | 58          |
| policy_entropy     | 0.40873972  |
| policy_loss        | 0.00679867  |
| serial_timesteps   | 7424        |
| time_elapsed       | 272         |
| total_timesteps    | 7424        |
| value_loss         | 16.438515   |
------------------------------------
An average of 203.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.003813606   |
| clipfrac           | 0.0390625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.47e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 59            |
| policy_entropy     | 0.4073206     |
| policy_loss        | 0.00053126295 |
| serial_timesteps   | 7552          |
| time_elapsed       | 277           |
| total_timesteps    | 7552          |
| value_loss         | 17.230421     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00034936663 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.47e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 60            |
| policy_entropy     | 0.40668064    |
| policy_loss        | 0.0021239899  |
| serial_timesteps   | 7680          |
| time_elapsed       | 281           |
| total_timesteps    | 7680          |
| value_loss         | 16.559427     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00082516525 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.48e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 61            |
| policy_entropy     | 0.4059076     |
| policy_loss        | -0.0012851427 |
| serial_timesteps   | 7808          |
| time_elapsed       | 285           |
| total_timesteps    | 7808          |
| value_loss         | 4877.4766     |
--------------------------------------
-------------------------------------
| approxkl           | 0.009306973  |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 62           |
| policy_entropy     | 0.40535155   |
| policy_loss        | -0.016335197 |
| serial_timesteps   | 7936         |
| time_elapsed       | 289          |
| total_timesteps    | 7936         |
| value_loss         | 10.963184    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03160541   |
| clipfrac           | 0.37109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | -2.86e-06    |
| fps                | 29           |
| n_updates          | 63           |
| policy_entropy     | 0.40463212   |
| policy_loss        | -0.037054084 |
| serial_timesteps   | 8064         |
| time_elapsed       | 293          |
| total_timesteps    | 8064         |
| value_loss         | 3.166944     |
-------------------------------------
-------------------------------------
| approxkl           | 0.01101951   |
| clipfrac           | 0.15429688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | 4.29e-06     |
| fps                | 29           |
| n_updates          | 64           |
| policy_entropy     | 0.40397668   |
| policy_loss        | -0.008944787 |
| serial_timesteps   | 8192         |
| time_elapsed       | 298          |
| total_timesteps    | 8192         |
| value_loss         | 12.762453    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0098047815 |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | -8.34e-07    |
| fps                | 31           |
| n_updates          | 65           |
| policy_entropy     | 0.40286952   |
| policy_loss        | 0.008539059  |
| serial_timesteps   | 8320         |
| time_elapsed       | 302          |
| total_timesteps    | 8320         |
| value_loss         | 17.277147    |
-------------------------------------
------------------------------------
| approxkl           | 0.016549444 |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.48e+03    |
| explained_variance | 0           |
| fps                | 31          |
| n_updates          | 66          |
| policy_entropy     | 0.40094924  |
| policy_loss        | 0.008028565 |
| serial_timesteps   | 8448        |
| time_elapsed       | 306         |
| total_timesteps    | 8448        |
| value_loss         | 12.674742   |
------------------------------------
An average of 204.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.00524086  |
| clipfrac           | 0.080078125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.48e+03    |
| explained_variance | 0           |
| fps                | 27          |
| n_updates          | 67          |
| policy_entropy     | 0.3996578   |
| policy_loss        | 0.006170661 |
| serial_timesteps   | 8576        |
| time_elapsed       | 310         |
| total_timesteps    | 8576        |
| value_loss         | 15.279827   |
------------------------------------
-------------------------------------
| approxkl           | 0.0027405955 |
| clipfrac           | 0.029296875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | 9.54e-07     |
| fps                | 30           |
| n_updates          | 68           |
| policy_entropy     | 0.39864978   |
| policy_loss        | 0.002003483  |
| serial_timesteps   | 8704         |
| time_elapsed       | 315          |
| total_timesteps    | 8704         |
| value_loss         | 15.401662    |
-------------------------------------
------------------------------------
| approxkl           | 0.012536689 |
| clipfrac           | 0.19335938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.48e+03    |
| explained_variance | 5.96e-08    |
| fps                | 30          |
| n_updates          | 69          |
| policy_entropy     | 0.39659017  |
| policy_loss        | 0.014632422 |
| serial_timesteps   | 8832        |
| time_elapsed       | 319         |
| total_timesteps    | 8832        |
| value_loss         | 16.179544   |
------------------------------------
-------------------------------------
| approxkl           | 0.00805934   |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | 0            |
| fps                | 32           |
| n_updates          | 70           |
| policy_entropy     | 0.39497063   |
| policy_loss        | 0.0041026156 |
| serial_timesteps   | 8960         |
| time_elapsed       | 323          |
| total_timesteps    | 8960         |
| value_loss         | 13.354456    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0014482867 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | -1.43e-06    |
| fps                | 29           |
| n_updates          | 71           |
| policy_entropy     | 0.39343074   |
| policy_loss        | 0.0053324746 |
| serial_timesteps   | 9088         |
| time_elapsed       | 327          |
| total_timesteps    | 9088         |
| value_loss         | 9.687508     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0028116726 |
| clipfrac           | 0.03125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.48e+03     |
| explained_variance | -4.05e-06    |
| fps                | 31           |
| n_updates          | 72           |
| policy_entropy     | 0.39154238   |
| policy_loss        | 0.0015193222 |
| serial_timesteps   | 9216         |
| time_elapsed       | 331          |
| total_timesteps    | 9216         |
| value_loss         | 16.799576    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0047253734 |
| clipfrac           | 0.05078125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.49e+03     |
| explained_variance | 5.96e-08     |
| fps                | 30           |
| n_updates          | 73           |
| policy_entropy     | 0.3902653    |
| policy_loss        | 0.0011641402 |
| serial_timesteps   | 9344         |
| time_elapsed       | 336          |
| total_timesteps    | 9344         |
| value_loss         | 4958.06      |
-------------------------------------
--------------------------------------
| approxkl           | 0.0017319319  |
| clipfrac           | 0.01171875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.49e+03      |
| explained_variance | 5.96e-08      |
| fps                | 30            |
| n_updates          | 74            |
| policy_entropy     | 0.38945377    |
| policy_loss        | -0.0014239468 |
| serial_timesteps   | 9472          |
| time_elapsed       | 340           |
| total_timesteps    | 9472          |
| value_loss         | 13.659894     |
--------------------------------------
An average of 205.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.008461794   |
| clipfrac           | 0.12890625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.49e+03      |
| explained_variance | 5.96e-08      |
| fps                | 29            |
| n_updates          | 75            |
| policy_entropy     | 0.3882875     |
| policy_loss        | -0.0052421456 |
| serial_timesteps   | 9600          |
| time_elapsed       | 344           |
| total_timesteps    | 9600          |
| value_loss         | 13.251853     |
--------------------------------------
--------------------------------------
| approxkl           | 0.004830907   |
| clipfrac           | 0.0703125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.49e+03      |
| explained_variance | -7.15e-07     |
| fps                | 30            |
| n_updates          | 76            |
| policy_entropy     | 0.38754612    |
| policy_loss        | -0.0038191201 |
| serial_timesteps   | 9728          |
| time_elapsed       | 348           |
| total_timesteps    | 9728          |
| value_loss         | 16.953836     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0053427108 |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.49e+03     |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 77           |
| policy_entropy     | 0.38573647   |
| policy_loss        | 0.0056782556 |
| serial_timesteps   | 9856         |
| time_elapsed       | 352          |
| total_timesteps    | 9856         |
| value_loss         | 6.5368214    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008643392   |
| clipfrac           | 0.111328125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.49e+03      |
| explained_variance | 5.96e-08      |
| fps                | 31            |
| n_updates          | 78            |
| policy_entropy     | 0.3833753     |
| policy_loss        | -0.0026876496 |
| serial_timesteps   | 9984          |
| time_elapsed       | 357           |
| total_timesteps    | 9984          |
| value_loss         | 14.207256     |
--------------------------------------
-------------------------------------
| approxkl           | 0.004378423  |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.49e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 79           |
| policy_entropy     | 0.38057572   |
| policy_loss        | -0.004028933 |
| serial_timesteps   | 10112        |
| time_elapsed       | 361          |
| total_timesteps    | 10112        |
| value_loss         | 10.4977865   |
-------------------------------------
--------------------------------------
| approxkl           | 0.0066824625  |
| clipfrac           | 0.095703125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.49e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 80            |
| policy_entropy     | 0.37860948    |
| policy_loss        | 0.00020393648 |
| serial_timesteps   | 10240         |
| time_elapsed       | 365           |
| total_timesteps    | 10240         |
| value_loss         | 10.99854      |
--------------------------------------
--------------------------------------
| approxkl           | 0.006478619   |
| clipfrac           | 0.076171875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.49e+03      |
| explained_variance | 8.34e-07      |
| fps                | 29            |
| n_updates          | 81            |
| policy_entropy     | 0.37766635    |
| policy_loss        | -0.0035248303 |
| serial_timesteps   | 10368         |
| time_elapsed       | 369           |
| total_timesteps    | 10368         |
| value_loss         | 13.452324     |
--------------------------------------
An average of 205.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0055019176 |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.49e+03     |
| explained_variance | 5.48e-06     |
| fps                | 28           |
| n_updates          | 82           |
| policy_entropy     | 0.37653664   |
| policy_loss        | 0.005196552  |
| serial_timesteps   | 10496        |
| time_elapsed       | 374          |
| total_timesteps    | 10496        |
| value_loss         | 15.885498    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007660842  |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.49e+03     |
| explained_variance | -2.38e-06    |
| fps                | 29           |
| n_updates          | 83           |
| policy_entropy     | 0.3746852    |
| policy_loss        | 0.0010436184 |
| serial_timesteps   | 10624        |
| time_elapsed       | 378          |
| total_timesteps    | 10624        |
| value_loss         | 11.892559    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015199338  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.49e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 84           |
| policy_entropy     | 0.37212807   |
| policy_loss        | 0.0046378793 |
| serial_timesteps   | 10752        |
| time_elapsed       | 382          |
| total_timesteps    | 10752        |
| value_loss         | 10.763156    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0019234087 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | -2.38e-07    |
| fps                | 30           |
| n_updates          | 85           |
| policy_entropy     | 0.36986715   |
| policy_loss        | 0.0018291274 |
| serial_timesteps   | 10880        |
| time_elapsed       | 386          |
| total_timesteps    | 10880        |
| value_loss         | 5038.6655    |
-------------------------------------
-------------------------------------
| approxkl           | 0.031533923  |
| clipfrac           | 0.30078125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 86           |
| policy_entropy     | 0.3690689    |
| policy_loss        | -0.014449905 |
| serial_timesteps   | 11008        |
| time_elapsed       | 391          |
| total_timesteps    | 11008        |
| value_loss         | 17.293526    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005287601  |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 87           |
| policy_entropy     | 0.36857235   |
| policy_loss        | 0.0035483844 |
| serial_timesteps   | 11136        |
| time_elapsed       | 395          |
| total_timesteps    | 11136        |
| value_loss         | 14.131277    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0050328486 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 88           |
| policy_entropy     | 0.3668692    |
| policy_loss        | 0.0024373573 |
| serial_timesteps   | 11264        |
| time_elapsed       | 400          |
| total_timesteps    | 11264        |
| value_loss         | 13.545922    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0055248393  |
| clipfrac           | 0.068359375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.5e+03       |
| explained_variance | 1.07e-06      |
| fps                | 30            |
| n_updates          | 89            |
| policy_entropy     | 0.3651867     |
| policy_loss        | 0.00058470597 |
| serial_timesteps   | 11392         |
| time_elapsed       | 404           |
| total_timesteps    | 11392         |
| value_loss         | 12.745373     |
--------------------------------------
An average of 206.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.010029066  |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | -1.55e-06    |
| fps                | 27           |
| n_updates          | 90           |
| policy_entropy     | 0.3634807    |
| policy_loss        | -0.009421183 |
| serial_timesteps   | 11520        |
| time_elapsed       | 408          |
| total_timesteps    | 11520        |
| value_loss         | 5.219514     |
-------------------------------------
--------------------------------------
| approxkl           | 0.020154532   |
| clipfrac           | 0.22265625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.5e+03       |
| explained_variance | -4.77e-07     |
| fps                | 31            |
| n_updates          | 91            |
| policy_entropy     | 0.36200196    |
| policy_loss        | -0.0056892666 |
| serial_timesteps   | 11648         |
| time_elapsed       | 413           |
| total_timesteps    | 11648         |
| value_loss         | 10.946444     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012890372  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 92           |
| policy_entropy     | 0.36081117   |
| policy_loss        | -0.006361197 |
| serial_timesteps   | 11776        |
| time_elapsed       | 417          |
| total_timesteps    | 11776        |
| value_loss         | 9.4266205    |
-------------------------------------
--------------------------------------
| approxkl           | 0.026339345   |
| clipfrac           | 0.25585938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.5e+03       |
| explained_variance | -2.38e-07     |
| fps                | 29            |
| n_updates          | 93            |
| policy_entropy     | 0.35951155    |
| policy_loss        | -0.0020465576 |
| serial_timesteps   | 11904         |
| time_elapsed       | 421           |
| total_timesteps    | 11904         |
| value_loss         | 12.132615     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005522126  |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 94           |
| policy_entropy     | 0.3578261    |
| policy_loss        | 0.0027321104 |
| serial_timesteps   | 12032        |
| time_elapsed       | 425          |
| total_timesteps    | 12032        |
| value_loss         | 16.150812    |
-------------------------------------
--------------------------------------
| approxkl           | 0.003298577   |
| clipfrac           | 0.03515625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.5e+03       |
| explained_variance | 5.96e-08      |
| fps                | 30            |
| n_updates          | 95            |
| policy_entropy     | 0.3563716     |
| policy_loss        | 0.00039263954 |
| serial_timesteps   | 12160         |
| time_elapsed       | 430           |
| total_timesteps    | 12160         |
| value_loss         | 6.5138264     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01821001   |
| clipfrac           | 0.22460938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.5e+03      |
| explained_variance | -1.19e-07    |
| fps                | 32           |
| n_updates          | 96           |
| policy_entropy     | 0.353147     |
| policy_loss        | -0.012382888 |
| serial_timesteps   | 12288        |
| time_elapsed       | 434          |
| total_timesteps    | 12288        |
| value_loss         | 7.8885713    |
-------------------------------------
--------------------------------------
| approxkl           | 0.001772203   |
| clipfrac           | 0.015625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.51e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 97            |
| policy_entropy     | 0.35044754    |
| policy_loss        | -0.0010125001 |
| serial_timesteps   | 12416         |
| time_elapsed       | 438           |
| total_timesteps    | 12416         |
| value_loss         | 5073.767      |
--------------------------------------
An average of 207.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0035847428  |
| clipfrac           | 0.048828125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.51e+03      |
| explained_variance | -1.19e-07     |
| fps                | 29            |
| n_updates          | 98            |
| policy_entropy     | 0.34937167    |
| policy_loss        | -0.0020678283 |
| serial_timesteps   | 12544         |
| time_elapsed       | 442           |
| total_timesteps    | 12544         |
| value_loss         | 11.174049     |
--------------------------------------
-------------------------------------
| approxkl           | 0.014175424  |
| clipfrac           | 0.20703125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 99           |
| policy_entropy     | 0.34840238   |
| policy_loss        | -0.009008749 |
| serial_timesteps   | 12672        |
| time_elapsed       | 446          |
| total_timesteps    | 12672        |
| value_loss         | 10.3625965   |
-------------------------------------
-------------------------------------
| approxkl           | 0.010766756  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | 1.19e-06     |
| fps                | 30           |
| n_updates          | 100          |
| policy_entropy     | 0.34730014   |
| policy_loss        | 0.0054260194 |
| serial_timesteps   | 12800        |
| time_elapsed       | 450          |
| total_timesteps    | 12800        |
| value_loss         | 5.7419662    |
-------------------------------------
-------------------------------------
| approxkl           | 0.003284146  |
| clipfrac           | 0.037109375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | 2.38e-07     |
| fps                | 29           |
| n_updates          | 101          |
| policy_entropy     | 0.34578073   |
| policy_loss        | 0.0015826859 |
| serial_timesteps   | 12928        |
| time_elapsed       | 455          |
| total_timesteps    | 12928        |
| value_loss         | 12.851534    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0032625934 |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 102          |
| policy_entropy     | 0.3443163    |
| policy_loss        | 0.0052429354 |
| serial_timesteps   | 13056        |
| time_elapsed       | 459          |
| total_timesteps    | 13056        |
| value_loss         | 5.4823117    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0028415835  |
| clipfrac           | 0.02734375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.51e+03      |
| explained_variance | -2.74e-06     |
| fps                | 30            |
| n_updates          | 103           |
| policy_entropy     | 0.34175587    |
| policy_loss        | -0.0028928688 |
| serial_timesteps   | 13184         |
| time_elapsed       | 463           |
| total_timesteps    | 13184         |
| value_loss         | 11.118129     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0056636278 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 104          |
| policy_entropy     | 0.33911392   |
| policy_loss        | 0.0035234983 |
| serial_timesteps   | 13312        |
| time_elapsed       | 467          |
| total_timesteps    | 13312        |
| value_loss         | 12.559252    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0059976405 |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | -3.58e-07    |
| fps                | 30           |
| n_updates          | 105          |
| policy_entropy     | 0.33700502   |
| policy_loss        | 0.0036160492 |
| serial_timesteps   | 13440        |
| time_elapsed       | 472          |
| total_timesteps    | 13440        |
| value_loss         | 9.764771     |
-------------------------------------
An average of 207.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.010226509 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.51e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 106         |
| policy_entropy     | 0.33550024  |
| policy_loss        | -0.00796056 |
| serial_timesteps   | 13568       |
| time_elapsed       | 476         |
| total_timesteps    | 13568       |
| value_loss         | 14.181319   |
------------------------------------
-------------------------------------
| approxkl           | 0.0042380644 |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | -2.03e-06    |
| fps                | 30           |
| n_updates          | 107          |
| policy_entropy     | 0.3335654    |
| policy_loss        | 0.0040559294 |
| serial_timesteps   | 13696        |
| time_elapsed       | 480          |
| total_timesteps    | 13696        |
| value_loss         | 7.943997     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0112763    |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.51e+03     |
| explained_variance | 5.36e-07     |
| fps                | 29           |
| n_updates          | 108          |
| policy_entropy     | 0.3313923    |
| policy_loss        | -0.005829149 |
| serial_timesteps   | 13824        |
| time_elapsed       | 484          |
| total_timesteps    | 13824        |
| value_loss         | 7.1820827    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004926556   |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.52e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 109           |
| policy_entropy     | 0.32979673    |
| policy_loss        | -0.0018991609 |
| serial_timesteps   | 13952         |
| time_elapsed       | 489           |
| total_timesteps    | 13952         |
| value_loss         | 5167.3384     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00019334609 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.52e+03      |
| explained_variance | 1.19e-07      |
| fps                | 31            |
| n_updates          | 110           |
| policy_entropy     | 0.32912248    |
| policy_loss        | 0.0014378595  |
| serial_timesteps   | 14080         |
| time_elapsed       | 493           |
| total_timesteps    | 14080         |
| value_loss         | 13.597612     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0044543934  |
| clipfrac           | 0.07421875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.52e+03      |
| explained_variance | 1.79e-07      |
| fps                | 30            |
| n_updates          | 111           |
| policy_entropy     | 0.32836685    |
| policy_loss        | -0.0041301292 |
| serial_timesteps   | 14208         |
| time_elapsed       | 497           |
| total_timesteps    | 14208         |
| value_loss         | 11.51803      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0079982905 |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.52e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 112          |
| policy_entropy     | 0.32673433   |
| policy_loss        | -0.011668917 |
| serial_timesteps   | 14336        |
| time_elapsed       | 501          |
| total_timesteps    | 14336        |
| value_loss         | 14.729979    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01567666   |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.52e+03     |
| explained_variance | 6.56e-07     |
| fps                | 31           |
| n_updates          | 113          |
| policy_entropy     | 0.3251891    |
| policy_loss        | -0.009417251 |
| serial_timesteps   | 14464        |
| time_elapsed       | 505          |
| total_timesteps    | 14464        |
| value_loss         | 9.34401      |
-------------------------------------
An average of 208.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0025469018  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.52e+03      |
| explained_variance | -1.07e-06     |
| fps                | 29            |
| n_updates          | 114           |
| policy_entropy     | 0.32363337    |
| policy_loss        | -0.0010115001 |
| serial_timesteps   | 14592         |
| time_elapsed       | 509           |
| total_timesteps    | 14592         |
| value_loss         | 12.022515     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0005438087  |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.52e+03      |
| explained_variance | 5.96e-08      |
| fps                | 29            |
| n_updates          | 115           |
| policy_entropy     | 0.32203645    |
| policy_loss        | -0.0005823872 |
| serial_timesteps   | 14720         |
| time_elapsed       | 514           |
| total_timesteps    | 14720         |
| value_loss         | 17.861506     |
--------------------------------------
-------------------------------------
| approxkl           | 0.020175891  |
| clipfrac           | 0.22460938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.52e+03     |
| explained_variance | 5.96e-08     |
| fps                | 27           |
| n_updates          | 116          |
| policy_entropy     | 0.31994176   |
| policy_loss        | -0.015134731 |
| serial_timesteps   | 14848        |
| time_elapsed       | 518          |
| total_timesteps    | 14848        |
| value_loss         | 6.535262     |
-------------------------------------
-------------------------------------
| approxkl           | 0.017443685  |
| clipfrac           | 0.20898438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.52e+03     |
| explained_variance | 4.17e-07     |
| fps                | 30           |
| n_updates          | 117          |
| policy_entropy     | 0.31824452   |
| policy_loss        | 0.0072301994 |
| serial_timesteps   | 14976        |
| time_elapsed       | 523          |
| total_timesteps    | 14976        |
| value_loss         | 7.7702003    |
-------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b54cf0128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b54cf0128>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b4a631a90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b4a631a90>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2810 samples, validate on 336 samples
Epoch 388/5000
 - 7s - loss: 0.0646 - val_loss: 0.0163
Epoch 389/5000
 - 1s - loss: 0.0085 - val_loss: 0.0104
Epoch 390/5000
 - 1s - loss: 0.0066 - val_loss: 0.0075
Epoch 391/5000
 - 1s - loss: 0.0058 - val_loss: 0.0062
Epoch 392/5000
 - 1s - loss: 0.0056 - val_loss: 0.0056
Epoch 393/5000
 - 1s - loss: 0.0056 - val_loss: 0.0055
Epoch 394/5000
 - 1s - loss: 0.0057 - val_loss: 0.0054
Epoch 395/5000
 - 1s - loss: 0.0058 - val_loss: 0.0054
Epoch 396/5000
 - 1s - loss: 0.0058 - val_loss: 0.0054
Epoch 397/5000
 - 1s - loss: 0.0058 - val_loss: 0.0054
Epoch 398/5000
 - 1s - loss: 0.0044 - val_loss: 0.0056
Epoch 399/5000
 - 1s - loss: 0.0043 - val_loss: 0.0057
Epoch 400/5000
 - 1s - loss: 0.0043 - val_loss: 0.0057
Train on 1770 samples, validate on 336 samples
Epoch 292/5000
 - 7s - loss: 0.0054 - val_loss: 0.0037
Epoch 293/5000
 - 1s - loss: 0.0054 - val_loss: 0.0037
Epoch 294/5000
 - 1s - loss: 0.0054 - val_loss: 0.0037
Epoch 295/5000
 - 1s - loss: 0.0054 - val_loss: 0.0037
Epoch 296/5000
 - 0s - loss: 0.0054 - val_loss: 0.0037
Epoch 297/5000
 - 0s - loss: 0.0054 - val_loss: 0.0037
Train on 2810 samples, validate on 336 samples
Epoch 1013/5000
 - 9s - loss: 0.6808 - val_loss: 0.6703
Epoch 1014/5000
 - 1s - loss: 0.6567 - val_loss: 0.6591
Epoch 1015/5000
 - 1s - loss: 0.6472 - val_loss: 0.6582
Epoch 1016/5000
 - 1s - loss: 0.6436 - val_loss: 0.6580
Epoch 1017/5000
 - 1s - loss: 0.6418 - val_loss: 0.6576
Epoch 1018/5000
 - 1s - loss: 0.6405 - val_loss: 0.6571
Epoch 1019/5000
 - 1s - loss: 0.6393 - val_loss: 0.6555
Epoch 1020/5000
 - 1s - loss: 0.6381 - val_loss: 0.6538
Epoch 1021/5000
 - 1s - loss: 0.6369 - val_loss: 0.6495
Epoch 1022/5000
 - 1s - loss: 0.6339 - val_loss: 0.6412
Epoch 1023/5000
 - 1s - loss: 0.6280 - val_loss: 0.6189
Epoch 1024/5000
 - 1s - loss: 0.6165 - val_loss: 0.5856
Epoch 1025/5000
 - 1s - loss: 0.6097 - val_loss: 0.5631
Epoch 1026/5000
 - 1s - loss: 0.6037 - val_loss: 0.5538
Epoch 1027/5000
 - 1s - loss: 0.5965 - val_loss: 0.5472
Epoch 1028/5000
 - 1s - loss: 0.5929 - val_loss: 0.5438
Epoch 1029/5000
 - 1s - loss: 0.5895 - val_loss: 0.5434
Epoch 1030/5000
 - 1s - loss: 0.5863 - val_loss: 0.5429
Epoch 1031/5000
 - 1s - loss: 0.5817 - val_loss: 0.5412
Epoch 1032/5000
 - 1s - loss: 0.5768 - val_loss: 0.5351
Epoch 1033/5000
 - 1s - loss: 0.5722 - val_loss: 0.5256
Epoch 1034/5000
 - 1s - loss: 0.5692 - val_loss: 0.5168
Epoch 1035/5000
 - 1s - loss: 0.5648 - val_loss: 0.5095
Epoch 1036/5000
 - 1s - loss: 0.5620 - val_loss: 0.5042
Epoch 1037/5000
 - 1s - loss: 0.5576 - val_loss: 0.4950
Epoch 1038/5000
 - 1s - loss: 0.5547 - val_loss: 0.4879
Epoch 1039/5000
 - 1s - loss: 0.5515 - val_loss: 0.4806
Epoch 1040/5000
 - 1s - loss: 0.5491 - val_loss: 0.4752
Epoch 1041/5000
 - 1s - loss: 0.5463 - val_loss: 0.4693
Epoch 1042/5000
 - 1s - loss: 0.5435 - val_loss: 0.4636
Epoch 1043/5000
 - 1s - loss: 0.5402 - val_loss: 0.4573
Epoch 1044/5000
 - 1s - loss: 0.5377 - val_loss: 0.4521
Epoch 1045/5000
 - 1s - loss: 0.5348 - val_loss: 0.4477
Epoch 1046/5000
 - 1s - loss: 0.5319 - val_loss: 0.4428
Epoch 1047/5000
 - 1s - loss: 0.5282 - val_loss: 0.4416
Epoch 1048/5000
 - 1s - loss: 0.5227 - val_loss: 0.4360
Epoch 1049/5000
 - 1s - loss: 0.5199 - val_loss: 0.4335
Epoch 1050/5000
 - 1s - loss: 0.5161 - val_loss: 0.4317
Epoch 1051/5000
 - 1s - loss: 0.5134 - val_loss: 0.4332
Epoch 1052/5000
 - 1s - loss: 0.5080 - val_loss: 0.4286
Epoch 1053/5000
 - 1s - loss: 0.5020 - val_loss: 0.4248
Epoch 1054/5000
 - 1s - loss: 0.4948 - val_loss: 0.4197
Epoch 1055/5000
 - 1s - loss: 0.4893 - val_loss: 0.4176
Epoch 1056/5000
 - 1s - loss: 0.4839 - val_loss: 0.4157
Epoch 1057/5000
 - 1s - loss: 0.4773 - val_loss: 0.4117
Epoch 1058/5000
 - 1s - loss: 0.4727 - val_loss: 0.4102
Epoch 1059/5000
 - 1s - loss: 0.4656 - val_loss: 0.4063
Epoch 1060/5000
 - 1s - loss: 0.4599 - val_loss: 0.4018
Epoch 1061/5000
 - 1s - loss: 0.4535 - val_loss: 0.3961
Epoch 1062/5000
 - 1s - loss: 0.4487 - val_loss: 0.3919
Epoch 1063/5000
 - 1s - loss: 0.4431 - val_loss: 0.3878
Epoch 1064/5000
 - 1s - loss: 0.4379 - val_loss: 0.3834
Epoch 1065/5000
 - 1s - loss: 0.4323 - val_loss: 0.3799
Epoch 1066/5000
 - 1s - loss: 0.4264 - val_loss: 0.3752
Epoch 1067/5000
 - 1s - loss: 0.4201 - val_loss: 0.3699
Epoch 1068/5000
 - 1s - loss: 0.4118 - val_loss: 0.3646
Epoch 1069/5000
 - 1s - loss: 0.4040 - val_loss: 0.3567
Epoch 1070/5000
 - 1s - loss: 0.3985 - val_loss: 0.3527
Epoch 1071/5000
 - 1s - loss: 0.3929 - val_loss: 0.3480
Epoch 1072/5000
 - 1s - loss: 0.3914 - val_loss: 0.3492
Epoch 1073/5000
 - 1s - loss: 0.3845 - val_loss: 0.3463
Epoch 1074/5000
 - 1s - loss: 0.3766 - val_loss: 0.3414
Epoch 1075/5000
 - 1s - loss: 0.3737 - val_loss: 0.3388
Epoch 1076/5000
 - 1s - loss: 0.3675 - val_loss: 0.3382
Epoch 1077/5000
 - 1s - loss: 0.3648 - val_loss: 0.3402
Epoch 1078/5000
 - 1s - loss: 0.3636 - val_loss: 0.3413
Epoch 1079/5000
 - 1s - loss: 0.3698 - val_loss: 0.3636
Epoch 1080/5000
 - 1s - loss: 0.3589 - val_loss: 0.3745
Epoch 1081/5000
 - 1s - loss: 0.3590 - val_loss: 0.3777
setting environment to train mode..... 

Training Started... 

---------------------------------------
| approxkl           | 0.01179927     |
| clipfrac           | 0.171875       |
| explained_variance | -2.03e-06      |
| fps                | 5              |
| n_updates          | 1              |
| policy_entropy     | 0.31707        |
| policy_loss        | -2.4263514e-05 |
| serial_timesteps   | 128            |
| time_elapsed       | 1.26e-05       |
| total_timesteps    | 128            |
| value_loss         | 11.446397      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0021825812 |
| clipfrac           | 0.013671875  |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 2            |
| policy_entropy     | 0.31506723   |
| policy_loss        | 0.0021756198 |
| serial_timesteps   | 256          |
| time_elapsed       | 25.3         |
| total_timesteps    | 256          |
| value_loss         | 9.62807      |
-------------------------------------
-------------------------------------
| approxkl           | 0.005447045  |
| clipfrac           | 0.078125     |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 3            |
| policy_entropy     | 0.31326157   |
| policy_loss        | 0.0022099428 |
| serial_timesteps   | 384          |
| time_elapsed       | 29.7         |
| total_timesteps    | 384          |
| value_loss         | 9.10958      |
-------------------------------------
An average of 209.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0045474293 |
| clipfrac           | 0.05859375   |
| explained_variance | 1.19e-07     |
| fps                | 30           |
| n_updates          | 4            |
| policy_entropy     | 0.31146783   |
| policy_loss        | 0.002104363  |
| serial_timesteps   | 512          |
| time_elapsed       | 34           |
| total_timesteps    | 512          |
| value_loss         | 10.703888    |
-------------------------------------
--------------------------------------
| approxkl           | 0.02026347    |
| clipfrac           | 0.24804688    |
| explained_variance | 7.69e-06      |
| fps                | 28            |
| n_updates          | 5             |
| policy_entropy     | 0.30989686    |
| policy_loss        | -0.0102090705 |
| serial_timesteps   | 640           |
| time_elapsed       | 38.3          |
| total_timesteps    | 640           |
| value_loss         | 5.774605      |
--------------------------------------
--------------------------------------
| approxkl           | 0.026522437   |
| clipfrac           | 0.25195312    |
| explained_variance | 2.32e-06      |
| fps                | 32            |
| n_updates          | 6             |
| policy_entropy     | 0.30859876    |
| policy_loss        | -0.0129666235 |
| serial_timesteps   | 768           |
| time_elapsed       | 42.8          |
| total_timesteps    | 768           |
| value_loss         | 4.400111      |
--------------------------------------
--------------------------------------
| approxkl           | 0.020628404   |
| clipfrac           | 0.234375      |
| explained_variance | -4.05e-06     |
| fps                | 29            |
| n_updates          | 7             |
| policy_entropy     | 0.30740333    |
| policy_loss        | -0.0088464115 |
| serial_timesteps   | 896           |
| time_elapsed       | 46.8          |
| total_timesteps    | 896           |
| value_loss         | 7.9170246     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0077542164 |
| clipfrac           | 0.099609375  |
| explained_variance | -1.91e-06    |
| fps                | 30           |
| n_updates          | 8            |
| policy_entropy     | 0.30645445   |
| policy_loss        | -0.00258796  |
| serial_timesteps   | 1024         |
| time_elapsed       | 51.2         |
| total_timesteps    | 1024         |
| value_loss         | 10.774896    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0033448571  |
| clipfrac           | 0.03125       |
| explained_variance | 5.96e-08      |
| fps                | 30            |
| n_updates          | 9             |
| policy_entropy     | 0.30469635    |
| policy_loss        | -0.0012518115 |
| serial_timesteps   | 1152          |
| time_elapsed       | 55.4          |
| total_timesteps    | 1152          |
| value_loss         | 12.721262     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0046880473  |
| clipfrac           | 0.068359375   |
| explained_variance | 0             |
| fps                | 28            |
| n_updates          | 10            |
| policy_entropy     | 0.30291033    |
| policy_loss        | 0.00011374685 |
| serial_timesteps   | 1280          |
| time_elapsed       | 59.6          |
| total_timesteps    | 1280          |
| value_loss         | 11.094109     |
--------------------------------------
-------------------------------------
| approxkl           | 0.014922556  |
| clipfrac           | 0.1796875    |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 11           |
| policy_entropy     | 0.30150723   |
| policy_loss        | -0.013857223 |
| serial_timesteps   | 1408         |
| time_elapsed       | 64.1         |
| total_timesteps    | 1408         |
| value_loss         | 9.10695      |
-------------------------------------
An average of 209.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.010319317  |
| clipfrac           | 0.13867188   |
| explained_variance | 2.56e-06     |
| fps                | 29           |
| n_updates          | 12           |
| policy_entropy     | 0.30007392   |
| policy_loss        | 0.0047505237 |
| serial_timesteps   | 1536         |
| time_elapsed       | 68.2         |
| total_timesteps    | 1536         |
| value_loss         | 11.168414    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0011459203 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.64e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 13           |
| policy_entropy     | 0.2985135    |
| policy_loss        | 0.0022630717 |
| serial_timesteps   | 1664         |
| time_elapsed       | 72.5         |
| total_timesteps    | 1664         |
| value_loss         | 3363.6753    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0005252998  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | 2.68e-06      |
| fps                | 30            |
| n_updates          | 14            |
| policy_entropy     | 0.29767752    |
| policy_loss        | -0.0019805955 |
| serial_timesteps   | 1792          |
| time_elapsed       | 76.6          |
| total_timesteps    | 1792          |
| value_loss         | 11.153403     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0063273357  |
| clipfrac           | 0.091796875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | -5.96e-07     |
| fps                | 30            |
| n_updates          | 15            |
| policy_entropy     | 0.29663476    |
| policy_loss        | -0.0056773536 |
| serial_timesteps   | 1920          |
| time_elapsed       | 80.8          |
| total_timesteps    | 1920          |
| value_loss         | 7.496843      |
--------------------------------------
--------------------------------------
| approxkl           | 0.01076349    |
| clipfrac           | 0.14453125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | 2.38e-07      |
| fps                | 31            |
| n_updates          | 16            |
| policy_entropy     | 0.2948501     |
| policy_loss        | 0.00097358087 |
| serial_timesteps   | 2048          |
| time_elapsed       | 85            |
| total_timesteps    | 2048          |
| value_loss         | 7.92948       |
--------------------------------------
--------------------------------------
| approxkl           | 0.012466674   |
| clipfrac           | 0.18945312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | 2.21e-06      |
| fps                | 8             |
| n_updates          | 17            |
| policy_entropy     | 0.2932638     |
| policy_loss        | -0.0039393264 |
| serial_timesteps   | 2176          |
| time_elapsed       | 89.1          |
| total_timesteps    | 2176          |
| value_loss         | 12.542383     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0042089364 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.64e+03     |
| explained_variance | -1.67e-06    |
| fps                | 28           |
| n_updates          | 18           |
| policy_entropy     | 0.29169792   |
| policy_loss        | 0.0015579611 |
| serial_timesteps   | 2304         |
| time_elapsed       | 104          |
| total_timesteps    | 2304         |
| value_loss         | 6.661766     |
-------------------------------------
-------------------------------------
| approxkl           | 0.008946258  |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.64e+03     |
| explained_variance | 7.75e-06     |
| fps                | 28           |
| n_updates          | 19           |
| policy_entropy     | 0.28949946   |
| policy_loss        | -0.011969313 |
| serial_timesteps   | 2432         |
| time_elapsed       | 109          |
| total_timesteps    | 2432         |
| value_loss         | 5.9416447    |
-------------------------------------
An average of 210.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.025895588   |
| clipfrac           | 0.25          |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | -2.38e-07     |
| fps                | 29            |
| n_updates          | 20            |
| policy_entropy     | 0.28834546    |
| policy_loss        | -0.0024717976 |
| serial_timesteps   | 2560          |
| time_elapsed       | 113           |
| total_timesteps    | 2560          |
| value_loss         | 10.642676     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0072276588  |
| clipfrac           | 0.095703125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | 1.19e-07      |
| fps                | 30            |
| n_updates          | 21            |
| policy_entropy     | 0.28759927    |
| policy_loss        | -0.0018976717 |
| serial_timesteps   | 2688          |
| time_elapsed       | 117           |
| total_timesteps    | 2688          |
| value_loss         | 10.016319     |
--------------------------------------
-------------------------------------
| approxkl           | 0.010949399  |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.64e+03     |
| explained_variance | 1.19e-07     |
| fps                | 29           |
| n_updates          | 22           |
| policy_entropy     | 0.28627023   |
| policy_loss        | -0.010132424 |
| serial_timesteps   | 2816         |
| time_elapsed       | 122          |
| total_timesteps    | 2816         |
| value_loss         | 9.742391     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016763392 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.64e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 23           |
| policy_entropy     | 0.28394565   |
| policy_loss        | 0.002644012  |
| serial_timesteps   | 2944         |
| time_elapsed       | 126          |
| total_timesteps    | 2944         |
| value_loss         | 7.236567     |
-------------------------------------
--------------------------------------
| approxkl           | 0.008045488   |
| clipfrac           | 0.1015625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.64e+03      |
| explained_variance | 1.19e-07      |
| fps                | 30            |
| n_updates          | 24            |
| policy_entropy     | 0.28198612    |
| policy_loss        | -0.0064528324 |
| serial_timesteps   | 3072          |
| time_elapsed       | 130           |
| total_timesteps    | 3072          |
| value_loss         | 9.869415      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0013907761 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 25           |
| policy_entropy     | 0.2809474    |
| policy_loss        | 0.006027897  |
| serial_timesteps   | 3200         |
| time_elapsed       | 135          |
| total_timesteps    | 3200         |
| value_loss         | 4651.63      |
-------------------------------------
-------------------------------------
| approxkl           | 0.005647419  |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -2.38e-07    |
| fps                | 29           |
| n_updates          | 26           |
| policy_entropy     | 0.28052267   |
| policy_loss        | -0.002432685 |
| serial_timesteps   | 3328         |
| time_elapsed       | 139          |
| total_timesteps    | 3328         |
| value_loss         | 9.190844     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0045344685 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 2.32e-06     |
| fps                | 30           |
| n_updates          | 27           |
| policy_entropy     | 0.2791354    |
| policy_loss        | 0.0027384216 |
| serial_timesteps   | 3456         |
| time_elapsed       | 143          |
| total_timesteps    | 3456         |
| value_loss         | 3.7773418    |
-------------------------------------
An average of 211.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.014208795  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 3.58e-07     |
| fps                | 29           |
| n_updates          | 28           |
| policy_entropy     | 0.27699876   |
| policy_loss        | -0.005674327 |
| serial_timesteps   | 3584         |
| time_elapsed       | 147          |
| total_timesteps    | 3584         |
| value_loss         | 7.7203493    |
-------------------------------------
--------------------------------------
| approxkl           | 0.002860006   |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | -1.19e-07     |
| fps                | 30            |
| n_updates          | 29            |
| policy_entropy     | 0.27460885    |
| policy_loss        | -0.0010079958 |
| serial_timesteps   | 3712          |
| time_elapsed       | 152           |
| total_timesteps    | 3712          |
| value_loss         | 10.533834     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00017876066 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | 5.96e-08      |
| fps                | 28            |
| n_updates          | 30            |
| policy_entropy     | 0.27286565    |
| policy_loss        | 0.0014348899  |
| serial_timesteps   | 3840          |
| time_elapsed       | 156           |
| total_timesteps    | 3840          |
| value_loss         | 16.361227     |
--------------------------------------
--------------------------------------
| approxkl           | 0.008891026   |
| clipfrac           | 0.123046875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | 0             |
| fps                | 29            |
| n_updates          | 31            |
| policy_entropy     | 0.2713919     |
| policy_loss        | -0.0058460934 |
| serial_timesteps   | 3968          |
| time_elapsed       | 160           |
| total_timesteps    | 3968          |
| value_loss         | 10.281079     |
--------------------------------------
-------------------------------------
| approxkl           | 0.021356791  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -8.34e-07    |
| fps                | 30           |
| n_updates          | 32           |
| policy_entropy     | 0.26986185   |
| policy_loss        | -0.008326815 |
| serial_timesteps   | 4096         |
| time_elapsed       | 165          |
| total_timesteps    | 4096         |
| value_loss         | 2.9130127    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0055247014  |
| clipfrac           | 0.076171875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | -5.96e-07     |
| fps                | 30            |
| n_updates          | 33            |
| policy_entropy     | 0.26808557    |
| policy_loss        | -0.0024536352 |
| serial_timesteps   | 4224          |
| time_elapsed       | 169           |
| total_timesteps    | 4224          |
| value_loss         | 6.0942307     |
--------------------------------------
------------------------------------
| approxkl           | 0.003015986 |
| clipfrac           | 0.04296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.65e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 34          |
| policy_entropy     | 0.26576117  |
| policy_loss        | 0.002519497 |
| serial_timesteps   | 4352        |
| time_elapsed       | 173         |
| total_timesteps    | 4352        |
| value_loss         | 3.7037904   |
------------------------------------
--------------------------------------
| approxkl           | 0.0070922337  |
| clipfrac           | 0.08984375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | 1.97e-06      |
| fps                | 31            |
| n_updates          | 35            |
| policy_entropy     | 0.2624689     |
| policy_loss        | -0.0054962477 |
| serial_timesteps   | 4480          |
| time_elapsed       | 177           |
| total_timesteps    | 4480          |
| value_loss         | 6.0501027     |
--------------------------------------
An average of 211.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.03862449   |
| clipfrac           | 0.33789062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 36           |
| policy_entropy     | 0.26013818   |
| policy_loss        | -0.003498141 |
| serial_timesteps   | 4608         |
| time_elapsed       | 181          |
| total_timesteps    | 4608         |
| value_loss         | 4.8267603    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021078844  |
| clipfrac           | 0.28320312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 37           |
| policy_entropy     | 0.25887746   |
| policy_loss        | 0.0015831762 |
| serial_timesteps   | 4736         |
| time_elapsed       | 186          |
| total_timesteps    | 4736         |
| value_loss         | 5287.3       |
-------------------------------------
-------------------------------------
| approxkl           | 0.0053898864 |
| clipfrac           | 0.06640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -2.38e-07    |
| fps                | 31           |
| n_updates          | 38           |
| policy_entropy     | 0.25828487   |
| policy_loss        | 0.0006162578 |
| serial_timesteps   | 4864         |
| time_elapsed       | 190          |
| total_timesteps    | 4864         |
| value_loss         | 11.452845    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0021989904  |
| clipfrac           | 0.02734375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | 1.19e-07      |
| fps                | 31            |
| n_updates          | 39            |
| policy_entropy     | 0.2571079     |
| policy_loss        | -0.0012918196 |
| serial_timesteps   | 4992          |
| time_elapsed       | 194           |
| total_timesteps    | 4992          |
| value_loss         | 7.3445997     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012604989  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 40           |
| policy_entropy     | 0.25528988   |
| policy_loss        | -0.011981095 |
| serial_timesteps   | 5120         |
| time_elapsed       | 198          |
| total_timesteps    | 5120         |
| value_loss         | 5.1000204    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008601128  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 41           |
| policy_entropy     | 0.2533363    |
| policy_loss        | -0.014211529 |
| serial_timesteps   | 5248         |
| time_elapsed       | 202          |
| total_timesteps    | 5248         |
| value_loss         | 8.236456     |
-------------------------------------
------------------------------------
| approxkl           | 0.021642696 |
| clipfrac           | 0.25        |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.65e+03    |
| explained_variance | -4.77e-06   |
| fps                | 30          |
| n_updates          | 42          |
| policy_entropy     | 0.25170645  |
| policy_loss        | -0.02780301 |
| serial_timesteps   | 5376        |
| time_elapsed       | 207         |
| total_timesteps    | 5376        |
| value_loss         | 2.3217616   |
------------------------------------
-------------------------------------
| approxkl           | 0.01652587   |
| clipfrac           | 0.1875       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -7.15e-07    |
| fps                | 28           |
| n_updates          | 43           |
| policy_entropy     | 0.2500319    |
| policy_loss        | -0.015076549 |
| serial_timesteps   | 5504         |
| time_elapsed       | 211          |
| total_timesteps    | 5504         |
| value_loss         | 3.0440953    |
-------------------------------------
An average of 212.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.02114891   |
| clipfrac           | 0.265625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.19e-07    |
| fps                | 28           |
| n_updates          | 44           |
| policy_entropy     | 0.24845809   |
| policy_loss        | -0.014336274 |
| serial_timesteps   | 5632         |
| time_elapsed       | 215          |
| total_timesteps    | 5632         |
| value_loss         | 6.1081657    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0030423875 |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -7.15e-07    |
| fps                | 30           |
| n_updates          | 45           |
| policy_entropy     | 0.24575219   |
| policy_loss        | 0.0028058616 |
| serial_timesteps   | 5760         |
| time_elapsed       | 220          |
| total_timesteps    | 5760         |
| value_loss         | 11.552708    |
-------------------------------------
-------------------------------------
| approxkl           | 0.026684122  |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 7.75e-07     |
| fps                | 30           |
| n_updates          | 46           |
| policy_entropy     | 0.24297297   |
| policy_loss        | -0.010660393 |
| serial_timesteps   | 5888         |
| time_elapsed       | 224          |
| total_timesteps    | 5888         |
| value_loss         | 9.247842     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0094131995 |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -4.77e-06    |
| fps                | 31           |
| n_updates          | 47           |
| policy_entropy     | 0.24123019   |
| policy_loss        | -0.006341112 |
| serial_timesteps   | 6016         |
| time_elapsed       | 228          |
| total_timesteps    | 6016         |
| value_loss         | 8.031357     |
-------------------------------------
-------------------------------------
| approxkl           | 0.007324286  |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 5.96e-08     |
| fps                | 29           |
| n_updates          | 48           |
| policy_entropy     | 0.23957554   |
| policy_loss        | -0.009142618 |
| serial_timesteps   | 6144         |
| time_elapsed       | 232          |
| total_timesteps    | 6144         |
| value_loss         | 5.0231967    |
-------------------------------------
------------------------------------
| approxkl           | 0.018028975 |
| clipfrac           | 0.25585938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.65e+03    |
| explained_variance | -1.19e-07   |
| fps                | 30          |
| n_updates          | 49          |
| policy_entropy     | 0.23808752  |
| policy_loss        | 0.026291912 |
| serial_timesteps   | 6272        |
| time_elapsed       | 236         |
| total_timesteps    | 6272        |
| value_loss         | 5395.233    |
------------------------------------
-------------------------------------
| approxkl           | 0.016156519  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 8.52e-06     |
| fps                | 30           |
| n_updates          | 50           |
| policy_entropy     | 0.23747757   |
| policy_loss        | -0.017502274 |
| serial_timesteps   | 6400         |
| time_elapsed       | 241          |
| total_timesteps    | 6400         |
| value_loss         | 9.335558     |
-------------------------------------
An average of 213.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.0076781595   |
| clipfrac           | 0.1015625      |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.65e+03       |
| explained_variance | -5.36e-06      |
| fps                | 30             |
| n_updates          | 51             |
| policy_entropy     | 0.23634742     |
| policy_loss        | -0.00026066927 |
| serial_timesteps   | 6528           |
| time_elapsed       | 245            |
| total_timesteps    | 6528           |
| value_loss         | 4.0226483      |
---------------------------------------
-------------------------------------
| approxkl           | 0.013874457  |
| clipfrac           | 0.15429688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.31e-06    |
| fps                | 29           |
| n_updates          | 52           |
| policy_entropy     | 0.23413461   |
| policy_loss        | -0.011501203 |
| serial_timesteps   | 6656         |
| time_elapsed       | 249          |
| total_timesteps    | 6656         |
| value_loss         | 3.0942326    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021656139  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.19e-07    |
| fps                | 29           |
| n_updates          | 53           |
| policy_entropy     | 0.23190495   |
| policy_loss        | -0.010883583 |
| serial_timesteps   | 6784         |
| time_elapsed       | 253          |
| total_timesteps    | 6784         |
| value_loss         | 7.162183     |
-------------------------------------
-------------------------------------
| approxkl           | 0.005961903  |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.07e-06    |
| fps                | 29           |
| n_updates          | 54           |
| policy_entropy     | 0.2303288    |
| policy_loss        | 0.0002912496 |
| serial_timesteps   | 6912         |
| time_elapsed       | 258          |
| total_timesteps    | 6912         |
| value_loss         | 7.0672956    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0073880344  |
| clipfrac           | 0.09765625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | -2.62e-06     |
| fps                | 29            |
| n_updates          | 55            |
| policy_entropy     | 0.22832221    |
| policy_loss        | -0.0012812271 |
| serial_timesteps   | 7040          |
| time_elapsed       | 262           |
| total_timesteps    | 7040          |
| value_loss         | 5.927641      |
--------------------------------------
------------------------------------
| approxkl           | 0.020249708 |
| clipfrac           | 0.23242188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.65e+03    |
| explained_variance | 0           |
| fps                | 29          |
| n_updates          | 56          |
| policy_entropy     | 0.22606996  |
| policy_loss        | 0.02066885  |
| serial_timesteps   | 7168        |
| time_elapsed       | 266         |
| total_timesteps    | 7168        |
| value_loss         | 3.03246     |
------------------------------------
-------------------------------------
| approxkl           | 0.004773499  |
| clipfrac           | 0.06640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 0            |
| fps                | 27           |
| n_updates          | 57           |
| policy_entropy     | 0.22328305   |
| policy_loss        | 0.0016370441 |
| serial_timesteps   | 7296         |
| time_elapsed       | 271          |
| total_timesteps    | 7296         |
| value_loss         | 3.0069456    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01326317   |
| clipfrac           | 0.1875       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 0            |
| fps                | 28           |
| n_updates          | 58           |
| policy_entropy     | 0.22022901   |
| policy_loss        | -0.015059869 |
| serial_timesteps   | 7424         |
| time_elapsed       | 275          |
| total_timesteps    | 7424         |
| value_loss         | 3.4197564    |
-------------------------------------
An average of 213.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0031886748  |
| clipfrac           | 0.03515625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | -1.19e-06     |
| fps                | 29            |
| n_updates          | 59            |
| policy_entropy     | 0.21780312    |
| policy_loss        | -0.0013142332 |
| serial_timesteps   | 7552          |
| time_elapsed       | 280           |
| total_timesteps    | 7552          |
| value_loss         | 5.4017243     |
--------------------------------------
-------------------------------------
| approxkl           | 0.009653735  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 4.89e-06     |
| fps                | 31           |
| n_updates          | 60           |
| policy_entropy     | 0.21495892   |
| policy_loss        | 0.0018170299 |
| serial_timesteps   | 7680         |
| time_elapsed       | 284          |
| total_timesteps    | 7680         |
| value_loss         | 3.8488445    |
-------------------------------------
--------------------------------------
| approxkl           | 2.019235e-05  |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | -1.19e-07     |
| fps                | 33            |
| n_updates          | 61            |
| policy_entropy     | 0.21303058    |
| policy_loss        | 0.00072968006 |
| serial_timesteps   | 7808          |
| time_elapsed       | 288           |
| total_timesteps    | 7808          |
| value_loss         | 5545.0674     |
--------------------------------------
-------------------------------------
| approxkl           | 0.022583904  |
| clipfrac           | 0.26171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -7.15e-07    |
| fps                | 29           |
| n_updates          | 62           |
| policy_entropy     | 0.21195045   |
| policy_loss        | -0.019272754 |
| serial_timesteps   | 7936         |
| time_elapsed       | 292          |
| total_timesteps    | 7936         |
| value_loss         | 2.0653713    |
-------------------------------------
------------------------------------
| approxkl           | 0.004111158 |
| clipfrac           | 0.048828125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.65e+03    |
| explained_variance | 0           |
| fps                | 31          |
| n_updates          | 63          |
| policy_entropy     | 0.2100473   |
| policy_loss        | 0.000608759 |
| serial_timesteps   | 8064        |
| time_elapsed       | 296         |
| total_timesteps    | 8064        |
| value_loss         | 5.947459    |
------------------------------------
--------------------------------------
| approxkl           | 0.015765483   |
| clipfrac           | 0.1796875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | 1.19e-07      |
| fps                | 31            |
| n_updates          | 64            |
| policy_entropy     | 0.20829365    |
| policy_loss        | -0.0055885073 |
| serial_timesteps   | 8192          |
| time_elapsed       | 300           |
| total_timesteps    | 8192          |
| value_loss         | 9.048394      |
--------------------------------------
-------------------------------------
| approxkl           | 0.010550528  |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 1.25e-06     |
| fps                | 31           |
| n_updates          | 65           |
| policy_entropy     | 0.20688152   |
| policy_loss        | 0.0028747641 |
| serial_timesteps   | 8320         |
| time_elapsed       | 305          |
| total_timesteps    | 8320         |
| value_loss         | 6.127658     |
-------------------------------------
-------------------------------------
| approxkl           | 0.011482058  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 66           |
| policy_entropy     | 0.20512342   |
| policy_loss        | -0.008332738 |
| serial_timesteps   | 8448         |
| time_elapsed       | 309          |
| total_timesteps    | 8448         |
| value_loss         | 6.059252     |
-------------------------------------
An average of 214.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.005655733   |
| clipfrac           | 0.076171875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.65e+03      |
| explained_variance | 5.19e-06      |
| fps                | 32            |
| n_updates          | 67            |
| policy_entropy     | 0.20350385    |
| policy_loss        | -0.0042808163 |
| serial_timesteps   | 8576          |
| time_elapsed       | 313           |
| total_timesteps    | 8576          |
| value_loss         | 7.3746276     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01084639   |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -2.57e-05    |
| fps                | 30           |
| n_updates          | 68           |
| policy_entropy     | 0.20201817   |
| policy_loss        | -0.004526644 |
| serial_timesteps   | 8704         |
| time_elapsed       | 317          |
| total_timesteps    | 8704         |
| value_loss         | 3.9512582    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009366797  |
| clipfrac           | 0.13085938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.67e-06    |
| fps                | 32           |
| n_updates          | 69           |
| policy_entropy     | 0.20034811   |
| policy_loss        | -0.005213275 |
| serial_timesteps   | 8832         |
| time_elapsed       | 321          |
| total_timesteps    | 8832         |
| value_loss         | 8.197633     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0061418316 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 1.61e-06     |
| fps                | 29           |
| n_updates          | 70           |
| policy_entropy     | 0.19852972   |
| policy_loss        | 0.007208945  |
| serial_timesteps   | 8960         |
| time_elapsed       | 325          |
| total_timesteps    | 8960         |
| value_loss         | 3.4297304    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0062575946 |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | -1.07e-06    |
| fps                | 28           |
| n_updates          | 71           |
| policy_entropy     | 0.19616744   |
| policy_loss        | 0.0036355758 |
| serial_timesteps   | 9088         |
| time_elapsed       | 329          |
| total_timesteps    | 9088         |
| value_loss         | 5.1207504    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0006480027 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.65e+03     |
| explained_variance | 9.89e-06     |
| fps                | 30           |
| n_updates          | 72           |
| policy_entropy     | 0.1937915    |
| policy_loss        | 0.0034897146 |
| serial_timesteps   | 9216         |
| time_elapsed       | 334          |
| total_timesteps    | 9216         |
| value_loss         | 4.3870416    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008581148  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 4.17e-07     |
| fps                | 29           |
| n_updates          | 73           |
| policy_entropy     | 0.19182096   |
| policy_loss        | -0.015315431 |
| serial_timesteps   | 9344         |
| time_elapsed       | 338          |
| total_timesteps    | 9344         |
| value_loss         | 5736.201     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0051244674 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 1.06e-05     |
| fps                | 31           |
| n_updates          | 74           |
| policy_entropy     | 0.19061941   |
| policy_loss        | -0.00273966  |
| serial_timesteps   | 9472         |
| time_elapsed       | 342          |
| total_timesteps    | 9472         |
| value_loss         | 1.9799086    |
-------------------------------------
An average of 215.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.00848789    |
| clipfrac           | 0.12109375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.66e+03      |
| explained_variance | -1.19e-07     |
| fps                | 29            |
| n_updates          | 75            |
| policy_entropy     | 0.18803608    |
| policy_loss        | 0.00046609365 |
| serial_timesteps   | 9600          |
| time_elapsed       | 346           |
| total_timesteps    | 9600          |
| value_loss         | 3.2796896     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0074327476 |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 76           |
| policy_entropy     | 0.18544674   |
| policy_loss        | 0.0004954494 |
| serial_timesteps   | 9728         |
| time_elapsed       | 351          |
| total_timesteps    | 9728         |
| value_loss         | 13.209999    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006967482  |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 2.03e-06     |
| fps                | 30           |
| n_updates          | 77           |
| policy_entropy     | 0.18363442   |
| policy_loss        | 0.0055011315 |
| serial_timesteps   | 9856         |
| time_elapsed       | 355          |
| total_timesteps    | 9856         |
| value_loss         | 3.549336     |
-------------------------------------
-------------------------------------
| approxkl           | 0.015413495  |
| clipfrac           | 0.20117188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 78           |
| policy_entropy     | 0.18132359   |
| policy_loss        | -0.008339108 |
| serial_timesteps   | 9984         |
| time_elapsed       | 359          |
| total_timesteps    | 9984         |
| value_loss         | 8.054972     |
-------------------------------------
-------------------------------------
| approxkl           | 0.014398857  |
| clipfrac           | 0.1796875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 1.37e-06     |
| fps                | 30           |
| n_updates          | 79           |
| policy_entropy     | 0.18004036   |
| policy_loss        | -0.014190195 |
| serial_timesteps   | 10112        |
| time_elapsed       | 363          |
| total_timesteps    | 10112        |
| value_loss         | 4.0829535    |
-------------------------------------
--------------------------------------
| approxkl           | 0.022085762   |
| clipfrac           | 0.20507812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.66e+03      |
| explained_variance | 3.99e-06      |
| fps                | 31            |
| n_updates          | 80            |
| policy_entropy     | 0.17846431    |
| policy_loss        | -0.0015397179 |
| serial_timesteps   | 10240         |
| time_elapsed       | 367           |
| total_timesteps    | 10240         |
| value_loss         | 4.9771223     |
--------------------------------------
-------------------------------------
| approxkl           | 0.002532957  |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | 1.19e-07     |
| fps                | 30           |
| n_updates          | 81           |
| policy_entropy     | 0.17644176   |
| policy_loss        | 0.0025276844 |
| serial_timesteps   | 10368        |
| time_elapsed       | 371          |
| total_timesteps    | 10368        |
| value_loss         | 4.758216     |
-------------------------------------
-------------------------------------
| approxkl           | 0.009480846  |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | -3.58e-06    |
| fps                | 31           |
| n_updates          | 82           |
| policy_entropy     | 0.17433003   |
| policy_loss        | -0.004648563 |
| serial_timesteps   | 10496        |
| time_elapsed       | 376          |
| total_timesteps    | 10496        |
| value_loss         | 4.773091     |
-------------------------------------
An average of 215.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.008425282 |
| clipfrac           | 0.119140625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.66e+03    |
| explained_variance | 0           |
| fps                | 30          |
| n_updates          | 83          |
| policy_entropy     | 0.17270043  |
| policy_loss        | 0.004141614 |
| serial_timesteps   | 10624       |
| time_elapsed       | 380         |
| total_timesteps    | 10624       |
| value_loss         | 6.523832    |
------------------------------------
-------------------------------------
| approxkl           | 0.0018953811 |
| clipfrac           | 0.013671875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.66e+03     |
| explained_variance | -9.54e-07    |
| fps                | 28           |
| n_updates          | 84           |
| policy_entropy     | 0.17105919   |
| policy_loss        | -0.002295044 |
| serial_timesteps   | 10752        |
| time_elapsed       | 384          |
| total_timesteps    | 10752        |
| value_loss         | 7.2123847    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0020348825 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.67e+03     |
| explained_variance | 1.19e-07     |
| fps                | 30           |
| n_updates          | 85           |
| policy_entropy     | 0.16953576   |
| policy_loss        | 0.0012385149 |
| serial_timesteps   | 10880        |
| time_elapsed       | 388          |
| total_timesteps    | 10880        |
| value_loss         | 5699.8945    |
-------------------------------------
-------------------------------------
| approxkl           | 0.013958648  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.67e+03     |
| explained_variance | -2.62e-06    |
| fps                | 30           |
| n_updates          | 86           |
| policy_entropy     | 0.16871417   |
| policy_loss        | -0.018677909 |
| serial_timesteps   | 11008        |
| time_elapsed       | 393          |
| total_timesteps    | 11008        |
| value_loss         | 5.1614704    |
-------------------------------------
--------------------------------------
| approxkl           | 0.011410429   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.67e+03      |
| explained_variance | 4.35e-06      |
| fps                | 30            |
| n_updates          | 87            |
| policy_entropy     | 0.16755822    |
| policy_loss        | 0.00016273046 |
| serial_timesteps   | 11136         |
| time_elapsed       | 397           |
| total_timesteps    | 11136         |
| value_loss         | 5.236719      |
--------------------------------------
-------------------------------------
| approxkl           | 0.015496986  |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.67e+03     |
| explained_variance | -3.7e-06     |
| fps                | 29           |
| n_updates          | 88           |
| policy_entropy     | 0.16619524   |
| policy_loss        | -0.018525187 |
| serial_timesteps   | 11264        |
| time_elapsed       | 401          |
| total_timesteps    | 11264        |
| value_loss         | 3.8322654    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0037502176  |
| clipfrac           | 0.044921875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.67e+03      |
| explained_variance | -1.19e-07     |
| fps                | 29            |
| n_updates          | 89            |
| policy_entropy     | 0.16431352    |
| policy_loss        | -0.0020152815 |
| serial_timesteps   | 11392         |
| time_elapsed       | 405           |
| total_timesteps    | 11392         |
| value_loss         | 4.324464      |
--------------------------------------
An average of 216.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.0053503686   |
| clipfrac           | 0.076171875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.67e+03       |
| explained_variance | 1.35e-05       |
| fps                | 29             |
| n_updates          | 90             |
| policy_entropy     | 0.16151199     |
| policy_loss        | -0.00028307317 |
| serial_timesteps   | 11520          |
| time_elapsed       | 410            |
| total_timesteps    | 11520          |
| value_loss         | 4.820315       |
---------------------------------------
--------------------------------------
| approxkl           | 0.011312537   |
| clipfrac           | 0.15234375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.67e+03      |
| explained_variance | -1.5e-05      |
| fps                | 30            |
| n_updates          | 91            |
| policy_entropy     | 0.15879215    |
| policy_loss        | -0.0024038632 |
| serial_timesteps   | 11648         |
| time_elapsed       | 414           |
| total_timesteps    | 11648         |
| value_loss         | 2.6949427     |
--------------------------------------
-------------------------------------
| approxkl           | 0.019418249  |
| clipfrac           | 0.21289062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.67e+03     |
| explained_variance | -3.58e-07    |
| fps                | 30           |
| n_updates          | 92           |
| policy_entropy     | 0.15620904   |
| policy_loss        | -0.009226531 |
| serial_timesteps   | 11776        |
| time_elapsed       | 418          |
| total_timesteps    | 11776        |
| value_loss         | 3.2585258    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0052272766 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.67e+03     |
| explained_variance | -2.26e-06    |
| fps                | 30           |
| n_updates          | 93           |
| policy_entropy     | 0.1547259    |
| policy_loss        | 0.002090335  |
| serial_timesteps   | 11904        |
| time_elapsed       | 423          |
| total_timesteps    | 11904        |
| value_loss         | 7.2833734    |
-------------------------------------
------------------------------------
| approxkl           | 0.016363211 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.67e+03    |
| explained_variance | 0           |
| fps                | 31          |
| n_updates          | 94          |
| policy_entropy     | 0.15251446  |
| policy_loss        | 0.016654946 |
| serial_timesteps   | 12032       |
| time_elapsed       | 427         |
| total_timesteps    | 12032       |
| value_loss         | 6.680023    |
------------------------------------
--------------------------------------
| approxkl           | 0.033640817   |
| clipfrac           | 0.27929688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.67e+03      |
| explained_variance | 0             |
| fps                | 30            |
| n_updates          | 95            |
| policy_entropy     | 0.15041894    |
| policy_loss        | -0.0037970352 |
| serial_timesteps   | 12160         |
| time_elapsed       | 431           |
| total_timesteps    | 12160         |
| value_loss         | 4.169582      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0038482475 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.67e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 96           |
| policy_entropy     | 0.14777407   |
| policy_loss        | 0.0024295973 |
| serial_timesteps   | 12288        |
| time_elapsed       | 435          |
| total_timesteps    | 12288        |
| value_loss         | 6.3690386    |
-------------------------------------
-----------------------------------
| approxkl           | 0.03303613 |
| clipfrac           | 0.3828125  |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 6.68e+03   |
| explained_variance | 0          |
| fps                | 31         |
| n_updates          | 97         |
| policy_entropy     | 0.14543673 |
| policy_loss        | 0.00228691 |
| serial_timesteps   | 12416      |
| time_elapsed       | 439        |
| total_timesteps    | 12416      |
| value_loss         | 5730.9077  |
-----------------------------------
An average of 217.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0072347387 |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.68e+03     |
| explained_variance | -2.5e-06     |
| fps                | 30           |
| n_updates          | 98           |
| policy_entropy     | 0.14459899   |
| policy_loss        | -0.011193568 |
| serial_timesteps   | 12544        |
| time_elapsed       | 443          |
| total_timesteps    | 12544        |
| value_loss         | 7.90039      |
-------------------------------------
-------------------------------------
| approxkl           | 0.0044904486 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.68e+03     |
| explained_variance | -2.03e-06    |
| fps                | 29           |
| n_updates          | 99           |
| policy_entropy     | 0.14330903   |
| policy_loss        | 0.004701855  |
| serial_timesteps   | 12672        |
| time_elapsed       | 448          |
| total_timesteps    | 12672        |
| value_loss         | 4.041963     |
-------------------------------------
--------------------------------------
| approxkl           | 0.015496401   |
| clipfrac           | 0.19335938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.68e+03      |
| explained_variance | 0             |
| fps                | 28            |
| n_updates          | 100           |
| policy_entropy     | 0.14064917    |
| policy_loss        | -0.0069738072 |
| serial_timesteps   | 12800         |
| time_elapsed       | 452           |
| total_timesteps    | 12800         |
| value_loss         | 3.628464      |
--------------------------------------
-------------------------------------
| approxkl           | 0.01601482   |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.68e+03     |
| explained_variance | 0            |
| fps                | 30           |
| n_updates          | 101          |
| policy_entropy     | 0.13875961   |
| policy_loss        | -0.007125673 |
| serial_timesteps   | 12928        |
| time_elapsed       | 456          |
| total_timesteps    | 12928        |
| value_loss         | 7.730479     |
-------------------------------------
-------------------------------------
| approxkl           | 0.010200698  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.68e+03     |
| explained_variance | -6.79e-06    |
| fps                | 29           |
| n_updates          | 102          |
| policy_entropy     | 0.13741425   |
| policy_loss        | 0.0008296167 |
| serial_timesteps   | 13056        |
| time_elapsed       | 461          |
| total_timesteps    | 13056        |
| value_loss         | 7.2446537    |
-------------------------------------
------------------------------------
| approxkl           | 0.020748109 |
| clipfrac           | 0.1953125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.68e+03    |
| explained_variance | 0           |
| fps                | 31          |
| n_updates          | 103         |
| policy_entropy     | 0.13569322  |
| policy_loss        | 0.002316992 |
| serial_timesteps   | 13184       |
| time_elapsed       | 465         |
| total_timesteps    | 13184       |
| value_loss         | 3.520205    |
------------------------------------
------------------------------------
| approxkl           | 0.008599921 |
| clipfrac           | 0.103515625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.68e+03    |
| explained_variance | 5.07e-06    |
| fps                | 30          |
| n_updates          | 104         |
| policy_entropy     | 0.13371627  |
| policy_loss        | 0.004364449 |
| serial_timesteps   | 13312       |
| time_elapsed       | 469         |
| total_timesteps    | 13312       |
| value_loss         | 4.7424254   |
------------------------------------
--------------------------------------
| approxkl           | 0.02675769    |
| clipfrac           | 0.24414062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.68e+03      |
| explained_variance | -3.58e-07     |
| fps                | 29            |
| n_updates          | 105           |
| policy_entropy     | 0.13183594    |
| policy_loss        | 0.00014758855 |
| serial_timesteps   | 13440         |
| time_elapsed       | 473           |
| total_timesteps    | 13440         |
| value_loss         | 5.9145217     |
--------------------------------------
An average of 217.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.009390207   |
| clipfrac           | 0.12109375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.68e+03      |
| explained_variance | -5.96e-07     |
| fps                | 31            |
| n_updates          | 106           |
| policy_entropy     | 0.13025773    |
| policy_loss        | -0.0038914748 |
| serial_timesteps   | 13568         |
| time_elapsed       | 477           |
| total_timesteps    | 13568         |
| value_loss         | 3.916473      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008727113  |
| clipfrac           | 0.12109375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.68e+03     |
| explained_variance | -2.25e-05    |
| fps                | 29           |
| n_updates          | 107          |
| policy_entropy     | 0.12702507   |
| policy_loss        | -0.004346137 |
| serial_timesteps   | 13696        |
| time_elapsed       | 482          |
| total_timesteps    | 13696        |
| value_loss         | 3.6365595    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0057111983 |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.68e+03     |
| explained_variance | -1.19e-07    |
| fps                | 30           |
| n_updates          | 108          |
| policy_entropy     | 0.1236278    |
| policy_loss        | 0.0018235769 |
| serial_timesteps   | 13824        |
| time_elapsed       | 486          |
| total_timesteps    | 13824        |
| value_loss         | 6.756739     |
-------------------------------------
------------------------------------
| approxkl           | 0.10300851  |
| clipfrac           | 0.5292969   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.69e+03    |
| explained_variance | 0           |
| fps                | 31          |
| n_updates          | 109         |
| policy_entropy     | 0.120183036 |
| policy_loss        | 0.043440454 |
| serial_timesteps   | 13952       |
| time_elapsed       | 490         |
| total_timesteps    | 13952       |
| value_loss         | 5815.983    |
------------------------------------
------------------------------------
| approxkl           | 0.016656954 |
| clipfrac           | 0.2265625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.69e+03    |
| explained_variance | -3.58e-07   |
| fps                | 30          |
| n_updates          | 110         |
| policy_entropy     | 0.118681155 |
| policy_loss        | -0.02172707 |
| serial_timesteps   | 14080       |
| time_elapsed       | 494         |
| total_timesteps    | 14080       |
| value_loss         | 1.4668015   |
------------------------------------
-------------------------------------
| approxkl           | 0.019939523  |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | 2.44e-06     |
| fps                | 31           |
| n_updates          | 111          |
| policy_entropy     | 0.117446505  |
| policy_loss        | 0.0070818732 |
| serial_timesteps   | 14208        |
| time_elapsed       | 498          |
| total_timesteps    | 14208        |
| value_loss         | 2.3344529    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0207815    |
| clipfrac           | 0.27734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | 1.19e-07     |
| fps                | 29           |
| n_updates          | 112          |
| policy_entropy     | 0.116357855  |
| policy_loss        | -0.029196138 |
| serial_timesteps   | 14336        |
| time_elapsed       | 503          |
| total_timesteps    | 14336        |
| value_loss         | 2.282038     |
-------------------------------------
-------------------------------------
| approxkl           | 0.012214678  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | 1.19e-07     |
| fps                | 31           |
| n_updates          | 113          |
| policy_entropy     | 0.11480317   |
| policy_loss        | -0.005939898 |
| serial_timesteps   | 14464        |
| time_elapsed       | 507          |
| total_timesteps    | 14464        |
| value_loss         | 4.3461967    |
-------------------------------------
An average of 218.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.01659242   |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | 5.96e-08     |
| fps                | 31           |
| n_updates          | 114          |
| policy_entropy     | 0.11291061   |
| policy_loss        | -0.021006122 |
| serial_timesteps   | 14592        |
| time_elapsed       | 511          |
| total_timesteps    | 14592        |
| value_loss         | 3.9720016    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008022825  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | 0            |
| fps                | 31           |
| n_updates          | 115          |
| policy_entropy     | 0.11059434   |
| policy_loss        | 0.0048501343 |
| serial_timesteps   | 14720        |
| time_elapsed       | 515          |
| total_timesteps    | 14720        |
| value_loss         | 1.5385427    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01225769   |
| clipfrac           | 0.1640625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | -2.98e-06    |
| fps                | 31           |
| n_updates          | 116          |
| policy_entropy     | 0.107833326  |
| policy_loss        | -0.007955137 |
| serial_timesteps   | 14848        |
| time_elapsed       | 519          |
| total_timesteps    | 14848        |
| value_loss         | 2.4958377    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011853503  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.69e+03     |
| explained_variance | 0            |
| fps                | 29           |
| n_updates          | 117          |
| policy_entropy     | 0.10566359   |
| policy_loss        | 0.0034503222 |
| serial_timesteps   | 14976        |
| time_elapsed       | 523          |
| total_timesteps    | 14976        |
| value_loss         | 3.2208142    |
-------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b480c6978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b480c6978>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b467f64a8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b467f64a8>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2822 samples, validate on 325 samples
Epoch 401/5000
 - 8s - loss: 0.4096 - val_loss: 0.3153
Epoch 402/5000
 - 1s - loss: 0.4096 - val_loss: 0.3153
Epoch 403/5000
 - 1s - loss: 0.4096 - val_loss: 0.3153
Epoch 404/5000
 - 1s - loss: 0.4096 - val_loss: 0.3153
Epoch 405/5000
 - 1s - loss: 0.4096 - val_loss: 0.3153
Epoch 406/5000
 - 1s - loss: 0.4096 - val_loss: 0.3153
Train on 1756 samples, validate on 325 samples
Epoch 298/5000
 - 8s - loss: 0.0019 - val_loss: 0.0020
Epoch 299/5000
 - 0s - loss: 0.0014 - val_loss: 0.0017
Epoch 300/5000
 - 0s - loss: 0.0012 - val_loss: 0.0016
Epoch 301/5000
 - 0s - loss: 0.0011 - val_loss: 0.0018
Epoch 302/5000
 - 0s - loss: 9.0995e-04 - val_loss: 0.0016
Epoch 303/5000
 - 0s - loss: 8.8225e-04 - val_loss: 0.0015
Epoch 304/5000
 - 0s - loss: 8.6990e-04 - val_loss: 0.0014
Epoch 305/5000
 - 0s - loss: 8.5975e-04 - val_loss: 0.0014
Epoch 306/5000
 - 1s - loss: 8.2893e-04 - val_loss: 0.0014
Epoch 307/5000
 - 1s - loss: 8.2787e-04 - val_loss: 0.0014
Epoch 308/5000
 - 0s - loss: 8.2678e-04 - val_loss: 0.0014
Epoch 309/5000
 - 1s - loss: 8.2574e-04 - val_loss: 0.0014
Epoch 310/5000
 - 0s - loss: 8.2470e-04 - val_loss: 0.0014
Epoch 311/5000
 - 1s - loss: 8.2132e-04 - val_loss: 0.0014
Epoch 312/5000
 - 1s - loss: 8.2122e-04 - val_loss: 0.0014
Epoch 313/5000
 - 1s - loss: 8.2111e-04 - val_loss: 0.0014
Epoch 314/5000
 - 1s - loss: 8.2100e-04 - val_loss: 0.0014
Epoch 315/5000
 - 1s - loss: 8.2066e-04 - val_loss: 0.0014
Epoch 316/5000
 - 1s - loss: 8.2065e-04 - val_loss: 0.0014
Epoch 317/5000
 - 0s - loss: 8.2063e-04 - val_loss: 0.0014
Epoch 318/5000
 - 1s - loss: 8.2062e-04 - val_loss: 0.0014
Epoch 319/5000
 - 1s - loss: 8.2059e-04 - val_loss: 0.0014
Epoch 320/5000
 - 0s - loss: 8.2059e-04 - val_loss: 0.0014
Epoch 321/5000
 - 0s - loss: 8.2059e-04 - val_loss: 0.0014
Epoch 322/5000
 - 1s - loss: 8.2059e-04 - val_loss: 0.0014
Epoch 323/5000
 - 1s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 324/5000
 - 0s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 325/5000
 - 0s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 326/5000
 - 1s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 327/5000
 - 1s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 328/5000
 - 1s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 329/5000
 - 1s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 330/5000
 - 1s - loss: 8.2058e-04 - val_loss: 0.0014
Epoch 331/5000
 - 0s - loss: 8.2058e-04 - val_loss: 0.0014
Train on 2822 samples, validate on 325 samples
Epoch 1082/5000
 - 9s - loss: 0.6898 - val_loss: 0.6624
Epoch 1083/5000
 - 1s - loss: 0.6772 - val_loss: 0.6255
Epoch 1084/5000
 - 1s - loss: 0.6670 - val_loss: 0.5747
Epoch 1085/5000
 - 1s - loss: 0.6607 - val_loss: 0.5521
Epoch 1086/5000
 - 1s - loss: 0.6593 - val_loss: 0.5418
Epoch 1087/5000
 - 1s - loss: 0.6589 - val_loss: 0.5368
Epoch 1088/5000
 - 1s - loss: 0.6587 - val_loss: 0.5343
Epoch 1089/5000
 - 1s - loss: 0.6586 - val_loss: 0.5329
Epoch 1090/5000
 - 1s - loss: 0.6585 - val_loss: 0.5322
Epoch 1091/5000
 - 1s - loss: 0.6584 - val_loss: 0.5318
Epoch 1092/5000
 - 1s - loss: 0.6583 - val_loss: 0.5315
Epoch 1093/5000
 - 1s - loss: 0.6582 - val_loss: 0.5314
Epoch 1094/5000
 - 1s - loss: 0.6582 - val_loss: 0.5313
Epoch 1095/5000
 - 1s - loss: 0.6581 - val_loss: 0.5312
Epoch 1096/5000
 - 1s - loss: 0.6580 - val_loss: 0.5312
Epoch 1097/5000
 - 1s - loss: 0.6580 - val_loss: 0.5312
Epoch 1098/5000
 - 1s - loss: 0.6539 - val_loss: 0.5312
Epoch 1099/5000
 - 1s - loss: 0.6539 - val_loss: 0.5312
Epoch 1100/5000
 - 1s - loss: 0.6539 - val_loss: 0.5313
Epoch 1101/5000
 - 1s - loss: 0.6539 - val_loss: 0.5313
Epoch 1102/5000
 - 1s - loss: 0.6535 - val_loss: 0.5313
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0045730593 |
| clipfrac           | 0.0625       |
| explained_variance | 5.96e-08     |
| fps                | 3            |
| n_updates          | 1            |
| policy_entropy     | 0.103881955  |
| policy_loss        | 0.0038957493 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.34e-05     |
| total_timesteps    | 128          |
| value_loss         | 10.465454    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0041275946   |
| clipfrac           | 0.05859375     |
| explained_variance | 3.58e-07       |
| fps                | 22             |
| n_updates          | 2              |
| policy_entropy     | 0.10245024     |
| policy_loss        | -0.00024269032 |
| serial_timesteps   | 256            |
| time_elapsed       | 39.2           |
| total_timesteps    | 256            |
| value_loss         | 9.603416       |
---------------------------------------
---------------------------------------
| approxkl           | 0.008001825    |
| clipfrac           | 0.109375       |
| explained_variance | -7.15e-07      |
| fps                | 22             |
| n_updates          | 3              |
| policy_entropy     | 0.10082937     |
| policy_loss        | -0.00081669656 |
| serial_timesteps   | 384            |
| time_elapsed       | 45             |
| total_timesteps    | 384            |
| value_loss         | 8.055996       |
---------------------------------------
-------------------------------------
| approxkl           | 0.019261703  |
| clipfrac           | 0.234375     |
| explained_variance | -1.55e-06    |
| fps                | 22           |
| n_updates          | 4            |
| policy_entropy     | 0.098354556  |
| policy_loss        | -0.010045882 |
| serial_timesteps   | 512          |
| time_elapsed       | 50.7         |
| total_timesteps    | 512          |
| value_loss         | 11.821151    |
-------------------------------------
An average of 219.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0061942395 |
| clipfrac           | 0.0859375    |
| explained_variance | 0            |
| fps                | 21           |
| n_updates          | 5            |
| policy_entropy     | 0.09666424   |
| policy_loss        | -0.003508118 |
| serial_timesteps   | 640          |
| time_elapsed       | 56.3         |
| total_timesteps    | 640          |
| value_loss         | 10.520642    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02604746   |
| clipfrac           | 0.25390625   |
| explained_variance | -5.01e-06    |
| fps                | 22           |
| n_updates          | 6            |
| policy_entropy     | 0.09468118   |
| policy_loss        | 0.0013990614 |
| serial_timesteps   | 768          |
| time_elapsed       | 62.3         |
| total_timesteps    | 768          |
| value_loss         | 8.321321     |
-------------------------------------
-------------------------------------
| approxkl           | 0.010622061  |
| clipfrac           | 0.1328125    |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 7            |
| policy_entropy     | 0.09315166   |
| policy_loss        | 0.0063113514 |
| serial_timesteps   | 896          |
| time_elapsed       | 68           |
| total_timesteps    | 896          |
| value_loss         | 5.4915986    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0030584354  |
| clipfrac           | 0.033203125   |
| explained_variance | -1.19e-07     |
| fps                | 22            |
| n_updates          | 8             |
| policy_entropy     | 0.09094027    |
| policy_loss        | -0.0003289549 |
| serial_timesteps   | 1024          |
| time_elapsed       | 73.8          |
| total_timesteps    | 1024          |
| value_loss         | 13.295266     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0032255112 |
| clipfrac           | 0.041015625  |
| explained_variance | 1.19e-07     |
| fps                | 21           |
| n_updates          | 9            |
| policy_entropy     | 0.088708304  |
| policy_loss        | 0.0010509883 |
| serial_timesteps   | 1152         |
| time_elapsed       | 79.4         |
| total_timesteps    | 1152         |
| value_loss         | 9.085867     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0121074235 |
| clipfrac           | 0.16601562   |
| explained_variance | -1.79e-06    |
| fps                | 21           |
| n_updates          | 10           |
| policy_entropy     | 0.08666132   |
| policy_loss        | -0.014219378 |
| serial_timesteps   | 1280         |
| time_elapsed       | 85.4         |
| total_timesteps    | 1280         |
| value_loss         | 14.053805    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021108743  |
| clipfrac           | 0.234375     |
| explained_variance | -5.96e-07    |
| fps                | 23           |
| n_updates          | 11           |
| policy_entropy     | 0.08563711   |
| policy_loss        | 0.0034210798 |
| serial_timesteps   | 1408         |
| time_elapsed       | 91.4         |
| total_timesteps    | 1408         |
| value_loss         | 8.867123     |
-------------------------------------
An average of 219.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0082751755 |
| clipfrac           | 0.12890625   |
| explained_variance | -2.98e-06    |
| fps                | 21           |
| n_updates          | 12           |
| policy_entropy     | 0.08492489   |
| policy_loss        | 0.0022723167 |
| serial_timesteps   | 1536         |
| time_elapsed       | 96.8         |
| total_timesteps    | 1536         |
| value_loss         | 5.33354      |
-------------------------------------
-------------------------------------
| approxkl           | 0.0081632845 |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 13           |
| policy_entropy     | 0.0834317    |
| policy_loss        | 0.014055178  |
| serial_timesteps   | 1664         |
| time_elapsed       | 103          |
| total_timesteps    | 1664         |
| value_loss         | 3725.4485    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023141261  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 1.75e-05     |
| fps                | 22           |
| n_updates          | 14           |
| policy_entropy     | 0.08289789   |
| policy_loss        | -0.008419589 |
| serial_timesteps   | 1792         |
| time_elapsed       | 108          |
| total_timesteps    | 1792         |
| value_loss         | 11.813856    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02160551   |
| clipfrac           | 0.24023438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -7.51e-06    |
| fps                | 22           |
| n_updates          | 15           |
| policy_entropy     | 0.08249885   |
| policy_loss        | -0.021332651 |
| serial_timesteps   | 1920         |
| time_elapsed       | 114          |
| total_timesteps    | 1920         |
| value_loss         | 6.5953364    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0515444    |
| clipfrac           | 0.41992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 1.79e-07     |
| fps                | 21           |
| n_updates          | 16           |
| policy_entropy     | 0.0816193    |
| policy_loss        | -0.032414213 |
| serial_timesteps   | 2048         |
| time_elapsed       | 120          |
| total_timesteps    | 2048         |
| value_loss         | 1.2814866    |
-------------------------------------
--------------------------------------
| approxkl           | 0.01913434    |
| clipfrac           | 0.21289062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.97e+03      |
| explained_variance | -2.15e-06     |
| fps                | 21            |
| n_updates          | 17            |
| policy_entropy     | 0.080604635   |
| policy_loss        | -0.0068339407 |
| serial_timesteps   | 2176          |
| time_elapsed       | 126           |
| total_timesteps    | 2176          |
| value_loss         | 10.94262      |
--------------------------------------
-------------------------------------
| approxkl           | 0.013729904  |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 1.19e-07     |
| fps                | 22           |
| n_updates          | 18           |
| policy_entropy     | 0.07930838   |
| policy_loss        | -0.009103135 |
| serial_timesteps   | 2304         |
| time_elapsed       | 132          |
| total_timesteps    | 2304         |
| value_loss         | 16.762848    |
-------------------------------------
-------------------------------------
| approxkl           | 0.013951538  |
| clipfrac           | 0.19140625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -5.6e-06     |
| fps                | 22           |
| n_updates          | 19           |
| policy_entropy     | 0.07822004   |
| policy_loss        | -0.015700433 |
| serial_timesteps   | 2432         |
| time_elapsed       | 137          |
| total_timesteps    | 2432         |
| value_loss         | 8.668135     |
-------------------------------------
An average of 220.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.014418406  |
| clipfrac           | 0.1796875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 1.19e-07     |
| fps                | 21           |
| n_updates          | 20           |
| policy_entropy     | 0.0771375    |
| policy_loss        | 0.0062850183 |
| serial_timesteps   | 2560         |
| time_elapsed       | 143          |
| total_timesteps    | 2560         |
| value_loss         | 4.9927692    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014289442  |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -3.58e-07    |
| fps                | 21           |
| n_updates          | 21           |
| policy_entropy     | 0.075992405  |
| policy_loss        | -0.008752597 |
| serial_timesteps   | 2688         |
| time_elapsed       | 149          |
| total_timesteps    | 2688         |
| value_loss         | 2.389216     |
-------------------------------------
-------------------------------------
| approxkl           | 0.015103586  |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -3.93e-06    |
| fps                | 22           |
| n_updates          | 22           |
| policy_entropy     | 0.07427642   |
| policy_loss        | -0.012266922 |
| serial_timesteps   | 2816         |
| time_elapsed       | 155          |
| total_timesteps    | 2816         |
| value_loss         | 4.8537602    |
-------------------------------------
--------------------------------------
| approxkl           | 0.010434226   |
| clipfrac           | 0.15039062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.97e+03      |
| explained_variance | -2.38e-06     |
| fps                | 22            |
| n_updates          | 23            |
| policy_entropy     | 0.072333716   |
| policy_loss        | -0.0109761935 |
| serial_timesteps   | 2944          |
| time_elapsed       | 160           |
| total_timesteps    | 2944          |
| value_loss         | 11.6871805    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0033106187  |
| clipfrac           | 0.0390625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.97e+03      |
| explained_variance | 1.79e-07      |
| fps                | 21            |
| n_updates          | 24            |
| policy_entropy     | 0.070476554   |
| policy_loss        | -0.0044110534 |
| serial_timesteps   | 3072          |
| time_elapsed       | 166           |
| total_timesteps    | 3072          |
| value_loss         | 9.556031      |
--------------------------------------
------------------------------------
| approxkl           | 0.10737808  |
| clipfrac           | 0.6074219   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | 0           |
| fps                | 23          |
| n_updates          | 25          |
| policy_entropy     | 0.06902031  |
| policy_loss        | 0.046754297 |
| serial_timesteps   | 3200        |
| time_elapsed       | 172         |
| total_timesteps    | 3200        |
| value_loss         | 5168.2646   |
------------------------------------
------------------------------------
| approxkl           | 0.014523545 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | -3.58e-07   |
| fps                | 23          |
| n_updates          | 26          |
| policy_entropy     | 0.06811607  |
| policy_loss        | 0.015236481 |
| serial_timesteps   | 3328        |
| time_elapsed       | 178         |
| total_timesteps    | 3328        |
| value_loss         | 5.146762    |
------------------------------------
-------------------------------------
| approxkl           | 0.014180942  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 5.96e-08     |
| fps                | 22           |
| n_updates          | 27           |
| policy_entropy     | 0.06676107   |
| policy_loss        | 6.068207e-05 |
| serial_timesteps   | 3456         |
| time_elapsed       | 183          |
| total_timesteps    | 3456         |
| value_loss         | 15.650171    |
-------------------------------------
An average of 221.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.025426311  |
| clipfrac           | 0.26367188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -1.79e-06    |
| fps                | 22           |
| n_updates          | 28           |
| policy_entropy     | 0.06586909   |
| policy_loss        | -0.017511189 |
| serial_timesteps   | 3584         |
| time_elapsed       | 189          |
| total_timesteps    | 3584         |
| value_loss         | 9.7213125    |
-------------------------------------
------------------------------------
| approxkl           | 0.005124131 |
| clipfrac           | 0.0625      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | -1.79e-06   |
| fps                | 21          |
| n_updates          | 29          |
| policy_entropy     | 0.06464922  |
| policy_loss        | 0.004791654 |
| serial_timesteps   | 3712        |
| time_elapsed       | 195         |
| total_timesteps    | 3712        |
| value_loss         | 10.628998   |
------------------------------------
-------------------------------------
| approxkl           | 0.027072482  |
| clipfrac           | 0.27148438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -9.54e-07    |
| fps                | 22           |
| n_updates          | 30           |
| policy_entropy     | 0.06358697   |
| policy_loss        | -0.012488836 |
| serial_timesteps   | 3840         |
| time_elapsed       | 200          |
| total_timesteps    | 3840         |
| value_loss         | 10.341032    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087580355 |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -1.19e-07    |
| fps                | 22           |
| n_updates          | 31           |
| policy_entropy     | 0.06252955   |
| policy_loss        | -0.010343019 |
| serial_timesteps   | 3968         |
| time_elapsed       | 206          |
| total_timesteps    | 3968         |
| value_loss         | 5.8814225    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077150655 |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 7.15e-07     |
| fps                | 22           |
| n_updates          | 32           |
| policy_entropy     | 0.06039995   |
| policy_loss        | -0.012039665 |
| serial_timesteps   | 4096         |
| time_elapsed       | 212          |
| total_timesteps    | 4096         |
| value_loss         | 7.6070247    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0061039515 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 2.86e-06     |
| fps                | 22           |
| n_updates          | 33           |
| policy_entropy     | 0.057397716  |
| policy_loss        | -0.008447671 |
| serial_timesteps   | 4224         |
| time_elapsed       | 217          |
| total_timesteps    | 4224         |
| value_loss         | 5.3561554    |
-------------------------------------
-------------------------------------
| approxkl           | 0.026579816  |
| clipfrac           | 0.28515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 4.35e-06     |
| fps                | 22           |
| n_updates          | 34           |
| policy_entropy     | 0.05436962   |
| policy_loss        | 0.0011956393 |
| serial_timesteps   | 4352         |
| time_elapsed       | 223          |
| total_timesteps    | 4352         |
| value_loss         | 7.288503     |
-------------------------------------
-------------------------------------
| approxkl           | 0.02515874   |
| clipfrac           | 0.25390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -6.68e-06    |
| fps                | 22           |
| n_updates          | 35           |
| policy_entropy     | 0.053956106  |
| policy_loss        | -0.012869376 |
| serial_timesteps   | 4480         |
| time_elapsed       | 229          |
| total_timesteps    | 4480         |
| value_loss         | 3.8258052    |
-------------------------------------
An average of 221.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.020773435 |
| clipfrac           | 0.23046875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | 1.79e-06    |
| fps                | 22          |
| n_updates          | 36          |
| policy_entropy     | 0.053517967 |
| policy_loss        | 0.012555613 |
| serial_timesteps   | 4608        |
| time_elapsed       | 234         |
| total_timesteps    | 4608        |
| value_loss         | 7.2839904   |
------------------------------------
------------------------------------
| approxkl           | 0.046400614 |
| clipfrac           | 0.41210938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | 0           |
| fps                | 23          |
| n_updates          | 37          |
| policy_entropy     | 0.052642882 |
| policy_loss        | 0.019224832 |
| serial_timesteps   | 4736        |
| time_elapsed       | 240         |
| total_timesteps    | 4736        |
| value_loss         | 5678.6855   |
------------------------------------
-------------------------------------
| approxkl           | 0.0329409    |
| clipfrac           | 0.33789062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 1.19e-07     |
| fps                | 22           |
| n_updates          | 38           |
| policy_entropy     | 0.052456096  |
| policy_loss        | -0.037010096 |
| serial_timesteps   | 4864         |
| time_elapsed       | 246          |
| total_timesteps    | 4864         |
| value_loss         | 3.7659235    |
-------------------------------------
--------------------------------------
| approxkl           | 0.014424173   |
| clipfrac           | 0.1875        |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 2.26e-06      |
| fps                | 21            |
| n_updates          | 39            |
| policy_entropy     | 0.052331075   |
| policy_loss        | -0.0038101948 |
| serial_timesteps   | 4992          |
| time_elapsed       | 251           |
| total_timesteps    | 4992          |
| value_loss         | 4.0190563     |
--------------------------------------
-------------------------------------
| approxkl           | 0.030714285  |
| clipfrac           | 0.27929688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 1.67e-06     |
| fps                | 22           |
| n_updates          | 40           |
| policy_entropy     | 0.052071743  |
| policy_loss        | -0.025413007 |
| serial_timesteps   | 5120         |
| time_elapsed       | 257          |
| total_timesteps    | 5120         |
| value_loss         | 0.6481937    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03719779   |
| clipfrac           | 0.3671875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 7.75e-07     |
| fps                | 23           |
| n_updates          | 41           |
| policy_entropy     | 0.052364156  |
| policy_loss        | -0.027403796 |
| serial_timesteps   | 5248         |
| time_elapsed       | 263          |
| total_timesteps    | 5248         |
| value_loss         | 0.9216968    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011885573  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -1.31e-06    |
| fps                | 21           |
| n_updates          | 42           |
| policy_entropy     | 0.051674537  |
| policy_loss        | -0.009188502 |
| serial_timesteps   | 5376         |
| time_elapsed       | 269          |
| total_timesteps    | 5376         |
| value_loss         | 5.217872     |
-------------------------------------
--------------------------------------
| approxkl           | 0.011539208   |
| clipfrac           | 0.13476562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 4.17e-07      |
| fps                | 22            |
| n_updates          | 43            |
| policy_entropy     | 0.050023578   |
| policy_loss        | -0.0044839336 |
| serial_timesteps   | 5504          |
| time_elapsed       | 274           |
| total_timesteps    | 5504          |
| value_loss         | 4.243009      |
--------------------------------------
An average of 222.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0026844267  |
| clipfrac           | 0.025390625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 0             |
| fps                | 20            |
| n_updates          | 44            |
| policy_entropy     | 0.047929354   |
| policy_loss        | -0.0018136003 |
| serial_timesteps   | 5632          |
| time_elapsed       | 280           |
| total_timesteps    | 5632          |
| value_loss         | 6.761295      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0036891745 |
| clipfrac           | 0.05078125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 45           |
| policy_entropy     | 0.045443036  |
| policy_loss        | 0.005961666  |
| serial_timesteps   | 5760         |
| time_elapsed       | 286          |
| total_timesteps    | 5760         |
| value_loss         | 5.258603     |
-------------------------------------
------------------------------------
| approxkl           | 0.007645209 |
| clipfrac           | 0.10546875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | 6.08e-06    |
| fps                | 22          |
| n_updates          | 46          |
| policy_entropy     | 0.042541876 |
| policy_loss        | 0.006837546 |
| serial_timesteps   | 5888        |
| time_elapsed       | 292         |
| total_timesteps    | 5888        |
| value_loss         | 6.531259    |
------------------------------------
------------------------------------
| approxkl           | 0.009449388 |
| clipfrac           | 0.13476562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -1.19e-07   |
| fps                | 23          |
| n_updates          | 47          |
| policy_entropy     | 0.039782815 |
| policy_loss        | 0.008305823 |
| serial_timesteps   | 6016        |
| time_elapsed       | 298         |
| total_timesteps    | 6016        |
| value_loss         | 9.532093    |
------------------------------------
--------------------------------------
| approxkl           | 0.005304704   |
| clipfrac           | 0.068359375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | -2.38e-07     |
| fps                | 22            |
| n_updates          | 48            |
| policy_entropy     | 0.03739743    |
| policy_loss        | -0.0040391725 |
| serial_timesteps   | 6144          |
| time_elapsed       | 303           |
| total_timesteps    | 6144          |
| value_loss         | 8.656625      |
--------------------------------------
------------------------------------
| approxkl           | 0.06270816  |
| clipfrac           | 0.43945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 1.79e-07    |
| fps                | 23          |
| n_updates          | 49          |
| policy_entropy     | 0.034147687 |
| policy_loss        | 0.027500961 |
| serial_timesteps   | 6272        |
| time_elapsed       | 309         |
| total_timesteps    | 6272        |
| value_loss         | 5894.6943   |
------------------------------------
--------------------------------------
| approxkl           | 0.006863773   |
| clipfrac           | 0.08984375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 0             |
| fps                | 24            |
| n_updates          | 50            |
| policy_entropy     | 0.0326209     |
| policy_loss        | -0.0057548014 |
| serial_timesteps   | 6400          |
| time_elapsed       | 315           |
| total_timesteps    | 6400          |
| value_loss         | 8.259428      |
--------------------------------------
------------------------------------
| approxkl           | 0.011399392 |
| clipfrac           | 0.1484375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 7.81e-06    |
| fps                | 22          |
| n_updates          | 51          |
| policy_entropy     | 0.030781701 |
| policy_loss        | -0.00573364 |
| serial_timesteps   | 6528        |
| time_elapsed       | 320         |
| total_timesteps    | 6528        |
| value_loss         | 5.732163    |
------------------------------------
An average of 223.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0076805237 |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -3.46e-06    |
| fps                | 21           |
| n_updates          | 52           |
| policy_entropy     | 0.028306901  |
| policy_loss        | 0.00430736   |
| serial_timesteps   | 6656         |
| time_elapsed       | 325          |
| total_timesteps    | 6656         |
| value_loss         | 7.004922     |
-------------------------------------
-------------------------------------
| approxkl           | 0.015655717  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -8.94e-06    |
| fps                | 22           |
| n_updates          | 53           |
| policy_entropy     | 0.025624692  |
| policy_loss        | -0.007630651 |
| serial_timesteps   | 6784         |
| time_elapsed       | 331          |
| total_timesteps    | 6784         |
| value_loss         | 5.2841887    |
-------------------------------------
-------------------------------------
| approxkl           | 0.018993147  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -4.05e-06    |
| fps                | 22           |
| n_updates          | 54           |
| policy_entropy     | 0.023391739  |
| policy_loss        | 0.0034628436 |
| serial_timesteps   | 6912         |
| time_elapsed       | 337          |
| total_timesteps    | 6912         |
| value_loss         | 3.9981282    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0026274817 |
| clipfrac           | 0.005859375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 6.02e-06     |
| fps                | 22           |
| n_updates          | 55           |
| policy_entropy     | 0.02135288   |
| policy_loss        | 0.0018778846 |
| serial_timesteps   | 7040         |
| time_elapsed       | 343          |
| total_timesteps    | 7040         |
| value_loss         | 5.8809824    |
-------------------------------------
-------------------------------------
| approxkl           | 0.012534819  |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -2.03e-06    |
| fps                | 21           |
| n_updates          | 56           |
| policy_entropy     | 0.01872506   |
| policy_loss        | 0.0039454126 |
| serial_timesteps   | 7168         |
| time_elapsed       | 348          |
| total_timesteps    | 7168         |
| value_loss         | 6.600787     |
-------------------------------------
------------------------------------
| approxkl           | 0.010881275 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 0           |
| fps                | 21          |
| n_updates          | 57          |
| policy_entropy     | 0.016796693 |
| policy_loss        | 0.008786947 |
| serial_timesteps   | 7296        |
| time_elapsed       | 354         |
| total_timesteps    | 7296        |
| value_loss         | 5.7972875   |
------------------------------------
-------------------------------------
| approxkl           | 0.073833235  |
| clipfrac           | 0.46484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -3.58e-07    |
| fps                | 21           |
| n_updates          | 58           |
| policy_entropy     | 0.015741117  |
| policy_loss        | -0.027411487 |
| serial_timesteps   | 7424         |
| time_elapsed       | 360          |
| total_timesteps    | 7424         |
| value_loss         | 0.28793284   |
-------------------------------------
An average of 223.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.014754799  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 3.4e-06      |
| fps                | 22           |
| n_updates          | 59           |
| policy_entropy     | 0.014434189  |
| policy_loss        | -0.008803535 |
| serial_timesteps   | 7552         |
| time_elapsed       | 366          |
| total_timesteps    | 7552         |
| value_loss         | 2.3259306    |
-------------------------------------
------------------------------------
| approxkl           | 0.01228715  |
| clipfrac           | 0.16992188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 1.19e-07    |
| fps                | 22          |
| n_updates          | 60          |
| policy_entropy     | 0.012046225 |
| policy_loss        | 0.009212013 |
| serial_timesteps   | 7680        |
| time_elapsed       | 372         |
| total_timesteps    | 7680        |
| value_loss         | 3.3607805   |
------------------------------------
-----------------------------------
| approxkl           | 0.04845246 |
| clipfrac           | 0.45507812 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 6.96e+03   |
| explained_variance | 0          |
| fps                | 22         |
| n_updates          | 61         |
| policy_entropy     | 0.00934764 |
| policy_loss        | 0.01625191 |
| serial_timesteps   | 7808       |
| time_elapsed       | 378        |
| total_timesteps    | 7808       |
| value_loss         | 6116.93    |
-----------------------------------
--------------------------------------
| approxkl           | 0.017193995   |
| clipfrac           | 0.18164062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -1.19e-07     |
| fps                | 21            |
| n_updates          | 62            |
| policy_entropy     | 0.008144468   |
| policy_loss        | -0.0028483104 |
| serial_timesteps   | 7936          |
| time_elapsed       | 383           |
| total_timesteps    | 7936          |
| value_loss         | 3.2278972     |
--------------------------------------
--------------------------------------
| approxkl           | 0.013368412   |
| clipfrac           | 0.1484375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -1.19e-07     |
| fps                | 22            |
| n_updates          | 63            |
| policy_entropy     | 0.0064258277  |
| policy_loss        | -0.0020351363 |
| serial_timesteps   | 8064          |
| time_elapsed       | 389           |
| total_timesteps    | 8064          |
| value_loss         | 5.5325866     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0020167497 |
| clipfrac           | 0.01171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 64           |
| policy_entropy     | 0.0042810515 |
| policy_loss        | 0.0007470612 |
| serial_timesteps   | 8192         |
| time_elapsed       | 395          |
| total_timesteps    | 8192         |
| value_loss         | 3.8549168    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0033041271  |
| clipfrac           | 0.037109375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 0             |
| fps                | 23            |
| n_updates          | 65            |
| policy_entropy     | 0.000777252   |
| policy_loss        | -6.205891e-05 |
| serial_timesteps   | 8320          |
| time_elapsed       | 401           |
| total_timesteps    | 8320          |
| value_loss         | 9.655893      |
--------------------------------------
-------------------------------------
| approxkl           | 0.005605072  |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -9.54e-07    |
| fps                | 21           |
| n_updates          | 66           |
| policy_entropy     | -0.004304126 |
| policy_loss        | -0.004179576 |
| serial_timesteps   | 8448         |
| time_elapsed       | 406          |
| total_timesteps    | 8448         |
| value_loss         | 5.9234962    |
-------------------------------------
An average of 224.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.020831296  |
| clipfrac           | 0.26953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 3.46e-06     |
| fps                | 21           |
| n_updates          | 67           |
| policy_entropy     | -0.008944258 |
| policy_loss        | -0.016103283 |
| serial_timesteps   | 8576         |
| time_elapsed       | 412          |
| total_timesteps    | 8576         |
| value_loss         | 1.8059424    |
-------------------------------------
--------------------------------------
| approxkl           | 0.018884396   |
| clipfrac           | 0.234375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 0             |
| fps                | 22            |
| n_updates          | 68            |
| policy_entropy     | -0.0114909485 |
| policy_loss        | -0.009957401  |
| serial_timesteps   | 8704          |
| time_elapsed       | 418           |
| total_timesteps    | 8704          |
| value_loss         | 3.8401337     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012091537  |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 6.62e-06     |
| fps                | 22           |
| n_updates          | 69           |
| policy_entropy     | -0.01307594  |
| policy_loss        | -0.011760129 |
| serial_timesteps   | 8832         |
| time_elapsed       | 424          |
| total_timesteps    | 8832         |
| value_loss         | 7.668245     |
-------------------------------------
-------------------------------------
| approxkl           | 0.007830319  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 2.8e-06      |
| fps                | 20           |
| n_updates          | 70           |
| policy_entropy     | -0.014279209 |
| policy_loss        | 0.0037228772 |
| serial_timesteps   | 8960         |
| time_elapsed       | 430          |
| total_timesteps    | 8960         |
| value_loss         | 4.4082384    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011492113  |
| clipfrac           | 0.125        |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -1.91e-06    |
| fps                | 21           |
| n_updates          | 71           |
| policy_entropy     | -0.015904255 |
| policy_loss        | 0.0015376869 |
| serial_timesteps   | 9088         |
| time_elapsed       | 436          |
| total_timesteps    | 9088         |
| value_loss         | 1.8718457    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011752216  |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 1.21e-05     |
| fps                | 22           |
| n_updates          | 72           |
| policy_entropy     | -0.017988041 |
| policy_loss        | -0.008778256 |
| serial_timesteps   | 9216         |
| time_elapsed       | 442          |
| total_timesteps    | 9216         |
| value_loss         | 0.6459094    |
-------------------------------------
-------------------------------------
| approxkl           | 0.123410076  |
| clipfrac           | 0.55859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 73           |
| policy_entropy     | -0.019304708 |
| policy_loss        | 0.04828442   |
| serial_timesteps   | 9344         |
| time_elapsed       | 448          |
| total_timesteps    | 9344         |
| value_loss         | 6207.9624    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0024136733 |
| clipfrac           | 0.0234375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -5.72e-06    |
| fps                | 22           |
| n_updates          | 74           |
| policy_entropy     | -0.019793525 |
| policy_loss        | 0.0026006657 |
| serial_timesteps   | 9472         |
| time_elapsed       | 453          |
| total_timesteps    | 9472         |
| value_loss         | 7.919742     |
-------------------------------------
An average of 225.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.01825404   |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 21           |
| n_updates          | 75           |
| policy_entropy     | -0.020932771 |
| policy_loss        | -0.02213075  |
| serial_timesteps   | 9600         |
| time_elapsed       | 459          |
| total_timesteps    | 9600         |
| value_loss         | 1.1621579    |
-------------------------------------
-------------------------------------
| approxkl           | 0.012263918  |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -3.58e-07    |
| fps                | 22           |
| n_updates          | 76           |
| policy_entropy     | -0.023369618 |
| policy_loss        | -0.009474734 |
| serial_timesteps   | 9728         |
| time_elapsed       | 465          |
| total_timesteps    | 9728         |
| value_loss         | 1.904377     |
-------------------------------------
-------------------------------------
| approxkl           | 0.031348042  |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -4.77e-07    |
| fps                | 23           |
| n_updates          | 77           |
| policy_entropy     | -0.025410287 |
| policy_loss        | -0.00663261  |
| serial_timesteps   | 9856         |
| time_elapsed       | 471          |
| total_timesteps    | 9856         |
| value_loss         | 1.7847946    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0049429117 |
| clipfrac           | 0.06640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 4.77e-07     |
| fps                | 23           |
| n_updates          | 78           |
| policy_entropy     | -0.027135812 |
| policy_loss        | -0.005359335 |
| serial_timesteps   | 9984         |
| time_elapsed       | 476          |
| total_timesteps    | 9984         |
| value_loss         | 6.7278595    |
-------------------------------------
--------------------------------------
| approxkl           | 0.004757347   |
| clipfrac           | 0.0546875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 0             |
| fps                | 21            |
| n_updates          | 79            |
| policy_entropy     | -0.029244363  |
| policy_loss        | -0.0012096134 |
| serial_timesteps   | 10112         |
| time_elapsed       | 482           |
| total_timesteps    | 10112         |
| value_loss         | 4.4337        |
--------------------------------------
-------------------------------------
| approxkl           | 0.008660199  |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 3.58e-07     |
| fps                | 22           |
| n_updates          | 80           |
| policy_entropy     | -0.030945525 |
| policy_loss        | 0.0018827934 |
| serial_timesteps   | 10240        |
| time_elapsed       | 487          |
| total_timesteps    | 10240        |
| value_loss         | 6.4846745    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006444037   |
| clipfrac           | 0.083984375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -5.96e-07     |
| fps                | 22            |
| n_updates          | 81            |
| policy_entropy     | -0.032153122  |
| policy_loss        | -2.306467e-05 |
| serial_timesteps   | 10368         |
| time_elapsed       | 493           |
| total_timesteps    | 10368         |
| value_loss         | 6.595574      |
--------------------------------------
--------------------------------------
| approxkl           | 0.008260292   |
| clipfrac           | 0.123046875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 0             |
| fps                | 21            |
| n_updates          | 82            |
| policy_entropy     | -0.033527374  |
| policy_loss        | -0.0022445025 |
| serial_timesteps   | 10496         |
| time_elapsed       | 499           |
| total_timesteps    | 10496         |
| value_loss         | 5.6754956     |
--------------------------------------
An average of 225.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.012466764   |
| clipfrac           | 0.15820312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 3.34e-06      |
| fps                | 21            |
| n_updates          | 83            |
| policy_entropy     | -0.03532535   |
| policy_loss        | -0.0032440694 |
| serial_timesteps   | 10624         |
| time_elapsed       | 505           |
| total_timesteps    | 10624         |
| value_loss         | 6.5186853     |
--------------------------------------
-------------------------------------
| approxkl           | 0.006023714  |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -1.19e-07    |
| fps                | 22           |
| n_updates          | 84           |
| policy_entropy     | -0.037180305 |
| policy_loss        | 0.009229363  |
| serial_timesteps   | 10752        |
| time_elapsed       | 511          |
| total_timesteps    | 10752        |
| value_loss         | 10.234181    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0023016327 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 85           |
| policy_entropy     | -0.03895904  |
| policy_loss        | 0.0029895452 |
| serial_timesteps   | 10880        |
| time_elapsed       | 516          |
| total_timesteps    | 10880        |
| value_loss         | 6184.2705    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0013149846 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -3.58e-07    |
| fps                | 21           |
| n_updates          | 86           |
| policy_entropy     | -0.039837167 |
| policy_loss        | 0.0030887106 |
| serial_timesteps   | 11008        |
| time_elapsed       | 522          |
| total_timesteps    | 11008        |
| value_loss         | 7.4049525    |
-------------------------------------
------------------------------------
| approxkl           | 0.004011338 |
| clipfrac           | 0.052734375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | -1.19e-07   |
| fps                | 23          |
| n_updates          | 87          |
| policy_entropy     | -0.04136703 |
| policy_loss        | 0.002579704 |
| serial_timesteps   | 11136       |
| time_elapsed       | 528         |
| total_timesteps    | 11136       |
| value_loss         | 8.436995    |
------------------------------------
-------------------------------------
| approxkl           | 0.0045363633 |
| clipfrac           | 0.056640625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -1.31e-06    |
| fps                | 22           |
| n_updates          | 88           |
| policy_entropy     | -0.043686673 |
| policy_loss        | 0.0033774597 |
| serial_timesteps   | 11264        |
| time_elapsed       | 533          |
| total_timesteps    | 11264        |
| value_loss         | 4.949423     |
-------------------------------------
--------------------------------------
| approxkl           | 0.019757736   |
| clipfrac           | 0.22851562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -5.6e-06      |
| fps                | 23            |
| n_updates          | 89            |
| policy_entropy     | -0.045548953  |
| policy_loss        | -0.0143231815 |
| serial_timesteps   | 11392         |
| time_elapsed       | 539           |
| total_timesteps    | 11392         |
| value_loss         | 3.3188007     |
--------------------------------------
-------------------------------------
| approxkl           | 0.016021065  |
| clipfrac           | 0.22070312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 2.62e-06     |
| fps                | 22           |
| n_updates          | 90           |
| policy_entropy     | -0.04703179  |
| policy_loss        | -0.016885933 |
| serial_timesteps   | 11520        |
| time_elapsed       | 545          |
| total_timesteps    | 11520        |
| value_loss         | 1.145676     |
-------------------------------------
An average of 226.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.022902776  |
| clipfrac           | 0.30859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 6.5e-06      |
| fps                | 21           |
| n_updates          | 91           |
| policy_entropy     | -0.049152665 |
| policy_loss        | -0.032340016 |
| serial_timesteps   | 11648        |
| time_elapsed       | 550          |
| total_timesteps    | 11648        |
| value_loss         | 3.8730464    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060845    |
| clipfrac           | 0.06640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -1.79e-06    |
| fps                | 21           |
| n_updates          | 92           |
| policy_entropy     | -0.05040264  |
| policy_loss        | 0.0056253015 |
| serial_timesteps   | 11776        |
| time_elapsed       | 556          |
| total_timesteps    | 11776        |
| value_loss         | 5.4597816    |
-------------------------------------
---------------------------------------
| approxkl           | 0.027013764    |
| clipfrac           | 0.24804688     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.96e+03       |
| explained_variance | 0              |
| fps                | 22             |
| n_updates          | 93             |
| policy_entropy     | -0.052075967   |
| policy_loss        | -0.00063097174 |
| serial_timesteps   | 11904          |
| time_elapsed       | 562            |
| total_timesteps    | 11904          |
| value_loss         | 1.6000595      |
---------------------------------------
-------------------------------------
| approxkl           | 0.014859155  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 94           |
| policy_entropy     | -0.053594373 |
| policy_loss        | -0.005886504 |
| serial_timesteps   | 12032        |
| time_elapsed       | 568          |
| total_timesteps    | 12032        |
| value_loss         | 2.8571682    |
-------------------------------------
--------------------------------------
| approxkl           | 0.03425692    |
| clipfrac           | 0.23632812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 2.56e-06      |
| fps                | 23            |
| n_updates          | 95            |
| policy_entropy     | -0.055474587  |
| policy_loss        | 0.00097629824 |
| serial_timesteps   | 12160         |
| time_elapsed       | 574           |
| total_timesteps    | 12160         |
| value_loss         | 0.63378435    |
--------------------------------------
-------------------------------------
| approxkl           | 0.023570077  |
| clipfrac           | 0.23046875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -3.1e-06     |
| fps                | 23           |
| n_updates          | 96           |
| policy_entropy     | -0.05820828  |
| policy_loss        | -0.017312303 |
| serial_timesteps   | 12288        |
| time_elapsed       | 579          |
| total_timesteps    | 12288        |
| value_loss         | 2.4999232    |
-------------------------------------
-------------------------------------
| approxkl           | 0.093284264  |
| clipfrac           | 0.5546875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 97           |
| policy_entropy     | -0.059242345 |
| policy_loss        | 0.054513853  |
| serial_timesteps   | 12416        |
| time_elapsed       | 585          |
| total_timesteps    | 12416        |
| value_loss         | 6231.363     |
-------------------------------------
An average of 227.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.018387526 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 5.96e-08    |
| fps                | 20          |
| n_updates          | 98          |
| policy_entropy     | -0.05986806 |
| policy_loss        | -0.01296612 |
| serial_timesteps   | 12544       |
| time_elapsed       | 590         |
| total_timesteps    | 12544       |
| value_loss         | 3.010556    |
------------------------------------
-------------------------------------
| approxkl           | 0.0043149986 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -1.19e-07    |
| fps                | 21           |
| n_updates          | 99           |
| policy_entropy     | -0.061265476 |
| policy_loss        | -0.001987752 |
| serial_timesteps   | 12672        |
| time_elapsed       | 597          |
| total_timesteps    | 12672        |
| value_loss         | 4.290371     |
-------------------------------------
------------------------------------
| approxkl           | 0.017273488 |
| clipfrac           | 0.23046875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 0           |
| fps                | 22          |
| n_updates          | 100         |
| policy_entropy     | -0.06274442 |
| policy_loss        | 0.022513086 |
| serial_timesteps   | 12800       |
| time_elapsed       | 603         |
| total_timesteps    | 12800       |
| value_loss         | 4.5632987   |
------------------------------------
-------------------------------------
| approxkl           | 0.0016400265 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 101          |
| policy_entropy     | -0.064466886 |
| policy_loss        | 0.003819873  |
| serial_timesteps   | 12928        |
| time_elapsed       | 608          |
| total_timesteps    | 12928        |
| value_loss         | 8.494451     |
-------------------------------------
--------------------------------------
| approxkl           | 0.01719701    |
| clipfrac           | 0.17773438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -2.26e-06     |
| fps                | 23            |
| n_updates          | 102           |
| policy_entropy     | -0.065836996  |
| policy_loss        | -0.0038875688 |
| serial_timesteps   | 13056         |
| time_elapsed       | 614           |
| total_timesteps    | 13056         |
| value_loss         | 10.983678     |
--------------------------------------
-------------------------------------
| approxkl           | 0.015709426  |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | -1.97e-05    |
| fps                | 22           |
| n_updates          | 103          |
| policy_entropy     | -0.068572834 |
| policy_loss        | 0.012427751  |
| serial_timesteps   | 13184        |
| time_elapsed       | 619          |
| total_timesteps    | 13184        |
| value_loss         | 6.7971277    |
-------------------------------------
--------------------------------------
| approxkl           | 0.01506984    |
| clipfrac           | 0.19335938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -1.19e-06     |
| fps                | 22            |
| n_updates          | 104           |
| policy_entropy     | -0.07093567   |
| policy_loss        | -0.0075280364 |
| serial_timesteps   | 13312         |
| time_elapsed       | 625           |
| total_timesteps    | 13312         |
| value_loss         | 2.6409175     |
--------------------------------------
-------------------------------------
| approxkl           | 0.014603743  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.96e+03     |
| explained_variance | 1.19e-07     |
| fps                | 21           |
| n_updates          | 105          |
| policy_entropy     | -0.07303172  |
| policy_loss        | 0.0106117055 |
| serial_timesteps   | 13440        |
| time_elapsed       | 631          |
| total_timesteps    | 13440        |
| value_loss         | 6.732903     |
-------------------------------------
An average of 227.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.007874224   |
| clipfrac           | 0.09375       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | -4.41e-06     |
| fps                | 22            |
| n_updates          | 106           |
| policy_entropy     | -0.07603801   |
| policy_loss        | -0.0054117534 |
| serial_timesteps   | 13568         |
| time_elapsed       | 636           |
| total_timesteps    | 13568         |
| value_loss         | 6.2196445     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00725802    |
| clipfrac           | 0.099609375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.96e+03      |
| explained_variance | 5.66e-06      |
| fps                | 21            |
| n_updates          | 107           |
| policy_entropy     | -0.07836789   |
| policy_loss        | -0.0038732365 |
| serial_timesteps   | 13696         |
| time_elapsed       | 642           |
| total_timesteps    | 13696         |
| value_loss         | 4.5515604     |
--------------------------------------
------------------------------------
| approxkl           | 0.024547229 |
| clipfrac           | 0.24414062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.96e+03    |
| explained_variance | 1.91e-06    |
| fps                | 22          |
| n_updates          | 108         |
| policy_entropy     | -0.08011884 |
| policy_loss        | -0.01972476 |
| serial_timesteps   | 13824       |
| time_elapsed       | 648         |
| total_timesteps    | 13824       |
| value_loss         | 2.5704663   |
------------------------------------
-------------------------------------
| approxkl           | 0.0009603687 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -1.19e-07    |
| fps                | 21           |
| n_updates          | 109          |
| policy_entropy     | -0.081284195 |
| policy_loss        | 0.004808167  |
| serial_timesteps   | 13952        |
| time_elapsed       | 654          |
| total_timesteps    | 13952        |
| value_loss         | 6331.457     |
-------------------------------------
-------------------------------------
| approxkl           | 0.006301293  |
| clipfrac           | 0.078125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 1.31e-06     |
| fps                | 22           |
| n_updates          | 110          |
| policy_entropy     | -0.081914075 |
| policy_loss        | -0.007112235 |
| serial_timesteps   | 14080        |
| time_elapsed       | 660          |
| total_timesteps    | 14080        |
| value_loss         | 11.461332    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077677127 |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -2.38e-06    |
| fps                | 22           |
| n_updates          | 111          |
| policy_entropy     | -0.082856275 |
| policy_loss        | -0.00878614  |
| serial_timesteps   | 14208        |
| time_elapsed       | 665          |
| total_timesteps    | 14208        |
| value_loss         | 8.629703     |
-------------------------------------
-------------------------------------
| approxkl           | 0.030484514  |
| clipfrac           | 0.32226562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 5.96e-08     |
| fps                | 22           |
| n_updates          | 112          |
| policy_entropy     | -0.08433769  |
| policy_loss        | -0.022520527 |
| serial_timesteps   | 14336        |
| time_elapsed       | 671          |
| total_timesteps    | 14336        |
| value_loss         | 0.7352003    |
-------------------------------------
------------------------------------
| approxkl           | 0.020843668 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | 2.38e-07    |
| fps                | 23          |
| n_updates          | 113         |
| policy_entropy     | -0.08715722 |
| policy_loss        | -0.00466706 |
| serial_timesteps   | 14464       |
| time_elapsed       | 677         |
| total_timesteps    | 14464       |
| value_loss         | 0.61037624  |
------------------------------------
An average of 228.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.02353388   |
| clipfrac           | 0.2890625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 2.38e-07     |
| fps                | 22           |
| n_updates          | 114          |
| policy_entropy     | -0.089183696 |
| policy_loss        | -0.02847031  |
| serial_timesteps   | 14592        |
| time_elapsed       | 682          |
| total_timesteps    | 14592        |
| value_loss         | 1.7089746    |
-------------------------------------
-------------------------------------
| approxkl           | 0.026985398  |
| clipfrac           | 0.27148438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 7.75e-07     |
| fps                | 22           |
| n_updates          | 115          |
| policy_entropy     | -0.09053537  |
| policy_loss        | -0.036829114 |
| serial_timesteps   | 14720        |
| time_elapsed       | 688          |
| total_timesteps    | 14720        |
| value_loss         | 1.1170849    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0071761194  |
| clipfrac           | 0.109375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | -1.43e-06     |
| fps                | 22            |
| n_updates          | 116           |
| policy_entropy     | -0.09205222   |
| policy_loss        | -0.0018005606 |
| serial_timesteps   | 14848         |
| time_elapsed       | 693           |
| total_timesteps    | 14848         |
| value_loss         | 3.732989      |
--------------------------------------
-------------------------------------
| approxkl           | 0.005200112  |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 117          |
| policy_entropy     | -0.093979865 |
| policy_loss        | 0.006141439  |
| serial_timesteps   | 14976        |
| time_elapsed       | 699          |
| total_timesteps    | 14976        |
| value_loss         | 3.3890955    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b42a11d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b42a11d30>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b429ba2b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b429ba2b0>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2812 samples, validate on 336 samples
Epoch 407/5000
 - 8s - loss: 0.0816 - val_loss: 0.0257
Epoch 408/5000
 - 1s - loss: 0.0202 - val_loss: 0.0211
Epoch 409/5000
 - 1s - loss: 0.0156 - val_loss: 0.0188
Epoch 410/5000
 - 1s - loss: 0.0127 - val_loss: 0.0177
Epoch 411/5000
 - 1s - loss: 0.0101 - val_loss: 0.0208
Epoch 412/5000
 - 1s - loss: 0.0090 - val_loss: 0.0192
Epoch 413/5000
 - 1s - loss: 0.0092 - val_loss: 0.0107
Epoch 414/5000
 - 1s - loss: 0.0075 - val_loss: 0.0106
Epoch 415/5000
 - 1s - loss: 0.0074 - val_loss: 0.0105
Epoch 416/5000
 - 1s - loss: 0.0073 - val_loss: 0.0104
Epoch 417/5000
 - 1s - loss: 0.0073 - val_loss: 0.0103
Epoch 418/5000
 - 1s - loss: 0.0072 - val_loss: 0.0102
Epoch 419/5000
 - 1s - loss: 0.0072 - val_loss: 0.0101
Epoch 420/5000
 - 1s - loss: 0.0071 - val_loss: 0.0100
Epoch 421/5000
 - 1s - loss: 0.0071 - val_loss: 0.0099
Epoch 422/5000
 - 1s - loss: 0.0070 - val_loss: 0.0098
Epoch 423/5000
 - 1s - loss: 0.0070 - val_loss: 0.0097
Epoch 424/5000
 - 1s - loss: 0.0069 - val_loss: 0.0097
Epoch 425/5000
 - 1s - loss: 0.0069 - val_loss: 0.0096
Epoch 426/5000
 - 1s - loss: 0.0069 - val_loss: 0.0095
Epoch 427/5000
 - 1s - loss: 0.0068 - val_loss: 0.0095
Epoch 428/5000
 - 1s - loss: 0.0068 - val_loss: 0.0094
Epoch 429/5000
 - 1s - loss: 0.0067 - val_loss: 0.0093
Epoch 430/5000
 - 1s - loss: 0.0067 - val_loss: 0.0093
Epoch 431/5000
 - 1s - loss: 0.0067 - val_loss: 0.0092
Epoch 432/5000
 - 1s - loss: 0.0066 - val_loss: 0.0092
Epoch 433/5000
 - 1s - loss: 0.0066 - val_loss: 0.0091
Epoch 434/5000
 - 1s - loss: 0.0066 - val_loss: 0.0091
Epoch 435/5000
 - 1s - loss: 0.0065 - val_loss: 0.0090
Epoch 436/5000
 - 1s - loss: 0.0064 - val_loss: 0.0089
Epoch 437/5000
 - 1s - loss: 0.0064 - val_loss: 0.0089
Epoch 438/5000
 - 1s - loss: 0.0064 - val_loss: 0.0089
Epoch 439/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 440/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 441/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 442/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 443/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 444/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 445/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 446/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 447/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 448/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 449/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 450/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 451/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 452/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 453/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 454/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 455/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 456/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Epoch 457/5000
 - 1s - loss: 0.0063 - val_loss: 0.0089
Train on 1878 samples, validate on 336 samples
Epoch 332/5000
 - 8s - loss: 0.0055 - val_loss: 0.0051
Epoch 333/5000
 - 0s - loss: 0.0055 - val_loss: 0.0051
Epoch 334/5000
 - 1s - loss: 0.0055 - val_loss: 0.0051
Epoch 335/5000
 - 0s - loss: 0.0055 - val_loss: 0.0051
Epoch 336/5000
 - 0s - loss: 0.0055 - val_loss: 0.0051
Epoch 337/5000
 - 1s - loss: 0.0055 - val_loss: 0.0051
Train on 2813 samples, validate on 336 samples
Epoch 1103/5000
 - 10s - loss: 0.6699 - val_loss: 0.4989
Epoch 1104/5000
 - 1s - loss: 0.6529 - val_loss: 0.4220
Epoch 1105/5000
 - 1s - loss: 0.6494 - val_loss: 0.4163
Epoch 1106/5000
 - 1s - loss: 0.6429 - val_loss: 0.4094
Epoch 1107/5000
 - 1s - loss: 0.6367 - val_loss: 0.4041
Epoch 1108/5000
 - 1s - loss: 0.6264 - val_loss: 0.3990
Epoch 1109/5000
 - 1s - loss: 0.6127 - val_loss: 0.3882
Epoch 1110/5000
 - 1s - loss: 0.6045 - val_loss: 0.3863
Epoch 1111/5000
 - 1s - loss: 0.5984 - val_loss: 0.4172
Epoch 1112/5000
 - 1s - loss: 0.5861 - val_loss: 0.4455
Epoch 1113/5000
 - 1s - loss: 0.5401 - val_loss: 0.5056
Epoch 1114/5000
 - 1s - loss: 0.5307 - val_loss: 0.5413
Epoch 1115/5000
 - 1s - loss: 0.5264 - val_loss: 0.5660
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0047757607 |
| clipfrac           | 0.0703125    |
| explained_variance | 6.32e-06     |
| fps                | 3            |
| n_updates          | 1            |
| policy_entropy     | -0.09640673  |
| policy_loss        | 0.003695936  |
| serial_timesteps   | 128          |
| time_elapsed       | 1.31e-05     |
| total_timesteps    | 128          |
| value_loss         | 0.578034     |
-------------------------------------
-------------------------------------
| approxkl           | 0.013992621  |
| clipfrac           | 0.17773438   |
| explained_variance | -4.77e-07    |
| fps                | 23           |
| n_updates          | 2            |
| policy_entropy     | -0.100618124 |
| policy_loss        | -0.007320256 |
| serial_timesteps   | 256          |
| time_elapsed       | 40.3         |
| total_timesteps    | 256          |
| value_loss         | 2.160649     |
-------------------------------------
-------------------------------------
| approxkl           | 0.013274233  |
| clipfrac           | 0.15625      |
| explained_variance | -3.58e-07    |
| fps                | 23           |
| n_updates          | 3            |
| policy_entropy     | -0.10354131  |
| policy_loss        | -0.010405979 |
| serial_timesteps   | 384          |
| time_elapsed       | 45.8         |
| total_timesteps    | 384          |
| value_loss         | 1.1263314    |
-------------------------------------
------------------------------------
| approxkl           | 0.017540954 |
| clipfrac           | 0.20117188  |
| explained_variance | 0           |
| fps                | 23          |
| n_updates          | 4           |
| policy_entropy     | -0.10604081 |
| policy_loss        | 0.004116596 |
| serial_timesteps   | 512         |
| time_elapsed       | 51.3        |
| total_timesteps    | 512         |
| value_loss         | 0.694414    |
------------------------------------
An average of 229.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.014081187    |
| clipfrac           | 0.17578125     |
| explained_variance | 0              |
| fps                | 23             |
| n_updates          | 5              |
| policy_entropy     | -0.10960878    |
| policy_loss        | -0.00025187107 |
| serial_timesteps   | 640            |
| time_elapsed       | 56.7           |
| total_timesteps    | 640            |
| value_loss         | 0.6642233      |
---------------------------------------
-------------------------------------
| approxkl           | 0.012588594  |
| clipfrac           | 0.19140625   |
| explained_variance | -1.19e-07    |
| fps                | 24           |
| n_updates          | 6            |
| policy_entropy     | -0.113015465 |
| policy_loss        | -0.017845072 |
| serial_timesteps   | 768          |
| time_elapsed       | 62.1         |
| total_timesteps    | 768          |
| value_loss         | 1.9148138    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014989832  |
| clipfrac           | 0.20703125   |
| explained_variance | 1.31e-06     |
| fps                | 24           |
| n_updates          | 7            |
| policy_entropy     | -0.1154358   |
| policy_loss        | 0.0032766561 |
| serial_timesteps   | 896          |
| time_elapsed       | 67.4         |
| total_timesteps    | 896          |
| value_loss         | 1.4182471    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01222724   |
| clipfrac           | 0.125        |
| explained_variance | -3.58e-06    |
| fps                | 24           |
| n_updates          | 8            |
| policy_entropy     | -0.117605634 |
| policy_loss        | 0.0021441916 |
| serial_timesteps   | 1024         |
| time_elapsed       | 72.7         |
| total_timesteps    | 1024         |
| value_loss         | 1.6219466    |
-------------------------------------
------------------------------------
| approxkl           | 0.018923527 |
| clipfrac           | 0.23828125  |
| explained_variance | -4.53e-06   |
| fps                | 25          |
| n_updates          | 9           |
| policy_entropy     | -0.12083042 |
| policy_loss        | 0.024013834 |
| serial_timesteps   | 1152        |
| time_elapsed       | 77.8        |
| total_timesteps    | 1152        |
| value_loss         | 0.6079378   |
------------------------------------
-------------------------------------
| approxkl           | 0.027118698  |
| clipfrac           | 0.26171875   |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 10           |
| policy_entropy     | -0.12697285  |
| policy_loss        | -0.010783869 |
| serial_timesteps   | 1280         |
| time_elapsed       | 82.8         |
| total_timesteps    | 1280         |
| value_loss         | 0.28868687   |
-------------------------------------
-------------------------------------
| approxkl           | 0.013692533  |
| clipfrac           | 0.19335938   |
| explained_variance | 1.31e-06     |
| fps                | 21           |
| n_updates          | 11           |
| policy_entropy     | -0.1322974   |
| policy_loss        | -0.019889189 |
| serial_timesteps   | 1408         |
| time_elapsed       | 88.3         |
| total_timesteps    | 1408         |
| value_loss         | 1.1270245    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014598331  |
| clipfrac           | 0.1953125    |
| explained_variance | -4.05e-06    |
| fps                | 25           |
| n_updates          | 12           |
| policy_entropy     | -0.13483584  |
| policy_loss        | -0.007691156 |
| serial_timesteps   | 1536         |
| time_elapsed       | 94.2         |
| total_timesteps    | 1536         |
| value_loss         | 1.32608      |
-------------------------------------
An average of 230.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.09243178   |
| clipfrac           | 0.55859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | -1.19e-07    |
| fps                | 25           |
| n_updates          | 13           |
| policy_entropy     | -0.13616337  |
| policy_loss        | 0.0045942757 |
| serial_timesteps   | 1664         |
| time_elapsed       | 99.2         |
| total_timesteps    | 1664         |
| value_loss         | 4057.6555    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0071236035  |
| clipfrac           | 0.109375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.93e+03      |
| explained_variance | -1.65e-05     |
| fps                | 24            |
| n_updates          | 14            |
| policy_entropy     | -0.13690923   |
| policy_loss        | -0.0050528888 |
| serial_timesteps   | 1792          |
| time_elapsed       | 104           |
| total_timesteps    | 1792          |
| value_loss         | 0.83665663    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0021242124 |
| clipfrac           | 0.017578125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | -8.82e-06    |
| fps                | 24           |
| n_updates          | 15           |
| policy_entropy     | -0.13933793  |
| policy_loss        | 0.0037742974 |
| serial_timesteps   | 1920         |
| time_elapsed       | 109          |
| total_timesteps    | 1920         |
| value_loss         | 1.4703469    |
-------------------------------------
-------------------------------------
| approxkl           | 0.019013083  |
| clipfrac           | 0.28125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | -1.47e-05    |
| fps                | 27           |
| n_updates          | 16           |
| policy_entropy     | -0.14303024  |
| policy_loss        | -0.017707631 |
| serial_timesteps   | 2048         |
| time_elapsed       | 115          |
| total_timesteps    | 2048         |
| value_loss         | 1.1830502    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01091127   |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | 6.74e-06     |
| fps                | 26           |
| n_updates          | 17           |
| policy_entropy     | -0.14504227  |
| policy_loss        | -0.007958615 |
| serial_timesteps   | 2176         |
| time_elapsed       | 119          |
| total_timesteps    | 2176         |
| value_loss         | 36.027058    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006453461   |
| clipfrac           | 0.091796875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.93e+03      |
| explained_variance | 1.23e-05      |
| fps                | 27            |
| n_updates          | 18            |
| policy_entropy     | -0.1454837    |
| policy_loss        | -0.0034319651 |
| serial_timesteps   | 2304          |
| time_elapsed       | 124           |
| total_timesteps    | 2304          |
| value_loss         | 91.87626      |
--------------------------------------
-------------------------------------
| approxkl           | 0.029536076  |
| clipfrac           | 0.31445312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | -1.67e-06    |
| fps                | 25           |
| n_updates          | 19           |
| policy_entropy     | -0.1454986   |
| policy_loss        | -0.008112838 |
| serial_timesteps   | 2432         |
| time_elapsed       | 129          |
| total_timesteps    | 2432         |
| value_loss         | 9.950756     |
-------------------------------------
An average of 230.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.039283734 |
| clipfrac           | 0.296875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.93e+03    |
| explained_variance | 2.98e-06    |
| fps                | 24          |
| n_updates          | 20          |
| policy_entropy     | -0.14503215 |
| policy_loss        | -0.01045049 |
| serial_timesteps   | 2560        |
| time_elapsed       | 134         |
| total_timesteps    | 2560        |
| value_loss         | 9.578327    |
------------------------------------
-------------------------------------
| approxkl           | 0.0337238    |
| clipfrac           | 0.32421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | 1.37e-06     |
| fps                | 23           |
| n_updates          | 21           |
| policy_entropy     | -0.14595744  |
| policy_loss        | -0.009153873 |
| serial_timesteps   | 2688         |
| time_elapsed       | 139          |
| total_timesteps    | 2688         |
| value_loss         | 0.34190223   |
-------------------------------------
------------------------------------
| approxkl           | 0.028372278 |
| clipfrac           | 0.2578125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.93e+03    |
| explained_variance | -2.38e-07   |
| fps                | 23          |
| n_updates          | 22          |
| policy_entropy     | -0.14792857 |
| policy_loss        | 0.011085204 |
| serial_timesteps   | 2816        |
| time_elapsed       | 145         |
| total_timesteps    | 2816        |
| value_loss         | 0.6663247   |
------------------------------------
-------------------------------------
| approxkl           | 0.0138343675 |
| clipfrac           | 0.21484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | 2.15e-06     |
| fps                | 22           |
| n_updates          | 23           |
| policy_entropy     | -0.14940524  |
| policy_loss        | -0.009278008 |
| serial_timesteps   | 2944         |
| time_elapsed       | 150          |
| total_timesteps    | 2944         |
| value_loss         | 1.169551     |
-------------------------------------
-------------------------------------
| approxkl           | 0.010744433  |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.93e+03     |
| explained_variance | 0            |
| fps                | 24           |
| n_updates          | 24           |
| policy_entropy     | -0.15135026  |
| policy_loss        | 0.0028014455 |
| serial_timesteps   | 3072         |
| time_elapsed       | 156          |
| total_timesteps    | 3072         |
| value_loss         | 0.92547625   |
-------------------------------------
------------------------------------
| approxkl           | 0.044972125 |
| clipfrac           | 0.42773438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | -1.19e-07   |
| fps                | 23          |
| n_updates          | 25          |
| policy_entropy     | -0.1533432  |
| policy_loss        | 0.029947974 |
| serial_timesteps   | 3200        |
| time_elapsed       | 161         |
| total_timesteps    | 3200        |
| value_loss         | 5549.608    |
------------------------------------
--------------------------------------
| approxkl           | 0.02357751    |
| clipfrac           | 0.21484375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.8e+03       |
| explained_variance | 2.8e-06       |
| fps                | 24            |
| n_updates          | 26            |
| policy_entropy     | -0.15456647   |
| policy_loss        | -0.0050867023 |
| serial_timesteps   | 3328          |
| time_elapsed       | 167           |
| total_timesteps    | 3328          |
| value_loss         | 0.43702012    |
--------------------------------------
------------------------------------
| approxkl           | 0.011719698 |
| clipfrac           | 0.16210938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 3.46e-06    |
| fps                | 27          |
| n_updates          | 27          |
| policy_entropy     | -0.15603037 |
| policy_loss        | 0.01109089  |
| serial_timesteps   | 3456        |
| time_elapsed       | 172         |
| total_timesteps    | 3456        |
| value_loss         | 1.3524625   |
------------------------------------
An average of 231.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.013877718   |
| clipfrac           | 0.20507812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.8e+03       |
| explained_variance | 1.79e-07      |
| fps                | 23            |
| n_updates          | 28            |
| policy_entropy     | -0.15842354   |
| policy_loss        | -0.0040272768 |
| serial_timesteps   | 3584          |
| time_elapsed       | 176           |
| total_timesteps    | 3584          |
| value_loss         | 1.9276159     |
--------------------------------------
-------------------------------------
| approxkl           | 0.008165743  |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | 5.96e-08     |
| fps                | 22           |
| n_updates          | 29           |
| policy_entropy     | -0.16122535  |
| policy_loss        | -0.012600839 |
| serial_timesteps   | 3712         |
| time_elapsed       | 182          |
| total_timesteps    | 3712         |
| value_loss         | 0.747803     |
-------------------------------------
-------------------------------------
| approxkl           | 0.012156674  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | -1.28e-05    |
| fps                | 24           |
| n_updates          | 30           |
| policy_entropy     | -0.16455798  |
| policy_loss        | -0.014046145 |
| serial_timesteps   | 3840         |
| time_elapsed       | 188          |
| total_timesteps    | 3840         |
| value_loss         | 1.8407166    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010872006  |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | -2.4e-05     |
| fps                | 24           |
| n_updates          | 31           |
| policy_entropy     | -0.16679743  |
| policy_loss        | 0.0024000546 |
| serial_timesteps   | 3968         |
| time_elapsed       | 193          |
| total_timesteps    | 3968         |
| value_loss         | 1.0676571    |
-------------------------------------
------------------------------------
| approxkl           | 0.036096156 |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 5.3e-06     |
| fps                | 25          |
| n_updates          | 32          |
| policy_entropy     | -0.16907331 |
| policy_loss        | -0.02486498 |
| serial_timesteps   | 4096        |
| time_elapsed       | 198         |
| total_timesteps    | 4096        |
| value_loss         | 0.40662378  |
------------------------------------
-------------------------------------
| approxkl           | 0.012728016  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | -3.34e-06    |
| fps                | 27           |
| n_updates          | 33           |
| policy_entropy     | -0.17102414  |
| policy_loss        | -0.004203639 |
| serial_timesteps   | 4224         |
| time_elapsed       | 203          |
| total_timesteps    | 4224         |
| value_loss         | 1.9347132    |
-------------------------------------
------------------------------------
| approxkl           | 0.005438101 |
| clipfrac           | 0.0546875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 5.62e-05    |
| fps                | 25          |
| n_updates          | 34          |
| policy_entropy     | -0.172398   |
| policy_loss        | 0.002036005 |
| serial_timesteps   | 4352        |
| time_elapsed       | 208         |
| total_timesteps    | 4352        |
| value_loss         | 1.9494306   |
------------------------------------
------------------------------------
| approxkl           | 0.009410764 |
| clipfrac           | 0.125       |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | -2.98e-06   |
| fps                | 25          |
| n_updates          | 35          |
| policy_entropy     | -0.17459828 |
| policy_loss        | 0.009093873 |
| serial_timesteps   | 4480        |
| time_elapsed       | 213         |
| total_timesteps    | 4480        |
| value_loss         | 1.3500361   |
------------------------------------
An average of 231.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.008203631   |
| clipfrac           | 0.12109375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.8e+03       |
| explained_variance | 5.3e-06       |
| fps                | 27            |
| n_updates          | 36            |
| policy_entropy     | -0.17648974   |
| policy_loss        | -0.0039284974 |
| serial_timesteps   | 4608          |
| time_elapsed       | 218           |
| total_timesteps    | 4608          |
| value_loss         | 121.514435    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0003108345 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 6.56e-07     |
| fps                | 26           |
| n_updates          | 37           |
| policy_entropy     | -0.17698333  |
| policy_loss        | 8.721708e-05 |
| serial_timesteps   | 4736         |
| time_elapsed       | 223          |
| total_timesteps    | 4736         |
| value_loss         | 6462.14      |
-------------------------------------
-------------------------------------
| approxkl           | 0.032502104  |
| clipfrac           | 0.29296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -3.22e-06    |
| fps                | 26           |
| n_updates          | 38           |
| policy_entropy     | -0.17669633  |
| policy_loss        | -0.010468139 |
| serial_timesteps   | 4864         |
| time_elapsed       | 227          |
| total_timesteps    | 4864         |
| value_loss         | 9.5096035    |
-------------------------------------
-------------------------------------
| approxkl           | 0.020029789  |
| clipfrac           | 0.20703125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 39           |
| policy_entropy     | -0.17660618  |
| policy_loss        | 0.0010168651 |
| serial_timesteps   | 4992         |
| time_elapsed       | 232          |
| total_timesteps    | 4992         |
| value_loss         | 13.71109     |
-------------------------------------
-------------------------------------
| approxkl           | 0.01883667   |
| clipfrac           | 0.25         |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 9.54e-07     |
| fps                | 24           |
| n_updates          | 40           |
| policy_entropy     | -0.17610362  |
| policy_loss        | -0.014501391 |
| serial_timesteps   | 5120         |
| time_elapsed       | 238          |
| total_timesteps    | 5120         |
| value_loss         | 1.0491275    |
-------------------------------------
-------------------------------------
| approxkl           | 0.039151397  |
| clipfrac           | 0.34960938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -8.34e-07    |
| fps                | 22           |
| n_updates          | 41           |
| policy_entropy     | -0.17646012  |
| policy_loss        | -0.024923591 |
| serial_timesteps   | 5248         |
| time_elapsed       | 243          |
| total_timesteps    | 5248         |
| value_loss         | 1.0661268    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0241854    |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 0            |
| fps                | 24           |
| n_updates          | 42           |
| policy_entropy     | -0.1772984   |
| policy_loss        | -0.011216148 |
| serial_timesteps   | 5376         |
| time_elapsed       | 248          |
| total_timesteps    | 5376         |
| value_loss         | 1.5671885    |
-------------------------------------
------------------------------------
| approxkl           | 0.022075634 |
| clipfrac           | 0.26171875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 0           |
| fps                | 23          |
| n_updates          | 43          |
| policy_entropy     | -0.17846088 |
| policy_loss        | 0.022199333 |
| serial_timesteps   | 5504        |
| time_elapsed       | 254         |
| total_timesteps    | 5504        |
| value_loss         | 1.009136    |
------------------------------------
An average of 232.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.013845869  |
| clipfrac           | 0.16992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 1.19e-07     |
| fps                | 24           |
| n_updates          | 44           |
| policy_entropy     | -0.18009779  |
| policy_loss        | -0.007528113 |
| serial_timesteps   | 5632         |
| time_elapsed       | 259          |
| total_timesteps    | 5632         |
| value_loss         | 2.9214272    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005678732   |
| clipfrac           | 0.08203125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.79e+03      |
| explained_variance | 5.07e-06      |
| fps                | 27            |
| n_updates          | 45            |
| policy_entropy     | -0.18196616   |
| policy_loss        | -0.0056247753 |
| serial_timesteps   | 5760          |
| time_elapsed       | 264           |
| total_timesteps    | 5760          |
| value_loss         | 0.5410459     |
--------------------------------------
-------------------------------------
| approxkl           | 0.028980702  |
| clipfrac           | 0.3125       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -7.15e-07    |
| fps                | 24           |
| n_updates          | 46           |
| policy_entropy     | -0.1838555   |
| policy_loss        | -0.033294477 |
| serial_timesteps   | 5888         |
| time_elapsed       | 269          |
| total_timesteps    | 5888         |
| value_loss         | 0.30963436   |
-------------------------------------
--------------------------------------
| approxkl           | 0.01607494    |
| clipfrac           | 0.18554688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.79e+03      |
| explained_variance | 0             |
| fps                | 23            |
| n_updates          | 47            |
| policy_entropy     | -0.18516307   |
| policy_loss        | -0.0032971627 |
| serial_timesteps   | 6016          |
| time_elapsed       | 274           |
| total_timesteps    | 6016          |
| value_loss         | 0.9148358     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012961291  |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -9.54e-07    |
| fps                | 24           |
| n_updates          | 48           |
| policy_entropy     | -0.18656658  |
| policy_loss        | -0.004734417 |
| serial_timesteps   | 6144         |
| time_elapsed       | 280          |
| total_timesteps    | 6144         |
| value_loss         | 1.2100747    |
-------------------------------------
------------------------------------
| approxkl           | 0.017790228 |
| clipfrac           | 0.2578125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | 0           |
| fps                | 23          |
| n_updates          | 49          |
| policy_entropy     | -0.18789774 |
| policy_loss        | 0.021982899 |
| serial_timesteps   | 6272        |
| time_elapsed       | 285         |
| total_timesteps    | 6272        |
| value_loss         | 6323.4453   |
------------------------------------
-------------------------------------
| approxkl           | 0.031654812  |
| clipfrac           | 0.27929688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | -4.89e-06    |
| fps                | 26           |
| n_updates          | 50           |
| policy_entropy     | -0.18843767  |
| policy_loss        | -0.023190208 |
| serial_timesteps   | 6400         |
| time_elapsed       | 290          |
| total_timesteps    | 6400         |
| value_loss         | 0.670405     |
-------------------------------------
-------------------------------------
| approxkl           | 0.036180507  |
| clipfrac           | 0.27734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | -4.17e-06    |
| fps                | 25           |
| n_updates          | 51           |
| policy_entropy     | -0.18928434  |
| policy_loss        | -0.034028903 |
| serial_timesteps   | 6528         |
| time_elapsed       | 295          |
| total_timesteps    | 6528         |
| value_loss         | 0.3189316    |
-------------------------------------
An average of 233.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.006844641 |
| clipfrac           | 0.103515625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | -9.3e-06    |
| fps                | 23          |
| n_updates          | 52          |
| policy_entropy     | -0.19099079 |
| policy_loss        | 0.009526342 |
| serial_timesteps   | 6656        |
| time_elapsed       | 300         |
| total_timesteps    | 6656        |
| value_loss         | 1.4257576   |
------------------------------------
--------------------------------------
| approxkl           | 0.003847043   |
| clipfrac           | 0.041015625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.78e+03      |
| explained_variance | 7.57e-06      |
| fps                | 26            |
| n_updates          | 53            |
| policy_entropy     | -0.19445816   |
| policy_loss        | -0.0033162097 |
| serial_timesteps   | 6784          |
| time_elapsed       | 306           |
| total_timesteps    | 6784          |
| value_loss         | 1.0009395     |
--------------------------------------
--------------------------------------
| approxkl           | 0.011081104   |
| clipfrac           | 0.15039062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.78e+03      |
| explained_variance | 6.38e-06      |
| fps                | 27            |
| n_updates          | 54            |
| policy_entropy     | -0.19775718   |
| policy_loss        | -0.0123669375 |
| serial_timesteps   | 6912          |
| time_elapsed       | 311           |
| total_timesteps    | 6912          |
| value_loss         | 52.02545      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0010197365 |
| clipfrac           | 0.0          |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 1.97e-06     |
| fps                | 27           |
| n_updates          | 55           |
| policy_entropy     | -0.19891629  |
| policy_loss        | 0.002081711  |
| serial_timesteps   | 7040         |
| time_elapsed       | 315          |
| total_timesteps    | 7040         |
| value_loss         | 116.45678    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0058454233 |
| clipfrac           | 0.087890625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 1.7e-05      |
| fps                | 26           |
| n_updates          | 56           |
| policy_entropy     | -0.19965678  |
| policy_loss        | 0.0080681965 |
| serial_timesteps   | 7168         |
| time_elapsed       | 320          |
| total_timesteps    | 7168         |
| value_loss         | 5.831011     |
-------------------------------------
-------------------------------------
| approxkl           | 0.01945981   |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 5.6e-06      |
| fps                | 24           |
| n_updates          | 57           |
| policy_entropy     | -0.1994785   |
| policy_loss        | -0.023907978 |
| serial_timesteps   | 7296         |
| time_elapsed       | 325          |
| total_timesteps    | 7296         |
| value_loss         | 6.7010617    |
-------------------------------------
------------------------------------
| approxkl           | 0.030944232 |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | 4.17e-07    |
| fps                | 23          |
| n_updates          | 58          |
| policy_entropy     | -0.19914618 |
| policy_loss        | -0.03177134 |
| serial_timesteps   | 7424        |
| time_elapsed       | 330         |
| total_timesteps    | 7424        |
| value_loss         | 1.0884285   |
------------------------------------
-------------------------------------
| approxkl           | 0.011813745  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 0            |
| fps                | 24           |
| n_updates          | 59           |
| policy_entropy     | -0.20068346  |
| policy_loss        | 0.0056297746 |
| serial_timesteps   | 7552         |
| time_elapsed       | 335          |
| total_timesteps    | 7552         |
| value_loss         | 1.5947292    |
-------------------------------------
An average of 233.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.016948324  |
| clipfrac           | 0.19921875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 3.58e-07     |
| fps                | 22           |
| n_updates          | 60           |
| policy_entropy     | -0.20424736  |
| policy_loss        | 0.0015249711 |
| serial_timesteps   | 7680         |
| time_elapsed       | 341          |
| total_timesteps    | 7680         |
| value_loss         | 2.443268     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077190083 |
| clipfrac           | 0.103515625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 61           |
| policy_entropy     | -0.20640421  |
| policy_loss        | 0.0061698514 |
| serial_timesteps   | 7808         |
| time_elapsed       | 346          |
| total_timesteps    | 7808         |
| value_loss         | 6446.1274    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087581305 |
| clipfrac           | 0.13085938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | -1.56e-05    |
| fps                | 24           |
| n_updates          | 62           |
| policy_entropy     | -0.20754635  |
| policy_loss        | -0.007239569 |
| serial_timesteps   | 7936         |
| time_elapsed       | 352          |
| total_timesteps    | 7936         |
| value_loss         | 1.6475687    |
-------------------------------------
-------------------------------------
| approxkl           | 0.004404205  |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | 7.21e-06     |
| fps                | 26           |
| n_updates          | 63           |
| policy_entropy     | -0.20962787  |
| policy_loss        | 0.0078021176 |
| serial_timesteps   | 8064         |
| time_elapsed       | 357          |
| total_timesteps    | 8064         |
| value_loss         | 2.507531     |
-------------------------------------
------------------------------------
| approxkl           | 0.008887044 |
| clipfrac           | 0.1171875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | 0           |
| fps                | 24          |
| n_updates          | 64          |
| policy_entropy     | -0.21199054 |
| policy_loss        | 0.008023088 |
| serial_timesteps   | 8192        |
| time_elapsed       | 362         |
| total_timesteps    | 8192        |
| value_loss         | 1.5240256   |
------------------------------------
-------------------------------------
| approxkl           | 0.010387512  |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | -1.67e-06    |
| fps                | 23           |
| n_updates          | 65           |
| policy_entropy     | -0.21495372  |
| policy_loss        | -0.002613936 |
| serial_timesteps   | 8320         |
| time_elapsed       | 367          |
| total_timesteps    | 8320         |
| value_loss         | 0.9793558    |
-------------------------------------
------------------------------------
| approxkl           | 0.016059885 |
| clipfrac           | 0.16992188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | -1.19e-07   |
| fps                | 23          |
| n_updates          | 66          |
| policy_entropy     | -0.21844919 |
| policy_loss        | -0.01290782 |
| serial_timesteps   | 8448        |
| time_elapsed       | 372         |
| total_timesteps    | 8448        |
| value_loss         | 1.9827403   |
------------------------------------
An average of 234.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01891085  |
| clipfrac           | 0.24414062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | -2.15e-06   |
| fps                | 23          |
| n_updates          | 67          |
| policy_entropy     | -0.22088224 |
| policy_loss        | 0.015008312 |
| serial_timesteps   | 8576        |
| time_elapsed       | 378         |
| total_timesteps    | 8576        |
| value_loss         | 1.1577598   |
------------------------------------
------------------------------------
| approxkl           | 0.041724734 |
| clipfrac           | 0.36132812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | 5.9e-06     |
| fps                | 26          |
| n_updates          | 68          |
| policy_entropy     | -0.22282854 |
| policy_loss        | 0.026135357 |
| serial_timesteps   | 8704        |
| time_elapsed       | 383         |
| total_timesteps    | 8704        |
| value_loss         | 1.9109256   |
------------------------------------
------------------------------------
| approxkl           | 0.03452789  |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | 1.4e-05     |
| fps                | 25          |
| n_updates          | 69          |
| policy_entropy     | -0.22417508 |
| policy_loss        | -0.01047316 |
| serial_timesteps   | 8832        |
| time_elapsed       | 388         |
| total_timesteps    | 8832        |
| value_loss         | 0.1545865   |
------------------------------------
------------------------------------
| approxkl           | 0.025571967 |
| clipfrac           | 0.24414062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | -6.91e-06   |
| fps                | 24          |
| n_updates          | 70          |
| policy_entropy     | -0.2259312  |
| policy_loss        | 0.014669632 |
| serial_timesteps   | 8960        |
| time_elapsed       | 393         |
| total_timesteps    | 8960        |
| value_loss         | 1.1440681   |
------------------------------------
------------------------------------
| approxkl           | 0.015158104 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | -9.54e-06   |
| fps                | 25          |
| n_updates          | 71          |
| policy_entropy     | -0.22832242 |
| policy_loss        | 0.016701102 |
| serial_timesteps   | 9088        |
| time_elapsed       | 398         |
| total_timesteps    | 9088        |
| value_loss         | 0.95908725  |
------------------------------------
---------------------------------------
| approxkl           | 0.0045398176   |
| clipfrac           | 0.056640625    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.76e+03       |
| explained_variance | -4.89e-06      |
| fps                | 25             |
| n_updates          | 72             |
| policy_entropy     | -0.23051998    |
| policy_loss        | -0.00014661276 |
| serial_timesteps   | 9216           |
| time_elapsed       | 403            |
| total_timesteps    | 9216           |
| value_loss         | 1.6191595      |
---------------------------------------
-------------------------------------
| approxkl           | 0.045076024  |
| clipfrac           | 0.4140625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 5.36e-07     |
| fps                | 27           |
| n_updates          | 73           |
| policy_entropy     | -0.23249061  |
| policy_loss        | 0.0149237085 |
| serial_timesteps   | 9344         |
| time_elapsed       | 408          |
| total_timesteps    | 9344         |
| value_loss         | 7033.6294    |
-------------------------------------
-------------------------------------
| approxkl           | 0.020357022  |
| clipfrac           | 0.22070312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 1.9e-05      |
| fps                | 26           |
| n_updates          | 74           |
| policy_entropy     | -0.23315763  |
| policy_loss        | -0.009858144 |
| serial_timesteps   | 9472         |
| time_elapsed       | 413          |
| total_timesteps    | 9472         |
| value_loss         | 27.73777     |
-------------------------------------
An average of 235.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.029449167  |
| clipfrac           | 0.26757812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 8.64e-06     |
| fps                | 23           |
| n_updates          | 75           |
| policy_entropy     | -0.23341575  |
| policy_loss        | -0.014459757 |
| serial_timesteps   | 9600         |
| time_elapsed       | 417          |
| total_timesteps    | 9600         |
| value_loss         | 2.298083     |
-------------------------------------
-------------------------------------
| approxkl           | 0.025413457  |
| clipfrac           | 0.27539062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 5.96e-07     |
| fps                | 23           |
| n_updates          | 76           |
| policy_entropy     | -0.23440893  |
| policy_loss        | -0.017184824 |
| serial_timesteps   | 9728         |
| time_elapsed       | 423          |
| total_timesteps    | 9728         |
| value_loss         | 2.0442939    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005031062  |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 5.96e-08     |
| fps                | 26           |
| n_updates          | 77           |
| policy_entropy     | -0.23653628  |
| policy_loss        | 0.0005171497 |
| serial_timesteps   | 9856         |
| time_elapsed       | 428          |
| total_timesteps    | 9856         |
| value_loss         | 1.8392411    |
-------------------------------------
------------------------------------
| approxkl           | 0.009830059 |
| clipfrac           | 0.15429688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 1.19e-07    |
| fps                | 21          |
| n_updates          | 78          |
| policy_entropy     | -0.2388841  |
| policy_loss        | 0.006620084 |
| serial_timesteps   | 9984        |
| time_elapsed       | 433         |
| total_timesteps    | 9984        |
| value_loss         | 1.3244281   |
------------------------------------
-------------------------------------
| approxkl           | 0.012279999  |
| clipfrac           | 0.16992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 1.07e-06     |
| fps                | 22           |
| n_updates          | 79           |
| policy_entropy     | -0.24157536  |
| policy_loss        | -0.002199919 |
| serial_timesteps   | 10112        |
| time_elapsed       | 439          |
| total_timesteps    | 10112        |
| value_loss         | 0.63607794   |
-------------------------------------
-------------------------------------
| approxkl           | 0.013052443  |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 0            |
| fps                | 24           |
| n_updates          | 80           |
| policy_entropy     | -0.24375519  |
| policy_loss        | -0.009331426 |
| serial_timesteps   | 10240        |
| time_elapsed       | 444          |
| total_timesteps    | 10240        |
| value_loss         | 1.4916732    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060366197 |
| clipfrac           | 0.08984375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -6.79e-06    |
| fps                | 24           |
| n_updates          | 81           |
| policy_entropy     | -0.24581218  |
| policy_loss        | 0.004803131  |
| serial_timesteps   | 10368        |
| time_elapsed       | 450          |
| total_timesteps    | 10368        |
| value_loss         | 2.3924773    |
-------------------------------------
------------------------------------
| approxkl           | 0.010806127 |
| clipfrac           | 0.1484375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | -1.07e-05   |
| fps                | 24          |
| n_updates          | 82          |
| policy_entropy     | -0.24792162 |
| policy_loss        | 0.013060794 |
| serial_timesteps   | 10496       |
| time_elapsed       | 455         |
| total_timesteps    | 10496       |
| value_loss         | 2.5941262   |
------------------------------------
An average of 235.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.04984894  |
| clipfrac           | 0.43554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | -1.16e-05   |
| fps                | 24          |
| n_updates          | 83          |
| policy_entropy     | -0.24995792 |
| policy_loss        | 0.048465572 |
| serial_timesteps   | 10624       |
| time_elapsed       | 460         |
| total_timesteps    | 10624       |
| value_loss         | 1.1662486   |
------------------------------------
-------------------------------------
| approxkl           | 0.025083965  |
| clipfrac           | 0.22851562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 5.96e-08     |
| fps                | 21           |
| n_updates          | 84           |
| policy_entropy     | -0.2512281   |
| policy_loss        | 0.0021159595 |
| serial_timesteps   | 10752        |
| time_elapsed       | 465          |
| total_timesteps    | 10752        |
| value_loss         | 1.6472331    |
-------------------------------------
------------------------------------
| approxkl           | 0.021647682 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 0           |
| fps                | 24          |
| n_updates          | 85          |
| policy_entropy     | -0.25203738 |
| policy_loss        | 0.016584795 |
| serial_timesteps   | 10880       |
| time_elapsed       | 471         |
| total_timesteps    | 10880       |
| value_loss         | 6437.8945   |
------------------------------------
-------------------------------------
| approxkl           | 0.0051017366 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 1.13e-06     |
| fps                | 25           |
| n_updates          | 86           |
| policy_entropy     | -0.25280553  |
| policy_loss        | 0.0030535301 |
| serial_timesteps   | 11008        |
| time_elapsed       | 477          |
| total_timesteps    | 11008        |
| value_loss         | 3.1128778    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02046471   |
| clipfrac           | 0.27734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -9.3e-06     |
| fps                | 25           |
| n_updates          | 87           |
| policy_entropy     | -0.25439376  |
| policy_loss        | -0.015186379 |
| serial_timesteps   | 11136        |
| time_elapsed       | 482          |
| total_timesteps    | 11136        |
| value_loss         | 1.8896499    |
-------------------------------------
-------------------------------------
| approxkl           | 0.012714079  |
| clipfrac           | 0.1640625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -1.23e-05    |
| fps                | 26           |
| n_updates          | 88           |
| policy_entropy     | -0.25567418  |
| policy_loss        | -0.011912773 |
| serial_timesteps   | 11264        |
| time_elapsed       | 487          |
| total_timesteps    | 11264        |
| value_loss         | 1.4550495    |
-------------------------------------
------------------------------------
| approxkl           | 0.019104313 |
| clipfrac           | 0.22265625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 1.2e-05     |
| fps                | 26          |
| n_updates          | 89          |
| policy_entropy     | -0.25697812 |
| policy_loss        | 0.020755498 |
| serial_timesteps   | 11392       |
| time_elapsed       | 491         |
| total_timesteps    | 11392       |
| value_loss         | 2.1195292   |
------------------------------------
-------------------------------------
| approxkl           | 0.013324638  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 1.79e-07     |
| fps                | 25           |
| n_updates          | 90           |
| policy_entropy     | -0.25828466  |
| policy_loss        | -0.022757232 |
| serial_timesteps   | 11520        |
| time_elapsed       | 496          |
| total_timesteps    | 11520        |
| value_loss         | 0.47188395   |
-------------------------------------
An average of 236.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.002903001    |
| clipfrac           | 0.02734375     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.79e+03       |
| explained_variance | 1.24e-05       |
| fps                | 27             |
| n_updates          | 91             |
| policy_entropy     | -0.25964522    |
| policy_loss        | -0.00022881315 |
| serial_timesteps   | 11648          |
| time_elapsed       | 501            |
| total_timesteps    | 11648          |
| value_loss         | 49.157597      |
---------------------------------------
-------------------------------------
| approxkl           | 0.007777089  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 3.16e-06     |
| fps                | 27           |
| n_updates          | 92           |
| policy_entropy     | -0.26057997  |
| policy_loss        | -0.008052777 |
| serial_timesteps   | 11776        |
| time_elapsed       | 506          |
| total_timesteps    | 11776        |
| value_loss         | 66.03728     |
-------------------------------------
-------------------------------------
| approxkl           | 0.013915108  |
| clipfrac           | 0.16992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 2.86e-06     |
| fps                | 25           |
| n_updates          | 93           |
| policy_entropy     | -0.2609023   |
| policy_loss        | 0.0008806451 |
| serial_timesteps   | 11904        |
| time_elapsed       | 511          |
| total_timesteps    | 11904        |
| value_loss         | 10.845286    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01581279   |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 3.16e-06     |
| fps                | 26           |
| n_updates          | 94           |
| policy_entropy     | -0.2608937   |
| policy_loss        | -0.012676628 |
| serial_timesteps   | 12032        |
| time_elapsed       | 516          |
| total_timesteps    | 12032        |
| value_loss         | 9.498474     |
-------------------------------------
-------------------------------------
| approxkl           | 0.024743889  |
| clipfrac           | 0.28125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -8.34e-07    |
| fps                | 24           |
| n_updates          | 95           |
| policy_entropy     | -0.26129553  |
| policy_loss        | -0.007521558 |
| serial_timesteps   | 12160        |
| time_elapsed       | 521          |
| total_timesteps    | 12160        |
| value_loss         | 2.1958194    |
-------------------------------------
--------------------------------------
| approxkl           | 0.013884778   |
| clipfrac           | 0.18945312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.79e+03      |
| explained_variance | 2.21e-06      |
| fps                | 22            |
| n_updates          | 96            |
| policy_entropy     | -0.2620212    |
| policy_loss        | -0.0125503605 |
| serial_timesteps   | 12288         |
| time_elapsed       | 526           |
| total_timesteps    | 12288         |
| value_loss         | 0.8617406     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00039153776 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.78e+03      |
| explained_variance | 1.19e-07      |
| fps                | 23            |
| n_updates          | 97            |
| policy_entropy     | -0.26364908   |
| policy_loss        | 0.0021617855  |
| serial_timesteps   | 12416         |
| time_elapsed       | 532           |
| total_timesteps    | 12416         |
| value_loss         | 6582.787      |
--------------------------------------
-------------------------------------
| approxkl           | 0.019127995  |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 0            |
| fps                | 23           |
| n_updates          | 98           |
| policy_entropy     | -0.26455927  |
| policy_loss        | -0.017654758 |
| serial_timesteps   | 12544        |
| time_elapsed       | 537          |
| total_timesteps    | 12544        |
| value_loss         | 1.4654583    |
-------------------------------------
An average of 237.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.01135997    |
| clipfrac           | 0.14453125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.78e+03      |
| explained_variance | -1.19e-06     |
| fps                | 23            |
| n_updates          | 99            |
| policy_entropy     | -0.2656226    |
| policy_loss        | -0.0052637514 |
| serial_timesteps   | 12672         |
| time_elapsed       | 542           |
| total_timesteps    | 12672         |
| value_loss         | 0.66793144    |
--------------------------------------
--------------------------------------
| approxkl           | 0.019181177   |
| clipfrac           | 0.22460938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.78e+03      |
| explained_variance | -7.27e-06     |
| fps                | 26            |
| n_updates          | 100           |
| policy_entropy     | -0.26835752   |
| policy_loss        | 0.00011048373 |
| serial_timesteps   | 12800         |
| time_elapsed       | 548           |
| total_timesteps    | 12800         |
| value_loss         | 0.84391654    |
--------------------------------------
--------------------------------------
| approxkl           | 0.0051831515  |
| clipfrac           | 0.068359375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.78e+03      |
| explained_variance | -1.19e-06     |
| fps                | 25            |
| n_updates          | 101           |
| policy_entropy     | -0.2712308    |
| policy_loss        | -0.0027998188 |
| serial_timesteps   | 12928         |
| time_elapsed       | 553           |
| total_timesteps    | 12928         |
| value_loss         | 2.6584525     |
--------------------------------------
---------------------------------------
| approxkl           | 0.017344981    |
| clipfrac           | 0.21289062     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.78e+03       |
| explained_variance | 0              |
| fps                | 22             |
| n_updates          | 102            |
| policy_entropy     | -0.27326176    |
| policy_loss        | -0.00036936556 |
| serial_timesteps   | 13056          |
| time_elapsed       | 558            |
| total_timesteps    | 13056          |
| value_loss         | 1.3757904      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0068910774 |
| clipfrac           | 0.09375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 0            |
| fps                | 21           |
| n_updates          | 103          |
| policy_entropy     | -0.27552956  |
| policy_loss        | -0.005150711 |
| serial_timesteps   | 13184        |
| time_elapsed       | 563          |
| total_timesteps    | 13184        |
| value_loss         | 0.9194844    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0077162874 |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 1.28e-05     |
| fps                | 24           |
| n_updates          | 104          |
| policy_entropy     | -0.2781169   |
| policy_loss        | 0.010744713  |
| serial_timesteps   | 13312        |
| time_elapsed       | 569          |
| total_timesteps    | 13312        |
| value_loss         | 1.9576395    |
-------------------------------------
-------------------------------------
| approxkl           | 0.017071642  |
| clipfrac           | 0.234375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | -2.38e-07    |
| fps                | 26           |
| n_updates          | 105          |
| policy_entropy     | -0.27979833  |
| policy_loss        | -0.010648952 |
| serial_timesteps   | 13440        |
| time_elapsed       | 575          |
| total_timesteps    | 13440        |
| value_loss         | 1.1154723    |
-------------------------------------
An average of 237.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.027115129  |
| clipfrac           | 0.265625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | -1.75e-05    |
| fps                | 24           |
| n_updates          | 106          |
| policy_entropy     | -0.28105626  |
| policy_loss        | -0.037740994 |
| serial_timesteps   | 13568        |
| time_elapsed       | 579          |
| total_timesteps    | 13568        |
| value_loss         | 1.1301403    |
-------------------------------------
------------------------------------
| approxkl           | 0.03150209  |
| clipfrac           | 0.2265625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | 1.79e-07    |
| fps                | 24          |
| n_updates          | 107         |
| policy_entropy     | -0.28185385 |
| policy_loss        | 0.016053153 |
| serial_timesteps   | 13696       |
| time_elapsed       | 585         |
| total_timesteps    | 13696       |
| value_loss         | 0.4472759   |
------------------------------------
------------------------------------
| approxkl           | 0.032651093 |
| clipfrac           | 0.296875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | -3.34e-06   |
| fps                | 25          |
| n_updates          | 108         |
| policy_entropy     | -0.28274924 |
| policy_loss        | 0.021210808 |
| serial_timesteps   | 13824       |
| time_elapsed       | 590         |
| total_timesteps    | 13824       |
| value_loss         | 1.9235514   |
------------------------------------
------------------------------------
| approxkl           | 0.11369709  |
| clipfrac           | 0.5859375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 1.19e-07    |
| fps                | 27          |
| n_updates          | 109         |
| policy_entropy     | -0.2834378  |
| policy_loss        | 0.033810824 |
| serial_timesteps   | 13952       |
| time_elapsed       | 595         |
| total_timesteps    | 13952       |
| value_loss         | 6472.713    |
------------------------------------
-------------------------------------
| approxkl           | 0.0009803817 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 2.74e-06     |
| fps                | 27           |
| n_updates          | 110          |
| policy_entropy     | -0.28365004  |
| policy_loss        | 0.0012815101 |
| serial_timesteps   | 14080        |
| time_elapsed       | 600          |
| total_timesteps    | 14080        |
| value_loss         | 109.53363    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007055956  |
| clipfrac           | 0.1015625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | 8.34e-07     |
| fps                | 25           |
| n_updates          | 111          |
| policy_entropy     | -0.2836771   |
| policy_loss        | -0.004498769 |
| serial_timesteps   | 14208        |
| time_elapsed       | 604          |
| total_timesteps    | 14208        |
| value_loss         | 5.6139803    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03461102   |
| clipfrac           | 0.36914062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.79e+03     |
| explained_variance | -7.15e-06    |
| fps                | 24           |
| n_updates          | 112          |
| policy_entropy     | -0.28348637  |
| policy_loss        | -0.018123694 |
| serial_timesteps   | 14336        |
| time_elapsed       | 609          |
| total_timesteps    | 14336        |
| value_loss         | 9.220545     |
-------------------------------------
------------------------------------
| approxkl           | 0.009931424 |
| clipfrac           | 0.11328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 0           |
| fps                | 23          |
| n_updates          | 113         |
| policy_entropy     | -0.28318098 |
| policy_loss        | 0.002557061 |
| serial_timesteps   | 14464       |
| time_elapsed       | 614         |
| total_timesteps    | 14464       |
| value_loss         | 2.605552    |
------------------------------------
An average of 238.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.037281957 |
| clipfrac           | 0.24804688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | -3.58e-07   |
| fps                | 24          |
| n_updates          | 114         |
| policy_entropy     | -0.28389075 |
| policy_loss        | 0.006713763 |
| serial_timesteps   | 14592       |
| time_elapsed       | 620         |
| total_timesteps    | 14592       |
| value_loss         | 0.684969    |
------------------------------------
------------------------------------
| approxkl           | 0.027567292 |
| clipfrac           | 0.27539062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | -2.38e-07   |
| fps                | 23          |
| n_updates          | 115         |
| policy_entropy     | -0.28553867 |
| policy_loss        | 0.010331651 |
| serial_timesteps   | 14720       |
| time_elapsed       | 625         |
| total_timesteps    | 14720       |
| value_loss         | 1.9150459   |
------------------------------------
------------------------------------
| approxkl           | 0.058276977 |
| clipfrac           | 0.4375      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | 0           |
| fps                | 22          |
| n_updates          | 116         |
| policy_entropy     | -0.2871282  |
| policy_loss        | 0.08042164  |
| serial_timesteps   | 14848       |
| time_elapsed       | 631         |
| total_timesteps    | 14848       |
| value_loss         | 2.5612955   |
------------------------------------
------------------------------------
| approxkl           | 0.07967983  |
| clipfrac           | 0.359375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.79e+03    |
| explained_variance | -1.19e-07   |
| fps                | 25          |
| n_updates          | 117         |
| policy_entropy     | -0.2883291  |
| policy_loss        | 0.020242997 |
| serial_timesteps   | 14976       |
| time_elapsed       | 636         |
| total_timesteps    | 14976       |
| value_loss         | 1.2159209   |
------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3f9d29b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3f9d29b0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3eb6fef0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3eb6fef0>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2817 samples, validate on 335 samples
Epoch 458/5000
 - 8s - loss: 0.4201 - val_loss: 0.2130
Epoch 459/5000
 - 1s - loss: 0.4201 - val_loss: 0.2130
Epoch 460/5000
 - 1s - loss: 0.4201 - val_loss: 0.2130
Epoch 461/5000
 - 1s - loss: 0.4201 - val_loss: 0.2130
Epoch 462/5000
 - 1s - loss: 0.4201 - val_loss: 0.2130
Epoch 463/5000
 - 1s - loss: 0.4201 - val_loss: 0.2130
Train on 1930 samples, validate on 335 samples
Epoch 338/5000
 - 8s - loss: 0.0053 - val_loss: 0.0141
Epoch 339/5000
 - 1s - loss: 0.0053 - val_loss: 0.0141
Epoch 340/5000
 - 1s - loss: 0.0053 - val_loss: 0.0141
Epoch 341/5000
 - 0s - loss: 0.0053 - val_loss: 0.0141
Epoch 342/5000
 - 0s - loss: 0.0053 - val_loss: 0.0141
Epoch 343/5000
 - 1s - loss: 0.0053 - val_loss: 0.0141
Train on 2818 samples, validate on 335 samples
Epoch 1116/5000
 - 10s - loss: 0.6770 - val_loss: 0.6043
Epoch 1117/5000
 - 1s - loss: 0.6326 - val_loss: 0.4722
Epoch 1118/5000
 - 1s - loss: 0.6314 - val_loss: 0.4432
Epoch 1119/5000
 - 1s - loss: 0.6297 - val_loss: 0.4358
Epoch 1120/5000
 - 1s - loss: 0.6287 - val_loss: 0.4395
Epoch 1121/5000
 - 1s - loss: 0.6244 - val_loss: 0.4353
Epoch 1122/5000
 - 1s - loss: 0.6240 - val_loss: 0.4334
Epoch 1123/5000
 - 1s - loss: 0.6234 - val_loss: 0.4321
Epoch 1124/5000
 - 1s - loss: 0.6226 - val_loss: 0.4306
Epoch 1125/5000
 - 1s - loss: 0.6219 - val_loss: 0.4288
Epoch 1126/5000
 - 1s - loss: 0.6210 - val_loss: 0.4261
Epoch 1127/5000
 - 1s - loss: 0.6199 - val_loss: 0.4222
Epoch 1128/5000
 - 1s - loss: 0.6185 - val_loss: 0.4165
Epoch 1129/5000
 - 1s - loss: 0.6164 - val_loss: 0.4072
Epoch 1130/5000
 - 1s - loss: 0.6142 - val_loss: 0.3958
Epoch 1131/5000
 - 1s - loss: 0.6100 - val_loss: 0.3787
Epoch 1132/5000
 - 1s - loss: 0.6070 - val_loss: 0.3650
Epoch 1133/5000
 - 1s - loss: 0.6015 - val_loss: 0.3517
Epoch 1134/5000
 - 1s - loss: 0.6025 - val_loss: 0.3489
Epoch 1135/5000
 - 1s - loss: 0.5984 - val_loss: 0.3439
Epoch 1136/5000
 - 1s - loss: 0.6131 - val_loss: 0.3562
Epoch 1137/5000
 - 1s - loss: 0.5773 - val_loss: 0.3349
Epoch 1138/5000
 - 1s - loss: 0.6072 - val_loss: 0.3468
Epoch 1139/5000
 - 1s - loss: 0.5836 - val_loss: 0.3387
Epoch 1140/5000
 - 1s - loss: 0.5685 - val_loss: 0.3420
Epoch 1141/5000
 - 1s - loss: 0.5563 - val_loss: 0.3458
Epoch 1142/5000
 - 1s - loss: 0.5451 - val_loss: 0.3487
setting environment to train mode..... 

Training Started... 

---------------------------------------
| approxkl           | 0.011693463    |
| clipfrac           | 0.16210938     |
| explained_variance | -1.07e-05      |
| fps                | 3              |
| n_updates          | 1              |
| policy_entropy     | -0.28973526    |
| policy_loss        | -0.00061162654 |
| serial_timesteps   | 128            |
| time_elapsed       | 1.17e-05       |
| total_timesteps    | 128            |
| value_loss         | 1.7620107      |
---------------------------------------
------------------------------------
| approxkl           | 0.008424142 |
| clipfrac           | 0.1328125   |
| explained_variance | -1.19e-07   |
| fps                | 22          |
| n_updates          | 2           |
| policy_entropy     | -0.29209092 |
| policy_loss        | 0.010525323 |
| serial_timesteps   | 256         |
| time_elapsed       | 42.5        |
| total_timesteps    | 256         |
| value_loss         | 4.0155315   |
------------------------------------
-------------------------------------
| approxkl           | 0.013918493  |
| clipfrac           | 0.15820312   |
| explained_variance | 0            |
| fps                | 21           |
| n_updates          | 3            |
| policy_entropy     | -0.29396045  |
| policy_loss        | 0.0003222758 |
| serial_timesteps   | 384          |
| time_elapsed       | 48.3         |
| total_timesteps    | 384          |
| value_loss         | 2.1228766    |
-------------------------------------
--------------------------------------
| approxkl           | 0.00896127    |
| clipfrac           | 0.125         |
| explained_variance | 1.25e-05      |
| fps                | 22            |
| n_updates          | 4             |
| policy_entropy     | -0.29547098   |
| policy_loss        | 0.00089626503 |
| serial_timesteps   | 512           |
| time_elapsed       | 54.1          |
| total_timesteps    | 512           |
| value_loss         | 3.1446705     |
--------------------------------------
An average of 239.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.011104494  |
| clipfrac           | 0.1640625    |
| explained_variance | 3.64e-06     |
| fps                | 24           |
| n_updates          | 5            |
| policy_entropy     | -0.29683825  |
| policy_loss        | -0.012505016 |
| serial_timesteps   | 640          |
| time_elapsed       | 59.7         |
| total_timesteps    | 640          |
| value_loss         | 4.305487     |
-------------------------------------
-------------------------------------
| approxkl           | 0.019419791  |
| clipfrac           | 0.19335938   |
| explained_variance | -4.77e-07    |
| fps                | 23           |
| n_updates          | 6            |
| policy_entropy     | -0.2989826   |
| policy_loss        | -0.010392368 |
| serial_timesteps   | 768          |
| time_elapsed       | 64.8         |
| total_timesteps    | 768          |
| value_loss         | 0.92893875   |
-------------------------------------
-------------------------------------
| approxkl           | 0.034441747  |
| clipfrac           | 0.3828125    |
| explained_variance | -4.05e-06    |
| fps                | 22           |
| n_updates          | 7            |
| policy_entropy     | -0.3003561   |
| policy_loss        | -0.040662907 |
| serial_timesteps   | 896          |
| time_elapsed       | 70.3         |
| total_timesteps    | 896          |
| value_loss         | 1.1665246    |
-------------------------------------
------------------------------------
| approxkl           | 0.019881943 |
| clipfrac           | 0.23632812  |
| explained_variance | 0           |
| fps                | 21          |
| n_updates          | 8           |
| policy_entropy     | -0.30111772 |
| policy_loss        | 0.008044258 |
| serial_timesteps   | 1024        |
| time_elapsed       | 76          |
| total_timesteps    | 1024        |
| value_loss         | 4.3023667   |
------------------------------------
------------------------------------
| approxkl           | 0.02303857  |
| clipfrac           | 0.23632812  |
| explained_variance | 9.36e-06    |
| fps                | 22          |
| n_updates          | 9           |
| policy_entropy     | -0.30206966 |
| policy_loss        | 0.023257421 |
| serial_timesteps   | 1152        |
| time_elapsed       | 81.8        |
| total_timesteps    | 1152        |
| value_loss         | 2.243838    |
------------------------------------
-------------------------------------
| approxkl           | 0.03703169   |
| clipfrac           | 0.30859375   |
| explained_variance | -9.42e-06    |
| fps                | 23           |
| n_updates          | 10           |
| policy_entropy     | -0.30270216  |
| policy_loss        | -0.008702245 |
| serial_timesteps   | 1280         |
| time_elapsed       | 87.6         |
| total_timesteps    | 1280         |
| value_loss         | 0.5910566    |
-------------------------------------
-------------------------------------
| approxkl           | 0.022898946  |
| clipfrac           | 0.29296875   |
| explained_variance | 2.03e-05     |
| fps                | 23           |
| n_updates          | 11           |
| policy_entropy     | -0.3014465   |
| policy_loss        | -0.024817163 |
| serial_timesteps   | 1408         |
| time_elapsed       | 93           |
| total_timesteps    | 1408         |
| value_loss         | 1.1380101    |
-------------------------------------
-------------------------------------
| approxkl           | 0.016212957  |
| clipfrac           | 0.18554688   |
| explained_variance | 5.96e-08     |
| fps                | 24           |
| n_updates          | 12           |
| policy_entropy     | -0.30146572  |
| policy_loss        | -0.015790928 |
| serial_timesteps   | 1536         |
| time_elapsed       | 98.5         |
| total_timesteps    | 1536         |
| value_loss         | 0.8499313    |
-------------------------------------
An average of 240.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.008218657   |
| clipfrac           | 0.1015625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -1.19e-07     |
| fps                | 22            |
| n_updates          | 13            |
| policy_entropy     | -0.3047199    |
| policy_loss        | -0.0031575088 |
| serial_timesteps   | 1664          |
| time_elapsed       | 104           |
| total_timesteps    | 1664          |
| value_loss         | 4090.36       |
--------------------------------------
-------------------------------------
| approxkl           | 0.011185197  |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 1.82e-05     |
| fps                | 23           |
| n_updates          | 14           |
| policy_entropy     | -0.30649027  |
| policy_loss        | -0.008881666 |
| serial_timesteps   | 1792         |
| time_elapsed       | 109          |
| total_timesteps    | 1792         |
| value_loss         | 1.86832      |
-------------------------------------
--------------------------------------
| approxkl           | 0.0051769074  |
| clipfrac           | 0.083984375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 7.99e-06      |
| fps                | 25            |
| n_updates          | 15            |
| policy_entropy     | -0.3080828    |
| policy_loss        | 0.00014861836 |
| serial_timesteps   | 1920          |
| time_elapsed       | 115           |
| total_timesteps    | 1920          |
| value_loss         | 122.94571     |
--------------------------------------
--------------------------------------
| approxkl           | 0.002851425   |
| clipfrac           | 0.021484375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 7.27e-06      |
| fps                | 25            |
| n_updates          | 16            |
| policy_entropy     | -0.30886117   |
| policy_loss        | -0.0006331733 |
| serial_timesteps   | 2048          |
| time_elapsed       | 120           |
| total_timesteps    | 2048          |
| value_loss         | 38.68333      |
--------------------------------------
--------------------------------------
| approxkl           | 0.006570984   |
| clipfrac           | 0.099609375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -7.15e-07     |
| fps                | 25            |
| n_updates          | 17            |
| policy_entropy     | -0.3103447    |
| policy_loss        | -0.0005172626 |
| serial_timesteps   | 2176          |
| time_elapsed       | 125           |
| total_timesteps    | 2176          |
| value_loss         | 29.884914     |
--------------------------------------
-------------------------------------
| approxkl           | 0.020263596  |
| clipfrac           | 0.23242188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 5.66e-06     |
| fps                | 25           |
| n_updates          | 18           |
| policy_entropy     | -0.31109554  |
| policy_loss        | -0.011138861 |
| serial_timesteps   | 2304         |
| time_elapsed       | 130          |
| total_timesteps    | 2304         |
| value_loss         | 41.481487    |
-------------------------------------
--------------------------------------
| approxkl           | 0.011112979   |
| clipfrac           | 0.13085938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 9.72e-06      |
| fps                | 22            |
| n_updates          | 19            |
| policy_entropy     | -0.31142056   |
| policy_loss        | -0.0023897346 |
| serial_timesteps   | 2432          |
| time_elapsed       | 135           |
| total_timesteps    | 2432          |
| value_loss         | 0.68057185    |
--------------------------------------
-------------------------------------
| approxkl           | 0.044085324  |
| clipfrac           | 0.29882812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 1.01e-06     |
| fps                | 21           |
| n_updates          | 20           |
| policy_entropy     | -0.31168738  |
| policy_loss        | 0.0050376207 |
| serial_timesteps   | 2560         |
| time_elapsed       | 141          |
| total_timesteps    | 2560         |
| value_loss         | 0.48173985   |
-------------------------------------
An average of 240.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.039583422  |
| clipfrac           | 0.35351562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -2.38e-07    |
| fps                | 22           |
| n_updates          | 21           |
| policy_entropy     | -0.31265938  |
| policy_loss        | -0.010848476 |
| serial_timesteps   | 2688         |
| time_elapsed       | 146          |
| total_timesteps    | 2688         |
| value_loss         | 0.6492049    |
-------------------------------------
------------------------------------
| approxkl           | 0.01970333  |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0           |
| fps                | 21          |
| n_updates          | 22          |
| policy_entropy     | -0.31394815 |
| policy_loss        | 0.01131849  |
| serial_timesteps   | 2816        |
| time_elapsed       | 152         |
| total_timesteps    | 2816        |
| value_loss         | 1.9217327   |
------------------------------------
------------------------------------
| approxkl           | 0.025188413 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -3.34e-06   |
| fps                | 23          |
| n_updates          | 23          |
| policy_entropy     | -0.3151642  |
| policy_loss        | -0.03314975 |
| serial_timesteps   | 2944        |
| time_elapsed       | 158         |
| total_timesteps    | 2944        |
| value_loss         | 0.29357174  |
------------------------------------
--------------------------------------
| approxkl           | 0.0077001355  |
| clipfrac           | 0.115234375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 1.13e-06      |
| fps                | 25            |
| n_updates          | 24            |
| policy_entropy     | -0.3162518    |
| policy_loss        | -0.0030661318 |
| serial_timesteps   | 3072          |
| time_elapsed       | 163           |
| total_timesteps    | 3072          |
| value_loss         | 2.172416      |
--------------------------------------
------------------------------------
| approxkl           | 0.007181297 |
| clipfrac           | 0.076171875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 0           |
| fps                | 22          |
| n_updates          | 25          |
| policy_entropy     | -0.31783786 |
| policy_loss        | 0.0005808   |
| serial_timesteps   | 3200        |
| time_elapsed       | 169         |
| total_timesteps    | 3200        |
| value_loss         | 5560.1772   |
------------------------------------
-------------------------------------
| approxkl           | 0.021488557  |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | 8.94e-07     |
| fps                | 22           |
| n_updates          | 26           |
| policy_entropy     | -0.318331    |
| policy_loss        | -0.023243649 |
| serial_timesteps   | 3328         |
| time_elapsed       | 174          |
| total_timesteps    | 3328         |
| value_loss         | 1.9756534    |
-------------------------------------
------------------------------------
| approxkl           | 0.010074793 |
| clipfrac           | 0.140625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 1.56e-05    |
| fps                | 22          |
| n_updates          | 27          |
| policy_entropy     | -0.31921312 |
| policy_loss        | 0.008089744 |
| serial_timesteps   | 3456        |
| time_elapsed       | 180         |
| total_timesteps    | 3456        |
| value_loss         | 1.7465967   |
------------------------------------
An average of 241.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.022068882  |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | -9.18e-06    |
| fps                | 22           |
| n_updates          | 28           |
| policy_entropy     | -0.32174578  |
| policy_loss        | -0.007634249 |
| serial_timesteps   | 3584         |
| time_elapsed       | 186          |
| total_timesteps    | 3584         |
| value_loss         | 1.5609847    |
-------------------------------------
--------------------------------------
| approxkl           | 0.013639754   |
| clipfrac           | 0.17578125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.8e+03       |
| explained_variance | -6.32e-06     |
| fps                | 26            |
| n_updates          | 29            |
| policy_entropy     | -0.32402927   |
| policy_loss        | -7.973821e-05 |
| serial_timesteps   | 3712          |
| time_elapsed       | 191           |
| total_timesteps    | 3712          |
| value_loss         | 2.004681      |
--------------------------------------
-------------------------------------
| approxkl           | 0.022656392  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | 7.67e-05     |
| fps                | 23           |
| n_updates          | 30           |
| policy_entropy     | -0.32597378  |
| policy_loss        | -0.023016661 |
| serial_timesteps   | 3840         |
| time_elapsed       | 196          |
| total_timesteps    | 3840         |
| value_loss         | 0.5250603    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0016754162 |
| clipfrac           | 0.01953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | 2.98e-07     |
| fps                | 22           |
| n_updates          | 31           |
| policy_entropy     | -0.32824674  |
| policy_loss        | 0.0009201504 |
| serial_timesteps   | 3968         |
| time_elapsed       | 202          |
| total_timesteps    | 3968         |
| value_loss         | 2.3762908    |
-------------------------------------
------------------------------------
| approxkl           | 0.013063655 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 7.57e-06    |
| fps                | 23          |
| n_updates          | 32          |
| policy_entropy     | -0.33189857 |
| policy_loss        | -0.01719115 |
| serial_timesteps   | 4096        |
| time_elapsed       | 207         |
| total_timesteps    | 4096        |
| value_loss         | 1.0996629   |
------------------------------------
-------------------------------------
| approxkl           | 0.008807891  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.8e+03      |
| explained_variance | 1.12e-05     |
| fps                | 24           |
| n_updates          | 33           |
| policy_entropy     | -0.3344704   |
| policy_loss        | -0.008324569 |
| serial_timesteps   | 4224         |
| time_elapsed       | 213          |
| total_timesteps    | 4224         |
| value_loss         | 51.484318    |
-------------------------------------
------------------------------------
| approxkl           | 0.007218136 |
| clipfrac           | 0.08984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 4.17e-06    |
| fps                | 26          |
| n_updates          | 34          |
| policy_entropy     | -0.33517954 |
| policy_loss        | 0.002385474 |
| serial_timesteps   | 4352        |
| time_elapsed       | 218         |
| total_timesteps    | 4352        |
| value_loss         | 76.37625    |
------------------------------------
--------------------------------------
| approxkl           | 0.011150273   |
| clipfrac           | 0.15820312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.8e+03       |
| explained_variance | 1.75e-05      |
| fps                | 24            |
| n_updates          | 35            |
| policy_entropy     | -0.33566168   |
| policy_loss        | 0.00085042464 |
| serial_timesteps   | 4480          |
| time_elapsed       | 223           |
| total_timesteps    | 4480          |
| value_loss         | 19.271883     |
--------------------------------------
An average of 241.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.030323567 |
| clipfrac           | 0.27929688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.8e+03     |
| explained_variance | 6.74e-06    |
| fps                | 25          |
| n_updates          | 36          |
| policy_entropy     | -0.33646932 |
| policy_loss        | -0.01431381 |
| serial_timesteps   | 4608        |
| time_elapsed       | 228         |
| total_timesteps    | 4608        |
| value_loss         | 6.058232    |
------------------------------------
------------------------------------
| approxkl           | 0.023480302 |
| clipfrac           | 0.29296875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | 3.58e-07    |
| fps                | 23          |
| n_updates          | 37          |
| policy_entropy     | -0.3370669  |
| policy_loss        | 0.039728127 |
| serial_timesteps   | 4736        |
| time_elapsed       | 233         |
| total_timesteps    | 4736        |
| value_loss         | 6174.174    |
------------------------------------
-----------------------------------
| approxkl           | 0.12069393 |
| clipfrac           | 0.49023438 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 6.78e+03   |
| explained_variance | 1.67e-06   |
| fps                | 21         |
| n_updates          | 38         |
| policy_entropy     | -0.3374286 |
| policy_loss        | 0.04678353 |
| serial_timesteps   | 4864       |
| time_elapsed       | 238        |
| total_timesteps    | 4864       |
| value_loss         | 0.52961344 |
-----------------------------------
-------------------------------------
| approxkl           | 0.03229621   |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 5.96e-08     |
| fps                | 22           |
| n_updates          | 39           |
| policy_entropy     | -0.33730483  |
| policy_loss        | 6.266334e-05 |
| serial_timesteps   | 4992         |
| time_elapsed       | 244          |
| total_timesteps    | 4992         |
| value_loss         | 2.1004317    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014168022  |
| clipfrac           | 0.1875       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 5.96e-08     |
| fps                | 22           |
| n_updates          | 40           |
| policy_entropy     | -0.3374958   |
| policy_loss        | -0.014558583 |
| serial_timesteps   | 5120         |
| time_elapsed       | 250          |
| total_timesteps    | 5120         |
| value_loss         | 1.1017616    |
-------------------------------------
------------------------------------
| approxkl           | 0.022240305 |
| clipfrac           | 0.21679688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | -1.31e-06   |
| fps                | 24          |
| n_updates          | 41          |
| policy_entropy     | -0.33933824 |
| policy_loss        | 0.0063121   |
| serial_timesteps   | 5248        |
| time_elapsed       | 256         |
| total_timesteps    | 5248        |
| value_loss         | 1.0705982   |
------------------------------------
-------------------------------------
| approxkl           | 0.038107794  |
| clipfrac           | 0.30273438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 1.55e-05     |
| fps                | 25           |
| n_updates          | 42           |
| policy_entropy     | -0.34054744  |
| policy_loss        | -0.004817815 |
| serial_timesteps   | 5376         |
| time_elapsed       | 261          |
| total_timesteps    | 5376         |
| value_loss         | 1.1334887    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0044696843 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 8.88e-06     |
| fps                | 23           |
| n_updates          | 43           |
| policy_entropy     | -0.34150454  |
| policy_loss        | 0.000866294  |
| serial_timesteps   | 5504         |
| time_elapsed       | 266          |
| total_timesteps    | 5504         |
| value_loss         | 3.6256943    |
-------------------------------------
An average of 242.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.004097681  |
| clipfrac           | 0.0546875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | -4.77e-07    |
| fps                | 22           |
| n_updates          | 44           |
| policy_entropy     | -0.34376994  |
| policy_loss        | 0.0049871434 |
| serial_timesteps   | 5632         |
| time_elapsed       | 271          |
| total_timesteps    | 5632         |
| value_loss         | 3.6790562    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009426755  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 0            |
| fps                | 22           |
| n_updates          | 45           |
| policy_entropy     | -0.34654438  |
| policy_loss        | -0.010828256 |
| serial_timesteps   | 5760         |
| time_elapsed       | 277          |
| total_timesteps    | 5760         |
| value_loss         | 4.4930553    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02415875   |
| clipfrac           | 0.25         |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 2.37e-05     |
| fps                | 24           |
| n_updates          | 46           |
| policy_entropy     | -0.34897014  |
| policy_loss        | -0.003659943 |
| serial_timesteps   | 5888         |
| time_elapsed       | 283          |
| total_timesteps    | 5888         |
| value_loss         | 0.820829     |
-------------------------------------
------------------------------------
| approxkl           | 0.03262521  |
| clipfrac           | 0.30273438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.78e+03    |
| explained_variance | -5.13e-06   |
| fps                | 25          |
| n_updates          | 47          |
| policy_entropy     | -0.35135552 |
| policy_loss        | -0.01579374 |
| serial_timesteps   | 6016        |
| time_elapsed       | 288         |
| total_timesteps    | 6016        |
| value_loss         | 1.2972747   |
------------------------------------
-------------------------------------
| approxkl           | 0.051224932  |
| clipfrac           | 0.33007812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.78e+03     |
| explained_variance | 1.87e-05     |
| fps                | 24           |
| n_updates          | 48           |
| policy_entropy     | -0.35511896  |
| policy_loss        | -0.013252909 |
| serial_timesteps   | 6144         |
| time_elapsed       | 293          |
| total_timesteps    | 6144         |
| value_loss         | 0.23189281   |
-------------------------------------
------------------------------------
| approxkl           | 0.045772094 |
| clipfrac           | 0.4140625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.81e+03    |
| explained_variance | -2.38e-07   |
| fps                | 23          |
| n_updates          | 49          |
| policy_entropy     | -0.35675657 |
| policy_loss        | 0.054641936 |
| serial_timesteps   | 6272        |
| time_elapsed       | 298         |
| total_timesteps    | 6272        |
| value_loss         | 6353.6445   |
------------------------------------
------------------------------------
| approxkl           | 0.009903251 |
| clipfrac           | 0.123046875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.81e+03    |
| explained_variance | -2.15e-06   |
| fps                | 25          |
| n_updates          | 50          |
| policy_entropy     | -0.35763025 |
| policy_loss        | 0.007124338 |
| serial_timesteps   | 6400        |
| time_elapsed       | 304         |
| total_timesteps    | 6400        |
| value_loss         | 2.580472    |
------------------------------------
-------------------------------------
| approxkl           | 0.011043922  |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.81e+03     |
| explained_variance | 8.88e-06     |
| fps                | 24           |
| n_updates          | 51           |
| policy_entropy     | -0.35944813  |
| policy_loss        | 0.0027715906 |
| serial_timesteps   | 6528         |
| time_elapsed       | 309          |
| total_timesteps    | 6528         |
| value_loss         | 3.7403967    |
-------------------------------------
An average of 243.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.005125419   |
| clipfrac           | 0.076171875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.81e+03      |
| explained_variance | 1.2e-05       |
| fps                | 24            |
| n_updates          | 52            |
| policy_entropy     | -0.36068016   |
| policy_loss        | -0.0039814236 |
| serial_timesteps   | 6656          |
| time_elapsed       | 314           |
| total_timesteps    | 6656          |
| value_loss         | 153.81094     |
--------------------------------------
---------------------------------------
| approxkl           | 0.005963376    |
| clipfrac           | 0.091796875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.81e+03       |
| explained_variance | 1.43e-05       |
| fps                | 25             |
| n_updates          | 53             |
| policy_entropy     | -0.3610474     |
| policy_loss        | -0.00022605155 |
| serial_timesteps   | 6784           |
| time_elapsed       | 319            |
| total_timesteps    | 6784           |
| value_loss         | 34.24917       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0058351457  |
| clipfrac           | 0.0859375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.81e+03      |
| explained_variance | -5.96e-07     |
| fps                | 25            |
| n_updates          | 54            |
| policy_entropy     | -0.361175     |
| policy_loss        | -0.0038857297 |
| serial_timesteps   | 6912          |
| time_elapsed       | 324           |
| total_timesteps    | 6912          |
| value_loss         | 34.45064      |
--------------------------------------
-------------------------------------
| approxkl           | 0.02429661   |
| clipfrac           | 0.28320312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.81e+03     |
| explained_variance | 1.78e-05     |
| fps                | 24           |
| n_updates          | 55           |
| policy_entropy     | -0.36120462  |
| policy_loss        | -0.006570871 |
| serial_timesteps   | 7040         |
| time_elapsed       | 329          |
| total_timesteps    | 7040         |
| value_loss         | 20.202995    |
-------------------------------------
-------------------------------------
| approxkl           | 0.022483796  |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.81e+03     |
| explained_variance | -7.99e-06    |
| fps                | 23           |
| n_updates          | 56           |
| policy_entropy     | -0.36159685  |
| policy_loss        | -0.001621932 |
| serial_timesteps   | 7168         |
| time_elapsed       | 335          |
| total_timesteps    | 7168         |
| value_loss         | 0.29923508   |
-------------------------------------
------------------------------------
| approxkl           | 0.009285823 |
| clipfrac           | 0.12890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.81e+03    |
| explained_variance | -1.55e-06   |
| fps                | 22          |
| n_updates          | 57          |
| policy_entropy     | -0.36270872 |
| policy_loss        | 0.003054047 |
| serial_timesteps   | 7296        |
| time_elapsed       | 340         |
| total_timesteps    | 7296        |
| value_loss         | 3.699627    |
------------------------------------
------------------------------------
| approxkl           | 0.015540032 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.81e+03    |
| explained_variance | -3.7e-06    |
| fps                | 22          |
| n_updates          | 58          |
| policy_entropy     | -0.36373538 |
| policy_loss        | -0.00589725 |
| serial_timesteps   | 7424        |
| time_elapsed       | 346         |
| total_timesteps    | 7424        |
| value_loss         | 0.7423193   |
------------------------------------
-------------------------------------
| approxkl           | 0.017871747  |
| clipfrac           | 0.21289062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.81e+03     |
| explained_variance | 1.19e-07     |
| fps                | 22           |
| n_updates          | 59           |
| policy_entropy     | -0.36472404  |
| policy_loss        | -0.013996096 |
| serial_timesteps   | 7552         |
| time_elapsed       | 351          |
| total_timesteps    | 7552         |
| value_loss         | 1.0282537    |
-------------------------------------
An average of 243.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.016666457  |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.81e+03     |
| explained_variance | 6.62e-06     |
| fps                | 22           |
| n_updates          | 60           |
| policy_entropy     | -0.3660523   |
| policy_loss        | -0.012285553 |
| serial_timesteps   | 7680         |
| time_elapsed       | 357          |
| total_timesteps    | 7680         |
| value_loss         | 1.3082993    |
-------------------------------------
------------------------------------
| approxkl           | 0.03155297  |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 0           |
| fps                | 26          |
| n_updates          | 61          |
| policy_entropy     | -0.36761537 |
| policy_loss        | 0.02712075  |
| serial_timesteps   | 7808        |
| time_elapsed       | 363         |
| total_timesteps    | 7808        |
| value_loss         | 6390.956    |
------------------------------------
-------------------------------------
| approxkl           | 0.032822955  |
| clipfrac           | 0.28125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 1.97e-05     |
| fps                | 23           |
| n_updates          | 62           |
| policy_entropy     | -0.36859435  |
| policy_loss        | -0.011275775 |
| serial_timesteps   | 7936         |
| time_elapsed       | 368          |
| total_timesteps    | 7936         |
| value_loss         | 0.88077605   |
-------------------------------------
-------------------------------------
| approxkl           | 0.012825069  |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -1.31e-06    |
| fps                | 21           |
| n_updates          | 63           |
| policy_entropy     | -0.3702575   |
| policy_loss        | 0.0061388984 |
| serial_timesteps   | 8064         |
| time_elapsed       | 373          |
| total_timesteps    | 8064         |
| value_loss         | 4.0649595    |
-------------------------------------
---------------------------------------
| approxkl           | 0.00796276     |
| clipfrac           | 0.10546875     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.77e+03       |
| explained_variance | 6.79e-06       |
| fps                | 22             |
| n_updates          | 64             |
| policy_entropy     | -0.37192628    |
| policy_loss        | -0.00018212083 |
| serial_timesteps   | 8192           |
| time_elapsed       | 379            |
| total_timesteps    | 8192           |
| value_loss         | 3.2248173      |
---------------------------------------
-------------------------------------
| approxkl           | 0.00533525   |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 1.79e-05     |
| fps                | 22           |
| n_updates          | 65           |
| policy_entropy     | -0.37311852  |
| policy_loss        | 0.0049715834 |
| serial_timesteps   | 8320         |
| time_elapsed       | 385          |
| total_timesteps    | 8320         |
| value_loss         | 3.8639567    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023375876  |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -5.96e-06    |
| fps                | 23           |
| n_updates          | 66           |
| policy_entropy     | -0.37399018  |
| policy_loss        | -0.019021802 |
| serial_timesteps   | 8448         |
| time_elapsed       | 390          |
| total_timesteps    | 8448         |
| value_loss         | 0.91839194   |
-------------------------------------
------------------------------------
| approxkl           | 0.009733068 |
| clipfrac           | 0.115234375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -2.74e-06   |
| fps                | 24          |
| n_updates          | 67          |
| policy_entropy     | -0.37503767 |
| policy_loss        | 0.004895201 |
| serial_timesteps   | 8576        |
| time_elapsed       | 396         |
| total_timesteps    | 8576        |
| value_loss         | 1.3029946   |
------------------------------------
An average of 244.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0061401753  |
| clipfrac           | 0.07421875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | 1.33e-05      |
| fps                | 23            |
| n_updates          | 68            |
| policy_entropy     | -0.3781332    |
| policy_loss        | 0.00045931875 |
| serial_timesteps   | 8704          |
| time_elapsed       | 401           |
| total_timesteps    | 8704          |
| value_loss         | 3.7220764     |
--------------------------------------
------------------------------------
| approxkl           | 0.01544158  |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -1.26e-05   |
| fps                | 22          |
| n_updates          | 69          |
| policy_entropy     | -0.38053626 |
| policy_loss        | 0.021302897 |
| serial_timesteps   | 8832        |
| time_elapsed       | 407         |
| total_timesteps    | 8832        |
| value_loss         | 2.1301165   |
------------------------------------
--------------------------------------
| approxkl           | 0.0011375288  |
| clipfrac           | 0.009765625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | 1.45e-05      |
| fps                | 24            |
| n_updates          | 70            |
| policy_entropy     | -0.38234782   |
| policy_loss        | -0.0011455349 |
| serial_timesteps   | 8960          |
| time_elapsed       | 413           |
| total_timesteps    | 8960          |
| value_loss         | 61.971886     |
--------------------------------------
-------------------------------------
| approxkl           | 0.012494266  |
| clipfrac           | 0.18164062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 1.01e-05     |
| fps                | 25           |
| n_updates          | 71           |
| policy_entropy     | -0.38279787  |
| policy_loss        | -0.007447547 |
| serial_timesteps   | 9088         |
| time_elapsed       | 418          |
| total_timesteps    | 9088         |
| value_loss         | 74.67634     |
-------------------------------------
------------------------------------
| approxkl           | 0.019224249 |
| clipfrac           | 0.20898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 8.82e-06    |
| fps                | 24          |
| n_updates          | 72          |
| policy_entropy     | -0.38390934 |
| policy_loss        | 0.022841439 |
| serial_timesteps   | 9216        |
| time_elapsed       | 423         |
| total_timesteps    | 9216        |
| value_loss         | 24.53952    |
------------------------------------
------------------------------------
| approxkl           | 0.022574523 |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 2.98e-07    |
| fps                | 26          |
| n_updates          | 73          |
| policy_entropy     | -0.3845303  |
| policy_loss        | 0.033901695 |
| serial_timesteps   | 9344        |
| time_elapsed       | 428         |
| total_timesteps    | 9344        |
| value_loss         | 6722.8584   |
------------------------------------
------------------------------------
| approxkl           | 0.019493487 |
| clipfrac           | 0.25195312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 3.9e-05     |
| fps                | 23          |
| n_updates          | 74          |
| policy_entropy     | -0.38452947 |
| policy_loss        | 0.012573367 |
| serial_timesteps   | 9472        |
| time_elapsed       | 433         |
| total_timesteps    | 9472        |
| value_loss         | 2.3530438   |
------------------------------------
An average of 245.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.03346702  |
| clipfrac           | 0.33007812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -2.74e-06   |
| fps                | 22          |
| n_updates          | 75          |
| policy_entropy     | -0.38424104 |
| policy_loss        | 0.016882189 |
| serial_timesteps   | 9600        |
| time_elapsed       | 438         |
| total_timesteps    | 9600        |
| value_loss         | 8.541338    |
------------------------------------
-------------------------------------
| approxkl           | 0.013787666  |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -3.46e-06    |
| fps                | 22           |
| n_updates          | 76           |
| policy_entropy     | -0.3838358   |
| policy_loss        | -0.009411289 |
| serial_timesteps   | 9728         |
| time_elapsed       | 444          |
| total_timesteps    | 9728         |
| value_loss         | 6.801526     |
-------------------------------------
-------------------------------------
| approxkl           | 0.040119015  |
| clipfrac           | 0.34960938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 0            |
| fps                | 21           |
| n_updates          | 77           |
| policy_entropy     | -0.38351768  |
| policy_loss        | -0.008108003 |
| serial_timesteps   | 9856         |
| time_elapsed       | 450          |
| total_timesteps    | 9856         |
| value_loss         | 8.332376     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0075310357  |
| clipfrac           | 0.103515625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | -2.03e-05     |
| fps                | 24            |
| n_updates          | 78            |
| policy_entropy     | -0.38329497   |
| policy_loss        | -0.0075963233 |
| serial_timesteps   | 9984          |
| time_elapsed       | 456           |
| total_timesteps    | 9984          |
| value_loss         | 3.6919403     |
--------------------------------------
------------------------------------
| approxkl           | 0.03134125  |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -1.59e-05   |
| fps                | 24          |
| n_updates          | 79          |
| policy_entropy     | -0.38315025 |
| policy_loss        | -0.02682492 |
| serial_timesteps   | 10112       |
| time_elapsed       | 461         |
| total_timesteps    | 10112       |
| value_loss         | 0.4113611   |
------------------------------------
-------------------------------------
| approxkl           | 0.012981952  |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -3.58e-06    |
| fps                | 24           |
| n_updates          | 80           |
| policy_entropy     | -0.38301504  |
| policy_loss        | 0.0050897673 |
| serial_timesteps   | 10240        |
| time_elapsed       | 466          |
| total_timesteps    | 10240        |
| value_loss         | 4.4584894    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006281303   |
| clipfrac           | 0.08203125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | -2.62e-05     |
| fps                | 20            |
| n_updates          | 81            |
| policy_entropy     | -0.38395932   |
| policy_loss        | -0.0036568542 |
| serial_timesteps   | 10368         |
| time_elapsed       | 471           |
| total_timesteps    | 10368         |
| value_loss         | 3.855843      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0069793276 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 5.9e-06      |
| fps                | 22           |
| n_updates          | 82           |
| policy_entropy     | -0.38664088  |
| policy_loss        | -0.008148871 |
| serial_timesteps   | 10496        |
| time_elapsed       | 478          |
| total_timesteps    | 10496        |
| value_loss         | 4.25109      |
-------------------------------------
An average of 245.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.009146943    |
| clipfrac           | 0.115234375    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.77e+03       |
| explained_variance | -2.03e-06      |
| fps                | 23             |
| n_updates          | 83             |
| policy_entropy     | -0.38978294    |
| policy_loss        | -0.00058630994 |
| serial_timesteps   | 10624          |
| time_elapsed       | 483            |
| total_timesteps    | 10624          |
| value_loss         | 2.1189842      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0128766345 |
| clipfrac           | 0.19921875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 1.42e-05     |
| fps                | 24           |
| n_updates          | 84           |
| policy_entropy     | -0.39275336  |
| policy_loss        | -0.018787486 |
| serial_timesteps   | 10752        |
| time_elapsed       | 489          |
| total_timesteps    | 10752        |
| value_loss         | 0.7596216    |
-------------------------------------
------------------------------------
| approxkl           | 0.022878176 |
| clipfrac           | 0.32226562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -2.38e-07   |
| fps                | 24          |
| n_updates          | 85          |
| policy_entropy     | -0.3941701  |
| policy_loss        | 0.010052621 |
| serial_timesteps   | 10880       |
| time_elapsed       | 494         |
| total_timesteps    | 10880       |
| value_loss         | 6471.193    |
------------------------------------
-------------------------------------
| approxkl           | 0.032149274  |
| clipfrac           | 0.31445312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 8.94e-07     |
| fps                | 22           |
| n_updates          | 86           |
| policy_entropy     | -0.3947984   |
| policy_loss        | -0.027351655 |
| serial_timesteps   | 11008        |
| time_elapsed       | 499          |
| total_timesteps    | 11008        |
| value_loss         | 1.3339736    |
-------------------------------------
------------------------------------
| approxkl           | 0.010749425 |
| clipfrac           | 0.1484375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -2.42e-05   |
| fps                | 24          |
| n_updates          | 87          |
| policy_entropy     | -0.3961376  |
| policy_loss        | 0.014266345 |
| serial_timesteps   | 11136       |
| time_elapsed       | 505         |
| total_timesteps    | 11136       |
| value_loss         | 3.4464374   |
------------------------------------
------------------------------------
| approxkl           | 0.010519737 |
| clipfrac           | 0.14257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 3.22e-05    |
| fps                | 23          |
| n_updates          | 88          |
| policy_entropy     | -0.39795384 |
| policy_loss        | 0.005247871 |
| serial_timesteps   | 11264       |
| time_elapsed       | 510         |
| total_timesteps    | 11264       |
| value_loss         | 1.2517655   |
------------------------------------
------------------------------------
| approxkl           | 0.0321287   |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 3.76e-06    |
| fps                | 25          |
| n_updates          | 89          |
| policy_entropy     | -0.39940256 |
| policy_loss        | 0.01699707  |
| serial_timesteps   | 11392       |
| time_elapsed       | 516         |
| total_timesteps    | 11392       |
| value_loss         | 142.8157    |
------------------------------------
-------------------------------------
| approxkl           | 0.011634516  |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 1.6e-05      |
| fps                | 25           |
| n_updates          | 90           |
| policy_entropy     | -0.3998213   |
| policy_loss        | 0.0024535307 |
| serial_timesteps   | 11520        |
| time_elapsed       | 521          |
| total_timesteps    | 11520        |
| value_loss         | 36.369305    |
-------------------------------------
An average of 246.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.016974727   |
| clipfrac           | 0.21484375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | 1.55e-05      |
| fps                | 26            |
| n_updates          | 91            |
| policy_entropy     | -0.3999955    |
| policy_loss        | -0.0041592056 |
| serial_timesteps   | 11648         |
| time_elapsed       | 526           |
| total_timesteps    | 11648         |
| value_loss         | 28.790173     |
--------------------------------------
------------------------------------
| approxkl           | 0.01895302  |
| clipfrac           | 0.2109375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 4.68e-05    |
| fps                | 24          |
| n_updates          | 92          |
| policy_entropy     | -0.39858186 |
| policy_loss        | 0.008092329 |
| serial_timesteps   | 11776       |
| time_elapsed       | 531         |
| total_timesteps    | 11776       |
| value_loss         | 12.858554   |
------------------------------------
-------------------------------------
| approxkl           | 0.010946447  |
| clipfrac           | 0.13867188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 2.69e-05     |
| fps                | 22           |
| n_updates          | 93           |
| policy_entropy     | -0.39833224  |
| policy_loss        | -0.008174542 |
| serial_timesteps   | 11904        |
| time_elapsed       | 536          |
| total_timesteps    | 11904        |
| value_loss         | 1.1957505    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03552664   |
| clipfrac           | 0.31640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -1.06e-05    |
| fps                | 22           |
| n_updates          | 94           |
| policy_entropy     | -0.39851344  |
| policy_loss        | -0.008651566 |
| serial_timesteps   | 12032        |
| time_elapsed       | 542          |
| total_timesteps    | 12032        |
| value_loss         | 0.6660902    |
-------------------------------------
-------------------------------------
| approxkl           | 0.035419963  |
| clipfrac           | 0.34375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -8.58e-06    |
| fps                | 23           |
| n_updates          | 95           |
| policy_entropy     | -0.39708573  |
| policy_loss        | -0.026814282 |
| serial_timesteps   | 12160        |
| time_elapsed       | 547          |
| total_timesteps    | 12160        |
| value_loss         | 0.8631369    |
-------------------------------------
-------------------------------------
| approxkl           | 0.019484952  |
| clipfrac           | 0.32421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -2.38e-07    |
| fps                | 22           |
| n_updates          | 96           |
| policy_entropy     | -0.39704922  |
| policy_loss        | -0.039364927 |
| serial_timesteps   | 12288        |
| time_elapsed       | 553          |
| total_timesteps    | 12288        |
| value_loss         | 1.3385175    |
-------------------------------------
------------------------------------
| approxkl           | 0.007582912 |
| clipfrac           | 0.11328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.74e+03    |
| explained_variance | -1.19e-07   |
| fps                | 23          |
| n_updates          | 97          |
| policy_entropy     | -0.3976836  |
| policy_loss        | 0.006739307 |
| serial_timesteps   | 12416       |
| time_elapsed       | 558         |
| total_timesteps    | 12416       |
| value_loss         | 6446.8975   |
------------------------------------
------------------------------------
| approxkl           | 0.020189757 |
| clipfrac           | 0.24023438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.74e+03    |
| explained_variance | 9e-06       |
| fps                | 25          |
| n_updates          | 98          |
| policy_entropy     | -0.3982796  |
| policy_loss        | 0.007342463 |
| serial_timesteps   | 12544       |
| time_elapsed       | 564         |
| total_timesteps    | 12544       |
| value_loss         | 2.7247343   |
------------------------------------
An average of 247.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.012432314  |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.74e+03     |
| explained_variance | -1.43e-06    |
| fps                | 23           |
| n_updates          | 99           |
| policy_entropy     | -0.3993108   |
| policy_loss        | 0.0050113816 |
| serial_timesteps   | 12672        |
| time_elapsed       | 569          |
| total_timesteps    | 12672        |
| value_loss         | 5.9039083    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0042371154 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.74e+03     |
| explained_variance | -6.08e-06    |
| fps                | 22           |
| n_updates          | 100          |
| policy_entropy     | -0.40009186  |
| policy_loss        | 0.001348688  |
| serial_timesteps   | 12800        |
| time_elapsed       | 574          |
| total_timesteps    | 12800        |
| value_loss         | 8.4092045    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0011193139 |
| clipfrac           | 0.0078125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.74e+03     |
| explained_variance | -1.14e-05    |
| fps                | 22           |
| n_updates          | 101          |
| policy_entropy     | -0.40123117  |
| policy_loss        | 0.0027385142 |
| serial_timesteps   | 12928        |
| time_elapsed       | 580          |
| total_timesteps    | 12928        |
| value_loss         | 3.9727516    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015270319  |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.74e+03     |
| explained_variance | 1.39e-05     |
| fps                | 23           |
| n_updates          | 102          |
| policy_entropy     | -0.40238112  |
| policy_loss        | 0.0050195963 |
| serial_timesteps   | 13056        |
| time_elapsed       | 586          |
| total_timesteps    | 13056        |
| value_loss         | 4.133317     |
-------------------------------------
------------------------------------
| approxkl           | 0.011440476 |
| clipfrac           | 0.13085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.74e+03    |
| explained_variance | -9.54e-07   |
| fps                | 22          |
| n_updates          | 103         |
| policy_entropy     | -0.40374503 |
| policy_loss        | 0.0086509   |
| serial_timesteps   | 13184       |
| time_elapsed       | 591         |
| total_timesteps    | 13184       |
| value_loss         | 2.6267285   |
------------------------------------
------------------------------------
| approxkl           | 0.016892077 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.74e+03    |
| explained_variance | 1.65e-05    |
| fps                | 23          |
| n_updates          | 104         |
| policy_entropy     | -0.40594453 |
| policy_loss        | 0.008974219 |
| serial_timesteps   | 13312       |
| time_elapsed       | 597         |
| total_timesteps    | 13312       |
| value_loss         | 2.6676784   |
------------------------------------
-------------------------------------
| approxkl           | 0.005640273  |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.74e+03     |
| explained_variance | 1.13e-06     |
| fps                | 23           |
| n_updates          | 105          |
| policy_entropy     | -0.40720224  |
| policy_loss        | 0.0014583124 |
| serial_timesteps   | 13440        |
| time_elapsed       | 602          |
| total_timesteps    | 13440        |
| value_loss         | 3.4730902    |
-------------------------------------
------------------------------------
| approxkl           | 0.01836135  |
| clipfrac           | 0.21289062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.74e+03    |
| explained_variance | 9.06e-06    |
| fps                | 23          |
| n_updates          | 106         |
| policy_entropy     | -0.4088974  |
| policy_loss        | 0.008540234 |
| serial_timesteps   | 13568       |
| time_elapsed       | 608         |
| total_timesteps    | 13568       |
| value_loss         | 6.2931285   |
------------------------------------
An average of 247.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.011024786 |
| clipfrac           | 0.16601562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.74e+03    |
| explained_variance | 2.03e-05    |
| fps                | 25          |
| n_updates          | 107         |
| policy_entropy     | -0.4098957  |
| policy_loss        | 0.013030866 |
| serial_timesteps   | 13696       |
| time_elapsed       | 613         |
| total_timesteps    | 13696       |
| value_loss         | 63.27208    |
------------------------------------
-------------------------------------
| approxkl           | 0.006199895  |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.74e+03     |
| explained_variance | 1e-05        |
| fps                | 26           |
| n_updates          | 108          |
| policy_entropy     | -0.41055855  |
| policy_loss        | -0.003498797 |
| serial_timesteps   | 13824        |
| time_elapsed       | 618          |
| total_timesteps    | 13824        |
| value_loss         | 74.175285    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0035121434 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | 1.79e-07     |
| fps                | 24           |
| n_updates          | 109          |
| policy_entropy     | -0.41114613  |
| policy_loss        | 0.0056363465 |
| serial_timesteps   | 13952        |
| time_elapsed       | 623          |
| total_timesteps    | 13952        |
| value_loss         | 6745.9062    |
-------------------------------------
-------------------------------------
| approxkl           | 0.022898337  |
| clipfrac           | 0.24804688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | 2.56e-06     |
| fps                | 23           |
| n_updates          | 110          |
| policy_entropy     | -0.41111737  |
| policy_loss        | -0.018756012 |
| serial_timesteps   | 14080        |
| time_elapsed       | 628          |
| total_timesteps    | 14080        |
| value_loss         | 26.02634     |
-------------------------------------
------------------------------------
| approxkl           | 0.011375036 |
| clipfrac           | 0.13085938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.76e+03    |
| explained_variance | 3.68e-05    |
| fps                | 24          |
| n_updates          | 111         |
| policy_entropy     | -0.41102594 |
| policy_loss        | 0.006787785 |
| serial_timesteps   | 14208       |
| time_elapsed       | 634         |
| total_timesteps    | 14208       |
| value_loss         | 5.613361    |
------------------------------------
-------------------------------------
| approxkl           | 0.018823547  |
| clipfrac           | 0.21289062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | -1.79e-06    |
| fps                | 21           |
| n_updates          | 112          |
| policy_entropy     | -0.41125846  |
| policy_loss        | -0.007981876 |
| serial_timesteps   | 14336        |
| time_elapsed       | 639          |
| total_timesteps    | 14336        |
| value_loss         | 0.9794031    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023778487  |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | -1.26e-05    |
| fps                | 22           |
| n_updates          | 113          |
| policy_entropy     | -0.4118123   |
| policy_loss        | -0.011454823 |
| serial_timesteps   | 14464        |
| time_elapsed       | 645          |
| total_timesteps    | 14464        |
| value_loss         | 1.9526979    |
-------------------------------------
An average of 248.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.012711623   |
| clipfrac           | 0.16992188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.76e+03      |
| explained_variance | 2.74e-06      |
| fps                | 20            |
| n_updates          | 114           |
| policy_entropy     | -0.41310677   |
| policy_loss        | -0.0085163135 |
| serial_timesteps   | 14592         |
| time_elapsed       | 651           |
| total_timesteps    | 14592         |
| value_loss         | 6.122611      |
--------------------------------------
-------------------------------------
| approxkl           | 0.00937001   |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | -3.93e-06    |
| fps                | 23           |
| n_updates          | 115          |
| policy_entropy     | -0.41455495  |
| policy_loss        | -0.004682414 |
| serial_timesteps   | 14720        |
| time_elapsed       | 657          |
| total_timesteps    | 14720        |
| value_loss         | 4.3024607    |
-------------------------------------
--------------------------------------
| approxkl           | 0.019213015   |
| clipfrac           | 0.19140625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.76e+03      |
| explained_variance | -1.26e-05     |
| fps                | 25            |
| n_updates          | 116           |
| policy_entropy     | -0.4165728    |
| policy_loss        | -0.0041098786 |
| serial_timesteps   | 14848         |
| time_elapsed       | 662           |
| total_timesteps    | 14848         |
| value_loss         | 3.5478303     |
--------------------------------------
-------------------------------------
| approxkl           | 0.00706035   |
| clipfrac           | 0.087890625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.76e+03     |
| explained_variance | 3.87e-06     |
| fps                | 24           |
| n_updates          | 117          |
| policy_entropy     | -0.41828567  |
| policy_loss        | 0.0055851694 |
| serial_timesteps   | 14976        |
| time_elapsed       | 667          |
| total_timesteps    | 14976        |
| value_loss         | 2.4768527    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3bbbf978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3bbbf978>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3ad3da90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3ad3da90>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2796 samples, validate on 336 samples
Epoch 464/5000
 - 9s - loss: 0.1913 - val_loss: 0.0733
Epoch 465/5000
 - 1s - loss: 0.0243 - val_loss: 0.0763
Epoch 466/5000
 - 1s - loss: 0.0205 - val_loss: 0.0686
Epoch 467/5000
 - 1s - loss: 0.0171 - val_loss: 0.0602
Epoch 468/5000
 - 1s - loss: 0.0135 - val_loss: 0.0497
Epoch 469/5000
 - 1s - loss: 0.0103 - val_loss: 0.0379
Epoch 470/5000
 - 1s - loss: 0.0085 - val_loss: 0.0215
Epoch 471/5000
 - 1s - loss: 0.0082 - val_loss: 0.0193
Epoch 472/5000
 - 1s - loss: 0.0081 - val_loss: 0.0160
Epoch 473/5000
 - 1s - loss: 0.0082 - val_loss: 0.0154
Epoch 474/5000
 - 1s - loss: 0.0082 - val_loss: 0.0145
Epoch 475/5000
 - 1s - loss: 0.0082 - val_loss: 0.0142
Epoch 476/5000
 - 1s - loss: 0.0082 - val_loss: 0.0138
Epoch 477/5000
 - 1s - loss: 0.0082 - val_loss: 0.0138
Epoch 478/5000
 - 1s - loss: 0.0083 - val_loss: 0.0137
Epoch 479/5000
 - 1s - loss: 0.0069 - val_loss: 0.0074
Epoch 480/5000
 - 1s - loss: 0.0060 - val_loss: 0.0079
Epoch 481/5000
 - 1s - loss: 0.0060 - val_loss: 0.0083
Epoch 482/5000
 - 1s - loss: 0.0059 - val_loss: 0.0086
Epoch 483/5000
 - 1s - loss: 0.0058 - val_loss: 0.0086
Epoch 484/5000
 - 1s - loss: 0.0058 - val_loss: 0.0086
Train on 1943 samples, validate on 336 samples
Epoch 344/5000
 - 9s - loss: 0.0063 - val_loss: 0.0321
Epoch 345/5000
 - 1s - loss: 0.0063 - val_loss: 0.0321
Epoch 346/5000
 - 1s - loss: 0.0063 - val_loss: 0.0321
Epoch 347/5000
 - 1s - loss: 0.0063 - val_loss: 0.0321
Epoch 348/5000
 - 1s - loss: 0.0063 - val_loss: 0.0321
Epoch 349/5000
 - 1s - loss: 0.0063 - val_loss: 0.0321
Train on 2797 samples, validate on 336 samples
Epoch 1143/5000
 - 10s - loss: 0.6772 - val_loss: 0.6592
Epoch 1144/5000
 - 1s - loss: 0.6012 - val_loss: 0.6469
Epoch 1145/5000
 - 1s - loss: 0.5836 - val_loss: 0.6647
Epoch 1146/5000
 - 1s - loss: 0.5886 - val_loss: 0.6676
Epoch 1147/5000
 - 1s - loss: 0.5799 - val_loss: 0.6661
Epoch 1148/5000
 - 1s - loss: 0.5794 - val_loss: 0.6650
Epoch 1149/5000
 - 1s - loss: 0.5791 - val_loss: 0.6641
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0042063324 |
| clipfrac           | 0.044921875  |
| explained_variance | -1.36e-05    |
| fps                | 2            |
| n_updates          | 1            |
| policy_entropy     | -0.420817    |
| policy_loss        | -0.004348955 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.31e-05     |
| total_timesteps    | 128          |
| value_loss         | 2.500614     |
-------------------------------------
------------------------------------
| approxkl           | 0.008332522 |
| clipfrac           | 0.1171875   |
| explained_variance | 4.77e-06    |
| fps                | 20          |
| n_updates          | 2           |
| policy_entropy     | -0.42354086 |
| policy_loss        | 0.011960261 |
| serial_timesteps   | 256         |
| time_elapsed       | 44.6        |
| total_timesteps    | 256         |
| value_loss         | 4.109465    |
------------------------------------
------------------------------------
| approxkl           | 0.009721476 |
| clipfrac           | 0.14648438  |
| explained_variance | -8.7e-06    |
| fps                | 21          |
| n_updates          | 3           |
| policy_entropy     | -0.42608458 |
| policy_loss        | 0.01522456  |
| serial_timesteps   | 384         |
| time_elapsed       | 50.9        |
| total_timesteps    | 384         |
| value_loss         | 4.6048436   |
------------------------------------
-------------------------------------
| approxkl           | 0.013615769  |
| clipfrac           | 0.1640625    |
| explained_variance | -2.38e-06    |
| fps                | 20           |
| n_updates          | 4            |
| policy_entropy     | -0.42809677  |
| policy_loss        | -0.017471362 |
| serial_timesteps   | 512          |
| time_elapsed       | 56.8         |
| total_timesteps    | 512          |
| value_loss         | 1.9793936    |
-------------------------------------
An average of 249.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0153644625 |
| clipfrac           | 0.19335938   |
| explained_variance | -1.14e-05    |
| fps                | 21           |
| n_updates          | 5            |
| policy_entropy     | -0.4298249   |
| policy_loss        | -0.011163373 |
| serial_timesteps   | 640          |
| time_elapsed       | 63           |
| total_timesteps    | 640          |
| value_loss         | 2.3247507    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005127283   |
| clipfrac           | 0.0625        |
| explained_variance | 1.47e-05      |
| fps                | 19            |
| n_updates          | 6             |
| policy_entropy     | -0.43134883   |
| policy_loss        | 0.00097396993 |
| serial_timesteps   | 768           |
| time_elapsed       | 69            |
| total_timesteps    | 768           |
| value_loss         | 2.5764005     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005187663  |
| clipfrac           | 0.05859375   |
| explained_variance | -9.54e-07    |
| fps                | 20           |
| n_updates          | 7            |
| policy_entropy     | -0.43382007  |
| policy_loss        | -0.007363797 |
| serial_timesteps   | 896          |
| time_elapsed       | 75.5         |
| total_timesteps    | 896          |
| value_loss         | 1.4623301    |
-------------------------------------
------------------------------------
| approxkl           | 0.031215673 |
| clipfrac           | 0.32421875  |
| explained_variance | 4.89e-06    |
| fps                | 20          |
| n_updates          | 8           |
| policy_entropy     | -0.4371531  |
| policy_loss        | 0.00512759  |
| serial_timesteps   | 1024        |
| time_elapsed       | 81.8        |
| total_timesteps    | 1024        |
| value_loss         | 0.50735366  |
------------------------------------
-------------------------------------
| approxkl           | 0.01891101   |
| clipfrac           | 0.26171875   |
| explained_variance | -2.66e-05    |
| fps                | 19           |
| n_updates          | 9            |
| policy_entropy     | -0.43872267  |
| policy_loss        | -0.020080954 |
| serial_timesteps   | 1152         |
| time_elapsed       | 88           |
| total_timesteps    | 1152         |
| value_loss         | 0.52191025   |
-------------------------------------
------------------------------------
| approxkl           | 0.013078063 |
| clipfrac           | 0.16601562  |
| explained_variance | 3.16e-05    |
| fps                | 20          |
| n_updates          | 10          |
| policy_entropy     | -0.44017893 |
| policy_loss        | 0.005000502 |
| serial_timesteps   | 1280        |
| time_elapsed       | 94.5        |
| total_timesteps    | 1280        |
| value_loss         | 3.7366054   |
------------------------------------
------------------------------------
| approxkl           | 0.02207435  |
| clipfrac           | 0.22070312  |
| explained_variance | -1.37e-05   |
| fps                | 21          |
| n_updates          | 11          |
| policy_entropy     | -0.44159773 |
| policy_loss        | 0.008025963 |
| serial_timesteps   | 1408        |
| time_elapsed       | 101         |
| total_timesteps    | 1408        |
| value_loss         | 1.9957871   |
------------------------------------
-------------------------------------
| approxkl           | 0.0081584975 |
| clipfrac           | 0.0859375    |
| explained_variance | 2.85e-05     |
| fps                | 20           |
| n_updates          | 12           |
| policy_entropy     | -0.44363818  |
| policy_loss        | -0.006713193 |
| serial_timesteps   | 1536         |
| time_elapsed       | 107          |
| total_timesteps    | 1536         |
| value_loss         | 58.980385    |
-------------------------------------
An average of 250.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.00796205   |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 5.36e-07     |
| fps                | 20           |
| n_updates          | 13           |
| policy_entropy     | -0.44461685  |
| policy_loss        | -0.004752617 |
| serial_timesteps   | 1664         |
| time_elapsed       | 113          |
| total_timesteps    | 1664         |
| value_loss         | 4224.8013    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0065387157 |
| clipfrac           | 0.09375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 3.58e-07     |
| fps                | 20           |
| n_updates          | 14           |
| policy_entropy     | -0.44440886  |
| policy_loss        | 0.0072992183 |
| serial_timesteps   | 1792         |
| time_elapsed       | 119          |
| total_timesteps    | 1792         |
| value_loss         | 30.242855    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008426268   |
| clipfrac           | 0.111328125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.99e+03      |
| explained_variance | 3.99e-05      |
| fps                | 21            |
| n_updates          | 15            |
| policy_entropy     | -0.44554538   |
| policy_loss        | -0.0035909733 |
| serial_timesteps   | 1920          |
| time_elapsed       | 125           |
| total_timesteps    | 1920          |
| value_loss         | 16.296463     |
--------------------------------------
------------------------------------
| approxkl           | 0.012035814 |
| clipfrac           | 0.16210938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | 4e-05       |
| fps                | 21          |
| n_updates          | 16          |
| policy_entropy     | -0.4468361  |
| policy_loss        | 0.003930539 |
| serial_timesteps   | 2048        |
| time_elapsed       | 131         |
| total_timesteps    | 2048        |
| value_loss         | 2.7489438   |
------------------------------------
-------------------------------------
| approxkl           | 0.019127972  |
| clipfrac           | 0.22265625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 3.44e-05     |
| fps                | 22           |
| n_updates          | 17           |
| policy_entropy     | -0.447861    |
| policy_loss        | -0.010881128 |
| serial_timesteps   | 2176         |
| time_elapsed       | 137          |
| total_timesteps    | 2176         |
| value_loss         | 1.2215437    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0063608573   |
| clipfrac           | 0.1015625      |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.99e+03       |
| explained_variance | -3.98e-05      |
| fps                | 21             |
| n_updates          | 18             |
| policy_entropy     | -0.44969696    |
| policy_loss        | -0.00095082377 |
| serial_timesteps   | 2304           |
| time_elapsed       | 143            |
| total_timesteps    | 2304           |
| value_loss         | 5.746307       |
---------------------------------------
-------------------------------------
| approxkl           | 0.0053996816 |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -4.02e-05    |
| fps                | 20           |
| n_updates          | 19           |
| policy_entropy     | -0.451607    |
| policy_loss        | 0.005372728  |
| serial_timesteps   | 2432         |
| time_elapsed       | 149          |
| total_timesteps    | 2432         |
| value_loss         | 2.2596426    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021518264  |
| clipfrac           | 0.25195312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -1.26e-05    |
| fps                | 20           |
| n_updates          | 20           |
| policy_entropy     | -0.45287395  |
| policy_loss        | -0.020761397 |
| serial_timesteps   | 2560         |
| time_elapsed       | 155          |
| total_timesteps    | 2560         |
| value_loss         | 2.8469453    |
-------------------------------------
An average of 250.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.036271933  |
| clipfrac           | 0.25976562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 4.35e-06     |
| fps                | 20           |
| n_updates          | 21           |
| policy_entropy     | -0.45451725  |
| policy_loss        | 0.0096265115 |
| serial_timesteps   | 2688         |
| time_elapsed       | 161          |
| total_timesteps    | 2688         |
| value_loss         | 0.3604158    |
-------------------------------------
------------------------------------
| approxkl           | 0.027402386 |
| clipfrac           | 0.28320312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -1.31e-05   |
| fps                | 21          |
| n_updates          | 22          |
| policy_entropy     | -0.45573774 |
| policy_loss        | -0.02559027 |
| serial_timesteps   | 2816        |
| time_elapsed       | 167         |
| total_timesteps    | 2816        |
| value_loss         | 4.274952    |
------------------------------------
-------------------------------------
| approxkl           | 0.03000712   |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 1.33e-05     |
| fps                | 20           |
| n_updates          | 23           |
| policy_entropy     | -0.45647997  |
| policy_loss        | 0.0046910103 |
| serial_timesteps   | 2944         |
| time_elapsed       | 173          |
| total_timesteps    | 2944         |
| value_loss         | 6.9885755    |
-------------------------------------
------------------------------------
| approxkl           | 0.013032575 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -4.89e-06   |
| fps                | 20          |
| n_updates          | 24          |
| policy_entropy     | -0.45765302 |
| policy_loss        | 0.013079463 |
| serial_timesteps   | 3072        |
| time_elapsed       | 180         |
| total_timesteps    | 3072        |
| value_loss         | 4.3641644   |
------------------------------------
--------------------------------------
| approxkl           | 8.2704384e-05 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | -1.19e-07     |
| fps                | 21            |
| n_updates          | 25            |
| policy_entropy     | -0.45906982   |
| policy_loss        | 0.0005439423  |
| serial_timesteps   | 3200          |
| time_elapsed       | 186           |
| total_timesteps    | 3200          |
| value_loss         | 5594.0063     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005867117  |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -9.54e-07    |
| fps                | 21           |
| n_updates          | 26           |
| policy_entropy     | -0.46009552  |
| policy_loss        | 0.0011127722 |
| serial_timesteps   | 3328         |
| time_elapsed       | 192          |
| total_timesteps    | 3328         |
| value_loss         | 2.714259     |
-------------------------------------
-------------------------------------
| approxkl           | 0.026324937  |
| clipfrac           | 0.29882812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -3.53e-05    |
| fps                | 20           |
| n_updates          | 27           |
| policy_entropy     | -0.46181107  |
| policy_loss        | -0.025380014 |
| serial_timesteps   | 3456         |
| time_elapsed       | 198          |
| total_timesteps    | 3456         |
| value_loss         | 2.0081391    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021599485  |
| clipfrac           | 0.21484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 3.64e-05     |
| fps                | 20           |
| n_updates          | 28           |
| policy_entropy     | -0.4627997   |
| policy_loss        | -0.005987634 |
| serial_timesteps   | 3584         |
| time_elapsed       | 204          |
| total_timesteps    | 3584         |
| value_loss         | 2.5332994    |
-------------------------------------
An average of 251.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.015225592  |
| clipfrac           | 0.20507812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 4.7e-05      |
| fps                | 21           |
| n_updates          | 29           |
| policy_entropy     | -0.46392065  |
| policy_loss        | 0.0022045663 |
| serial_timesteps   | 3712         |
| time_elapsed       | 210          |
| total_timesteps    | 3712         |
| value_loss         | 2.644944     |
-------------------------------------
-------------------------------------
| approxkl           | 0.012929668  |
| clipfrac           | 0.115234375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -2.26e-06    |
| fps                | 20           |
| n_updates          | 30           |
| policy_entropy     | -0.4653548   |
| policy_loss        | 0.0015240354 |
| serial_timesteps   | 3840         |
| time_elapsed       | 216          |
| total_timesteps    | 3840         |
| value_loss         | 5.6795745    |
-------------------------------------
--------------------------------------
| approxkl           | 0.003260599   |
| clipfrac           | 0.046875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 7.72e-05      |
| fps                | 21            |
| n_updates          | 31            |
| policy_entropy     | -0.46610582   |
| policy_loss        | -0.0028542173 |
| serial_timesteps   | 3968          |
| time_elapsed       | 222           |
| total_timesteps    | 3968          |
| value_loss         | 64.678856     |
--------------------------------------
-------------------------------------
| approxkl           | 0.015979426  |
| clipfrac           | 0.18945312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -2.5e-06     |
| fps                | 21           |
| n_updates          | 32           |
| policy_entropy     | -0.4662573   |
| policy_loss        | -0.014368332 |
| serial_timesteps   | 4096         |
| time_elapsed       | 228          |
| total_timesteps    | 4096         |
| value_loss         | 9.356174     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0123487385 |
| clipfrac           | 0.16601562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -7.46e-05    |
| fps                | 21           |
| n_updates          | 33           |
| policy_entropy     | -0.46629468  |
| policy_loss        | -0.004325329 |
| serial_timesteps   | 4224         |
| time_elapsed       | 234          |
| total_timesteps    | 4224         |
| value_loss         | 2.8258135    |
-------------------------------------
-------------------------------------
| approxkl           | 0.035041627  |
| clipfrac           | 0.26171875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.00016      |
| fps                | 21           |
| n_updates          | 34           |
| policy_entropy     | -0.46693084  |
| policy_loss        | -0.013125906 |
| serial_timesteps   | 4352         |
| time_elapsed       | 240          |
| total_timesteps    | 4352         |
| value_loss         | 1.4669893    |
-------------------------------------
-------------------------------------
| approxkl           | 0.012160415  |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -0.000109    |
| fps                | 21           |
| n_updates          | 35           |
| policy_entropy     | -0.46754268  |
| policy_loss        | -0.005394752 |
| serial_timesteps   | 4480         |
| time_elapsed       | 246          |
| total_timesteps    | 4480         |
| value_loss         | 2.2063715    |
-------------------------------------
An average of 251.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.018632319  |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -1.2e-05     |
| fps                | 20           |
| n_updates          | 36           |
| policy_entropy     | -0.46888137  |
| policy_loss        | -0.009919977 |
| serial_timesteps   | 4608         |
| time_elapsed       | 252          |
| total_timesteps    | 4608         |
| value_loss         | 3.0664623    |
-------------------------------------
------------------------------------
| approxkl           | 0.013013689 |
| clipfrac           | 0.20117188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 2.98e-07    |
| fps                | 21          |
| n_updates          | 37          |
| policy_entropy     | -0.47015244 |
| policy_loss        | 0.013723329 |
| serial_timesteps   | 4736        |
| time_elapsed       | 259         |
| total_timesteps    | 4736        |
| value_loss         | 6162.131    |
------------------------------------
------------------------------------
| approxkl           | 0.0262882   |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -2.09e-05   |
| fps                | 22          |
| n_updates          | 38          |
| policy_entropy     | -0.47064197 |
| policy_loss        | -0.01708654 |
| serial_timesteps   | 4864        |
| time_elapsed       | 264         |
| total_timesteps    | 4864        |
| value_loss         | 6.6429195   |
------------------------------------
-------------------------------------
| approxkl           | 0.023891699  |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 2.48e-05     |
| fps                | 20           |
| n_updates          | 39           |
| policy_entropy     | -0.47108248  |
| policy_loss        | -0.016652012 |
| serial_timesteps   | 4992         |
| time_elapsed       | 270          |
| total_timesteps    | 4992         |
| value_loss         | 5.0766363    |
-------------------------------------
--------------------------------------
| approxkl           | 0.03222823    |
| clipfrac           | 0.31445312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 1.42e-05      |
| fps                | 20            |
| n_updates          | 40            |
| policy_entropy     | -0.4707452    |
| policy_loss        | -9.251805e-05 |
| serial_timesteps   | 5120          |
| time_elapsed       | 276           |
| total_timesteps    | 5120          |
| value_loss         | 1.008326      |
--------------------------------------
--------------------------------------
| approxkl           | 0.009071827   |
| clipfrac           | 0.14257812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 2.69e-05      |
| fps                | 20            |
| n_updates          | 41            |
| policy_entropy     | -0.47190917   |
| policy_loss        | -0.0075957137 |
| serial_timesteps   | 5248          |
| time_elapsed       | 283           |
| total_timesteps    | 5248          |
| value_loss         | 4.0363417     |
--------------------------------------
------------------------------------
| approxkl           | 0.009159749 |
| clipfrac           | 0.115234375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 5.07e-06    |
| fps                | 21          |
| n_updates          | 42          |
| policy_entropy     | -0.47381213 |
| policy_loss        | 0.01054766  |
| serial_timesteps   | 5376        |
| time_elapsed       | 289         |
| total_timesteps    | 5376        |
| value_loss         | 3.379601    |
------------------------------------
-------------------------------------
| approxkl           | 0.02112857   |
| clipfrac           | 0.20703125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 1.69e-05     |
| fps                | 20           |
| n_updates          | 43           |
| policy_entropy     | -0.47569305  |
| policy_loss        | 0.0129536735 |
| serial_timesteps   | 5504         |
| time_elapsed       | 295          |
| total_timesteps    | 5504         |
| value_loss         | 2.7453475    |
-------------------------------------
An average of 252.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0055398727 |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -3.5e-05     |
| fps                | 20           |
| n_updates          | 44           |
| policy_entropy     | -0.47727138  |
| policy_loss        | 0.0056609167 |
| serial_timesteps   | 5632         |
| time_elapsed       | 301          |
| total_timesteps    | 5632         |
| value_loss         | 3.8407242    |
-------------------------------------
-------------------------------------
| approxkl           | 0.032377053  |
| clipfrac           | 0.36132812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -3.89e-05    |
| fps                | 21           |
| n_updates          | 45           |
| policy_entropy     | -0.47893426  |
| policy_loss        | -0.024136577 |
| serial_timesteps   | 5760         |
| time_elapsed       | 307          |
| total_timesteps    | 5760         |
| value_loss         | 2.4512804    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0060383263 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -1.92e-05    |
| fps                | 19           |
| n_updates          | 46           |
| policy_entropy     | -0.48010412  |
| policy_loss        | 0.0008709228 |
| serial_timesteps   | 5888         |
| time_elapsed       | 313          |
| total_timesteps    | 5888         |
| value_loss         | 3.178919     |
-------------------------------------
------------------------------------
| approxkl           | 0.02280298  |
| clipfrac           | 0.24609375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 3.39e-05    |
| fps                | 21          |
| n_updates          | 47          |
| policy_entropy     | -0.4819418  |
| policy_loss        | 0.015429716 |
| serial_timesteps   | 6016        |
| time_elapsed       | 320         |
| total_timesteps    | 6016        |
| value_loss         | 3.419071    |
------------------------------------
--------------------------------------
| approxkl           | 0.013269353   |
| clipfrac           | 0.1640625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | -1.78e-05     |
| fps                | 21            |
| n_updates          | 48            |
| policy_entropy     | -0.48366067   |
| policy_loss        | -0.0056463163 |
| serial_timesteps   | 6144          |
| time_elapsed       | 326           |
| total_timesteps    | 6144          |
| value_loss         | 4.1232867     |
--------------------------------------
---------------------------------------
| approxkl           | 0.00027700447  |
| clipfrac           | 0.0            |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.9e+03        |
| explained_variance | -1.79e-06      |
| fps                | 20             |
| n_updates          | 49             |
| policy_entropy     | -0.48491636    |
| policy_loss        | -0.00065790303 |
| serial_timesteps   | 6272           |
| time_elapsed       | 332            |
| total_timesteps    | 6272           |
| value_loss         | 6459.3477      |
---------------------------------------
--------------------------------------
| approxkl           | 0.00872727    |
| clipfrac           | 0.115234375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.9e+03       |
| explained_variance | 3.09e-05      |
| fps                | 20            |
| n_updates          | 50            |
| policy_entropy     | -0.48514122   |
| policy_loss        | 0.00054966717 |
| serial_timesteps   | 6400          |
| time_elapsed       | 338           |
| total_timesteps    | 6400          |
| value_loss         | 20.786163     |
--------------------------------------
------------------------------------
| approxkl           | 0.024319474 |
| clipfrac           | 0.25        |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.9e+03     |
| explained_variance | 4.4e-05     |
| fps                | 21          |
| n_updates          | 51          |
| policy_entropy     | -0.48426083 |
| policy_loss        | 0.020548346 |
| serial_timesteps   | 6528        |
| time_elapsed       | 344         |
| total_timesteps    | 6528        |
| value_loss         | 8.889118    |
------------------------------------
An average of 253.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.05331966   |
| clipfrac           | 0.36328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 0.000205     |
| fps                | 22           |
| n_updates          | 52           |
| policy_entropy     | -0.48425347  |
| policy_loss        | -0.027275797 |
| serial_timesteps   | 6656         |
| time_elapsed       | 350          |
| total_timesteps    | 6656         |
| value_loss         | 4.619946     |
-------------------------------------
------------------------------------
| approxkl           | 0.047636747 |
| clipfrac           | 0.375       |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.9e+03     |
| explained_variance | -3.81e-05   |
| fps                | 21          |
| n_updates          | 53          |
| policy_entropy     | -0.4842675  |
| policy_loss        | -0.01918451 |
| serial_timesteps   | 6784        |
| time_elapsed       | 356         |
| total_timesteps    | 6784        |
| value_loss         | 1.1630285   |
------------------------------------
------------------------------------
| approxkl           | 0.013544478 |
| clipfrac           | 0.19335938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.9e+03     |
| explained_variance | -1.57e-05   |
| fps                | 22          |
| n_updates          | 54          |
| policy_entropy     | -0.48481864 |
| policy_loss        | 0.010915786 |
| serial_timesteps   | 6912        |
| time_elapsed       | 362         |
| total_timesteps    | 6912        |
| value_loss         | 4.428961    |
------------------------------------
-------------------------------------
| approxkl           | 0.022350768  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 6.56e-05     |
| fps                | 21           |
| n_updates          | 55           |
| policy_entropy     | -0.48562014  |
| policy_loss        | -0.020272948 |
| serial_timesteps   | 7040         |
| time_elapsed       | 368          |
| total_timesteps    | 7040         |
| value_loss         | 4.6648436    |
-------------------------------------
-------------------------------------
| approxkl           | 0.017974319  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 3.22e-06     |
| fps                | 21           |
| n_updates          | 56           |
| policy_entropy     | -0.48611656  |
| policy_loss        | -0.007896531 |
| serial_timesteps   | 7168         |
| time_elapsed       | 374          |
| total_timesteps    | 7168         |
| value_loss         | 7.7708664    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02784454   |
| clipfrac           | 0.24023438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | -4.54e-05    |
| fps                | 20           |
| n_updates          | 57           |
| policy_entropy     | -0.4862929   |
| policy_loss        | 0.0099468175 |
| serial_timesteps   | 7296         |
| time_elapsed       | 380          |
| total_timesteps    | 7296         |
| value_loss         | 3.3215637    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03404056   |
| clipfrac           | 0.32617188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 3.87e-05     |
| fps                | 20           |
| n_updates          | 58           |
| policy_entropy     | -0.48645926  |
| policy_loss        | -0.023339689 |
| serial_timesteps   | 7424         |
| time_elapsed       | 386          |
| total_timesteps    | 7424         |
| value_loss         | 0.40285763   |
-------------------------------------
-------------------------------------
| approxkl           | 0.005860598  |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | -3.81e-06    |
| fps                | 21           |
| n_updates          | 59           |
| policy_entropy     | -0.4871142   |
| policy_loss        | 0.0057095536 |
| serial_timesteps   | 7552         |
| time_elapsed       | 392          |
| total_timesteps    | 7552         |
| value_loss         | 4.029078     |
-------------------------------------
An average of 253.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0056693247 |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | -6.44e-06    |
| fps                | 20           |
| n_updates          | 60           |
| policy_entropy     | -0.48905098  |
| policy_loss        | 0.0055580027 |
| serial_timesteps   | 7680         |
| time_elapsed       | 398          |
| total_timesteps    | 7680         |
| value_loss         | 3.2172823    |
-------------------------------------
------------------------------------
| approxkl           | 0.013407366 |
| clipfrac           | 0.19921875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -1.19e-07   |
| fps                | 19          |
| n_updates          | 61          |
| policy_entropy     | -0.49112603 |
| policy_loss        | 0.010763057 |
| serial_timesteps   | 7808        |
| time_elapsed       | 404         |
| total_timesteps    | 7808        |
| value_loss         | 6453.788    |
------------------------------------
-------------------------------------
| approxkl           | 0.011431115  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 3.5e-05      |
| fps                | 21           |
| n_updates          | 62           |
| policy_entropy     | -0.49180385  |
| policy_loss        | -0.010721342 |
| serial_timesteps   | 7936         |
| time_elapsed       | 411          |
| total_timesteps    | 7936         |
| value_loss         | 4.0068316    |
-------------------------------------
------------------------------------
| approxkl           | 0.019764833 |
| clipfrac           | 0.20898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 8.7e-06     |
| fps                | 20          |
| n_updates          | 63          |
| policy_entropy     | -0.49300975 |
| policy_loss        | 0.008705051 |
| serial_timesteps   | 8064        |
| time_elapsed       | 417         |
| total_timesteps    | 8064        |
| value_loss         | 3.4226675   |
------------------------------------
--------------------------------------
| approxkl           | 0.011018194   |
| clipfrac           | 0.1328125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | -4.41e-06     |
| fps                | 20            |
| n_updates          | 64            |
| policy_entropy     | -0.49502766   |
| policy_loss        | -0.0016518927 |
| serial_timesteps   | 8192          |
| time_elapsed       | 423           |
| total_timesteps    | 8192          |
| value_loss         | 3.0387733     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0013405749 |
| clipfrac           | 0.001953125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 5.43e-05     |
| fps                | 21           |
| n_updates          | 65           |
| policy_entropy     | -0.49653533  |
| policy_loss        | 0.0035702104 |
| serial_timesteps   | 8320         |
| time_elapsed       | 429          |
| total_timesteps    | 8320         |
| value_loss         | 5.127194     |
-------------------------------------
-------------------------------------
| approxkl           | 0.025347162  |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -1.87e-05    |
| fps                | 21           |
| n_updates          | 66           |
| policy_entropy     | -0.49768347  |
| policy_loss        | -0.010972439 |
| serial_timesteps   | 8448         |
| time_elapsed       | 436          |
| total_timesteps    | 8448         |
| value_loss         | 2.9441617    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015867269  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 4.3e-05      |
| fps                | 20           |
| n_updates          | 67           |
| policy_entropy     | -0.49823746  |
| policy_loss        | 0.0033318088 |
| serial_timesteps   | 8576         |
| time_elapsed       | 441          |
| total_timesteps    | 8576         |
| value_loss         | 40.73915     |
-------------------------------------
An average of 254.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.004979306  |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 2.49e-05     |
| fps                | 20           |
| n_updates          | 68           |
| policy_entropy     | -0.4984491   |
| policy_loss        | 0.0001364341 |
| serial_timesteps   | 8704         |
| time_elapsed       | 448          |
| total_timesteps    | 8704         |
| value_loss         | 57.633602    |
-------------------------------------
--------------------------------------
| approxkl           | 0.006127834   |
| clipfrac           | 0.083984375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 5.61e-05      |
| fps                | 21            |
| n_updates          | 69            |
| policy_entropy     | -0.49808556   |
| policy_loss        | -0.0041772583 |
| serial_timesteps   | 8832          |
| time_elapsed       | 454           |
| total_timesteps    | 8832          |
| value_loss         | 20.842604     |
--------------------------------------
--------------------------------------
| approxkl           | 0.009090715   |
| clipfrac           | 0.125         |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 0.000186      |
| fps                | 20            |
| n_updates          | 70            |
| policy_entropy     | -0.4974095    |
| policy_loss        | -0.0040777577 |
| serial_timesteps   | 8960          |
| time_elapsed       | 460           |
| total_timesteps    | 8960          |
| value_loss         | 5.1168013     |
--------------------------------------
------------------------------------
| approxkl           | 0.03417278  |
| clipfrac           | 0.33398438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 0.000125    |
| fps                | 19          |
| n_updates          | 71          |
| policy_entropy     | -0.49524662 |
| policy_loss        | 0.017452927 |
| serial_timesteps   | 9088        |
| time_elapsed       | 466         |
| total_timesteps    | 9088        |
| value_loss         | 1.2440038   |
------------------------------------
------------------------------------
| approxkl           | 0.02929949  |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 4.61e-05    |
| fps                | 21          |
| n_updates          | 72          |
| policy_entropy     | -0.49270314 |
| policy_loss        | 0.016006548 |
| serial_timesteps   | 9216        |
| time_elapsed       | 473         |
| total_timesteps    | 9216        |
| value_loss         | 1.9304898   |
------------------------------------
---------------------------------------
| approxkl           | 0.0022180341   |
| clipfrac           | 0.017578125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.87e+03       |
| explained_variance | 1.19e-07       |
| fps                | 21             |
| n_updates          | 73             |
| policy_entropy     | -0.49249026    |
| policy_loss        | -0.00043637876 |
| serial_timesteps   | 9344           |
| time_elapsed       | 479            |
| total_timesteps    | 9344           |
| value_loss         | 6467.295       |
---------------------------------------
--------------------------------------
| approxkl           | 0.012000983   |
| clipfrac           | 0.15820312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | -7.62e-05     |
| fps                | 21            |
| n_updates          | 74            |
| policy_entropy     | -0.4922662    |
| policy_loss        | -0.0015036757 |
| serial_timesteps   | 9472          |
| time_elapsed       | 485           |
| total_timesteps    | 9472          |
| value_loss         | 2.6033072     |
--------------------------------------
-------------------------------------
| approxkl           | 0.01771776   |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 3.4e-05      |
| fps                | 20           |
| n_updates          | 75           |
| policy_entropy     | -0.49166375  |
| policy_loss        | -0.009158967 |
| serial_timesteps   | 9600         |
| time_elapsed       | 491          |
| total_timesteps    | 9600         |
| value_loss         | 3.1914408    |
-------------------------------------
An average of 255.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.036897544 |
| clipfrac           | 0.3359375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 2.16e-05    |
| fps                | 21          |
| n_updates          | 76          |
| policy_entropy     | -0.49109882 |
| policy_loss        | -0.02578405 |
| serial_timesteps   | 9728        |
| time_elapsed       | 497         |
| total_timesteps    | 9728        |
| value_loss         | 1.4478642   |
------------------------------------
------------------------------------
| approxkl           | 0.008290528 |
| clipfrac           | 0.1171875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 1.52e-05    |
| fps                | 21          |
| n_updates          | 77          |
| policy_entropy     | -0.49091792 |
| policy_loss        | -0.01145941 |
| serial_timesteps   | 9856        |
| time_elapsed       | 503         |
| total_timesteps    | 9856        |
| value_loss         | 1.7338395   |
------------------------------------
------------------------------------
| approxkl           | 0.018309489 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 9e-06       |
| fps                | 21          |
| n_updates          | 78          |
| policy_entropy     | -0.49163598 |
| policy_loss        | 0.003229646 |
| serial_timesteps   | 9984        |
| time_elapsed       | 509         |
| total_timesteps    | 9984        |
| value_loss         | 4.5383086   |
------------------------------------
--------------------------------------
| approxkl           | 0.0032523165  |
| clipfrac           | 0.03515625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 2.74e-06      |
| fps                | 21            |
| n_updates          | 79            |
| policy_entropy     | -0.49303722   |
| policy_loss        | 0.00028956204 |
| serial_timesteps   | 10112         |
| time_elapsed       | 515           |
| total_timesteps    | 10112         |
| value_loss         | 3.3981447     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00073261285 |
| clipfrac           | 0.001953125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 0.000113      |
| fps                | 21            |
| n_updates          | 80            |
| policy_entropy     | -0.49607408   |
| policy_loss        | 0.0019969721  |
| serial_timesteps   | 10240         |
| time_elapsed       | 521           |
| total_timesteps    | 10240         |
| value_loss         | 4.2314043     |
--------------------------------------
-------------------------------------
| approxkl           | 0.020863745  |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -1.23e-05    |
| fps                | 20           |
| n_updates          | 81           |
| policy_entropy     | -0.49915224  |
| policy_loss        | -0.004117131 |
| serial_timesteps   | 10368        |
| time_elapsed       | 527          |
| total_timesteps    | 10368        |
| value_loss         | 2.990713     |
-------------------------------------
------------------------------------
| approxkl           | 0.02477964  |
| clipfrac           | 0.25585938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -1.5e-05    |
| fps                | 21          |
| n_updates          | 82          |
| policy_entropy     | -0.5007318  |
| policy_loss        | 0.015637891 |
| serial_timesteps   | 10496       |
| time_elapsed       | 534         |
| total_timesteps    | 10496       |
| value_loss         | 3.4933686   |
------------------------------------
An average of 255.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.006389528   |
| clipfrac           | 0.0859375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | -2.22e-05     |
| fps                | 21            |
| n_updates          | 83            |
| policy_entropy     | -0.5028428    |
| policy_loss        | -0.0076798247 |
| serial_timesteps   | 10624         |
| time_elapsed       | 540           |
| total_timesteps    | 10624         |
| value_loss         | 5.6779966     |
--------------------------------------
------------------------------------
| approxkl           | 0.017236887 |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -2.26e-06   |
| fps                | 21          |
| n_updates          | 84          |
| policy_entropy     | -0.5038747  |
| policy_loss        | 0.00598294  |
| serial_timesteps   | 10752       |
| time_elapsed       | 546         |
| total_timesteps    | 10752       |
| value_loss         | 1.5788631   |
------------------------------------
------------------------------------
| approxkl           | 0.067430705 |
| clipfrac           | 0.50390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 1.19e-07    |
| fps                | 21          |
| n_updates          | 85          |
| policy_entropy     | -0.50460607 |
| policy_loss        | 0.07922366  |
| serial_timesteps   | 10880       |
| time_elapsed       | 552         |
| total_timesteps    | 10880       |
| value_loss         | 6513.8735   |
------------------------------------
--------------------------------------
| approxkl           | 0.010288744   |
| clipfrac           | 0.140625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.89e+03      |
| explained_variance | 3.5e-05       |
| fps                | 21            |
| n_updates          | 86            |
| policy_entropy     | -0.50485516   |
| policy_loss        | -0.0034560114 |
| serial_timesteps   | 11008         |
| time_elapsed       | 558           |
| total_timesteps    | 11008         |
| value_loss         | 62.037796     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0026902605 |
| clipfrac           | 0.02734375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | -9.92e-05    |
| fps                | 20           |
| n_updates          | 87           |
| policy_entropy     | -0.5037005   |
| policy_loss        | 0.0031852007 |
| serial_timesteps   | 11136        |
| time_elapsed       | 564          |
| total_timesteps    | 11136        |
| value_loss         | 8.385976     |
-------------------------------------
------------------------------------
| approxkl           | 0.03034874  |
| clipfrac           | 0.28125     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 0.000164    |
| fps                | 20          |
| n_updates          | 88          |
| policy_entropy     | -0.50312793 |
| policy_loss        | -0.01185517 |
| serial_timesteps   | 11264       |
| time_elapsed       | 570         |
| total_timesteps    | 11264       |
| value_loss         | 4.1472635   |
------------------------------------
-------------------------------------
| approxkl           | 0.013239641  |
| clipfrac           | 0.1640625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | 0.000383     |
| fps                | 22           |
| n_updates          | 89           |
| policy_entropy     | -0.503269    |
| policy_loss        | -0.008350756 |
| serial_timesteps   | 11392        |
| time_elapsed       | 576          |
| total_timesteps    | 11392        |
| value_loss         | 1.3599272    |
-------------------------------------
-------------------------------------
| approxkl           | 0.023497825  |
| clipfrac           | 0.25390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | -0.000177    |
| fps                | 20           |
| n_updates          | 90           |
| policy_entropy     | -0.5040004   |
| policy_loss        | -0.023509737 |
| serial_timesteps   | 11520        |
| time_elapsed       | 582          |
| total_timesteps    | 11520        |
| value_loss         | 1.2471797    |
-------------------------------------
An average of 256.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0040639383 |
| clipfrac           | 0.044921875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | -2.86e-05    |
| fps                | 20           |
| n_updates          | 91           |
| policy_entropy     | -0.5065489   |
| policy_loss        | 0.005371203  |
| serial_timesteps   | 11648        |
| time_elapsed       | 588          |
| total_timesteps    | 11648        |
| value_loss         | 2.682693     |
-------------------------------------
------------------------------------
| approxkl           | 0.04001743  |
| clipfrac           | 0.35546875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | -0.000137   |
| fps                | 20          |
| n_updates          | 92          |
| policy_entropy     | -0.5090632  |
| policy_loss        | 0.034383878 |
| serial_timesteps   | 11776       |
| time_elapsed       | 594         |
| total_timesteps    | 11776       |
| value_loss         | 1.6194975   |
------------------------------------
--------------------------------------
| approxkl           | 0.02127625    |
| clipfrac           | 0.24414062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.89e+03      |
| explained_variance | -1.19e-06     |
| fps                | 20            |
| n_updates          | 93            |
| policy_entropy     | -0.5101766    |
| policy_loss        | -0.0052351817 |
| serial_timesteps   | 11904         |
| time_elapsed       | 600           |
| total_timesteps    | 11904         |
| value_loss         | 3.292685      |
--------------------------------------
-------------------------------------
| approxkl           | 0.028404145  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | -2.32e-05    |
| fps                | 21           |
| n_updates          | 94           |
| policy_entropy     | -0.50987273  |
| policy_loss        | -0.008946765 |
| serial_timesteps   | 12032        |
| time_elapsed       | 607          |
| total_timesteps    | 12032        |
| value_loss         | 0.59174126   |
-------------------------------------
--------------------------------------
| approxkl           | 0.034045555   |
| clipfrac           | 0.3203125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.89e+03      |
| explained_variance | 5.95e-05      |
| fps                | 19            |
| n_updates          | 95            |
| policy_entropy     | -0.5096304    |
| policy_loss        | -0.0036676528 |
| serial_timesteps   | 12160         |
| time_elapsed       | 613           |
| total_timesteps    | 12160         |
| value_loss         | 1.9263501     |
--------------------------------------
---------------------------------------
| approxkl           | 0.009740382    |
| clipfrac           | 0.13476562     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.89e+03       |
| explained_variance | -1.75e-05      |
| fps                | 20             |
| n_updates          | 96             |
| policy_entropy     | -0.51008487    |
| policy_loss        | -0.00048555853 |
| serial_timesteps   | 12288          |
| time_elapsed       | 619            |
| total_timesteps    | 12288          |
| value_loss         | 5.0798883      |
---------------------------------------
--------------------------------------
| approxkl           | 0.015752837   |
| clipfrac           | 0.2265625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | 0             |
| fps                | 20            |
| n_updates          | 97            |
| policy_entropy     | -0.5110513    |
| policy_loss        | -0.0070561375 |
| serial_timesteps   | 12416         |
| time_elapsed       | 625           |
| total_timesteps    | 12416         |
| value_loss         | 6517.132      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0025991295 |
| clipfrac           | 0.021484375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.000149     |
| fps                | 20           |
| n_updates          | 98           |
| policy_entropy     | -0.5118521   |
| policy_loss        | 0.0022010095 |
| serial_timesteps   | 12544        |
| time_elapsed       | 631          |
| total_timesteps    | 12544        |
| value_loss         | 5.7629642    |
-------------------------------------
An average of 257.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0057308488  |
| clipfrac           | 0.06640625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | -0.000188     |
| fps                | 20            |
| n_updates          | 99            |
| policy_entropy     | -0.5136403    |
| policy_loss        | -0.0008022955 |
| serial_timesteps   | 12672         |
| time_elapsed       | 638           |
| total_timesteps    | 12672         |
| value_loss         | 3.3872774     |
--------------------------------------
-------------------------------------
| approxkl           | 0.013952137  |
| clipfrac           | 0.20898438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -0.000165    |
| fps                | 21           |
| n_updates          | 100          |
| policy_entropy     | -0.5158567   |
| policy_loss        | -0.026622795 |
| serial_timesteps   | 12800        |
| time_elapsed       | 644          |
| total_timesteps    | 12800        |
| value_loss         | 0.93396455   |
-------------------------------------
-------------------------------------
| approxkl           | 0.042157244  |
| clipfrac           | 0.33398438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 7.28e-05     |
| fps                | 20           |
| n_updates          | 101          |
| policy_entropy     | -0.5171044   |
| policy_loss        | -0.011471437 |
| serial_timesteps   | 12928        |
| time_elapsed       | 650          |
| total_timesteps    | 12928        |
| value_loss         | 1.8285159    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0037903094 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 2.33e-05     |
| fps                | 20           |
| n_updates          | 102          |
| policy_entropy     | -0.51864284  |
| policy_loss        | 0.004667926  |
| serial_timesteps   | 13056        |
| time_elapsed       | 656          |
| total_timesteps    | 13056        |
| value_loss         | 4.1564546    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011375742  |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -5.72e-06    |
| fps                | 21           |
| n_updates          | 103          |
| policy_entropy     | -0.5214129   |
| policy_loss        | 0.0079156095 |
| serial_timesteps   | 13184        |
| time_elapsed       | 662          |
| total_timesteps    | 13184        |
| value_loss         | 4.148195     |
-------------------------------------
------------------------------------
| approxkl           | 0.01606894  |
| clipfrac           | 0.21289062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | 9.6e-05     |
| fps                | 20          |
| n_updates          | 104         |
| policy_entropy     | -0.5235254  |
| policy_loss        | -0.01633407 |
| serial_timesteps   | 13312       |
| time_elapsed       | 668         |
| total_timesteps    | 13312       |
| value_loss         | 45.809746   |
------------------------------------
-------------------------------------
| approxkl           | 0.0055453056 |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.000101     |
| fps                | 20           |
| n_updates          | 105          |
| policy_entropy     | -0.52402204  |
| policy_loss        | 0.0053357356 |
| serial_timesteps   | 13440        |
| time_elapsed       | 674          |
| total_timesteps    | 13440        |
| value_loss         | 12.821656    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008108115  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.000197     |
| fps                | 21           |
| n_updates          | 106          |
| policy_entropy     | -0.5245071   |
| policy_loss        | -0.009089809 |
| serial_timesteps   | 13568        |
| time_elapsed       | 680          |
| total_timesteps    | 13568        |
| value_loss         | 2.3978982    |
-------------------------------------
An average of 257.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0462971    |
| clipfrac           | 0.3671875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.000181     |
| fps                | 20           |
| n_updates          | 107          |
| policy_entropy     | -0.52458984  |
| policy_loss        | -0.026255565 |
| serial_timesteps   | 13696        |
| time_elapsed       | 686          |
| total_timesteps    | 13696        |
| value_loss         | 1.0386294    |
-------------------------------------
-------------------------------------
| approxkl           | 0.03151889   |
| clipfrac           | 0.265625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.000558     |
| fps                | 20           |
| n_updates          | 108          |
| policy_entropy     | -0.5244684   |
| policy_loss        | -0.018393792 |
| serial_timesteps   | 13824        |
| time_elapsed       | 693          |
| total_timesteps    | 13824        |
| value_loss         | 2.2872496    |
-------------------------------------
------------------------------------
| approxkl           | 0.017006764 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -2.5e-06    |
| fps                | 21          |
| n_updates          | 109         |
| policy_entropy     | -0.52476645 |
| policy_loss        | 0.022961944 |
| serial_timesteps   | 13952       |
| time_elapsed       | 699         |
| total_timesteps    | 13952       |
| value_loss         | 6489.8057   |
------------------------------------
------------------------------------
| approxkl           | 0.018117746 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.000233    |
| fps                | 21          |
| n_updates          | 110         |
| policy_entropy     | -0.5254069  |
| policy_loss        | 0.017581662 |
| serial_timesteps   | 14080       |
| time_elapsed       | 705         |
| total_timesteps    | 14080       |
| value_loss         | 3.3648214   |
------------------------------------
--------------------------------------
| approxkl           | 0.016349442   |
| clipfrac           | 0.21679688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | -4.1e-05      |
| fps                | 21            |
| n_updates          | 111           |
| policy_entropy     | -0.52687293   |
| policy_loss        | -0.0066702296 |
| serial_timesteps   | 14208         |
| time_elapsed       | 711           |
| total_timesteps    | 14208         |
| value_loss         | 1.2974232     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011413259  |
| clipfrac           | 0.13085938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -2.09e-05    |
| fps                | 21           |
| n_updates          | 112          |
| policy_entropy     | -0.5275003   |
| policy_loss        | -0.010798495 |
| serial_timesteps   | 14336        |
| time_elapsed       | 717          |
| total_timesteps    | 14336        |
| value_loss         | 2.7461464    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01799421   |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -5.38e-05    |
| fps                | 20           |
| n_updates          | 113          |
| policy_entropy     | -0.5277356   |
| policy_loss        | -0.021228988 |
| serial_timesteps   | 14464        |
| time_elapsed       | 723          |
| total_timesteps    | 14464        |
| value_loss         | 0.7394045    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02418749   |
| clipfrac           | 0.2734375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -1.55e-05    |
| fps                | 20           |
| n_updates          | 114          |
| policy_entropy     | -0.5287929   |
| policy_loss        | -0.010398833 |
| serial_timesteps   | 14592        |
| time_elapsed       | 729          |
| total_timesteps    | 14592        |
| value_loss         | 0.6016262    |
-------------------------------------
An average of 258.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.007170742   |
| clipfrac           | 0.0859375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | -8.87e-05     |
| fps                | 20            |
| n_updates          | 115           |
| policy_entropy     | -0.5304768    |
| policy_loss        | -0.0017407581 |
| serial_timesteps   | 14720         |
| time_elapsed       | 735           |
| total_timesteps    | 14720         |
| value_loss         | 5.553407      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0068323715 |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.000121     |
| fps                | 20           |
| n_updates          | 116          |
| policy_entropy     | -0.53200513  |
| policy_loss        | 0.0005392404 |
| serial_timesteps   | 14848        |
| time_elapsed       | 742          |
| total_timesteps    | 14848        |
| value_loss         | 5.921928     |
-------------------------------------
-------------------------------------
| approxkl           | 0.017225524  |
| clipfrac           | 0.20117188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.000198     |
| fps                | 21           |
| n_updates          | 117          |
| policy_entropy     | -0.5339473   |
| policy_loss        | -0.004288329 |
| serial_timesteps   | 14976        |
| time_elapsed       | 748          |
| total_timesteps    | 14976        |
| value_loss         | 4.6899443    |
-------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3854bda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3854bda0>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b384d8a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b384d8a20>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2963 samples, validate on 316 samples
Epoch 485/5000
 - 10s - loss: 0.3712 - val_loss: 0.0651
Epoch 486/5000
 - 1s - loss: 0.3712 - val_loss: 0.0651
Epoch 487/5000
 - 1s - loss: 0.3712 - val_loss: 0.0651
Epoch 488/5000
 - 1s - loss: 0.3712 - val_loss: 0.0651
Epoch 489/5000
 - 1s - loss: 0.3712 - val_loss: 0.0651
Epoch 490/5000
 - 1s - loss: 0.3712 - val_loss: 0.0651
Train on 2145 samples, validate on 316 samples
Epoch 350/5000
 - 9s - loss: 0.0016 - val_loss: 0.0082
Epoch 351/5000
 - 1s - loss: 0.0028 - val_loss: 0.0085
Epoch 352/5000
 - 1s - loss: 0.0017 - val_loss: 0.0061
Epoch 353/5000
 - 1s - loss: 0.0013 - val_loss: 0.0050
Epoch 354/5000
 - 1s - loss: 9.6632e-04 - val_loss: 0.0039
Epoch 355/5000
 - 1s - loss: 7.6011e-04 - val_loss: 0.0035
Epoch 356/5000
 - 1s - loss: 7.4770e-04 - val_loss: 0.0033
Epoch 357/5000
 - 1s - loss: 6.6112e-04 - val_loss: 0.0037
Epoch 358/5000
 - 1s - loss: 7.6131e-04 - val_loss: 0.0044
Epoch 359/5000
 - 1s - loss: 8.4982e-04 - val_loss: 0.0034
Epoch 360/5000
 - 1s - loss: 6.2528e-04 - val_loss: 0.0035
Epoch 361/5000
 - 1s - loss: 6.0971e-04 - val_loss: 0.0035
Train on 2964 samples, validate on 316 samples
Epoch 1150/5000
 - 11s - loss: 0.6834 - val_loss: 0.6760
Epoch 1151/5000
 - 1s - loss: 0.6553 - val_loss: 0.6611
Epoch 1152/5000
 - 1s - loss: 0.6336 - val_loss: 0.6503
Epoch 1153/5000
 - 1s - loss: 0.6163 - val_loss: 0.6427
Epoch 1154/5000
 - 1s - loss: 0.6027 - val_loss: 0.6375
Epoch 1155/5000
 - 1s - loss: 0.5920 - val_loss: 0.6342
Epoch 1156/5000
 - 1s - loss: 0.5836 - val_loss: 0.6323
Epoch 1157/5000
 - 1s - loss: 0.5770 - val_loss: 0.6314
Epoch 1158/5000
 - 1s - loss: 0.5719 - val_loss: 0.6313
Epoch 1159/5000
 - 1s - loss: 0.5678 - val_loss: 0.6317
Epoch 1160/5000
 - 1s - loss: 0.5647 - val_loss: 0.6324
Epoch 1161/5000
 - 1s - loss: 0.5625 - val_loss: 0.6325
Epoch 1162/5000
 - 1s - loss: 0.5623 - val_loss: 0.6326
Epoch 1163/5000
 - 1s - loss: 0.5621 - val_loss: 0.6326
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.03783165   |
| clipfrac           | 0.27929688   |
| explained_variance | -3.68e-05    |
| fps                | 2            |
| n_updates          | 1            |
| policy_entropy     | -0.53568673  |
| policy_loss        | -0.010914456 |
| serial_timesteps   | 128          |
| time_elapsed       | 1.31e-05     |
| total_timesteps    | 128          |
| value_loss         | 9.791295     |
-------------------------------------
------------------------------------
| approxkl           | 0.022603713 |
| clipfrac           | 0.26171875  |
| explained_variance | -5.61e-05   |
| fps                | 19          |
| n_updates          | 2           |
| policy_entropy     | -0.5362082  |
| policy_loss        | 0.010774476 |
| serial_timesteps   | 256         |
| time_elapsed       | 47.6        |
| total_timesteps    | 256         |
| value_loss         | 11.614697   |
------------------------------------
--------------------------------------
| approxkl           | 0.0093935365  |
| clipfrac           | 0.13476562    |
| explained_variance | -7.57e-05     |
| fps                | 19            |
| n_updates          | 3             |
| policy_entropy     | -0.53672636   |
| policy_loss        | -0.0018713127 |
| serial_timesteps   | 384           |
| time_elapsed       | 54            |
| total_timesteps    | 384           |
| value_loss         | 9.915686      |
--------------------------------------
-------------------------------------
| approxkl           | 0.009256246  |
| clipfrac           | 0.14257812   |
| explained_variance | -4.17e-06    |
| fps                | 19           |
| n_updates          | 4            |
| policy_entropy     | -0.537583    |
| policy_loss        | 0.0068690935 |
| serial_timesteps   | 512          |
| time_elapsed       | 60.5         |
| total_timesteps    | 512          |
| value_loss         | 7.9192653    |
-------------------------------------
An average of 259.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.02823391   |
| clipfrac           | 0.265625     |
| explained_variance | 1.06e-05     |
| fps                | 20           |
| n_updates          | 5            |
| policy_entropy     | -0.53828806  |
| policy_loss        | -0.011213043 |
| serial_timesteps   | 640          |
| time_elapsed       | 67           |
| total_timesteps    | 640          |
| value_loss         | 5.5546627    |
-------------------------------------
------------------------------------
| approxkl           | 0.017174872 |
| clipfrac           | 0.18945312  |
| explained_variance | -0.000388   |
| fps                | 19          |
| n_updates          | 6           |
| policy_entropy     | -0.53842443 |
| policy_loss        | 0.016560607 |
| serial_timesteps   | 768         |
| time_elapsed       | 73.1        |
| total_timesteps    | 768         |
| value_loss         | 11.165005   |
------------------------------------
--------------------------------------
| approxkl           | 0.005461905   |
| clipfrac           | 0.072265625   |
| explained_variance | -7.46e-05     |
| fps                | 20            |
| n_updates          | 7             |
| policy_entropy     | -0.5385314    |
| policy_loss        | -0.0019370909 |
| serial_timesteps   | 896           |
| time_elapsed       | 79.6          |
| total_timesteps    | 896           |
| value_loss         | 15.085669     |
--------------------------------------
------------------------------------
| approxkl           | 0.016212717 |
| clipfrac           | 0.20507812  |
| explained_variance | 3.08e-05    |
| fps                | 20          |
| n_updates          | 8           |
| policy_entropy     | -0.53926754 |
| policy_loss        | 0.009708014 |
| serial_timesteps   | 1024        |
| time_elapsed       | 85.8        |
| total_timesteps    | 1024        |
| value_loss         | 8.229823    |
------------------------------------
--------------------------------------
| approxkl           | 0.020133894   |
| clipfrac           | 0.25976562    |
| explained_variance | -2.93e-05     |
| fps                | 21            |
| n_updates          | 9             |
| policy_entropy     | -0.54090756   |
| policy_loss        | -0.0007850535 |
| serial_timesteps   | 1152          |
| time_elapsed       | 92.1          |
| total_timesteps    | 1152          |
| value_loss         | 6.341024      |
--------------------------------------
------------------------------------
| approxkl           | 0.03439073  |
| clipfrac           | 0.26757812  |
| explained_variance | -0.000101   |
| fps                | 20          |
| n_updates          | 10          |
| policy_entropy     | -0.54162616 |
| policy_loss        | 0.022321953 |
| serial_timesteps   | 1280        |
| time_elapsed       | 98          |
| total_timesteps    | 1280        |
| value_loss         | 12.1678095  |
------------------------------------
-------------------------------------
| approxkl           | 0.007833467  |
| clipfrac           | 0.0703125    |
| explained_variance | 0.000104     |
| fps                | 20           |
| n_updates          | 11           |
| policy_entropy     | -0.542668    |
| policy_loss        | -0.007590881 |
| serial_timesteps   | 1408         |
| time_elapsed       | 104          |
| total_timesteps    | 1408         |
| value_loss         | 61.064278    |
-------------------------------------
------------------------------------
| approxkl           | 0.006850633 |
| clipfrac           | 0.091796875 |
| explained_variance | 0.000114    |
| fps                | 19          |
| n_updates          | 12          |
| policy_entropy     | -0.5437409  |
| policy_loss        | -0.0017982  |
| serial_timesteps   | 1536        |
| time_elapsed       | 111         |
| total_timesteps    | 1536        |
| value_loss         | 29.567686   |
------------------------------------
An average of 260.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.036632255  |
| clipfrac           | 0.32617188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.15e+03     |
| explained_variance | 9.18e-06     |
| fps                | 19           |
| n_updates          | 13           |
| policy_entropy     | -0.54403615  |
| policy_loss        | 0.0014523221 |
| serial_timesteps   | 1664         |
| time_elapsed       | 117          |
| total_timesteps    | 1664         |
| value_loss         | 4187.373     |
-------------------------------------
---------------------------------------
| approxkl           | 0.031305294    |
| clipfrac           | 0.29101562     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 7.15e+03       |
| explained_variance | -0.00125       |
| fps                | 19             |
| n_updates          | 14             |
| policy_entropy     | -0.54388064    |
| policy_loss        | -0.00078946096 |
| serial_timesteps   | 1792           |
| time_elapsed       | 124            |
| total_timesteps    | 1792           |
| value_loss         | 5.222334       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0141934715  |
| clipfrac           | 0.16210938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.15e+03      |
| explained_variance | 0.00202       |
| fps                | 20            |
| n_updates          | 15            |
| policy_entropy     | -0.54310215   |
| policy_loss        | -0.0033843585 |
| serial_timesteps   | 1920          |
| time_elapsed       | 130           |
| total_timesteps    | 1920          |
| value_loss         | 1.6318396     |
--------------------------------------
-------------------------------------
| approxkl           | 0.008283784  |
| clipfrac           | 0.09375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.15e+03     |
| explained_variance | 0.00226      |
| fps                | 20           |
| n_updates          | 16           |
| policy_entropy     | -0.5414235   |
| policy_loss        | -0.003428483 |
| serial_timesteps   | 2048         |
| time_elapsed       | 136          |
| total_timesteps    | 2048         |
| value_loss         | 6.2097898    |
-------------------------------------
------------------------------------
| approxkl           | 0.007000539 |
| clipfrac           | 0.1015625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.15e+03    |
| explained_variance | 0.00152     |
| fps                | 19          |
| n_updates          | 17          |
| policy_entropy     | -0.5425391  |
| policy_loss        | 0.0057763   |
| serial_timesteps   | 2176        |
| time_elapsed       | 142         |
| total_timesteps    | 2176        |
| value_loss         | 5.3093185   |
------------------------------------
------------------------------------
| approxkl           | 0.035084564 |
| clipfrac           | 0.32226562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.15e+03    |
| explained_variance | 0.000845    |
| fps                | 19          |
| n_updates          | 18          |
| policy_entropy     | -0.5443944  |
| policy_loss        | 0.015649835 |
| serial_timesteps   | 2304        |
| time_elapsed       | 149         |
| total_timesteps    | 2304        |
| value_loss         | 3.2211697   |
------------------------------------
------------------------------------
| approxkl           | 0.017337523 |
| clipfrac           | 0.19140625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.15e+03    |
| explained_variance | 0.000499    |
| fps                | 19          |
| n_updates          | 19          |
| policy_entropy     | -0.54475474 |
| policy_loss        | 0.007507656 |
| serial_timesteps   | 2432        |
| time_elapsed       | 155         |
| total_timesteps    | 2432        |
| value_loss         | 2.7395024   |
------------------------------------
-------------------------------------
| approxkl           | 0.026918923  |
| clipfrac           | 0.29101562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.15e+03     |
| explained_variance | -0.000112    |
| fps                | 20           |
| n_updates          | 20           |
| policy_entropy     | -0.5453889   |
| policy_loss        | -0.018316286 |
| serial_timesteps   | 2560         |
| time_elapsed       | 162          |
| total_timesteps    | 2560         |
| value_loss         | 2.021818     |
-------------------------------------
An average of 260.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.013702943  |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.15e+03     |
| explained_variance | -0.000403    |
| fps                | 19           |
| n_updates          | 21           |
| policy_entropy     | -0.54601574  |
| policy_loss        | 0.0030705398 |
| serial_timesteps   | 2688         |
| time_elapsed       | 168          |
| total_timesteps    | 2688         |
| value_loss         | 6.0032034    |
-------------------------------------
--------------------------------------
| approxkl           | 0.012886204   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.15e+03      |
| explained_variance | -0.000205     |
| fps                | 21            |
| n_updates          | 22            |
| policy_entropy     | -0.54621977   |
| policy_loss        | -0.0046937726 |
| serial_timesteps   | 2816          |
| time_elapsed       | 175           |
| total_timesteps    | 2816          |
| value_loss         | 6.130886      |
--------------------------------------
------------------------------------
| approxkl           | 0.02481507  |
| clipfrac           | 0.25976562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.15e+03    |
| explained_variance | -0.000132   |
| fps                | 20          |
| n_updates          | 23          |
| policy_entropy     | -0.5472111  |
| policy_loss        | 0.004051307 |
| serial_timesteps   | 2944        |
| time_elapsed       | 181         |
| total_timesteps    | 2944        |
| value_loss         | 5.7591634   |
------------------------------------
-------------------------------------
| approxkl           | 0.022395529  |
| clipfrac           | 0.24414062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.15e+03     |
| explained_variance | 0.000131     |
| fps                | 21           |
| n_updates          | 24           |
| policy_entropy     | -0.54825497  |
| policy_loss        | -0.013566887 |
| serial_timesteps   | 3072         |
| time_elapsed       | 187          |
| total_timesteps    | 3072         |
| value_loss         | 6.5964093    |
-------------------------------------
---------------------------------------
| approxkl           | 0.015302366    |
| clipfrac           | 0.16015625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 7.09e+03       |
| explained_variance | -6.2e-06       |
| fps                | 20             |
| n_updates          | 25             |
| policy_entropy     | -0.54881185    |
| policy_loss        | -0.00026734313 |
| serial_timesteps   | 3200           |
| time_elapsed       | 193            |
| total_timesteps    | 3200           |
| value_loss         | 5842.17        |
---------------------------------------
--------------------------------------
| approxkl           | 0.029369147   |
| clipfrac           | 0.23046875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.09e+03      |
| explained_variance | 0.000147      |
| fps                | 19            |
| n_updates          | 26            |
| policy_entropy     | -0.54875946   |
| policy_loss        | -0.0015446143 |
| serial_timesteps   | 3328          |
| time_elapsed       | 199           |
| total_timesteps    | 3328          |
| value_loss         | 3.7499118     |
--------------------------------------
------------------------------------
| approxkl           | 0.023749512 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.09e+03    |
| explained_variance | -0.000278   |
| fps                | 20          |
| n_updates          | 27          |
| policy_entropy     | -0.5486089  |
| policy_loss        | -0.01011304 |
| serial_timesteps   | 3456        |
| time_elapsed       | 206         |
| total_timesteps    | 3456        |
| value_loss         | 4.3423696   |
------------------------------------
------------------------------------
| approxkl           | 0.02528093  |
| clipfrac           | 0.20703125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.09e+03    |
| explained_variance | -0.000149   |
| fps                | 20          |
| n_updates          | 28          |
| policy_entropy     | -0.54927975 |
| policy_loss        | 0.009453268 |
| serial_timesteps   | 3584        |
| time_elapsed       | 212         |
| total_timesteps    | 3584        |
| value_loss         | 9.718009    |
------------------------------------
An average of 261.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.010427029   |
| clipfrac           | 0.15234375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.09e+03      |
| explained_variance | -0.000342     |
| fps                | 20            |
| n_updates          | 29            |
| policy_entropy     | -0.5503563    |
| policy_loss        | -0.0018176776 |
| serial_timesteps   | 3712          |
| time_elapsed       | 218           |
| total_timesteps    | 3712          |
| value_loss         | 13.468557     |
--------------------------------------
------------------------------------
| approxkl           | 0.074499354 |
| clipfrac           | 0.36328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.09e+03    |
| explained_variance | 0.00034     |
| fps                | 20          |
| n_updates          | 30          |
| policy_entropy     | -0.5509033  |
| policy_loss        | 0.009405173 |
| serial_timesteps   | 3840        |
| time_elapsed       | 224         |
| total_timesteps    | 3840        |
| value_loss         | 60.435677   |
------------------------------------
-------------------------------------
| approxkl           | 0.002683478  |
| clipfrac           | 0.03125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.09e+03     |
| explained_variance | 0.000276     |
| fps                | 20           |
| n_updates          | 31           |
| policy_entropy     | -0.55055946  |
| policy_loss        | 0.0009090386 |
| serial_timesteps   | 3968         |
| time_elapsed       | 231          |
| total_timesteps    | 3968         |
| value_loss         | 59.52994     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0087816715 |
| clipfrac           | 0.15234375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.09e+03     |
| explained_variance | 0.00118      |
| fps                | 19           |
| n_updates          | 32           |
| policy_entropy     | -0.54871833  |
| policy_loss        | -0.005021975 |
| serial_timesteps   | 4096         |
| time_elapsed       | 237          |
| total_timesteps    | 4096         |
| value_loss         | 17.047953    |
-------------------------------------
-------------------------------------
| approxkl           | 0.026651025  |
| clipfrac           | 0.24023438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.09e+03     |
| explained_variance | 0.0052       |
| fps                | 21           |
| n_updates          | 33           |
| policy_entropy     | -0.54834735  |
| policy_loss        | -0.006007068 |
| serial_timesteps   | 4224         |
| time_elapsed       | 243          |
| total_timesteps    | 4224         |
| value_loss         | 11.445289    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02571739   |
| clipfrac           | 0.296875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.09e+03     |
| explained_variance | 0.0853       |
| fps                | 20           |
| n_updates          | 34           |
| policy_entropy     | -0.5477747   |
| policy_loss        | -0.013916897 |
| serial_timesteps   | 4352         |
| time_elapsed       | 249          |
| total_timesteps    | 4352         |
| value_loss         | 6.6921706    |
-------------------------------------
-------------------------------------
| approxkl           | 0.02032884   |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.09e+03     |
| explained_variance | 0.0536       |
| fps                | 20           |
| n_updates          | 35           |
| policy_entropy     | -0.5457731   |
| policy_loss        | -0.017522398 |
| serial_timesteps   | 4480         |
| time_elapsed       | 256          |
| total_timesteps    | 4480         |
| value_loss         | 2.7687805    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01581211   |
| clipfrac           | 0.20507812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.09e+03     |
| explained_variance | -0.213       |
| fps                | 19           |
| n_updates          | 36           |
| policy_entropy     | -0.54405075  |
| policy_loss        | -0.004586397 |
| serial_timesteps   | 4608         |
| time_elapsed       | 262          |
| total_timesteps    | 4608         |
| value_loss         | 1.8486377    |
-------------------------------------
An average of 261.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01713979  |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.00151     |
| fps                | 20          |
| n_updates          | 37          |
| policy_entropy     | -0.5437915  |
| policy_loss        | 0.014876387 |
| serial_timesteps   | 4736        |
| time_elapsed       | 269         |
| total_timesteps    | 4736        |
| value_loss         | 6242.1655   |
------------------------------------
------------------------------------
| approxkl           | 0.036805544 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.0874     |
| fps                | 20          |
| n_updates          | 38          |
| policy_entropy     | -0.5435132  |
| policy_loss        | 0.010943071 |
| serial_timesteps   | 4864        |
| time_elapsed       | 275         |
| total_timesteps    | 4864        |
| value_loss         | 7.9437246   |
------------------------------------
-------------------------------------
| approxkl           | 0.015432957  |
| clipfrac           | 0.18554688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.153        |
| fps                | 21           |
| n_updates          | 39           |
| policy_entropy     | -0.54279226  |
| policy_loss        | 0.0071237287 |
| serial_timesteps   | 4992         |
| time_elapsed       | 281          |
| total_timesteps    | 4992         |
| value_loss         | 4.0451293    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009447715  |
| clipfrac           | 0.13671875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.222       |
| fps                | 20           |
| n_updates          | 40           |
| policy_entropy     | -0.54320073  |
| policy_loss        | -0.007959779 |
| serial_timesteps   | 5120         |
| time_elapsed       | 287          |
| total_timesteps    | 5120         |
| value_loss         | 7.1888657    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008154662  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0649      |
| fps                | 19           |
| n_updates          | 41           |
| policy_entropy     | -0.5440023   |
| policy_loss        | 0.0040813265 |
| serial_timesteps   | 5248         |
| time_elapsed       | 293          |
| total_timesteps    | 5248         |
| value_loss         | 12.106474    |
-------------------------------------
------------------------------------
| approxkl           | 0.019898046 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.00824    |
| fps                | 21          |
| n_updates          | 42          |
| policy_entropy     | -0.54481065 |
| policy_loss        | 0.024376668 |
| serial_timesteps   | 5376        |
| time_elapsed       | 300         |
| total_timesteps    | 5376        |
| value_loss         | 2.323423    |
------------------------------------
------------------------------------
| approxkl           | 0.035059374 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.00109    |
| fps                | 21          |
| n_updates          | 43          |
| policy_entropy     | -0.5454987  |
| policy_loss        | 0.019536767 |
| serial_timesteps   | 5504        |
| time_elapsed       | 306         |
| total_timesteps    | 5504        |
| value_loss         | 3.1833603   |
------------------------------------
An average of 262.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.04137314    |
| clipfrac           | 0.359375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.021        |
| fps                | 20            |
| n_updates          | 44            |
| policy_entropy     | -0.54574597   |
| policy_loss        | -0.0029159153 |
| serial_timesteps   | 5632          |
| time_elapsed       | 312           |
| total_timesteps    | 5632          |
| value_loss         | 8.435502      |
--------------------------------------
------------------------------------
| approxkl           | 0.023254478 |
| clipfrac           | 0.2109375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.0144      |
| fps                | 20          |
| n_updates          | 45          |
| policy_entropy     | -0.5458835  |
| policy_loss        | 0.0045977   |
| serial_timesteps   | 5760        |
| time_elapsed       | 318         |
| total_timesteps    | 5760        |
| value_loss         | 7.2244787   |
------------------------------------
------------------------------------
| approxkl           | 0.029304085 |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.0185     |
| fps                | 20          |
| n_updates          | 46          |
| policy_entropy     | -0.5464095  |
| policy_loss        | 0.013995107 |
| serial_timesteps   | 5888        |
| time_elapsed       | 324         |
| total_timesteps    | 5888        |
| value_loss         | 5.3565164   |
------------------------------------
-------------------------------------
| approxkl           | 0.018899236  |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0117      |
| fps                | 21           |
| n_updates          | 47           |
| policy_entropy     | -0.5462618   |
| policy_loss        | 0.0033516814 |
| serial_timesteps   | 6016         |
| time_elapsed       | 330          |
| total_timesteps    | 6016         |
| value_loss         | 2.9201584    |
-------------------------------------
------------------------------------
| approxkl           | 0.008878282 |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.00838    |
| fps                | 20          |
| n_updates          | 48          |
| policy_entropy     | -0.5451401  |
| policy_loss        | 0.012765103 |
| serial_timesteps   | 6144        |
| time_elapsed       | 336         |
| total_timesteps    | 6144        |
| value_loss         | 13.340485   |
------------------------------------
-------------------------------------
| approxkl           | 0.0023723617 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.000485    |
| fps                | 20           |
| n_updates          | 49           |
| policy_entropy     | -0.5452172   |
| policy_loss        | 0.006239598  |
| serial_timesteps   | 6272         |
| time_elapsed       | 343          |
| total_timesteps    | 6272         |
| value_loss         | 6490.462     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0027746398  |
| clipfrac           | 0.033203125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | 0.0105        |
| fps                | 20            |
| n_updates          | 50            |
| policy_entropy     | -0.54535604   |
| policy_loss        | 0.00069364323 |
| serial_timesteps   | 6400          |
| time_elapsed       | 349           |
| total_timesteps    | 6400          |
| value_loss         | 56.59552      |
--------------------------------------
-------------------------------------
| approxkl           | 0.006824631  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0335      |
| fps                | 20           |
| n_updates          | 51           |
| policy_entropy     | -0.5442278   |
| policy_loss        | 0.0038872645 |
| serial_timesteps   | 6528         |
| time_elapsed       | 355          |
| total_timesteps    | 6528         |
| value_loss         | 5.1061277    |
-------------------------------------
An average of 263.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.017337184   |
| clipfrac           | 0.19140625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | -0.158        |
| fps                | 19            |
| n_updates          | 52            |
| policy_entropy     | -0.5435453    |
| policy_loss        | -0.0052003656 |
| serial_timesteps   | 6656          |
| time_elapsed       | 361           |
| total_timesteps    | 6656          |
| value_loss         | 4.0073633     |
--------------------------------------
-------------------------------------
| approxkl           | 0.03530218   |
| clipfrac           | 0.30273438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0652      |
| fps                | 20           |
| n_updates          | 53           |
| policy_entropy     | -0.54367924  |
| policy_loss        | -0.020611048 |
| serial_timesteps   | 6784         |
| time_elapsed       | 368          |
| total_timesteps    | 6784         |
| value_loss         | 0.65108156   |
-------------------------------------
------------------------------------
| approxkl           | 0.024327086 |
| clipfrac           | 0.19140625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.04e+03    |
| explained_variance | 0.0753      |
| fps                | 20          |
| n_updates          | 54          |
| policy_entropy     | -0.5442889  |
| policy_loss        | 0.017172325 |
| serial_timesteps   | 6912        |
| time_elapsed       | 374         |
| total_timesteps    | 6912        |
| value_loss         | 2.8719916   |
------------------------------------
--------------------------------------
| approxkl           | 0.011743831   |
| clipfrac           | 0.14648438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | 0.0512        |
| fps                | 20            |
| n_updates          | 55            |
| policy_entropy     | -0.5451357    |
| policy_loss        | 0.00038955873 |
| serial_timesteps   | 7040          |
| time_elapsed       | 380           |
| total_timesteps    | 7040          |
| value_loss         | 4.4978676     |
--------------------------------------
------------------------------------
| approxkl           | 0.015414342 |
| clipfrac           | 0.20703125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.04e+03    |
| explained_variance | 0.000629    |
| fps                | 20          |
| n_updates          | 56          |
| policy_entropy     | -0.54776454 |
| policy_loss        | -0.00678598 |
| serial_timesteps   | 7168        |
| time_elapsed       | 386         |
| total_timesteps    | 7168        |
| value_loss         | 6.0738764   |
------------------------------------
-------------------------------------
| approxkl           | 0.0124856485 |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0587      |
| fps                | 20           |
| n_updates          | 57           |
| policy_entropy     | -0.54905164  |
| policy_loss        | 0.001320722  |
| serial_timesteps   | 7296         |
| time_elapsed       | 393          |
| total_timesteps    | 7296         |
| value_loss         | 1.127991     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0039251144  |
| clipfrac           | 0.037109375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | -0.0208       |
| fps                | 20            |
| n_updates          | 58            |
| policy_entropy     | -0.5499487    |
| policy_loss        | -0.0002619481 |
| serial_timesteps   | 7424          |
| time_elapsed       | 399           |
| total_timesteps    | 7424          |
| value_loss         | 1.7133521     |
--------------------------------------
-------------------------------------
| approxkl           | 0.027611956  |
| clipfrac           | 0.32421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.00915     |
| fps                | 20           |
| n_updates          | 59           |
| policy_entropy     | -0.55100524  |
| policy_loss        | -0.007410851 |
| serial_timesteps   | 7552         |
| time_elapsed       | 405          |
| total_timesteps    | 7552         |
| value_loss         | 1.9096934    |
-------------------------------------
An average of 263.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.026460882  |
| clipfrac           | 0.27929688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.00508     |
| fps                | 21           |
| n_updates          | 60           |
| policy_entropy     | -0.5504284   |
| policy_loss        | -0.011272669 |
| serial_timesteps   | 7680         |
| time_elapsed       | 411          |
| total_timesteps    | 7680         |
| value_loss         | 1.4880989    |
-------------------------------------
--------------------------------------
| approxkl           | 0.005164525   |
| clipfrac           | 0.05859375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.01e+03      |
| explained_variance | -3.09e-05     |
| fps                | 19            |
| n_updates          | 61            |
| policy_entropy     | -0.5501458    |
| policy_loss        | -0.0031617081 |
| serial_timesteps   | 7808          |
| time_elapsed       | 417           |
| total_timesteps    | 7808          |
| value_loss         | 6659.823      |
--------------------------------------
------------------------------------
| approxkl           | 0.039668955 |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | 0.000717    |
| fps                | 20          |
| n_updates          | 62          |
| policy_entropy     | -0.5506261  |
| policy_loss        | -0.01462416 |
| serial_timesteps   | 7936        |
| time_elapsed       | 424         |
| total_timesteps    | 7936        |
| value_loss         | 1.453725    |
------------------------------------
------------------------------------
| approxkl           | 0.02296025  |
| clipfrac           | 0.21289062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | -0.00266    |
| fps                | 20          |
| n_updates          | 63          |
| policy_entropy     | -0.55163026 |
| policy_loss        | 0.011705988 |
| serial_timesteps   | 8064        |
| time_elapsed       | 430         |
| total_timesteps    | 8064        |
| value_loss         | 3.7582924   |
------------------------------------
------------------------------------
| approxkl           | 0.026203668 |
| clipfrac           | 0.27734375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | -0.0113     |
| fps                | 21          |
| n_updates          | 64          |
| policy_entropy     | -0.550917   |
| policy_loss        | 0.024555579 |
| serial_timesteps   | 8192        |
| time_elapsed       | 437         |
| total_timesteps    | 8192        |
| value_loss         | 13.368748   |
------------------------------------
------------------------------------
| approxkl           | 0.011420207 |
| clipfrac           | 0.14257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | -0.00216    |
| fps                | 20          |
| n_updates          | 65          |
| policy_entropy     | -0.55102795 |
| policy_loss        | -0.00688695 |
| serial_timesteps   | 8320        |
| time_elapsed       | 443         |
| total_timesteps    | 8320        |
| value_loss         | 14.257217   |
------------------------------------
--------------------------------------
| approxkl           | 0.01231121    |
| clipfrac           | 0.17773438    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.01e+03      |
| explained_variance | -0.00703      |
| fps                | 20            |
| n_updates          | 66            |
| policy_entropy     | -0.55261886   |
| policy_loss        | -0.0055371216 |
| serial_timesteps   | 8448          |
| time_elapsed       | 449           |
| total_timesteps    | 8448          |
| value_loss         | 9.03373       |
--------------------------------------
---------------------------------------
| approxkl           | 0.006145186    |
| clipfrac           | 0.06640625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 7.01e+03       |
| explained_variance | -0.00357       |
| fps                | 19             |
| n_updates          | 67             |
| policy_entropy     | -0.5543821     |
| policy_loss        | -0.00094709906 |
| serial_timesteps   | 8576           |
| time_elapsed       | 455            |
| total_timesteps    | 8576           |
| value_loss         | 13.553438      |
---------------------------------------
An average of 264.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.015407808 |
| clipfrac           | 0.17773438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | -0.00281    |
| fps                | 19          |
| n_updates          | 68          |
| policy_entropy     | -0.5586542  |
| policy_loss        | 0.01611745  |
| serial_timesteps   | 8704        |
| time_elapsed       | 461         |
| total_timesteps    | 8704        |
| value_loss         | 15.870867   |
------------------------------------
-------------------------------------
| approxkl           | 0.007868272  |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | -0.00192     |
| fps                | 20           |
| n_updates          | 69           |
| policy_entropy     | -0.56101614  |
| policy_loss        | -0.008087408 |
| serial_timesteps   | 8832         |
| time_elapsed       | 468          |
| total_timesteps    | 8832         |
| value_loss         | 60.79991     |
-------------------------------------
-------------------------------------
| approxkl           | 0.017616875  |
| clipfrac           | 0.20703125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.00188      |
| fps                | 20           |
| n_updates          | 70           |
| policy_entropy     | -0.5613895   |
| policy_loss        | -0.014191891 |
| serial_timesteps   | 8960         |
| time_elapsed       | 474          |
| total_timesteps    | 8960         |
| value_loss         | 3.984101     |
-------------------------------------
-------------------------------------
| approxkl           | 0.009020654  |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.00479      |
| fps                | 21           |
| n_updates          | 71           |
| policy_entropy     | -0.5625098   |
| policy_loss        | -0.006463604 |
| serial_timesteps   | 9088         |
| time_elapsed       | 480          |
| total_timesteps    | 9088         |
| value_loss         | 0.8748099    |
-------------------------------------
-------------------------------------
| approxkl           | 0.017731098  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.0276       |
| fps                | 20           |
| n_updates          | 72           |
| policy_entropy     | -0.5646263   |
| policy_loss        | -0.013268743 |
| serial_timesteps   | 9216         |
| time_elapsed       | 486          |
| total_timesteps    | 9216         |
| value_loss         | 1.6997585    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0025511791 |
| clipfrac           | 0.017578125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | 0.000554     |
| fps                | 20           |
| n_updates          | 73           |
| policy_entropy     | -0.56598663  |
| policy_loss        | 0.0052367793 |
| serial_timesteps   | 9344         |
| time_elapsed       | 492          |
| total_timesteps    | 9344         |
| value_loss         | 6628.8833    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015818445  |
| clipfrac           | 0.23242188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.0605      |
| fps                | 21           |
| n_updates          | 74           |
| policy_entropy     | -0.5665193   |
| policy_loss        | 0.0069078603 |
| serial_timesteps   | 9472         |
| time_elapsed       | 499          |
| total_timesteps    | 9472         |
| value_loss         | 3.7822647    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008636253  |
| clipfrac           | 0.125        |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.0394      |
| fps                | 21           |
| n_updates          | 75           |
| policy_entropy     | -0.5674396   |
| policy_loss        | -0.009990348 |
| serial_timesteps   | 9600         |
| time_elapsed       | 505          |
| total_timesteps    | 9600         |
| value_loss         | 2.8609624    |
-------------------------------------
An average of 265.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.009580847 |
| clipfrac           | 0.12695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | -0.0256     |
| fps                | 19          |
| n_updates          | 76          |
| policy_entropy     | -0.56986165 |
| policy_loss        | 0.003484139 |
| serial_timesteps   | 9728        |
| time_elapsed       | 511         |
| total_timesteps    | 9728        |
| value_loss         | 1.8667456   |
------------------------------------
-------------------------------------
| approxkl           | 0.0125782415 |
| clipfrac           | 0.19140625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | 0.00667      |
| fps                | 21           |
| n_updates          | 77           |
| policy_entropy     | -0.5712786   |
| policy_loss        | 0.013944936  |
| serial_timesteps   | 9856         |
| time_elapsed       | 517          |
| total_timesteps    | 9856         |
| value_loss         | 1.1321483    |
-------------------------------------
-------------------------------------
| approxkl           | 0.027332086  |
| clipfrac           | 0.30273438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.00655     |
| fps                | 20           |
| n_updates          | 78           |
| policy_entropy     | -0.57089365  |
| policy_loss        | -0.010737602 |
| serial_timesteps   | 9984         |
| time_elapsed       | 523          |
| total_timesteps    | 9984         |
| value_loss         | 4.288653     |
-------------------------------------
--------------------------------------
| approxkl           | 0.023217112   |
| clipfrac           | 0.22070312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.03e+03      |
| explained_variance | -0.00438      |
| fps                | 20            |
| n_updates          | 79            |
| policy_entropy     | -0.5706363    |
| policy_loss        | -0.0028087373 |
| serial_timesteps   | 10112         |
| time_elapsed       | 529           |
| total_timesteps    | 10112         |
| value_loss         | 1.8628272     |
--------------------------------------
------------------------------------
| approxkl           | 0.022528987 |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | -0.00351    |
| fps                | 20          |
| n_updates          | 80          |
| policy_entropy     | -0.5713069  |
| policy_loss        | -0.013695   |
| serial_timesteps   | 10240       |
| time_elapsed       | 536         |
| total_timesteps    | 10240       |
| value_loss         | 0.7866887   |
------------------------------------
-------------------------------------
| approxkl           | 0.05729292   |
| clipfrac           | 0.37304688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.00189     |
| fps                | 20           |
| n_updates          | 81           |
| policy_entropy     | -0.5703624   |
| policy_loss        | -0.030270148 |
| serial_timesteps   | 10368        |
| time_elapsed       | 542          |
| total_timesteps    | 10368        |
| value_loss         | 2.3385193    |
-------------------------------------
-------------------------------------
| approxkl           | 0.010262118  |
| clipfrac           | 0.13476562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.0011      |
| fps                | 19           |
| n_updates          | 82           |
| policy_entropy     | -0.5701075   |
| policy_loss        | -0.002588776 |
| serial_timesteps   | 10496        |
| time_elapsed       | 548          |
| total_timesteps    | 10496        |
| value_loss         | 4.7145615    |
-------------------------------------
------------------------------------
| approxkl           | 0.012692398 |
| clipfrac           | 0.17382812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | -0.0133     |
| fps                | 20          |
| n_updates          | 83          |
| policy_entropy     | -0.57035357 |
| policy_loss        | 0.009362084 |
| serial_timesteps   | 10624       |
| time_elapsed       | 555         |
| total_timesteps    | 10624       |
| value_loss         | 8.755032    |
------------------------------------
An average of 265.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0073355297  |
| clipfrac           | 0.09375       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.03e+03      |
| explained_variance | -0.0102       |
| fps                | 19            |
| n_updates          | 84            |
| policy_entropy     | -0.57134813   |
| policy_loss        | -0.0027403305 |
| serial_timesteps   | 10752         |
| time_elapsed       | 561           |
| total_timesteps    | 10752         |
| value_loss         | 7.7070932     |
--------------------------------------
------------------------------------
| approxkl           | 0.017043645 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.04e+03    |
| explained_variance | -6.88e-05   |
| fps                | 20          |
| n_updates          | 85          |
| policy_entropy     | -0.57150227 |
| policy_loss        | 0.018042712 |
| serial_timesteps   | 10880       |
| time_elapsed       | 567         |
| total_timesteps    | 10880       |
| value_loss         | 6634.8887   |
------------------------------------
--------------------------------------
| approxkl           | 0.0086982865  |
| clipfrac           | 0.099609375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | 0.00375       |
| fps                | 20            |
| n_updates          | 86            |
| policy_entropy     | -0.57182795   |
| policy_loss        | -0.0068941354 |
| serial_timesteps   | 11008         |
| time_elapsed       | 574           |
| total_timesteps    | 11008         |
| value_loss         | 9.251201      |
--------------------------------------
--------------------------------------
| approxkl           | 0.005472673   |
| clipfrac           | 0.05859375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | -0.00507      |
| fps                | 20            |
| n_updates          | 87            |
| policy_entropy     | -0.57392174   |
| policy_loss        | 0.00014948146 |
| serial_timesteps   | 11136         |
| time_elapsed       | 580           |
| total_timesteps    | 11136         |
| value_loss         | 14.510631     |
--------------------------------------
-------------------------------------
| approxkl           | 0.010640948  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | 0.00799      |
| fps                | 21           |
| n_updates          | 88           |
| policy_entropy     | -0.57694614  |
| policy_loss        | -0.002014429 |
| serial_timesteps   | 11264        |
| time_elapsed       | 586          |
| total_timesteps    | 11264        |
| value_loss         | 67.75429     |
-------------------------------------
------------------------------------
| approxkl           | 0.01836394  |
| clipfrac           | 0.23242188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.04e+03    |
| explained_variance | 0.0125      |
| fps                | 20          |
| n_updates          | 89          |
| policy_entropy     | -0.57775825 |
| policy_loss        | 0.01161844  |
| serial_timesteps   | 11392       |
| time_elapsed       | 592         |
| total_timesteps    | 11392       |
| value_loss         | 19.770796   |
------------------------------------
--------------------------------------
| approxkl           | 0.0055934004  |
| clipfrac           | 0.072265625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | -0.00153      |
| fps                | 19            |
| n_updates          | 90            |
| policy_entropy     | -0.57772475   |
| policy_loss        | 0.00073482515 |
| serial_timesteps   | 11520         |
| time_elapsed       | 598           |
| total_timesteps    | 11520         |
| value_loss         | 9.019632      |
--------------------------------------
An average of 266.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.018690772  |
| clipfrac           | 0.23046875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0745      |
| fps                | 20           |
| n_updates          | 91           |
| policy_entropy     | -0.57811624  |
| policy_loss        | -0.014494627 |
| serial_timesteps   | 11648        |
| time_elapsed       | 605          |
| total_timesteps    | 11648        |
| value_loss         | 3.9238555    |
-------------------------------------
--------------------------------------
| approxkl           | 0.030190231   |
| clipfrac           | 0.265625      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | -0.0254       |
| fps                | 19            |
| n_updates          | 92            |
| policy_entropy     | -0.579066     |
| policy_loss        | -0.0058513447 |
| serial_timesteps   | 11776         |
| time_elapsed       | 611           |
| total_timesteps    | 11776         |
| value_loss         | 0.6823271     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011628889  |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | 0.0176       |
| fps                | 21           |
| n_updates          | 93           |
| policy_entropy     | -0.5804459   |
| policy_loss        | 0.0035270439 |
| serial_timesteps   | 11904        |
| time_elapsed       | 617          |
| total_timesteps    | 11904        |
| value_loss         | 4.490489     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0050992817 |
| clipfrac           | 0.0625       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.19        |
| fps                | 20           |
| n_updates          | 94           |
| policy_entropy     | -0.58261913  |
| policy_loss        | 0.0054588807 |
| serial_timesteps   | 12032        |
| time_elapsed       | 623          |
| total_timesteps    | 12032        |
| value_loss         | 5.491187     |
-------------------------------------
-------------------------------------
| approxkl           | 0.011435431  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | 0.0139       |
| fps                | 20           |
| n_updates          | 95           |
| policy_entropy     | -0.5858049   |
| policy_loss        | 0.0058150133 |
| serial_timesteps   | 12160        |
| time_elapsed       | 630          |
| total_timesteps    | 12160        |
| value_loss         | 3.9171355    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0124442745  |
| clipfrac           | 0.17382812    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.04e+03      |
| explained_variance | 0.00104       |
| fps                | 19            |
| n_updates          | 96            |
| policy_entropy     | -0.5882271    |
| policy_loss        | -0.0120656425 |
| serial_timesteps   | 12288         |
| time_elapsed       | 636           |
| total_timesteps    | 12288         |
| value_loss         | 1.3304616     |
--------------------------------------
------------------------------------
| approxkl           | 0.02088624  |
| clipfrac           | 0.25        |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | -0.000103   |
| fps                | 21          |
| n_updates          | 97          |
| policy_entropy     | -0.58903193 |
| policy_loss        | 0.017243637 |
| serial_timesteps   | 12416       |
| time_elapsed       | 643         |
| total_timesteps    | 12416       |
| value_loss         | 6818.454    |
------------------------------------
------------------------------------
| approxkl           | 0.014480503 |
| clipfrac           | 0.1953125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | -0.00858    |
| fps                | 20          |
| n_updates          | 98          |
| policy_entropy     | -0.5892581  |
| policy_loss        | 0.011850824 |
| serial_timesteps   | 12544       |
| time_elapsed       | 649         |
| total_timesteps    | 12544       |
| value_loss         | 2.1595852   |
------------------------------------
An average of 267.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.025445312  |
| clipfrac           | 0.28125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.00837     |
| fps                | 20           |
| n_updates          | 99           |
| policy_entropy     | -0.58988684  |
| policy_loss        | -0.021051615 |
| serial_timesteps   | 12672        |
| time_elapsed       | 655          |
| total_timesteps    | 12672        |
| value_loss         | 1.8539915    |
-------------------------------------
--------------------------------------
| approxkl           | 0.020445518   |
| clipfrac           | 0.22460938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.03e+03      |
| explained_variance | 7.25e-05      |
| fps                | 20            |
| n_updates          | 100           |
| policy_entropy     | -0.5904839    |
| policy_loss        | -0.0017002067 |
| serial_timesteps   | 12800         |
| time_elapsed       | 661           |
| total_timesteps    | 12800         |
| value_loss         | 0.80966383    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008322828  |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | 0.000136     |
| fps                | 21           |
| n_updates          | 101          |
| policy_entropy     | -0.5908636   |
| policy_loss        | 0.0025659876 |
| serial_timesteps   | 12928        |
| time_elapsed       | 668          |
| total_timesteps    | 12928        |
| value_loss         | 5.774091     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0099135395 |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.0187      |
| fps                | 20           |
| n_updates          | 102          |
| policy_entropy     | -0.5889193   |
| policy_loss        | 0.0030247886 |
| serial_timesteps   | 13056        |
| time_elapsed       | 674          |
| total_timesteps    | 13056        |
| value_loss         | 6.0356107    |
-------------------------------------
------------------------------------
| approxkl           | 0.011663508 |
| clipfrac           | 0.1640625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | 0.00852     |
| fps                | 20          |
| n_updates          | 103         |
| policy_entropy     | -0.5891083  |
| policy_loss        | 0.01981913  |
| serial_timesteps   | 13184       |
| time_elapsed       | 680         |
| total_timesteps    | 13184       |
| value_loss         | 12.541069   |
------------------------------------
-------------------------------------
| approxkl           | 0.0048738397 |
| clipfrac           | 0.06640625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | -0.00699     |
| fps                | 20           |
| n_updates          | 104          |
| policy_entropy     | -0.5907636   |
| policy_loss        | 0.0028691534 |
| serial_timesteps   | 13312        |
| time_elapsed       | 686          |
| total_timesteps    | 13312        |
| value_loss         | 9.684965     |
-------------------------------------
------------------------------------
| approxkl           | 0.017276835 |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.03e+03    |
| explained_variance | -0.00555    |
| fps                | 20          |
| n_updates          | 105         |
| policy_entropy     | -0.59191865 |
| policy_loss        | 0.004552166 |
| serial_timesteps   | 13440       |
| time_elapsed       | 692         |
| total_timesteps    | 13440       |
| value_loss         | 10.3725395  |
------------------------------------
-------------------------------------
| approxkl           | 0.005698471  |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | 0.00285      |
| fps                | 19           |
| n_updates          | 106          |
| policy_entropy     | -0.59280455  |
| policy_loss        | 0.0015825725 |
| serial_timesteps   | 13568        |
| time_elapsed       | 699          |
| total_timesteps    | 13568        |
| value_loss         | 14.194715    |
-------------------------------------
An average of 267.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.004240527   |
| clipfrac           | 0.046875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.03e+03      |
| explained_variance | 0.00827       |
| fps                | 21            |
| n_updates          | 107           |
| policy_entropy     | -0.5939871    |
| policy_loss        | -0.0048802076 |
| serial_timesteps   | 13696         |
| time_elapsed       | 705           |
| total_timesteps    | 13696         |
| value_loss         | 52.920563     |
--------------------------------------
-------------------------------------
| approxkl           | 0.014976813  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.03e+03     |
| explained_variance | 0.00855      |
| fps                | 20           |
| n_updates          | 108          |
| policy_entropy     | -0.59484553  |
| policy_loss        | -0.002137889 |
| serial_timesteps   | 13824        |
| time_elapsed       | 711          |
| total_timesteps    | 13824        |
| value_loss         | 34.343082    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01657677   |
| clipfrac           | 0.23242188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | 0.00113      |
| fps                | 21           |
| n_updates          | 109          |
| policy_entropy     | -0.59587324  |
| policy_loss        | 0.0128032565 |
| serial_timesteps   | 13952        |
| time_elapsed       | 717          |
| total_timesteps    | 13952        |
| value_loss         | 6811.6064    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021920335  |
| clipfrac           | 0.26953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0902      |
| fps                | 21           |
| n_updates          | 110          |
| policy_entropy     | -0.59622616  |
| policy_loss        | -0.026896702 |
| serial_timesteps   | 14080        |
| time_elapsed       | 723          |
| total_timesteps    | 14080        |
| value_loss         | 0.9959977    |
-------------------------------------
-------------------------------------
| approxkl           | 0.016112067  |
| clipfrac           | 0.19921875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.113       |
| fps                | 20           |
| n_updates          | 111          |
| policy_entropy     | -0.5967917   |
| policy_loss        | 0.0064074947 |
| serial_timesteps   | 14208        |
| time_elapsed       | 730          |
| total_timesteps    | 14208        |
| value_loss         | 1.0702405    |
-------------------------------------
------------------------------------
| approxkl           | 0.01076501  |
| clipfrac           | 0.15234375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.04e+03    |
| explained_variance | 0.0309      |
| fps                | 21          |
| n_updates          | 112         |
| policy_entropy     | -0.59764725 |
| policy_loss        | 0.008795483 |
| serial_timesteps   | 14336       |
| time_elapsed       | 736         |
| total_timesteps    | 14336       |
| value_loss         | 4.5189505   |
------------------------------------
-------------------------------------
| approxkl           | 0.024293136  |
| clipfrac           | 0.2890625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | 0.00642      |
| fps                | 19           |
| n_updates          | 113          |
| policy_entropy     | -0.5999156   |
| policy_loss        | -0.017672129 |
| serial_timesteps   | 14464        |
| time_elapsed       | 742          |
| total_timesteps    | 14464        |
| value_loss         | 2.5917907    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01078753   |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0389      |
| fps                | 20           |
| n_updates          | 114          |
| policy_entropy     | -0.60157883  |
| policy_loss        | -0.005237719 |
| serial_timesteps   | 14592        |
| time_elapsed       | 748          |
| total_timesteps    | 14592        |
| value_loss         | 2.7600513    |
-------------------------------------
An average of 268.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.033722665  |
| clipfrac           | 0.24804688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | -0.0244      |
| fps                | 21           |
| n_updates          | 115          |
| policy_entropy     | -0.6038753   |
| policy_loss        | 0.0017382347 |
| serial_timesteps   | 14720        |
| time_elapsed       | 754          |
| total_timesteps    | 14720        |
| value_loss         | 1.0602959    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015625557  |
| clipfrac           | 0.20507812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.04e+03     |
| explained_variance | 0.00096      |
| fps                | 20           |
| n_updates          | 116          |
| policy_entropy     | -0.6051614   |
| policy_loss        | 0.0016759611 |
| serial_timesteps   | 14848        |
| time_elapsed       | 760          |
| total_timesteps    | 14848        |
| value_loss         | 4.673425     |
-------------------------------------
---------------------------------------
| approxkl           | 0.01795398     |
| clipfrac           | 0.20898438     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 7.04e+03       |
| explained_variance | -0.00874       |
| fps                | 19             |
| n_updates          | 117            |
| policy_entropy     | -0.6059563     |
| policy_loss        | -0.00031361438 |
| serial_timesteps   | 14976          |
| time_elapsed       | 766            |
| total_timesteps    | 14976          |
| value_loss         | 1.6899844      |
---------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b34770f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b34770f60>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3469ce48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3469ce48>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2743 samples, validate on 297 samples
Epoch 491/5000
 - 10s - loss: 0.0926 - val_loss: 0.0249
Epoch 492/5000
 - 1s - loss: 0.0217 - val_loss: 0.0147
Epoch 493/5000
 - 1s - loss: 0.0127 - val_loss: 0.0103
Epoch 494/5000
 - 1s - loss: 0.0098 - val_loss: 0.0084
Epoch 495/5000
 - 1s - loss: 0.0087 - val_loss: 0.0077
Epoch 496/5000
 - 1s - loss: 0.0084 - val_loss: 0.0075
Epoch 497/5000
 - 1s - loss: 0.0083 - val_loss: 0.0073
Epoch 498/5000
 - 1s - loss: 0.0082 - val_loss: 0.0073
Epoch 499/5000
 - 1s - loss: 0.0082 - val_loss: 0.0072
Epoch 500/5000
 - 1s - loss: 0.0081 - val_loss: 0.0073
Epoch 501/5000
 - 1s - loss: 0.0080 - val_loss: 0.0073
Epoch 502/5000
 - 1s - loss: 0.0068 - val_loss: 0.0071
Epoch 503/5000
 - 1s - loss: 0.0061 - val_loss: 0.0071
Epoch 504/5000
 - 1s - loss: 0.0060 - val_loss: 0.0071
Epoch 505/5000
 - 1s - loss: 0.0060 - val_loss: 0.0071
Epoch 506/5000
 - 1s - loss: 0.0058 - val_loss: 0.0070
Epoch 507/5000
 - 1s - loss: 0.0058 - val_loss: 0.0069
Epoch 508/5000
 - 1s - loss: 0.0058 - val_loss: 0.0069
Epoch 509/5000
 - 1s - loss: 0.0057 - val_loss: 0.0069
Epoch 510/5000
 - 1s - loss: 0.0057 - val_loss: 0.0069
Epoch 511/5000
 - 1s - loss: 0.0057 - val_loss: 0.0069
Epoch 512/5000
 - 1s - loss: 0.0057 - val_loss: 0.0069
Epoch 513/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 514/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 515/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 516/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 517/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 518/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 519/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 520/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 521/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 522/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 523/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 524/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 525/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 526/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 527/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 528/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 529/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 530/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 531/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 532/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Epoch 533/5000
 - 1s - loss: 0.0057 - val_loss: 0.0068
Train on 2171 samples, validate on 297 samples
Epoch 362/5000
 - 10s - loss: 0.0032 - val_loss: 0.0594
Epoch 363/5000
 - 1s - loss: 0.0038 - val_loss: 0.0571
Epoch 364/5000
 - 1s - loss: 0.0028 - val_loss: 0.0482
Epoch 365/5000
 - 1s - loss: 0.0025 - val_loss: 0.0444
Epoch 366/5000
 - 1s - loss: 0.0031 - val_loss: 0.0445
Epoch 367/5000
 - 1s - loss: 0.0022 - val_loss: 0.0394
Epoch 368/5000
 - 1s - loss: 0.0017 - val_loss: 0.0338
Epoch 369/5000
 - 1s - loss: 0.0015 - val_loss: 0.0315
Epoch 370/5000
 - 1s - loss: 0.0013 - val_loss: 0.0252
Epoch 371/5000
 - 1s - loss: 0.0012 - val_loss: 0.0257
Epoch 372/5000
 - 1s - loss: 0.0010 - val_loss: 0.0223
Epoch 373/5000
 - 1s - loss: 0.0010 - val_loss: 0.0222
Epoch 374/5000
 - 1s - loss: 9.6871e-04 - val_loss: 0.0215
Epoch 375/5000
 - 1s - loss: 9.4322e-04 - val_loss: 0.0213
Epoch 376/5000
 - 1s - loss: 9.2039e-04 - val_loss: 0.0207
Epoch 377/5000
 - 1s - loss: 9.1363e-04 - val_loss: 0.0206
Epoch 378/5000
 - 1s - loss: 9.0551e-04 - val_loss: 0.0204
Epoch 379/5000
 - 1s - loss: 8.9682e-04 - val_loss: 0.0204
Epoch 380/5000
 - 1s - loss: 8.8899e-04 - val_loss: 0.0203
Epoch 381/5000
 - 1s - loss: 8.8665e-04 - val_loss: 0.0201
Epoch 382/5000
 - 1s - loss: 8.8297e-04 - val_loss: 0.0201
Epoch 383/5000
 - 1s - loss: 8.7032e-04 - val_loss: 0.0203
Epoch 384/5000
 - 1s - loss: 9.0795e-04 - val_loss: 0.0208
Epoch 385/5000
 - 1s - loss: 8.3636e-04 - val_loss: 0.0200
Epoch 386/5000
 - 1s - loss: 7.9684e-04 - val_loss: 0.0197
Epoch 387/5000
 - 1s - loss: 7.9054e-04 - val_loss: 0.0195
Epoch 388/5000
 - 1s - loss: 7.8761e-04 - val_loss: 0.0194
Epoch 389/5000
 - 1s - loss: 7.8484e-04 - val_loss: 0.0192
Epoch 390/5000
 - 1s - loss: 7.8256e-04 - val_loss: 0.0191
Epoch 391/5000
 - 1s - loss: 7.8023e-04 - val_loss: 0.0190
Epoch 392/5000
 - 1s - loss: 7.7861e-04 - val_loss: 0.0189
Epoch 393/5000
 - 1s - loss: 7.7636e-04 - val_loss: 0.0188
Epoch 394/5000
 - 1s - loss: 7.7463e-04 - val_loss: 0.0188
Epoch 395/5000
 - 1s - loss: 7.7267e-04 - val_loss: 0.0187
Epoch 396/5000
 - 1s - loss: 7.7085e-04 - val_loss: 0.0187
Epoch 397/5000
 - 1s - loss: 7.6931e-04 - val_loss: 0.0186
Epoch 398/5000
 - 1s - loss: 7.6215e-04 - val_loss: 0.0189
Epoch 399/5000
 - 1s - loss: 7.3792e-04 - val_loss: 0.0191
Epoch 400/5000
 - 1s - loss: 7.2697e-04 - val_loss: 0.0192
Epoch 401/5000
 - 1s - loss: 7.2188e-04 - val_loss: 0.0192
Epoch 402/5000
 - 1s - loss: 7.1471e-04 - val_loss: 0.0192
Train on 2793 samples, validate on 297 samples
Epoch 1164/5000
 - 11s - loss: 0.6090 - val_loss: 0.5066
Epoch 1165/5000
 - 1s - loss: 0.5188 - val_loss: 0.4894
Epoch 1166/5000
 - 1s - loss: 0.5114 - val_loss: 0.4864
Epoch 1167/5000
 - 1s - loss: 0.5090 - val_loss: 0.4826
Epoch 1168/5000
 - 1s - loss: 0.5065 - val_loss: 0.4772
Epoch 1169/5000
 - 1s - loss: 0.5033 - val_loss: 0.4695
Epoch 1170/5000
 - 1s - loss: 0.4986 - val_loss: 0.4576
Epoch 1171/5000
 - 1s - loss: 0.4928 - val_loss: 0.4364
Epoch 1172/5000
 - 1s - loss: 0.4797 - val_loss: 0.4146
Epoch 1173/5000
 - 1s - loss: 0.4673 - val_loss: 0.3909
Epoch 1174/5000
 - 1s - loss: 0.4553 - val_loss: 0.3705
Epoch 1175/5000
 - 1s - loss: 0.4453 - val_loss: 0.3552
Epoch 1176/5000
 - 1s - loss: 0.4381 - val_loss: 0.3453
Epoch 1177/5000
 - 1s - loss: 0.4326 - val_loss: 0.3394
Epoch 1178/5000
 - 1s - loss: 0.4284 - val_loss: 0.3356
Epoch 1179/5000
 - 1s - loss: 0.4259 - val_loss: 0.3337
Epoch 1180/5000
 - 1s - loss: 0.4245 - val_loss: 0.3333
Epoch 1181/5000
 - 1s - loss: 0.4223 - val_loss: 0.3332
Epoch 1182/5000
 - 1s - loss: 0.4201 - val_loss: 0.3320
Epoch 1183/5000
 - 1s - loss: 0.4196 - val_loss: 0.3323
Epoch 1184/5000
 - 1s - loss: 0.4170 - val_loss: 0.3316
Epoch 1185/5000
 - 1s - loss: 0.4172 - val_loss: 0.3326
Epoch 1186/5000
 - 1s - loss: 0.4142 - val_loss: 0.3320
Epoch 1187/5000
 - 1s - loss: 0.3912 - val_loss: 0.3313
Epoch 1188/5000
 - 1s - loss: 0.3901 - val_loss: 0.3300
Epoch 1189/5000
 - 1s - loss: 0.3892 - val_loss: 0.3287
Epoch 1190/5000
 - 1s - loss: 0.3885 - val_loss: 0.3274
Epoch 1191/5000
 - 1s - loss: 0.3879 - val_loss: 0.3263
Epoch 1192/5000
 - 1s - loss: 0.3875 - val_loss: 0.3253
Epoch 1193/5000
 - 1s - loss: 0.3871 - val_loss: 0.3244
Epoch 1194/5000
 - 1s - loss: 0.3868 - val_loss: 0.3237
Epoch 1195/5000
 - 1s - loss: 0.3865 - val_loss: 0.3230
Epoch 1196/5000
 - 1s - loss: 0.3862 - val_loss: 0.3223
Epoch 1197/5000
 - 1s - loss: 0.3860 - val_loss: 0.3218
Epoch 1198/5000
 - 1s - loss: 0.3858 - val_loss: 0.3213
Epoch 1199/5000
 - 1s - loss: 0.3856 - val_loss: 0.3208
Epoch 1200/5000
 - 1s - loss: 0.3854 - val_loss: 0.3203
Epoch 1201/5000
 - 1s - loss: 0.3852 - val_loss: 0.3199
Epoch 1202/5000
 - 1s - loss: 0.3850 - val_loss: 0.3195
Epoch 1203/5000
 - 2s - loss: 0.3848 - val_loss: 0.3192
Epoch 1204/5000
 - 1s - loss: 0.3846 - val_loss: 0.3188
Epoch 1205/5000
 - 1s - loss: 0.3845 - val_loss: 0.3185
Epoch 1206/5000
 - 1s - loss: 0.3843 - val_loss: 0.3182
Epoch 1207/5000
 - 1s - loss: 0.3842 - val_loss: 0.3179
Epoch 1208/5000
 - 1s - loss: 0.3840 - val_loss: 0.3176
Epoch 1209/5000
 - 1s - loss: 0.3838 - val_loss: 0.3174
Epoch 1210/5000
 - 1s - loss: 0.3837 - val_loss: 0.3171
Epoch 1211/5000
 - 1s - loss: 0.3835 - val_loss: 0.3169
Epoch 1212/5000
 - 1s - loss: 0.3834 - val_loss: 0.3166
Epoch 1213/5000
 - 1s - loss: 0.3833 - val_loss: 0.3164
Epoch 1214/5000
 - 1s - loss: 0.3831 - val_loss: 0.3162
Epoch 1215/5000
 - 1s - loss: 0.3830 - val_loss: 0.3160
Epoch 1216/5000
 - 1s - loss: 0.3828 - val_loss: 0.3158
Epoch 1217/5000
 - 1s - loss: 0.3827 - val_loss: 0.3157
Epoch 1218/5000
 - 1s - loss: 0.3826 - val_loss: 0.3155
Epoch 1219/5000
 - 1s - loss: 0.3824 - val_loss: 0.3153
Epoch 1220/5000
 - 1s - loss: 0.3823 - val_loss: 0.3152
Epoch 1221/5000
 - 1s - loss: 0.3822 - val_loss: 0.3150
Epoch 1222/5000
 - 1s - loss: 0.3821 - val_loss: 0.3149
Epoch 1223/5000
 - 1s - loss: 0.3819 - val_loss: 0.3148
Epoch 1224/5000
 - 1s - loss: 0.3818 - val_loss: 0.3146
Epoch 1225/5000
 - 1s - loss: 0.3817 - val_loss: 0.3145
Epoch 1226/5000
 - 1s - loss: 0.3816 - val_loss: 0.3144
Epoch 1227/5000
 - 1s - loss: 0.3815 - val_loss: 0.3143
Epoch 1228/5000
 - 1s - loss: 0.3813 - val_loss: 0.3142
Epoch 1229/5000
 - 1s - loss: 0.3812 - val_loss: 0.3141
Epoch 1230/5000
 - 1s - loss: 0.3811 - val_loss: 0.3140
Epoch 1231/5000
 - 1s - loss: 0.3810 - val_loss: 0.3139
Epoch 1232/5000
 - 1s - loss: 0.3809 - val_loss: 0.3138
Epoch 1233/5000
 - 1s - loss: 0.3808 - val_loss: 0.3137
Epoch 1234/5000
 - 1s - loss: 0.3807 - val_loss: 0.3136
Epoch 1235/5000
 - 1s - loss: 0.3805 - val_loss: 0.3135
Epoch 1236/5000
 - 1s - loss: 0.3804 - val_loss: 0.3134
Epoch 1237/5000
 - 1s - loss: 0.3803 - val_loss: 0.3134
Epoch 1238/5000
 - 1s - loss: 0.3802 - val_loss: 0.3133
Epoch 1239/5000
 - 1s - loss: 0.3801 - val_loss: 0.3133
Epoch 1240/5000
 - 1s - loss: 0.3800 - val_loss: 0.3132
Epoch 1241/5000
 - 1s - loss: 0.3799 - val_loss: 0.3132
Epoch 1242/5000
 - 1s - loss: 0.3798 - val_loss: 0.3131
Epoch 1243/5000
 - 1s - loss: 0.3768 - val_loss: 0.3131
Epoch 1244/5000
 - 1s - loss: 0.3768 - val_loss: 0.3131
Epoch 1245/5000
 - 1s - loss: 0.3768 - val_loss: 0.3132
Epoch 1246/5000
 - 1s - loss: 0.3768 - val_loss: 0.3132
Epoch 1247/5000
 - 1s - loss: 0.3765 - val_loss: 0.3132
setting environment to train mode..... 

Training Started... 

------------------------------------
| approxkl           | 0.039464924 |
| clipfrac           | 0.23828125  |
| explained_variance | -0.00111    |
| fps                | 2           |
| n_updates          | 1           |
| policy_entropy     | -0.6059531  |
| policy_loss        | 0.012119308 |
| serial_timesteps   | 128         |
| time_elapsed       | 1.17e-05    |
| total_timesteps    | 128         |
| value_loss         | 2.8835855   |
------------------------------------
-------------------------------------
| approxkl           | 0.01263684   |
| clipfrac           | 0.1875       |
| explained_variance | -1.23e-05    |
| fps                | 19           |
| n_updates          | 2            |
| policy_entropy     | -0.6059462   |
| policy_loss        | -0.011117136 |
| serial_timesteps   | 256          |
| time_elapsed       | 49.2         |
| total_timesteps    | 256          |
| value_loss         | 2.4358237    |
-------------------------------------
------------------------------------
| approxkl           | 0.01019122  |
| clipfrac           | 0.1328125   |
| explained_variance | -0.00158    |
| fps                | 20          |
| n_updates          | 3           |
| policy_entropy     | -0.60563415 |
| policy_loss        | 0.00915612  |
| serial_timesteps   | 384         |
| time_elapsed       | 55.6        |
| total_timesteps    | 384         |
| value_loss         | 12.218797   |
------------------------------------
------------------------------------
| approxkl           | 0.007516999 |
| clipfrac           | 0.1015625   |
| explained_variance | 0.00181     |
| fps                | 20          |
| n_updates          | 4           |
| policy_entropy     | -0.6059751  |
| policy_loss        | 0.005824439 |
| serial_timesteps   | 512         |
| time_elapsed       | 61.8        |
| total_timesteps    | 512         |
| value_loss         | 13.0160675  |
------------------------------------
------------------------------------
| approxkl           | 0.021800494 |
| clipfrac           | 0.30273438  |
| explained_variance | 0.00361     |
| fps                | 20          |
| n_updates          | 5           |
| policy_entropy     | -0.6061428  |
| policy_loss        | 0.012937158 |
| serial_timesteps   | 640         |
| time_elapsed       | 68.1        |
| total_timesteps    | 640         |
| value_loss         | 6.54694     |
------------------------------------
An average of 269.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.009802278 |
| clipfrac           | 0.099609375 |
| explained_variance | 0.00261     |
| fps                | 20          |
| n_updates          | 6           |
| policy_entropy     | -0.60634476 |
| policy_loss        | 0.002056156 |
| serial_timesteps   | 768         |
| time_elapsed       | 74.4        |
| total_timesteps    | 768         |
| value_loss         | 9.671013    |
------------------------------------
--------------------------------------
| approxkl           | 0.017146846   |
| clipfrac           | 0.1875        |
| explained_variance | 0.00251       |
| fps                | 21            |
| n_updates          | 7             |
| policy_entropy     | -0.60689175   |
| policy_loss        | -0.0028122333 |
| serial_timesteps   | 896           |
| time_elapsed       | 80.7          |
| total_timesteps    | 896           |
| value_loss         | 2.8476326     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0072370614  |
| clipfrac           | 0.08984375    |
| explained_variance | 0.00946       |
| fps                | 21            |
| n_updates          | 8             |
| policy_entropy     | -0.6079785    |
| policy_loss        | -0.0048292344 |
| serial_timesteps   | 1024          |
| time_elapsed       | 86.7          |
| total_timesteps    | 1024          |
| value_loss         | 29.787998     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0054119923 |
| clipfrac           | 0.0625       |
| explained_variance | 0.02         |
| fps                | 21           |
| n_updates          | 9            |
| policy_entropy     | -0.6081868   |
| policy_loss        | 0.0010636728 |
| serial_timesteps   | 1152         |
| time_elapsed       | 92.7         |
| total_timesteps    | 1152         |
| value_loss         | 83.57213     |
-------------------------------------
------------------------------------
| approxkl           | 0.016362222 |
| clipfrac           | 0.1953125   |
| explained_variance | 0.0346      |
| fps                | 22          |
| n_updates          | 10          |
| policy_entropy     | -0.607985   |
| policy_loss        | 0.004231264 |
| serial_timesteps   | 1280        |
| time_elapsed       | 98.6        |
| total_timesteps    | 1280        |
| value_loss         | 11.647793   |
------------------------------------
-------------------------------------
| approxkl           | 0.017477758  |
| clipfrac           | 0.22265625   |
| explained_variance | -0.00556     |
| fps                | 21           |
| n_updates          | 11           |
| policy_entropy     | -0.60696054  |
| policy_loss        | -0.021477172 |
| serial_timesteps   | 1408         |
| time_elapsed       | 104          |
| total_timesteps    | 1408         |
| value_loss         | 6.4559026    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007674206  |
| clipfrac           | 0.123046875  |
| explained_variance | 0.138        |
| fps                | 20           |
| n_updates          | 12           |
| policy_entropy     | -0.60566205  |
| policy_loss        | 0.0043713963 |
| serial_timesteps   | 1536         |
| time_elapsed       | 110          |
| total_timesteps    | 1536         |
| value_loss         | 4.5592184    |
-------------------------------------
An average of 270.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.03717959   |
| clipfrac           | 0.328125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 0.000501     |
| fps                | 20           |
| n_updates          | 13           |
| policy_entropy     | -0.60534906  |
| policy_loss        | 0.0029081579 |
| serial_timesteps   | 1664         |
| time_elapsed       | 116          |
| total_timesteps    | 1664         |
| value_loss         | 4238.352     |
-------------------------------------
--------------------------------------
| approxkl           | 0.017033432   |
| clipfrac           | 0.23242188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | 0.0624        |
| fps                | 22            |
| n_updates          | 14            |
| policy_entropy     | -0.6056242    |
| policy_loss        | -0.0087233465 |
| serial_timesteps   | 1792          |
| time_elapsed       | 123           |
| total_timesteps    | 1792          |
| value_loss         | 3.4974086     |
--------------------------------------
------------------------------------
| approxkl           | 0.008500362 |
| clipfrac           | 0.11328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | 0.159       |
| fps                | 21          |
| n_updates          | 15          |
| policy_entropy     | -0.6064755  |
| policy_loss        | 0.011140244 |
| serial_timesteps   | 1920        |
| time_elapsed       | 129         |
| total_timesteps    | 1920        |
| value_loss         | 2.7429247   |
------------------------------------
--------------------------------------
| approxkl           | 0.008675778   |
| clipfrac           | 0.109375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | -0.467        |
| fps                | 22            |
| n_updates          | 16            |
| policy_entropy     | -0.6086984    |
| policy_loss        | -0.0012635048 |
| serial_timesteps   | 2048          |
| time_elapsed       | 134           |
| total_timesteps    | 2048          |
| value_loss         | 3.1735616     |
--------------------------------------
------------------------------------
| approxkl           | 0.010732406 |
| clipfrac           | 0.14257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -0.047      |
| fps                | 21          |
| n_updates          | 17          |
| policy_entropy     | -0.6121018  |
| policy_loss        | 0.009411364 |
| serial_timesteps   | 2176        |
| time_elapsed       | 140         |
| total_timesteps    | 2176        |
| value_loss         | 5.530014    |
------------------------------------
-------------------------------------
| approxkl           | 0.008505805  |
| clipfrac           | 0.107421875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | -0.00653     |
| fps                | 19           |
| n_updates          | 18           |
| policy_entropy     | -0.6149946   |
| policy_loss        | 0.0093786605 |
| serial_timesteps   | 2304         |
| time_elapsed       | 146          |
| total_timesteps    | 2304         |
| value_loss         | 4.2764854    |
-------------------------------------
-------------------------------------
| approxkl           | 0.013126501  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 0.000574     |
| fps                | 19           |
| n_updates          | 19           |
| policy_entropy     | -0.6153984   |
| policy_loss        | -0.008151064 |
| serial_timesteps   | 2432         |
| time_elapsed       | 153          |
| total_timesteps    | 2432         |
| value_loss         | 6.7747736    |
-------------------------------------
------------------------------------
| approxkl           | 0.014503934 |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.77e+03    |
| explained_variance | -0.00183    |
| fps                | 19          |
| n_updates          | 20          |
| policy_entropy     | -0.61626756 |
| policy_loss        | 0.024270173 |
| serial_timesteps   | 2560        |
| time_elapsed       | 159         |
| total_timesteps    | 2560        |
| value_loss         | 5.383763    |
------------------------------------
An average of 270.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.008662585   |
| clipfrac           | 0.095703125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | -0.00501      |
| fps                | 22            |
| n_updates          | 21            |
| policy_entropy     | -0.6177897    |
| policy_loss        | -0.0024611005 |
| serial_timesteps   | 2688          |
| time_elapsed       | 166           |
| total_timesteps    | 2688          |
| value_loss         | 25.416702     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0046674157 |
| clipfrac           | 0.068359375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 0.00564      |
| fps                | 20           |
| n_updates          | 22           |
| policy_entropy     | -0.61769414  |
| policy_loss        | 0.0074238284 |
| serial_timesteps   | 2816         |
| time_elapsed       | 172          |
| total_timesteps    | 2816         |
| value_loss         | 11.955843    |
-------------------------------------
--------------------------------------
| approxkl           | 0.014642911   |
| clipfrac           | 0.21289062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.77e+03      |
| explained_variance | 0.00891       |
| fps                | 20            |
| n_updates          | 23            |
| policy_entropy     | -0.6165303    |
| policy_loss        | -0.0031683824 |
| serial_timesteps   | 2944          |
| time_elapsed       | 178           |
| total_timesteps    | 2944          |
| value_loss         | 6.5255475     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0128029175 |
| clipfrac           | 0.14648438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.77e+03     |
| explained_variance | 0.00685      |
| fps                | 21           |
| n_updates          | 24           |
| policy_entropy     | -0.6144762   |
| policy_loss        | 0.0035007158 |
| serial_timesteps   | 3072         |
| time_elapsed       | 184          |
| total_timesteps    | 3072         |
| value_loss         | 15.612301    |
-------------------------------------
------------------------------------
| approxkl           | 0.034574337 |
| clipfrac           | 0.39453125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.9e+03     |
| explained_variance | -0.000286   |
| fps                | 20          |
| n_updates          | 25          |
| policy_entropy     | -0.61295986 |
| policy_loss        | 0.012750096 |
| serial_timesteps   | 3200        |
| time_elapsed       | 190         |
| total_timesteps    | 3200        |
| value_loss         | 5726.499    |
------------------------------------
-------------------------------------
| approxkl           | 0.020093478  |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 0.00148      |
| fps                | 21           |
| n_updates          | 26           |
| policy_entropy     | -0.6121901   |
| policy_loss        | -0.020660881 |
| serial_timesteps   | 3328         |
| time_elapsed       | 196          |
| total_timesteps    | 3328         |
| value_loss         | 8.956166     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0044959625  |
| clipfrac           | 0.060546875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.9e+03       |
| explained_variance | 0.0564        |
| fps                | 21            |
| n_updates          | 27            |
| policy_entropy     | -0.6113272    |
| policy_loss        | -0.0030861285 |
| serial_timesteps   | 3456          |
| time_elapsed       | 202           |
| total_timesteps    | 3456          |
| value_loss         | 105.98834     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0194085    |
| clipfrac           | 0.20703125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 0.0223       |
| fps                | 21           |
| n_updates          | 28           |
| policy_entropy     | -0.6120074   |
| policy_loss        | 0.0057146233 |
| serial_timesteps   | 3584         |
| time_elapsed       | 208          |
| total_timesteps    | 3584         |
| value_loss         | 7.336857     |
-------------------------------------
An average of 271.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.017167473 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.9e+03     |
| explained_variance | 0.0685      |
| fps                | 21          |
| n_updates          | 29          |
| policy_entropy     | -0.6137821  |
| policy_loss        | 0.013363175 |
| serial_timesteps   | 3712        |
| time_elapsed       | 214         |
| total_timesteps    | 3712        |
| value_loss         | 5.904089    |
------------------------------------
-------------------------------------
| approxkl           | 0.022604845  |
| clipfrac           | 0.2578125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 0.362        |
| fps                | 22           |
| n_updates          | 30           |
| policy_entropy     | -0.61518353  |
| policy_loss        | 0.0024984751 |
| serial_timesteps   | 3840         |
| time_elapsed       | 220          |
| total_timesteps    | 3840         |
| value_loss         | 2.7586937    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0131898625 |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | -1.1         |
| fps                | 21           |
| n_updates          | 31           |
| policy_entropy     | -0.6163139   |
| policy_loss        | 0.0070314133 |
| serial_timesteps   | 3968         |
| time_elapsed       | 226          |
| total_timesteps    | 3968         |
| value_loss         | 2.683487     |
-------------------------------------
--------------------------------------
| approxkl           | 0.014324246   |
| clipfrac           | 0.16992188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.9e+03       |
| explained_variance | -0.0943       |
| fps                | 20            |
| n_updates          | 32            |
| policy_entropy     | -0.6172739    |
| policy_loss        | -0.0036345574 |
| serial_timesteps   | 4096          |
| time_elapsed       | 232           |
| total_timesteps    | 4096          |
| value_loss         | 2.4392674     |
--------------------------------------
------------------------------------
| approxkl           | 0.010139661 |
| clipfrac           | 0.13867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.9e+03     |
| explained_variance | 0.116       |
| fps                | 22          |
| n_updates          | 33          |
| policy_entropy     | -0.6165892  |
| policy_loss        | 0.009401944 |
| serial_timesteps   | 4224        |
| time_elapsed       | 238         |
| total_timesteps    | 4224        |
| value_loss         | 3.65135     |
------------------------------------
-------------------------------------
| approxkl           | 0.012683937  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | 0.000384     |
| fps                | 22           |
| n_updates          | 34           |
| policy_entropy     | -0.61831063  |
| policy_loss        | -0.004909721 |
| serial_timesteps   | 4352         |
| time_elapsed       | 244          |
| total_timesteps    | 4352         |
| value_loss         | 1.4722455    |
-------------------------------------
-----------------------------------
| approxkl           | 0.06630074 |
| clipfrac           | 0.45898438 |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 6.9e+03    |
| explained_variance | -0.0476    |
| fps                | 21         |
| n_updates          | 35         |
| policy_entropy     | -0.6195769 |
| policy_loss        | 0.01782733 |
| serial_timesteps   | 4480       |
| time_elapsed       | 249        |
| total_timesteps    | 4480       |
| value_loss         | 7.774168   |
-----------------------------------
-------------------------------------
| approxkl           | 0.027192725  |
| clipfrac           | 0.28320312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.9e+03      |
| explained_variance | -0.00573     |
| fps                | 19           |
| n_updates          | 36           |
| policy_entropy     | -0.6185191   |
| policy_loss        | 0.0139067415 |
| serial_timesteps   | 4608         |
| time_elapsed       | 255          |
| total_timesteps    | 4608         |
| value_loss         | 12.12685     |
-------------------------------------
An average of 272.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.023153415 |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.000114    |
| fps                | 19          |
| n_updates          | 37          |
| policy_entropy     | -0.61797744 |
| policy_loss        | 0.01670452  |
| serial_timesteps   | 4736        |
| time_elapsed       | 262         |
| total_timesteps    | 4736        |
| value_loss         | 6398.6924   |
------------------------------------
------------------------------------
| approxkl           | 0.007886277 |
| clipfrac           | 0.111328125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.000229   |
| fps                | 20          |
| n_updates          | 38          |
| policy_entropy     | -0.61821395 |
| policy_loss        | -0.0080777  |
| serial_timesteps   | 4864        |
| time_elapsed       | 268         |
| total_timesteps    | 4864        |
| value_loss         | 8.145595    |
------------------------------------
--------------------------------------
| approxkl           | 0.0046970453  |
| clipfrac           | 0.072265625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | -0.002        |
| fps                | 20            |
| n_updates          | 39            |
| policy_entropy     | -0.61885065   |
| policy_loss        | -0.0034676949 |
| serial_timesteps   | 4992          |
| time_elapsed       | 275           |
| total_timesteps    | 4992          |
| value_loss         | 20.309303     |
--------------------------------------
--------------------------------------
| approxkl           | 0.014496415   |
| clipfrac           | 0.16992188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.00423       |
| fps                | 20            |
| n_updates          | 40            |
| policy_entropy     | -0.61807555   |
| policy_loss        | -0.0026386757 |
| serial_timesteps   | 5120          |
| time_elapsed       | 281           |
| total_timesteps    | 5120          |
| value_loss         | 10.18694      |
--------------------------------------
-------------------------------------
| approxkl           | 0.012440897  |
| clipfrac           | 0.17773438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.0103       |
| fps                | 19           |
| n_updates          | 41           |
| policy_entropy     | -0.6144054   |
| policy_loss        | 0.0056774556 |
| serial_timesteps   | 5248         |
| time_elapsed       | 287          |
| total_timesteps    | 5248         |
| value_loss         | 5.143141     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0063587585 |
| clipfrac           | 0.08984375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.0076       |
| fps                | 21           |
| n_updates          | 42           |
| policy_entropy     | -0.6126985   |
| policy_loss        | 0.0072574867 |
| serial_timesteps   | 5376         |
| time_elapsed       | 293          |
| total_timesteps    | 5376         |
| value_loss         | 18.21804     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0043570884 |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.0213       |
| fps                | 21           |
| n_updates          | 43           |
| policy_entropy     | -0.612298    |
| policy_loss        | 0.00590348   |
| serial_timesteps   | 5504         |
| time_elapsed       | 299          |
| total_timesteps    | 5504         |
| value_loss         | 3.701558     |
-------------------------------------
---------------------------------------
| approxkl           | 0.0074494155   |
| clipfrac           | 0.099609375    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.88e+03       |
| explained_variance | 0.00262        |
| fps                | 21             |
| n_updates          | 44             |
| policy_entropy     | -0.6129647     |
| policy_loss        | -0.00023228396 |
| serial_timesteps   | 5632           |
| time_elapsed       | 305            |
| total_timesteps    | 5632           |
| value_loss         | 11.158219      |
---------------------------------------
An average of 272.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.012017584  |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -0.00467     |
| fps                | 22           |
| n_updates          | 45           |
| policy_entropy     | -0.6138178   |
| policy_loss        | -0.019299768 |
| serial_timesteps   | 5760         |
| time_elapsed       | 311          |
| total_timesteps    | 5760         |
| value_loss         | 128.47472    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0117829945   |
| clipfrac           | 0.16210938     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.88e+03       |
| explained_variance | 0.113          |
| fps                | 20             |
| n_updates          | 46             |
| policy_entropy     | -0.614001      |
| policy_loss        | -0.00038271374 |
| serial_timesteps   | 5888           |
| time_elapsed       | 317            |
| total_timesteps    | 5888           |
| value_loss         | 12.381339      |
---------------------------------------
------------------------------------
| approxkl           | 0.019210257 |
| clipfrac           | 0.2734375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.194       |
| fps                | 22          |
| n_updates          | 47          |
| policy_entropy     | -0.6126044  |
| policy_loss        | 0.021120586 |
| serial_timesteps   | 6016        |
| time_elapsed       | 323         |
| total_timesteps    | 6016        |
| value_loss         | 14.916583   |
------------------------------------
------------------------------------
| approxkl           | 0.0171468   |
| clipfrac           | 0.20703125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.221       |
| fps                | 23          |
| n_updates          | 48          |
| policy_entropy     | -0.6122059  |
| policy_loss        | 0.007823564 |
| serial_timesteps   | 6144        |
| time_elapsed       | 329         |
| total_timesteps    | 6144        |
| value_loss         | 5.1778092   |
------------------------------------
--------------------------------------
| approxkl           | 0.010446816   |
| clipfrac           | 0.15625       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.85e+03      |
| explained_variance | -0.00421      |
| fps                | 21            |
| n_updates          | 49            |
| policy_entropy     | -0.6126923    |
| policy_loss        | -0.0040852493 |
| serial_timesteps   | 6272          |
| time_elapsed       | 334           |
| total_timesteps    | 6272          |
| value_loss         | 6540.98       |
--------------------------------------
-------------------------------------
| approxkl           | 0.00291883   |
| clipfrac           | 0.0234375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.85e+03     |
| explained_variance | -0.835       |
| fps                | 20           |
| n_updates          | 50           |
| policy_entropy     | -0.61335146  |
| policy_loss        | 0.0008368321 |
| serial_timesteps   | 6400         |
| time_elapsed       | 340          |
| total_timesteps    | 6400         |
| value_loss         | 3.673762     |
-------------------------------------
--------------------------------------
| approxkl           | 0.012628559   |
| clipfrac           | 0.171875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.85e+03      |
| explained_variance | 0.291         |
| fps                | 21            |
| n_updates          | 51            |
| policy_entropy     | -0.6164065    |
| policy_loss        | -0.0012816618 |
| serial_timesteps   | 6528          |
| time_elapsed       | 347           |
| total_timesteps    | 6528          |
| value_loss         | 3.36879       |
--------------------------------------
An average of 273.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.031905457   |
| clipfrac           | 0.3125        |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.85e+03      |
| explained_variance | -0.509        |
| fps                | 21            |
| n_updates          | 52            |
| policy_entropy     | -0.61831975   |
| policy_loss        | -0.0068898383 |
| serial_timesteps   | 6656          |
| time_elapsed       | 353           |
| total_timesteps    | 6656          |
| value_loss         | 3.690226      |
--------------------------------------
------------------------------------
| approxkl           | 0.021443196 |
| clipfrac           | 0.25        |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.85e+03    |
| explained_variance | -0.123      |
| fps                | 21          |
| n_updates          | 53          |
| policy_entropy     | -0.6193349  |
| policy_loss        | 0.023434024 |
| serial_timesteps   | 6784        |
| time_elapsed       | 359         |
| total_timesteps    | 6784        |
| value_loss         | 3.4714642   |
------------------------------------
-------------------------------------
| approxkl           | 0.0059816535 |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.85e+03     |
| explained_variance | -0.0174      |
| fps                | 19           |
| n_updates          | 54           |
| policy_entropy     | -0.6201253   |
| policy_loss        | 0.0012554605 |
| serial_timesteps   | 6912         |
| time_elapsed       | 364          |
| total_timesteps    | 6912         |
| value_loss         | 6.0207644    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0034517406 |
| clipfrac           | 0.03125      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.85e+03     |
| explained_variance | -0.00941     |
| fps                | 19           |
| n_updates          | 55           |
| policy_entropy     | -0.6200673   |
| policy_loss        | 0.0026335248 |
| serial_timesteps   | 7040         |
| time_elapsed       | 371          |
| total_timesteps    | 7040         |
| value_loss         | 3.970709     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0051063052 |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.85e+03     |
| explained_variance | -0.00427     |
| fps                | 19           |
| n_updates          | 56           |
| policy_entropy     | -0.61992246  |
| policy_loss        | 0.0033918126 |
| serial_timesteps   | 7168         |
| time_elapsed       | 378          |
| total_timesteps    | 7168         |
| value_loss         | 2.3837402    |
-------------------------------------
------------------------------------
| approxkl           | 0.011636938 |
| clipfrac           | 0.15039062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.85e+03    |
| explained_variance | -0.00111    |
| fps                | 21          |
| n_updates          | 57          |
| policy_entropy     | -0.6200558  |
| policy_loss        | 0.006559402 |
| serial_timesteps   | 7296        |
| time_elapsed       | 384         |
| total_timesteps    | 7296        |
| value_loss         | 27.37121    |
------------------------------------
--------------------------------------
| approxkl           | 0.017007932   |
| clipfrac           | 0.23242188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.85e+03      |
| explained_variance | 0.0058        |
| fps                | 21            |
| n_updates          | 58            |
| policy_entropy     | -0.62017864   |
| policy_loss        | -0.0069628283 |
| serial_timesteps   | 7424          |
| time_elapsed       | 390           |
| total_timesteps    | 7424          |
| value_loss         | 12.935679     |
--------------------------------------
------------------------------------
| approxkl           | 0.03081741  |
| clipfrac           | 0.31835938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.85e+03    |
| explained_variance | 0.0209      |
| fps                | 21          |
| n_updates          | 59          |
| policy_entropy     | -0.61918014 |
| policy_loss        | 0.006381739 |
| serial_timesteps   | 7552        |
| time_elapsed       | 396         |
| total_timesteps    | 7552        |
| value_loss         | 5.9758167   |
------------------------------------
An average of 273.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.008553865  |
| clipfrac           | 0.08984375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.85e+03     |
| explained_variance | 0.0135       |
| fps                | 19           |
| n_updates          | 60           |
| policy_entropy     | -0.61616707  |
| policy_loss        | 0.0030130637 |
| serial_timesteps   | 7680         |
| time_elapsed       | 402          |
| total_timesteps    | 7680         |
| value_loss         | 12.711632    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014153035  |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -0.000648    |
| fps                | 22           |
| n_updates          | 61           |
| policy_entropy     | -0.61412597  |
| policy_loss        | 0.0020615251 |
| serial_timesteps   | 7808         |
| time_elapsed       | 409          |
| total_timesteps    | 7808         |
| value_loss         | 6617.3027    |
-------------------------------------
------------------------------------
| approxkl           | 0.018224567 |
| clipfrac           | 0.17382812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.0132      |
| fps                | 21          |
| n_updates          | 62          |
| policy_entropy     | -0.6134069  |
| policy_loss        | 0.015016328 |
| serial_timesteps   | 7936        |
| time_elapsed       | 414         |
| total_timesteps    | 7936        |
| value_loss         | 10.0317955  |
------------------------------------
------------------------------------
| approxkl           | 0.009649647 |
| clipfrac           | 0.14257812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.0754     |
| fps                | 22          |
| n_updates          | 63          |
| policy_entropy     | -0.61396724 |
| policy_loss        | 0.008524992 |
| serial_timesteps   | 8064        |
| time_elapsed       | 420         |
| total_timesteps    | 8064        |
| value_loss         | 76.54746    |
------------------------------------
------------------------------------
| approxkl           | 0.027250957 |
| clipfrac           | 0.25390625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.457       |
| fps                | 22          |
| n_updates          | 64          |
| policy_entropy     | -0.6143388  |
| policy_loss        | 0.014542042 |
| serial_timesteps   | 8192        |
| time_elapsed       | 426         |
| total_timesteps    | 8192        |
| value_loss         | 4.5203595   |
------------------------------------
------------------------------------
| approxkl           | 0.022374514 |
| clipfrac           | 0.26367188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.239       |
| fps                | 20          |
| n_updates          | 65          |
| policy_entropy     | -0.6140731  |
| policy_loss        | 0.011996566 |
| serial_timesteps   | 8320        |
| time_elapsed       | 432         |
| total_timesteps    | 8320        |
| value_loss         | 3.4662676   |
------------------------------------
--------------------------------------
| approxkl           | 0.006377408   |
| clipfrac           | 0.087890625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.124         |
| fps                | 23            |
| n_updates          | 66            |
| policy_entropy     | -0.61455405   |
| policy_loss        | -0.0058699152 |
| serial_timesteps   | 8448          |
| time_elapsed       | 438           |
| total_timesteps    | 8448          |
| value_loss         | 3.5305617     |
--------------------------------------
------------------------------------
| approxkl           | 0.025754098 |
| clipfrac           | 0.234375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.0878     |
| fps                | 21          |
| n_updates          | 67          |
| policy_entropy     | -0.6156756  |
| policy_loss        | 0.019032406 |
| serial_timesteps   | 8576        |
| time_elapsed       | 444         |
| total_timesteps    | 8576        |
| value_loss         | 6.044532    |
------------------------------------
An average of 274.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.008450699  |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.183        |
| fps                | 21           |
| n_updates          | 68           |
| policy_entropy     | -0.6167214   |
| policy_loss        | 0.0015847832 |
| serial_timesteps   | 8704         |
| time_elapsed       | 450          |
| total_timesteps    | 8704         |
| value_loss         | 3.5639408    |
-------------------------------------
-------------------------------------
| approxkl           | 0.021209773  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.229        |
| fps                | 21           |
| n_updates          | 69           |
| policy_entropy     | -0.61724395  |
| policy_loss        | -0.032894023 |
| serial_timesteps   | 8832         |
| time_elapsed       | 456          |
| total_timesteps    | 8832         |
| value_loss         | 0.85172313   |
-------------------------------------
------------------------------------
| approxkl           | 0.027457591 |
| clipfrac           | 0.25976562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.0898     |
| fps                | 21          |
| n_updates          | 70          |
| policy_entropy     | -0.61772907 |
| policy_loss        | 0.023336416 |
| serial_timesteps   | 8960        |
| time_elapsed       | 462         |
| total_timesteps    | 8960        |
| value_loss         | 5.5334215   |
------------------------------------
------------------------------------
| approxkl           | 0.08001248  |
| clipfrac           | 0.35742188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.107      |
| fps                | 22          |
| n_updates          | 71          |
| policy_entropy     | -0.6182458  |
| policy_loss        | 0.013548252 |
| serial_timesteps   | 9088        |
| time_elapsed       | 467         |
| total_timesteps    | 9088        |
| value_loss         | 3.3932528   |
------------------------------------
------------------------------------
| approxkl           | 0.018872855 |
| clipfrac           | 0.21875     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.0125     |
| fps                | 19          |
| n_updates          | 72          |
| policy_entropy     | -0.61776763 |
| policy_loss        | 0.019515876 |
| serial_timesteps   | 9216        |
| time_elapsed       | 473         |
| total_timesteps    | 9216        |
| value_loss         | 6.5012794   |
------------------------------------
------------------------------------
| approxkl           | 0.07913739  |
| clipfrac           | 0.5         |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.000135    |
| fps                | 20          |
| n_updates          | 73          |
| policy_entropy     | -0.61712986 |
| policy_loss        | 0.06238195  |
| serial_timesteps   | 9344        |
| time_elapsed       | 480         |
| total_timesteps    | 9344        |
| value_loss         | 6642.5195   |
------------------------------------
------------------------------------
| approxkl           | 0.033411756 |
| clipfrac           | 0.34765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.0091     |
| fps                | 20          |
| n_updates          | 74          |
| policy_entropy     | -0.61699176 |
| policy_loss        | 0.026467033 |
| serial_timesteps   | 9472        |
| time_elapsed       | 486         |
| total_timesteps    | 9472        |
| value_loss         | 1.4832996   |
------------------------------------
-------------------------------------
| approxkl           | 0.014704292  |
| clipfrac           | 0.1875       |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | -0.00186     |
| fps                | 21           |
| n_updates          | 75           |
| policy_entropy     | -0.6167969   |
| policy_loss        | 0.0050610634 |
| serial_timesteps   | 9600         |
| time_elapsed       | 492          |
| total_timesteps    | 9600         |
| value_loss         | 37.202904    |
-------------------------------------
An average of 275.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
---------------------------------------
| approxkl           | 0.023443265    |
| clipfrac           | 0.265625       |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.88e+03       |
| explained_variance | 0.0228         |
| fps                | 22             |
| n_updates          | 76             |
| policy_entropy     | -0.6165842     |
| policy_loss        | -0.00066396035 |
| serial_timesteps   | 9728           |
| time_elapsed       | 498            |
| total_timesteps    | 9728           |
| value_loss         | 9.315672       |
---------------------------------------
--------------------------------------
| approxkl           | 0.0043911757  |
| clipfrac           | 0.064453125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.0242        |
| fps                | 20            |
| n_updates          | 77            |
| policy_entropy     | -0.6163926    |
| policy_loss        | -0.0029941385 |
| serial_timesteps   | 9856          |
| time_elapsed       | 504           |
| total_timesteps    | 9856          |
| value_loss         | 7.146568      |
--------------------------------------
-------------------------------------
| approxkl           | 0.017914582  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.0193       |
| fps                | 21           |
| n_updates          | 78           |
| policy_entropy     | -0.6164146   |
| policy_loss        | -0.028466286 |
| serial_timesteps   | 9984         |
| time_elapsed       | 510          |
| total_timesteps    | 9984         |
| value_loss         | 11.16473     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0103199     |
| clipfrac           | 0.171875      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.0238        |
| fps                | 20            |
| n_updates          | 79            |
| policy_entropy     | -0.61667436   |
| policy_loss        | -0.0023602406 |
| serial_timesteps   | 10112         |
| time_elapsed       | 516           |
| total_timesteps    | 10112         |
| value_loss         | 3.5407805     |
--------------------------------------
-------------------------------------
| approxkl           | 0.011184695  |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.013        |
| fps                | 20           |
| n_updates          | 80           |
| policy_entropy     | -0.6168323   |
| policy_loss        | 0.0078009116 |
| serial_timesteps   | 10240        |
| time_elapsed       | 523          |
| total_timesteps    | 10240        |
| value_loss         | 5.1716046    |
-------------------------------------
------------------------------------
| approxkl           | 0.012130865 |
| clipfrac           | 0.13867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.0632      |
| fps                | 21          |
| n_updates          | 81          |
| policy_entropy     | -0.61740804 |
| policy_loss        | 0.006027712 |
| serial_timesteps   | 10368       |
| time_elapsed       | 529         |
| total_timesteps    | 10368       |
| value_loss         | 74.49755    |
------------------------------------
------------------------------------
| approxkl           | 0.007249784 |
| clipfrac           | 0.087890625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.265       |
| fps                | 22          |
| n_updates          | 82          |
| policy_entropy     | -0.6182582  |
| policy_loss        | 0.006369186 |
| serial_timesteps   | 10496       |
| time_elapsed       | 535         |
| total_timesteps    | 10496       |
| value_loss         | 13.275339   |
------------------------------------
-------------------------------------
| approxkl           | 0.018705579  |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.16         |
| fps                | 22           |
| n_updates          | 83           |
| policy_entropy     | -0.6180101   |
| policy_loss        | -0.009744691 |
| serial_timesteps   | 10624        |
| time_elapsed       | 540          |
| total_timesteps    | 10624        |
| value_loss         | 11.19949     |
-------------------------------------
An average of 275.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.018577904 |
| clipfrac           | 0.23046875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.131       |
| fps                | 22          |
| n_updates          | 84          |
| policy_entropy     | -0.61776114 |
| policy_loss        | 0.011559211 |
| serial_timesteps   | 10752       |
| time_elapsed       | 546         |
| total_timesteps    | 10752       |
| value_loss         | 2.6483612   |
------------------------------------
------------------------------------
| approxkl           | 0.014355063 |
| clipfrac           | 0.1640625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -0.00665    |
| fps                | 21          |
| n_updates          | 85          |
| policy_entropy     | -0.6194226  |
| policy_loss        | 0.011209437 |
| serial_timesteps   | 10880       |
| time_elapsed       | 552         |
| total_timesteps    | 10880       |
| value_loss         | 6579.9443   |
------------------------------------
-------------------------------------
| approxkl           | 0.011378718  |
| clipfrac           | 0.16015625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.35         |
| fps                | 20           |
| n_updates          | 86           |
| policy_entropy     | -0.62014264  |
| policy_loss        | -0.009922065 |
| serial_timesteps   | 11008        |
| time_elapsed       | 558          |
| total_timesteps    | 11008        |
| value_loss         | 5.221949     |
-------------------------------------
-------------------------------------
| approxkl           | 0.023413066  |
| clipfrac           | 0.27539062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -0.564       |
| fps                | 22           |
| n_updates          | 87           |
| policy_entropy     | -0.62318105  |
| policy_loss        | -0.011265347 |
| serial_timesteps   | 11136        |
| time_elapsed       | 564          |
| total_timesteps    | 11136        |
| value_loss         | 0.89130306   |
-------------------------------------
------------------------------------
| approxkl           | 0.03455039  |
| clipfrac           | 0.37304688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -0.714      |
| fps                | 22          |
| n_updates          | 88          |
| policy_entropy     | -0.6250714  |
| policy_loss        | 0.030442355 |
| serial_timesteps   | 11264       |
| time_elapsed       | 570         |
| total_timesteps    | 11264       |
| value_loss         | 3.121785    |
------------------------------------
-------------------------------------
| approxkl           | 0.022527449  |
| clipfrac           | 0.22851562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.0383       |
| fps                | 21           |
| n_updates          | 89           |
| policy_entropy     | -0.6250164   |
| policy_loss        | -0.015592516 |
| serial_timesteps   | 11392        |
| time_elapsed       | 575          |
| total_timesteps    | 11392        |
| value_loss         | 4.038817     |
-------------------------------------
------------------------------------
| approxkl           | 0.025779342 |
| clipfrac           | 0.27734375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -0.0304     |
| fps                | 20          |
| n_updates          | 90          |
| policy_entropy     | -0.6241274  |
| policy_loss        | 0.013706407 |
| serial_timesteps   | 11520       |
| time_elapsed       | 581         |
| total_timesteps    | 11520       |
| value_loss         | 2.6826854   |
------------------------------------
------------------------------------
| approxkl           | 0.011777891 |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -0.0471     |
| fps                | 19          |
| n_updates          | 91          |
| policy_entropy     | -0.622862   |
| policy_loss        | 0.008661014 |
| serial_timesteps   | 11648       |
| time_elapsed       | 588         |
| total_timesteps    | 11648       |
| value_loss         | 2.162661    |
------------------------------------
An average of 276.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.010162659   |
| clipfrac           | 0.15039062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.87e+03      |
| explained_variance | -0.0218       |
| fps                | 20            |
| n_updates          | 92            |
| policy_entropy     | -0.6233413    |
| policy_loss        | -0.0028620595 |
| serial_timesteps   | 11776         |
| time_elapsed       | 594           |
| total_timesteps    | 11776         |
| value_loss         | 2.4321086     |
--------------------------------------
-------------------------------------
| approxkl           | 0.00952132   |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | -0.00452     |
| fps                | 20           |
| n_updates          | 93           |
| policy_entropy     | -0.62310386  |
| policy_loss        | 0.0021010279 |
| serial_timesteps   | 11904        |
| time_elapsed       | 601          |
| total_timesteps    | 11904        |
| value_loss         | 22.614866    |
-------------------------------------
------------------------------------
| approxkl           | 0.008658264 |
| clipfrac           | 0.123046875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.87e+03    |
| explained_variance | -0.0121     |
| fps                | 21          |
| n_updates          | 94          |
| policy_entropy     | -0.6234482  |
| policy_loss        | 0.008315247 |
| serial_timesteps   | 12032       |
| time_elapsed       | 607         |
| total_timesteps    | 12032       |
| value_loss         | 1.2524815   |
------------------------------------
-------------------------------------
| approxkl           | 0.011407143  |
| clipfrac           | 0.16992188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.0227       |
| fps                | 20           |
| n_updates          | 95           |
| policy_entropy     | -0.626521    |
| policy_loss        | -0.012180132 |
| serial_timesteps   | 12160        |
| time_elapsed       | 613          |
| total_timesteps    | 12160        |
| value_loss         | 11.865627    |
-------------------------------------
-------------------------------------
| approxkl           | 0.017963449  |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.87e+03     |
| explained_variance | 0.0258       |
| fps                | 20           |
| n_updates          | 96           |
| policy_entropy     | -0.6280419   |
| policy_loss        | -0.000968206 |
| serial_timesteps   | 12288        |
| time_elapsed       | 619          |
| total_timesteps    | 12288        |
| value_loss         | 14.91056     |
-------------------------------------
-------------------------------------
| approxkl           | 0.011694159  |
| clipfrac           | 0.18945312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 9.56e-05     |
| fps                | 21           |
| n_updates          | 97           |
| policy_entropy     | -0.6275888   |
| policy_loss        | 0.0009147725 |
| serial_timesteps   | 12416        |
| time_elapsed       | 625          |
| total_timesteps    | 12416        |
| value_loss         | 6680.2065    |
-------------------------------------
--------------------------------------
| approxkl           | 0.024142157   |
| clipfrac           | 0.21875       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.0405        |
| fps                | 22            |
| n_updates          | 98            |
| policy_entropy     | -0.6280294    |
| policy_loss        | -0.0065592164 |
| serial_timesteps   | 12544         |
| time_elapsed       | 631           |
| total_timesteps    | 12544         |
| value_loss         | 2.2737677     |
--------------------------------------
An average of 277.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.019453758 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.00982    |
| fps                | 22          |
| n_updates          | 99          |
| policy_entropy     | -0.6278074  |
| policy_loss        | 0.015197836 |
| serial_timesteps   | 12672       |
| time_elapsed       | 637         |
| total_timesteps    | 12672       |
| value_loss         | 69.352554   |
------------------------------------
-------------------------------------
| approxkl           | 0.008004722  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.213        |
| fps                | 22           |
| n_updates          | 100          |
| policy_entropy     | -0.6280987   |
| policy_loss        | 0.0056808507 |
| serial_timesteps   | 12800        |
| time_elapsed       | 642          |
| total_timesteps    | 12800        |
| value_loss         | 10.599239    |
-------------------------------------
------------------------------------
| approxkl           | 0.031943124 |
| clipfrac           | 0.3359375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.23        |
| fps                | 22          |
| n_updates          | 101         |
| policy_entropy     | -0.6290277  |
| policy_loss        | 0.027460307 |
| serial_timesteps   | 12928       |
| time_elapsed       | 648         |
| total_timesteps    | 12928       |
| value_loss         | 3.5524845   |
------------------------------------
-------------------------------------
| approxkl           | 0.0008832398 |
| clipfrac           | 0.00390625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.156        |
| fps                | 23           |
| n_updates          | 102          |
| policy_entropy     | -0.63021487  |
| policy_loss        | 0.0024676833 |
| serial_timesteps   | 13056        |
| time_elapsed       | 654          |
| total_timesteps    | 13056        |
| value_loss         | 2.3433437    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008827728  |
| clipfrac           | 0.1171875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.88e+03     |
| explained_variance | 0.0174       |
| fps                | 20           |
| n_updates          | 103          |
| policy_entropy     | -0.63132536  |
| policy_loss        | 0.0044693113 |
| serial_timesteps   | 13184        |
| time_elapsed       | 659          |
| total_timesteps    | 13184        |
| value_loss         | 6.651452     |
-------------------------------------
------------------------------------
| approxkl           | 0.03127878  |
| clipfrac           | 0.34375     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | 0.0989      |
| fps                | 20          |
| n_updates          | 104         |
| policy_entropy     | -0.6326072  |
| policy_loss        | 0.021901289 |
| serial_timesteps   | 13312       |
| time_elapsed       | 666         |
| total_timesteps    | 13312       |
| value_loss         | 4.117472    |
------------------------------------
--------------------------------------
| approxkl           | 0.024506846   |
| clipfrac           | 0.23828125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.166         |
| fps                | 22            |
| n_updates          | 105           |
| policy_entropy     | -0.6338769    |
| policy_loss        | 0.00033377577 |
| serial_timesteps   | 13440         |
| time_elapsed       | 672           |
| total_timesteps    | 13440         |
| value_loss         | 1.2453356     |
--------------------------------------
--------------------------------------
| approxkl           | 0.005409024   |
| clipfrac           | 0.07421875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.304         |
| fps                | 22            |
| n_updates          | 106           |
| policy_entropy     | -0.6346447    |
| policy_loss        | 0.00091784797 |
| serial_timesteps   | 13568         |
| time_elapsed       | 678           |
| total_timesteps    | 13568         |
| value_loss         | 4.045673      |
--------------------------------------
An average of 277.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.011766365   |
| clipfrac           | 0.15429688    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.88e+03      |
| explained_variance | 0.063         |
| fps                | 22            |
| n_updates          | 107           |
| policy_entropy     | -0.6354405    |
| policy_loss        | -0.0046460405 |
| serial_timesteps   | 13696         |
| time_elapsed       | 683           |
| total_timesteps    | 13696         |
| value_loss         | 3.0075586     |
--------------------------------------
------------------------------------
| approxkl           | 0.012512998 |
| clipfrac           | 0.1875      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.88e+03    |
| explained_variance | -0.0128     |
| fps                | 20          |
| n_updates          | 108         |
| policy_entropy     | -0.6358926  |
| policy_loss        | 0.021445645 |
| serial_timesteps   | 13824       |
| time_elapsed       | 689         |
| total_timesteps    | 13824       |
| value_loss         | 4.03657     |
------------------------------------
------------------------------------
| approxkl           | 0.029258335 |
| clipfrac           | 0.35351562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 5.64e-05    |
| fps                | 20          |
| n_updates          | 109         |
| policy_entropy     | -0.6360451  |
| policy_loss        | 0.027360389 |
| serial_timesteps   | 13952       |
| time_elapsed       | 695         |
| total_timesteps    | 13952       |
| value_loss         | 6654.687    |
------------------------------------
------------------------------------
| approxkl           | 0.0556878   |
| clipfrac           | 0.47851562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | -0.0121     |
| fps                | 20          |
| n_updates          | 110         |
| policy_entropy     | -0.6359388  |
| policy_loss        | 0.041989516 |
| serial_timesteps   | 14080       |
| time_elapsed       | 702         |
| total_timesteps    | 14080       |
| value_loss         | 1.9650854   |
------------------------------------
------------------------------------
| approxkl           | 0.07802464  |
| clipfrac           | 0.40820312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 0.00433     |
| fps                | 20          |
| n_updates          | 111         |
| policy_entropy     | -0.63538134 |
| policy_loss        | 0.038642433 |
| serial_timesteps   | 14208       |
| time_elapsed       | 708         |
| total_timesteps    | 14208       |
| value_loss         | 21.578135   |
------------------------------------
-------------------------------------
| approxkl           | 0.02238803   |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | -0.0314      |
| fps                | 21           |
| n_updates          | 112          |
| policy_entropy     | -0.63484573  |
| policy_loss        | 0.0035769641 |
| serial_timesteps   | 14336        |
| time_elapsed       | 714          |
| total_timesteps    | 14336        |
| value_loss         | 0.94394106   |
-------------------------------------
------------------------------------
| approxkl           | 0.012143588 |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 0.0151      |
| fps                | 20          |
| n_updates          | 113         |
| policy_entropy     | -0.63522875 |
| policy_loss        | 0.009055337 |
| serial_timesteps   | 14464       |
| time_elapsed       | 720         |
| total_timesteps    | 14464       |
| value_loss         | 12.184536   |
------------------------------------
-------------------------------------
| approxkl           | 0.026033297  |
| clipfrac           | 0.26953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.89e+03     |
| explained_variance | 0.0135       |
| fps                | 19           |
| n_updates          | 114          |
| policy_entropy     | -0.63599473  |
| policy_loss        | -0.008845121 |
| serial_timesteps   | 14592        |
| time_elapsed       | 726          |
| total_timesteps    | 14592        |
| value_loss         | 12.481386    |
-------------------------------------
An average of 278.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01433245  |
| clipfrac           | 0.15039062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 0.031       |
| fps                | 21          |
| n_updates          | 115         |
| policy_entropy     | -0.63667774 |
| policy_loss        | 0.007615369 |
| serial_timesteps   | 14720       |
| time_elapsed       | 733         |
| total_timesteps    | 14720       |
| value_loss         | 5.7744913   |
------------------------------------
------------------------------------
| approxkl           | 0.03410179  |
| clipfrac           | 0.36132812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 0.0444      |
| fps                | 21          |
| n_updates          | 116         |
| policy_entropy     | -0.63783866 |
| policy_loss        | 0.03072108  |
| serial_timesteps   | 14848       |
| time_elapsed       | 739         |
| total_timesteps    | 14848       |
| value_loss         | 5.0357304   |
------------------------------------
------------------------------------
| approxkl           | 0.017112937 |
| clipfrac           | 0.21679688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.89e+03    |
| explained_variance | 0.0723      |
| fps                | 21          |
| n_updates          | 117         |
| policy_entropy     | -0.63802713 |
| policy_loss        | 0.008675397 |
| serial_timesteps   | 14976       |
| time_elapsed       | 745         |
| total_timesteps    | 14976       |
| value_loss         | 58.972404   |
------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3171bb70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b3171bb70>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b30857e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b30857e80>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2615 samples, validate on 137 samples
Epoch 534/5000
 - 10s - loss: 0.0706 - val_loss: 0.0388
Epoch 535/5000
 - 1s - loss: 0.0175 - val_loss: 0.0262
Epoch 536/5000
 - 1s - loss: 0.0121 - val_loss: 0.0171
Epoch 537/5000
 - 1s - loss: 0.0090 - val_loss: 0.0093
Epoch 538/5000
 - 1s - loss: 0.0076 - val_loss: 0.0106
Epoch 539/5000
 - 1s - loss: 0.0071 - val_loss: 0.0089
Epoch 540/5000
 - 1s - loss: 0.0069 - val_loss: 0.0114
Epoch 541/5000
 - 1s - loss: 0.0067 - val_loss: 0.0125
Epoch 542/5000
 - 1s - loss: 0.0065 - val_loss: 0.0142
Epoch 543/5000
 - 1s - loss: 0.0064 - val_loss: 0.0146
Epoch 544/5000
 - 1s - loss: 0.0063 - val_loss: 0.0149
Train on 2087 samples, validate on 137 samples
Epoch 403/5000
 - 10s - loss: 0.0101 - val_loss: 0.0510
Epoch 404/5000
 - 1s - loss: 0.0172 - val_loss: 0.0592
Epoch 405/5000
 - 1s - loss: 0.0135 - val_loss: 0.0556
Epoch 406/5000
 - 1s - loss: 0.0110 - val_loss: 0.0580
Epoch 407/5000
 - 1s - loss: 0.0102 - val_loss: 0.0591
Epoch 408/5000
 - 1s - loss: 0.0097 - val_loss: 0.0589
Train on 2709 samples, validate on 137 samples
Epoch 1248/5000
 - 11s - loss: 0.6024 - val_loss: 0.2992
Epoch 1249/5000
 - 1s - loss: 0.5483 - val_loss: 0.2549
Epoch 1250/5000
 - 1s - loss: 0.5461 - val_loss: 0.2533
Epoch 1251/5000
 - 1s - loss: 0.5431 - val_loss: 0.2487
Epoch 1252/5000
 - 1s - loss: 0.5395 - val_loss: 0.2435
Epoch 1253/5000
 - 1s - loss: 0.5344 - val_loss: 0.2364
Epoch 1254/5000
 - 1s - loss: 0.5271 - val_loss: 0.2286
Epoch 1255/5000
 - 1s - loss: 0.5173 - val_loss: 0.2219
Epoch 1256/5000
 - 1s - loss: 0.5056 - val_loss: 0.2189
Epoch 1257/5000
 - 1s - loss: 0.4936 - val_loss: 0.2199
Epoch 1258/5000
 - 1s - loss: 0.4842 - val_loss: 0.2233
Epoch 1259/5000
 - 1s - loss: 0.4631 - val_loss: 0.2113
Epoch 1260/5000
 - 1s - loss: 0.4594 - val_loss: 0.1991
Epoch 1261/5000
 - 1s - loss: 0.4565 - val_loss: 0.1901
Epoch 1262/5000
 - 1s - loss: 0.4541 - val_loss: 0.1834
Epoch 1263/5000
 - 1s - loss: 0.4519 - val_loss: 0.1782
Epoch 1264/5000
 - 1s - loss: 0.4498 - val_loss: 0.1741
Epoch 1265/5000
 - 1s - loss: 0.4478 - val_loss: 0.1707
Epoch 1266/5000
 - 1s - loss: 0.4459 - val_loss: 0.1679
Epoch 1267/5000
 - 1s - loss: 0.4441 - val_loss: 0.1655
Epoch 1268/5000
 - 1s - loss: 0.4424 - val_loss: 0.1634
Epoch 1269/5000
 - 1s - loss: 0.4408 - val_loss: 0.1615
Epoch 1270/5000
 - 1s - loss: 0.4393 - val_loss: 0.1597
Epoch 1271/5000
 - 1s - loss: 0.4379 - val_loss: 0.1581
Epoch 1272/5000
 - 1s - loss: 0.4366 - val_loss: 0.1567
Epoch 1273/5000
 - 1s - loss: 0.4354 - val_loss: 0.1554
Epoch 1274/5000
 - 1s - loss: 0.4343 - val_loss: 0.1543
Epoch 1275/5000
 - 1s - loss: 0.4332 - val_loss: 0.1534
Epoch 1276/5000
 - 1s - loss: 0.4322 - val_loss: 0.1527
Epoch 1277/5000
 - 1s - loss: 0.4313 - val_loss: 0.1522
Epoch 1278/5000
 - 1s - loss: 0.4304 - val_loss: 0.1517
Epoch 1279/5000
 - 1s - loss: 0.4295 - val_loss: 0.1514
Epoch 1280/5000
 - 1s - loss: 0.4288 - val_loss: 0.1511
Epoch 1281/5000
 - 1s - loss: 0.4280 - val_loss: 0.1509
Epoch 1282/5000
 - 1s - loss: 0.4274 - val_loss: 0.1507
Epoch 1283/5000
 - 1s - loss: 0.4268 - val_loss: 0.1507
Epoch 1284/5000
 - 1s - loss: 0.4262 - val_loss: 0.1507
Epoch 1285/5000
 - 1s - loss: 0.4232 - val_loss: 0.1507
Epoch 1286/5000
 - 1s - loss: 0.4231 - val_loss: 0.1507
Epoch 1287/5000
 - 1s - loss: 0.4230 - val_loss: 0.1506
Epoch 1288/5000
 - 1s - loss: 0.4230 - val_loss: 0.1506
Epoch 1289/5000
 - 1s - loss: 0.4229 - val_loss: 0.1506
Epoch 1290/5000
 - 1s - loss: 0.4229 - val_loss: 0.1505
Epoch 1291/5000
 - 1s - loss: 0.4226 - val_loss: 0.1505
Epoch 1292/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1293/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1294/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1295/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1296/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1297/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1298/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1299/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1300/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1301/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1302/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
Epoch 1303/5000
 - 1s - loss: 0.4225 - val_loss: 0.1505
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.0054053846 |
| clipfrac           | 0.064453125  |
| explained_variance | -0.131       |
| fps                | 2            |
| n_updates          | 1            |
| policy_entropy     | -0.6388142   |
| policy_loss        | 0.001963795  |
| serial_timesteps   | 128          |
| time_elapsed       | 1.34e-05     |
| total_timesteps    | 128          |
| value_loss         | 2.9426007    |
-------------------------------------
-------------------------------------
| approxkl           | 0.015676467  |
| clipfrac           | 0.171875     |
| explained_variance | -0.0401      |
| fps                | 19           |
| n_updates          | 2            |
| policy_entropy     | -0.6408487   |
| policy_loss        | 0.0026098834 |
| serial_timesteps   | 256          |
| time_elapsed       | 50.7         |
| total_timesteps    | 256          |
| value_loss         | 5.446355     |
-------------------------------------
-------------------------------------
| approxkl           | 0.00729288   |
| clipfrac           | 0.10546875   |
| explained_variance | -0.179       |
| fps                | 19           |
| n_updates          | 3            |
| policy_entropy     | -0.6419342   |
| policy_loss        | -0.006560474 |
| serial_timesteps   | 384          |
| time_elapsed       | 57.2         |
| total_timesteps    | 384          |
| value_loss         | 4.9554477    |
-------------------------------------
--------------------------------------
| approxkl           | 0.017585903   |
| clipfrac           | 0.19335938    |
| explained_variance | 0.0149        |
| fps                | 18            |
| n_updates          | 4             |
| policy_entropy     | -0.6425294    |
| policy_loss        | -0.0045072567 |
| serial_timesteps   | 512           |
| time_elapsed       | 63.7          |
| total_timesteps    | 512           |
| value_loss         | 2.1697645     |
--------------------------------------
------------------------------------
| approxkl           | 0.010397867 |
| clipfrac           | 0.13671875  |
| explained_variance | -0.0303     |
| fps                | 18          |
| n_updates          | 5           |
| policy_entropy     | -0.6427175  |
| policy_loss        | 0.011065145 |
| serial_timesteps   | 640         |
| time_elapsed       | 70.7        |
| total_timesteps    | 640         |
| value_loss         | 3.9901688   |
------------------------------------
An average of 279.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.017211737  |
| clipfrac           | 0.21679688   |
| explained_variance | 0.0623       |
| fps                | 19           |
| n_updates          | 6            |
| policy_entropy     | -0.64376986  |
| policy_loss        | 0.0041266456 |
| serial_timesteps   | 768          |
| time_elapsed       | 77.7         |
| total_timesteps    | 768          |
| value_loss         | 62.286495    |
-------------------------------------
--------------------------------------
| approxkl           | 0.03519581    |
| clipfrac           | 0.26757812    |
| explained_variance | 0.174         |
| fps                | 20            |
| n_updates          | 7             |
| policy_entropy     | -0.6440226    |
| policy_loss        | -0.0053786254 |
| serial_timesteps   | 896           |
| time_elapsed       | 84.4          |
| total_timesteps    | 896           |
| value_loss         | 15.875755     |
--------------------------------------
--------------------------------------
| approxkl           | 0.010442995   |
| clipfrac           | 0.13085938    |
| explained_variance | 0.09          |
| fps                | 18            |
| n_updates          | 8             |
| policy_entropy     | -0.6434766    |
| policy_loss        | -0.0018768492 |
| serial_timesteps   | 1024          |
| time_elapsed       | 90.8          |
| total_timesteps    | 1024          |
| value_loss         | 2.7947311     |
--------------------------------------
--------------------------------------
| approxkl           | 0.035121143   |
| clipfrac           | 0.3203125     |
| explained_variance | -0.0501       |
| fps                | 19            |
| n_updates          | 9             |
| policy_entropy     | -0.642697     |
| policy_loss        | -0.0049716057 |
| serial_timesteps   | 1152          |
| time_elapsed       | 97.6          |
| total_timesteps    | 1152          |
| value_loss         | 0.95089954    |
--------------------------------------
-------------------------------------
| approxkl           | 0.0067558484 |
| clipfrac           | 0.0703125    |
| explained_variance | -0.383       |
| fps                | 18           |
| n_updates          | 10           |
| policy_entropy     | -0.6420822   |
| policy_loss        | -0.003772268 |
| serial_timesteps   | 1280         |
| time_elapsed       | 104          |
| total_timesteps    | 1280         |
| value_loss         | 4.5805006    |
-------------------------------------
-------------------------------------
| approxkl           | 0.012490691  |
| clipfrac           | 0.1640625    |
| explained_variance | 0.0492       |
| fps                | 19           |
| n_updates          | 11           |
| policy_entropy     | -0.64249194  |
| policy_loss        | -0.008888623 |
| serial_timesteps   | 1408         |
| time_elapsed       | 111          |
| total_timesteps    | 1408         |
| value_loss         | 2.6398447    |
-------------------------------------
--------------------------------------
| approxkl           | 0.02010226    |
| clipfrac           | 0.20507812    |
| explained_variance | -0.267        |
| fps                | 19            |
| n_updates          | 12            |
| policy_entropy     | -0.6441656    |
| policy_loss        | -0.0019369554 |
| serial_timesteps   | 1536          |
| time_elapsed       | 118           |
| total_timesteps    | 1536          |
| value_loss         | 2.3097456     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0043812394 |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -0.000428    |
| fps                | 18           |
| n_updates          | 13           |
| policy_entropy     | -0.6458355   |
| policy_loss        | 0.0042597954 |
| serial_timesteps   | 1664         |
| time_elapsed       | 124          |
| total_timesteps    | 1664         |
| value_loss         | 4182.118     |
-------------------------------------
An average of 280.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.009863969   |
| clipfrac           | 0.1171875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.99e+03      |
| explained_variance | -0.158        |
| fps                | 19            |
| n_updates          | 14            |
| policy_entropy     | -0.6465315    |
| policy_loss        | -0.0061688074 |
| serial_timesteps   | 1792          |
| time_elapsed       | 131           |
| total_timesteps    | 1792          |
| value_loss         | 0.6073674     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0075488347 |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -0.0162      |
| fps                | 18           |
| n_updates          | 15           |
| policy_entropy     | -0.6473568   |
| policy_loss        | 0.0015108677 |
| serial_timesteps   | 1920         |
| time_elapsed       | 138          |
| total_timesteps    | 1920         |
| value_loss         | 1.3166955    |
-------------------------------------
-------------------------------------
| approxkl           | 0.013428983  |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -0.0268      |
| fps                | 19           |
| n_updates          | 16           |
| policy_entropy     | -0.6493423   |
| policy_loss        | -0.006518366 |
| serial_timesteps   | 2048         |
| time_elapsed       | 144          |
| total_timesteps    | 2048         |
| value_loss         | 2.2541695    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0138561195 |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 0.0962       |
| fps                | 19           |
| n_updates          | 17           |
| policy_entropy     | -0.65145946  |
| policy_loss        | 0.0042162486 |
| serial_timesteps   | 2176         |
| time_elapsed       | 151          |
| total_timesteps    | 2176         |
| value_loss         | 0.59656054   |
-------------------------------------
------------------------------------
| approxkl           | 0.027317666 |
| clipfrac           | 0.28515625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -0.0379     |
| fps                | 18          |
| n_updates          | 18          |
| policy_entropy     | -0.65290445 |
| policy_loss        | 0.018359274 |
| serial_timesteps   | 2304        |
| time_elapsed       | 157         |
| total_timesteps    | 2304        |
| value_loss         | 2.2481298   |
------------------------------------
------------------------------------
| approxkl           | 0.007261521 |
| clipfrac           | 0.080078125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -0.0729     |
| fps                | 19          |
| n_updates          | 19          |
| policy_entropy     | -0.6540708  |
| policy_loss        | -0.00891328 |
| serial_timesteps   | 2432        |
| time_elapsed       | 164         |
| total_timesteps    | 2432        |
| value_loss         | 1.6405209   |
------------------------------------
-------------------------------------
| approxkl           | 0.023202635  |
| clipfrac           | 0.26953125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -0.0668      |
| fps                | 20           |
| n_updates          | 20           |
| policy_entropy     | -0.65610623  |
| policy_loss        | -0.014650386 |
| serial_timesteps   | 2560         |
| time_elapsed       | 171          |
| total_timesteps    | 2560         |
| value_loss         | 1.776107     |
-------------------------------------
An average of 280.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.019673966  |
| clipfrac           | 0.19335938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -0.0188      |
| fps                | 18           |
| n_updates          | 21           |
| policy_entropy     | -0.6578382   |
| policy_loss        | -0.011467146 |
| serial_timesteps   | 2688         |
| time_elapsed       | 177          |
| total_timesteps    | 2688         |
| value_loss         | 1.3949608    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0058677867 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 0.0502       |
| fps                | 19           |
| n_updates          | 22           |
| policy_entropy     | -0.65826464  |
| policy_loss        | 0.007588017  |
| serial_timesteps   | 2816         |
| time_elapsed       | 184          |
| total_timesteps    | 2816         |
| value_loss         | 14.761216    |
-------------------------------------
-------------------------------------
| approxkl           | 0.007675684  |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 0.0995       |
| fps                | 19           |
| n_updates          | 23           |
| policy_entropy     | -0.65830946  |
| policy_loss        | 0.0019319123 |
| serial_timesteps   | 2944         |
| time_elapsed       | 190          |
| total_timesteps    | 2944         |
| value_loss         | 39.386536    |
-------------------------------------
--------------------------------------
| approxkl           | 0.02235841    |
| clipfrac           | 0.23828125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.99e+03      |
| explained_variance | 0.0586        |
| fps                | 19            |
| n_updates          | 24            |
| policy_entropy     | -0.66235435   |
| policy_loss        | -0.0030705945 |
| serial_timesteps   | 3072          |
| time_elapsed       | 197           |
| total_timesteps    | 3072          |
| value_loss         | 2.003389      |
--------------------------------------
-------------------------------------
| approxkl           | 0.002552818  |
| clipfrac           | 0.017578125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -0.00152     |
| fps                | 19           |
| n_updates          | 25           |
| policy_entropy     | -0.66450644  |
| policy_loss        | 0.0005252671 |
| serial_timesteps   | 3200         |
| time_elapsed       | 203          |
| total_timesteps    | 3200         |
| value_loss         | 5766.4707    |
-------------------------------------
-------------------------------------
| approxkl           | 0.002961815  |
| clipfrac           | 0.03515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 0.212        |
| fps                | 19           |
| n_updates          | 26           |
| policy_entropy     | -0.66475284  |
| policy_loss        | 0.0011677986 |
| serial_timesteps   | 3328         |
| time_elapsed       | 210          |
| total_timesteps    | 3328         |
| value_loss         | 2.0629315    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0073753204 |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -0.282       |
| fps                | 19           |
| n_updates          | 27           |
| policy_entropy     | -0.6651015   |
| policy_loss        | 0.0015837431 |
| serial_timesteps   | 3456         |
| time_elapsed       | 216          |
| total_timesteps    | 3456         |
| value_loss         | 3.4596782    |
-------------------------------------
------------------------------------
| approxkl           | 0.04713429  |
| clipfrac           | 0.3203125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | -0.185      |
| fps                | 18          |
| n_updates          | 28          |
| policy_entropy     | -0.66548836 |
| policy_loss        | 0.003440443 |
| serial_timesteps   | 3584        |
| time_elapsed       | 223         |
| total_timesteps    | 3584        |
| value_loss         | 0.41705096  |
------------------------------------
An average of 281.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.032887     |
| clipfrac           | 0.31835938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -0.073       |
| fps                | 18           |
| n_updates          | 29           |
| policy_entropy     | -0.66554236  |
| policy_loss        | 0.0027931568 |
| serial_timesteps   | 3712         |
| time_elapsed       | 230          |
| total_timesteps    | 3712         |
| value_loss         | 2.1322067    |
-------------------------------------
-------------------------------------
| approxkl           | 0.036241338  |
| clipfrac           | 0.28515625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -0.0874      |
| fps                | 19           |
| n_updates          | 30           |
| policy_entropy     | -0.66556907  |
| policy_loss        | -0.015269799 |
| serial_timesteps   | 3840         |
| time_elapsed       | 237          |
| total_timesteps    | 3840         |
| value_loss         | 1.4239585    |
-------------------------------------
------------------------------------
| approxkl           | 0.023084817 |
| clipfrac           | 0.28710938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | -0.131      |
| fps                | 18          |
| n_updates          | 31          |
| policy_entropy     | -0.6659644  |
| policy_loss        | 0.011662323 |
| serial_timesteps   | 3968        |
| time_elapsed       | 243         |
| total_timesteps    | 3968        |
| value_loss         | 2.1012273   |
------------------------------------
------------------------------------
| approxkl           | 0.015494612 |
| clipfrac           | 0.18945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | -0.0159     |
| fps                | 19          |
| n_updates          | 32          |
| policy_entropy     | -0.6664897  |
| policy_loss        | 0.006811547 |
| serial_timesteps   | 4096        |
| time_elapsed       | 250         |
| total_timesteps    | 4096        |
| value_loss         | 2.2719312   |
------------------------------------
--------------------------------------
| approxkl           | 0.009183086   |
| clipfrac           | 0.13671875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.97e+03      |
| explained_variance | -0.0073       |
| fps                | 20            |
| n_updates          | 33            |
| policy_entropy     | -0.66730773   |
| policy_loss        | -0.0029567778 |
| serial_timesteps   | 4224          |
| time_elapsed       | 257           |
| total_timesteps    | 4224          |
| value_loss         | 2.1823094     |
--------------------------------------
-------------------------------------
| approxkl           | 0.014035723  |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | 0.0395       |
| fps                | 19           |
| n_updates          | 34           |
| policy_entropy     | -0.668068    |
| policy_loss        | -0.011136479 |
| serial_timesteps   | 4352         |
| time_elapsed       | 263          |
| total_timesteps    | 4352         |
| value_loss         | 0.36562085   |
-------------------------------------
-------------------------------------
| approxkl           | 0.021102266  |
| clipfrac           | 0.21484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.97e+03     |
| explained_variance | -0.0204      |
| fps                | 19           |
| n_updates          | 35           |
| policy_entropy     | -0.6685683   |
| policy_loss        | 0.0021317743 |
| serial_timesteps   | 4480         |
| time_elapsed       | 269          |
| total_timesteps    | 4480         |
| value_loss         | 5.127564     |
-------------------------------------
------------------------------------
| approxkl           | 0.020060893 |
| clipfrac           | 0.24023438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.97e+03    |
| explained_variance | -0.0078     |
| fps                | 19          |
| n_updates          | 36          |
| policy_entropy     | -0.6691156  |
| policy_loss        | 0.010404618 |
| serial_timesteps   | 4608        |
| time_elapsed       | 276         |
| total_timesteps    | 4608        |
| value_loss         | 5.518697    |
------------------------------------
An average of 282.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.048473686 |
| clipfrac           | 0.4609375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | 0.000262    |
| fps                | 20          |
| n_updates          | 37          |
| policy_entropy     | -0.66947305 |
| policy_loss        | 0.01052936  |
| serial_timesteps   | 4736        |
| time_elapsed       | 282         |
| total_timesteps    | 4736        |
| value_loss         | 6363.8574   |
------------------------------------
-------------------------------------
| approxkl           | 0.007975533  |
| clipfrac           | 0.099609375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.0177       |
| fps                | 19           |
| n_updates          | 38           |
| policy_entropy     | -0.6697794   |
| policy_loss        | 0.0033153156 |
| serial_timesteps   | 4864         |
| time_elapsed       | 289          |
| total_timesteps    | 4864         |
| value_loss         | 1.9992088    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0034632043 |
| clipfrac           | 0.037109375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.0591       |
| fps                | 18           |
| n_updates          | 39           |
| policy_entropy     | -0.67054975  |
| policy_loss        | 0.0052032536 |
| serial_timesteps   | 4992         |
| time_elapsed       | 295          |
| total_timesteps    | 4992         |
| value_loss         | 39.59862     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0048977453  |
| clipfrac           | 0.0703125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.01e+03      |
| explained_variance | 0.0579        |
| fps                | 18            |
| n_updates          | 40            |
| policy_entropy     | -0.67127156   |
| policy_loss        | -0.0018248082 |
| serial_timesteps   | 5120          |
| time_elapsed       | 302           |
| total_timesteps    | 5120          |
| value_loss         | 28.271992     |
--------------------------------------
-------------------------------------
| approxkl           | 0.010341585  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.0503       |
| fps                | 19           |
| n_updates          | 41           |
| policy_entropy     | -0.6729221   |
| policy_loss        | 0.0023721685 |
| serial_timesteps   | 5248         |
| time_elapsed       | 309          |
| total_timesteps    | 5248         |
| value_loss         | 8.43244      |
-------------------------------------
-------------------------------------
| approxkl           | 0.013861449  |
| clipfrac           | 0.17382812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.0701       |
| fps                | 20           |
| n_updates          | 42           |
| policy_entropy     | -0.67343485  |
| policy_loss        | -0.016206507 |
| serial_timesteps   | 5376         |
| time_elapsed       | 315          |
| total_timesteps    | 5376         |
| value_loss         | 3.8673968    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008956476  |
| clipfrac           | 0.095703125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.326        |
| fps                | 19           |
| n_updates          | 43           |
| policy_entropy     | -0.6745649   |
| policy_loss        | -0.012053785 |
| serial_timesteps   | 5504         |
| time_elapsed       | 322          |
| total_timesteps    | 5504         |
| value_loss         | 1.523419     |
-------------------------------------
------------------------------------
| approxkl           | 0.030580655 |
| clipfrac           | 0.265625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | 0.0162      |
| fps                | 19          |
| n_updates          | 44          |
| policy_entropy     | -0.6759156  |
| policy_loss        | 0.01600622  |
| serial_timesteps   | 5632        |
| time_elapsed       | 328         |
| total_timesteps    | 5632        |
| value_loss         | 0.68077004  |
------------------------------------
An average of 282.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.017803073 |
| clipfrac           | 0.21875     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.01e+03    |
| explained_variance | -0.333      |
| fps                | 18          |
| n_updates          | 45          |
| policy_entropy     | -0.67824113 |
| policy_loss        | 0.022962028 |
| serial_timesteps   | 5760        |
| time_elapsed       | 335         |
| total_timesteps    | 5760        |
| value_loss         | 3.8212514   |
------------------------------------
-------------------------------------
| approxkl           | 0.027572319  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | 0.0945       |
| fps                | 20           |
| n_updates          | 46           |
| policy_entropy     | -0.67979014  |
| policy_loss        | 0.0009037162 |
| serial_timesteps   | 5888         |
| time_elapsed       | 342          |
| total_timesteps    | 5888         |
| value_loss         | 1.3840361    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014435649  |
| clipfrac           | 0.23046875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | -0.038       |
| fps                | 20           |
| n_updates          | 47           |
| policy_entropy     | -0.6805127   |
| policy_loss        | -0.022470675 |
| serial_timesteps   | 6016         |
| time_elapsed       | 348          |
| total_timesteps    | 6016         |
| value_loss         | 0.34810513   |
-------------------------------------
-------------------------------------
| approxkl           | 0.008074588  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.01e+03     |
| explained_variance | -0.0244      |
| fps                | 19           |
| n_updates          | 48           |
| policy_entropy     | -0.6816767   |
| policy_loss        | 0.0029774937 |
| serial_timesteps   | 6144         |
| time_elapsed       | 354          |
| total_timesteps    | 6144         |
| value_loss         | 2.4354327    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0069591883 |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -0.000167    |
| fps                | 19           |
| n_updates          | 49           |
| policy_entropy     | -0.6831477   |
| policy_loss        | 0.0055042785 |
| serial_timesteps   | 6272         |
| time_elapsed       | 361          |
| total_timesteps    | 6272         |
| value_loss         | 6573.746     |
-------------------------------------
------------------------------------
| approxkl           | 0.010042219 |
| clipfrac           | 0.14648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | 0.00497     |
| fps                | 19          |
| n_updates          | 50          |
| policy_entropy     | -0.6835571  |
| policy_loss        | 0.005447566 |
| serial_timesteps   | 6400        |
| time_elapsed       | 368         |
| total_timesteps    | 6400        |
| value_loss         | 1.7653861   |
------------------------------------
-------------------------------------
| approxkl           | 0.01606415   |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -0.11        |
| fps                | 20           |
| n_updates          | 51           |
| policy_entropy     | -0.6833409   |
| policy_loss        | -0.018361526 |
| serial_timesteps   | 6528         |
| time_elapsed       | 374          |
| total_timesteps    | 6528         |
| value_loss         | 1.7120204    |
-------------------------------------
------------------------------------
| approxkl           | 0.009272001 |
| clipfrac           | 0.1171875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.0203     |
| fps                | 19          |
| n_updates          | 52          |
| policy_entropy     | -0.6840223  |
| policy_loss        | 0.004821169 |
| serial_timesteps   | 6656        |
| time_elapsed       | 381         |
| total_timesteps    | 6656        |
| value_loss         | 3.959752    |
------------------------------------
An average of 283.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.0053606     |
| clipfrac           | 0.07421875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | -0.0653       |
| fps                | 19            |
| n_updates          | 53            |
| policy_entropy     | -0.6849689    |
| policy_loss        | -0.0037216241 |
| serial_timesteps   | 6784          |
| time_elapsed       | 387           |
| total_timesteps    | 6784          |
| value_loss         | 6.0539403     |
--------------------------------------
------------------------------------
| approxkl           | 0.009637037 |
| clipfrac           | 0.12890625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.0078     |
| fps                | 19          |
| n_updates          | 54          |
| policy_entropy     | -0.6860048  |
| policy_loss        | 0.004185274 |
| serial_timesteps   | 6912        |
| time_elapsed       | 394         |
| total_timesteps    | 6912        |
| value_loss         | 1.3834126   |
------------------------------------
--------------------------------------
| approxkl           | 0.009873686   |
| clipfrac           | 0.15039062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 0.00167       |
| fps                | 18            |
| n_updates          | 55            |
| policy_entropy     | -0.6873438    |
| policy_loss        | -0.0001345065 |
| serial_timesteps   | 7040          |
| time_elapsed       | 400           |
| total_timesteps    | 7040          |
| value_loss         | 2.901909      |
--------------------------------------
--------------------------------------
| approxkl           | 0.017989796   |
| clipfrac           | 0.25585938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 0.0723        |
| fps                | 19            |
| n_updates          | 56            |
| policy_entropy     | -0.68880224   |
| policy_loss        | -0.0066555627 |
| serial_timesteps   | 7168          |
| time_elapsed       | 407           |
| total_timesteps    | 7168          |
| value_loss         | 62.96501      |
--------------------------------------
-------------------------------------
| approxkl           | 0.01393591   |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 0.0941       |
| fps                | 19           |
| n_updates          | 57           |
| policy_entropy     | -0.6896337   |
| policy_loss        | -0.010845201 |
| serial_timesteps   | 7296         |
| time_elapsed       | 414          |
| total_timesteps    | 7296         |
| value_loss         | 13.949889    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0062270793  |
| clipfrac           | 0.091796875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 0.0631        |
| fps                | 19            |
| n_updates          | 58            |
| policy_entropy     | -0.69116443   |
| policy_loss        | 0.00018865045 |
| serial_timesteps   | 7424          |
| time_elapsed       | 420           |
| total_timesteps    | 7424          |
| value_loss         | 3.3138938     |
--------------------------------------
-------------------------------------
| approxkl           | 0.020789608  |
| clipfrac           | 0.1796875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | 0.152        |
| fps                | 18           |
| n_updates          | 59           |
| policy_entropy     | -0.69215846  |
| policy_loss        | 0.0043206844 |
| serial_timesteps   | 7552         |
| time_elapsed       | 427          |
| total_timesteps    | 7552         |
| value_loss         | 1.3244569    |
-------------------------------------
An average of 283.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.013028235   |
| clipfrac           | 0.15820312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | -0.103        |
| fps                | 19            |
| n_updates          | 60            |
| policy_entropy     | -0.6920798    |
| policy_loss        | -0.0013010027 |
| serial_timesteps   | 7680          |
| time_elapsed       | 434           |
| total_timesteps    | 7680          |
| value_loss         | 4.578574      |
--------------------------------------
------------------------------------
| approxkl           | 0.007356874 |
| clipfrac           | 0.115234375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.00117    |
| fps                | 18          |
| n_updates          | 61          |
| policy_entropy     | -0.6924416  |
| policy_loss        | 0.013263089 |
| serial_timesteps   | 7808        |
| time_elapsed       | 440         |
| total_timesteps    | 7808        |
| value_loss         | 6602.0664   |
------------------------------------
-------------------------------------
| approxkl           | 0.026744734  |
| clipfrac           | 0.31054688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -0.0666      |
| fps                | 20           |
| n_updates          | 62           |
| policy_entropy     | -0.69259405  |
| policy_loss        | -0.025864886 |
| serial_timesteps   | 7936         |
| time_elapsed       | 447          |
| total_timesteps    | 7936         |
| value_loss         | 1.8710318    |
-------------------------------------
------------------------------------
| approxkl           | 0.014747278 |
| clipfrac           | 0.15429688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.446      |
| fps                | 19          |
| n_updates          | 63          |
| policy_entropy     | -0.6935219  |
| policy_loss        | 0.006435834 |
| serial_timesteps   | 8064        |
| time_elapsed       | 453         |
| total_timesteps    | 8064        |
| value_loss         | 3.2977393   |
------------------------------------
-------------------------------------
| approxkl           | 0.017909277  |
| clipfrac           | 0.17578125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -0.159       |
| fps                | 19           |
| n_updates          | 64           |
| policy_entropy     | -0.6962808   |
| policy_loss        | 0.0023314322 |
| serial_timesteps   | 8192         |
| time_elapsed       | 460          |
| total_timesteps    | 8192         |
| value_loss         | 1.8139542    |
-------------------------------------
-------------------------------------
| approxkl           | 0.011531916  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -0.0139      |
| fps                | 19           |
| n_updates          | 65           |
| policy_entropy     | -0.70043796  |
| policy_loss        | -0.008806085 |
| serial_timesteps   | 8320         |
| time_elapsed       | 467          |
| total_timesteps    | 8320         |
| value_loss         | 1.0378892    |
-------------------------------------
--------------------------------------
| approxkl           | 0.013826074   |
| clipfrac           | 0.19921875    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | -0.00142      |
| fps                | 20            |
| n_updates          | 66            |
| policy_entropy     | -0.70322126   |
| policy_loss        | -0.0111220945 |
| serial_timesteps   | 8448          |
| time_elapsed       | 473           |
| total_timesteps    | 8448          |
| value_loss         | 1.4839004     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0129724685   |
| clipfrac           | 0.15820312     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 6.98e+03       |
| explained_variance | 0.0275         |
| fps                | 18             |
| n_updates          | 67             |
| policy_entropy     | -0.7053242     |
| policy_loss        | -0.00023333635 |
| serial_timesteps   | 8576           |
| time_elapsed       | 479            |
| total_timesteps    | 8576           |
| value_loss         | 0.53594095     |
---------------------------------------
An average of 284.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.01417821  |
| clipfrac           | 0.18164062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.0459     |
| fps                | 19          |
| n_updates          | 68          |
| policy_entropy     | -0.7069088  |
| policy_loss        | 0.012056364 |
| serial_timesteps   | 8704        |
| time_elapsed       | 486         |
| total_timesteps    | 8704        |
| value_loss         | 4.235403    |
------------------------------------
------------------------------------
| approxkl           | 0.012371    |
| clipfrac           | 0.15234375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.0036     |
| fps                | 19          |
| n_updates          | 69          |
| policy_entropy     | -0.70850515 |
| policy_loss        | 0.011145208 |
| serial_timesteps   | 8832        |
| time_elapsed       | 493         |
| total_timesteps    | 8832        |
| value_loss         | 4.469313    |
------------------------------------
-------------------------------------
| approxkl           | 0.009078481  |
| clipfrac           | 0.16015625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.98e+03     |
| explained_variance | -0.0214      |
| fps                | 19           |
| n_updates          | 70           |
| policy_entropy     | -0.7102773   |
| policy_loss        | -0.012954118 |
| serial_timesteps   | 8960         |
| time_elapsed       | 500          |
| total_timesteps    | 8960         |
| value_loss         | 4.840009     |
-------------------------------------
------------------------------------
| approxkl           | 0.020263016 |
| clipfrac           | 0.20898438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.98e+03    |
| explained_variance | -0.00724    |
| fps                | 20          |
| n_updates          | 71          |
| policy_entropy     | -0.71183926 |
| policy_loss        | 0.013734474 |
| serial_timesteps   | 9088        |
| time_elapsed       | 506         |
| total_timesteps    | 9088        |
| value_loss         | 1.5165819   |
------------------------------------
--------------------------------------
| approxkl           | 0.016576435   |
| clipfrac           | 0.111328125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.98e+03      |
| explained_variance | 0.0412        |
| fps                | 18            |
| n_updates          | 72            |
| policy_entropy     | -0.71266025   |
| policy_loss        | -0.0059182327 |
| serial_timesteps   | 9216          |
| time_elapsed       | 512           |
| total_timesteps    | 9216          |
| value_loss         | 17.947763     |
--------------------------------------
------------------------------------
| approxkl           | 0.010117301 |
| clipfrac           | 0.15625     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.00124    |
| fps                | 18          |
| n_updates          | 73          |
| policy_entropy     | -0.7132742  |
| policy_loss        | 0.004709215 |
| serial_timesteps   | 9344        |
| time_elapsed       | 519         |
| total_timesteps    | 9344        |
| value_loss         | 7115.7686   |
------------------------------------
------------------------------------
| approxkl           | 0.009785444 |
| clipfrac           | 0.123046875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.054       |
| fps                | 20          |
| n_updates          | 74          |
| policy_entropy     | -0.7131314  |
| policy_loss        | 0.003283756 |
| serial_timesteps   | 9472        |
| time_elapsed       | 526         |
| total_timesteps    | 9472        |
| value_loss         | 6.697793    |
------------------------------------
-------------------------------------
| approxkl           | 0.011997865  |
| clipfrac           | 0.15820312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0224      |
| fps                | 19           |
| n_updates          | 75           |
| policy_entropy     | -0.71182686  |
| policy_loss        | -0.009188609 |
| serial_timesteps   | 9600         |
| time_elapsed       | 532          |
| total_timesteps    | 9600         |
| value_loss         | 3.923953     |
-------------------------------------
An average of 285.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.016196089 |
| clipfrac           | 0.13867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.163       |
| fps                | 19          |
| n_updates          | 76          |
| policy_entropy     | -0.711327   |
| policy_loss        | -0.00511749 |
| serial_timesteps   | 9728        |
| time_elapsed       | 539         |
| total_timesteps    | 9728        |
| value_loss         | 3.5928438   |
------------------------------------
------------------------------------
| approxkl           | 0.007960497 |
| clipfrac           | 0.107421875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.395      |
| fps                | 19          |
| n_updates          | 77          |
| policy_entropy     | -0.7105263  |
| policy_loss        | 0.00748155  |
| serial_timesteps   | 9856        |
| time_elapsed       | 545         |
| total_timesteps    | 9856        |
| value_loss         | 2.7683508   |
------------------------------------
------------------------------------
| approxkl           | 0.011194278 |
| clipfrac           | 0.13671875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.163      |
| fps                | 20          |
| n_updates          | 78          |
| policy_entropy     | -0.71154344 |
| policy_loss        | 0.013059343 |
| serial_timesteps   | 9984        |
| time_elapsed       | 552         |
| total_timesteps    | 9984        |
| value_loss         | 3.7549076   |
------------------------------------
-------------------------------------
| approxkl           | 0.0071202256 |
| clipfrac           | 0.095703125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.337       |
| fps                | 19           |
| n_updates          | 79           |
| policy_entropy     | -0.7131552   |
| policy_loss        | 0.006070037  |
| serial_timesteps   | 10112        |
| time_elapsed       | 558          |
| total_timesteps    | 10112        |
| value_loss         | 3.9608233    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014656967  |
| clipfrac           | 0.203125     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.0821       |
| fps                | 19           |
| n_updates          | 80           |
| policy_entropy     | -0.7145345   |
| policy_loss        | 0.0014484259 |
| serial_timesteps   | 10240        |
| time_elapsed       | 565          |
| total_timesteps    | 10240        |
| value_loss         | 0.9949795    |
-------------------------------------
------------------------------------
| approxkl           | 0.008203521 |
| clipfrac           | 0.103515625 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.196      |
| fps                | 19          |
| n_updates          | 81          |
| policy_entropy     | -0.7157459  |
| policy_loss        | 0.002391566 |
| serial_timesteps   | 10368       |
| time_elapsed       | 571         |
| total_timesteps    | 10368       |
| value_loss         | 0.48569563  |
------------------------------------
------------------------------------
| approxkl           | 0.015013696 |
| clipfrac           | 0.16992188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.0177     |
| fps                | 19          |
| n_updates          | 82          |
| policy_entropy     | -0.7175363  |
| policy_loss        | 0.014323815 |
| serial_timesteps   | 10496       |
| time_elapsed       | 578         |
| total_timesteps    | 10496       |
| value_loss         | 1.7050797   |
------------------------------------
--------------------------------------
| approxkl           | 0.017980317   |
| clipfrac           | 0.17578125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.000307     |
| fps                | 19            |
| n_updates          | 83            |
| policy_entropy     | -0.71862197   |
| policy_loss        | -0.0073272074 |
| serial_timesteps   | 10624         |
| time_elapsed       | 584           |
| total_timesteps    | 10624         |
| value_loss         | 1.3894238     |
--------------------------------------
An average of 285.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.022193316  |
| clipfrac           | 0.27929688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.00274      |
| fps                | 19           |
| n_updates          | 84           |
| policy_entropy     | -0.72007865  |
| policy_loss        | -0.011950625 |
| serial_timesteps   | 10752        |
| time_elapsed       | 591          |
| total_timesteps    | 10752        |
| value_loss         | 0.32164034   |
-------------------------------------
------------------------------------
| approxkl           | 0.04332583  |
| clipfrac           | 0.3359375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.000182    |
| fps                | 19          |
| n_updates          | 85          |
| policy_entropy     | -0.7209221  |
| policy_loss        | 0.026544044 |
| serial_timesteps   | 10880       |
| time_elapsed       | 598         |
| total_timesteps    | 10880       |
| value_loss         | 6683.9385   |
------------------------------------
------------------------------------
| approxkl           | 0.014607444 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.0334     |
| fps                | 19          |
| n_updates          | 86          |
| policy_entropy     | -0.7219163  |
| policy_loss        | 0.015966408 |
| serial_timesteps   | 11008       |
| time_elapsed       | 604         |
| total_timesteps    | 11008       |
| value_loss         | 4.6585784   |
------------------------------------
-------------------------------------
| approxkl           | 0.0055765193 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0234      |
| fps                | 19           |
| n_updates          | 87           |
| policy_entropy     | -0.7236867   |
| policy_loss        | 0.0022945753 |
| serial_timesteps   | 11136        |
| time_elapsed       | 611          |
| total_timesteps    | 11136        |
| value_loss         | 3.6232324    |
-------------------------------------
-------------------------------------
| approxkl           | 0.017727828  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0432      |
| fps                | 19           |
| n_updates          | 88           |
| policy_entropy     | -0.724526    |
| policy_loss        | -0.009649222 |
| serial_timesteps   | 11264        |
| time_elapsed       | 617          |
| total_timesteps    | 11264        |
| value_loss         | 0.49175063   |
-------------------------------------
-------------------------------------
| approxkl           | 0.011233337  |
| clipfrac           | 0.123046875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.072        |
| fps                | 19           |
| n_updates          | 89           |
| policy_entropy     | -0.725495    |
| policy_loss        | 0.0010545527 |
| serial_timesteps   | 11392        |
| time_elapsed       | 624          |
| total_timesteps    | 11392        |
| value_loss         | 28.463467    |
-------------------------------------
------------------------------------
| approxkl           | 0.035917554 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.0756      |
| fps                | 20          |
| n_updates          | 90          |
| policy_entropy     | -0.7258236  |
| policy_loss        | 0.029296484 |
| serial_timesteps   | 11520       |
| time_elapsed       | 630         |
| total_timesteps    | 11520       |
| value_loss         | 24.621939   |
------------------------------------
-------------------------------------
| approxkl           | 0.028017769  |
| clipfrac           | 0.25585938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.107        |
| fps                | 19           |
| n_updates          | 91           |
| policy_entropy     | -0.72600394  |
| policy_loss        | -0.008229736 |
| serial_timesteps   | 11648        |
| time_elapsed       | 637          |
| total_timesteps    | 11648        |
| value_loss         | 12.440343    |
-------------------------------------
An average of 286.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.009264037   |
| clipfrac           | 0.15039062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 0.183         |
| fps                | 19            |
| n_updates          | 92            |
| policy_entropy     | -0.7267634    |
| policy_loss        | -0.0064495476 |
| serial_timesteps   | 11776         |
| time_elapsed       | 644           |
| total_timesteps    | 11776         |
| value_loss         | 1.8602164     |
--------------------------------------
-------------------------------------
| approxkl           | 0.021894498  |
| clipfrac           | 0.22460938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.296        |
| fps                | 18           |
| n_updates          | 93           |
| policy_entropy     | -0.72742146  |
| policy_loss        | -0.004813685 |
| serial_timesteps   | 11904        |
| time_elapsed       | 650          |
| total_timesteps    | 11904        |
| value_loss         | 2.535779     |
-------------------------------------
--------------------------------------
| approxkl           | 0.018080164   |
| clipfrac           | 0.22460938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.105        |
| fps                | 18            |
| n_updates          | 94            |
| policy_entropy     | -0.729313     |
| policy_loss        | -0.0033668536 |
| serial_timesteps   | 12032         |
| time_elapsed       | 657           |
| total_timesteps    | 12032         |
| value_loss         | 2.3711052     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0168669     |
| clipfrac           | 0.17578125    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.263        |
| fps                | 19            |
| n_updates          | 95            |
| policy_entropy     | -0.7313364    |
| policy_loss        | -0.0005948242 |
| serial_timesteps   | 12160         |
| time_elapsed       | 664           |
| total_timesteps    | 12160         |
| value_loss         | 5.0082426     |
--------------------------------------
------------------------------------
| approxkl           | 0.013936625 |
| clipfrac           | 0.16601562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.233      |
| fps                | 19          |
| n_updates          | 96          |
| policy_entropy     | -0.73277706 |
| policy_loss        | 0.016418247 |
| serial_timesteps   | 12288       |
| time_elapsed       | 671         |
| total_timesteps    | 12288       |
| value_loss         | 3.105368    |
------------------------------------
--------------------------------------
| approxkl           | 0.00082583504 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.00136      |
| fps                | 19            |
| n_updates          | 97            |
| policy_entropy     | -0.73422825   |
| policy_loss        | 0.00028406165 |
| serial_timesteps   | 12416         |
| time_elapsed       | 677           |
| total_timesteps    | 12416         |
| value_loss         | 6755.0957     |
--------------------------------------
--------------------------------------
| approxkl           | 0.010385152   |
| clipfrac           | 0.16015625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.0634       |
| fps                | 19            |
| n_updates          | 98            |
| policy_entropy     | -0.73461455   |
| policy_loss        | -0.0017772056 |
| serial_timesteps   | 12544         |
| time_elapsed       | 684           |
| total_timesteps    | 12544         |
| value_loss         | 2.147343      |
--------------------------------------
-------------------------------------
| approxkl           | 0.019298797  |
| clipfrac           | 0.26367188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0466      |
| fps                | 19           |
| n_updates          | 99           |
| policy_entropy     | -0.73489195  |
| policy_loss        | -0.020372804 |
| serial_timesteps   | 12672        |
| time_elapsed       | 690          |
| total_timesteps    | 12672        |
| value_loss         | 1.3522018    |
-------------------------------------
An average of 287.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.030700158  |
| clipfrac           | 0.24609375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0736      |
| fps                | 19           |
| n_updates          | 100          |
| policy_entropy     | -0.7357091   |
| policy_loss        | 0.0018918924 |
| serial_timesteps   | 12800        |
| time_elapsed       | 697          |
| total_timesteps    | 12800        |
| value_loss         | 0.5128255    |
-------------------------------------
--------------------------------------
| approxkl           | 0.012885453   |
| clipfrac           | 0.18359375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 0.00537       |
| fps                | 19            |
| n_updates          | 101           |
| policy_entropy     | -0.73612034   |
| policy_loss        | -0.0058780755 |
| serial_timesteps   | 12928         |
| time_elapsed       | 704           |
| total_timesteps    | 12928         |
| value_loss         | 2.3058681     |
--------------------------------------
------------------------------------
| approxkl           | 0.009164595 |
| clipfrac           | 0.12109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | -0.00383    |
| fps                | 18          |
| n_updates          | 102         |
| policy_entropy     | -0.73756635 |
| policy_loss        | -0.00783797 |
| serial_timesteps   | 13056       |
| time_elapsed       | 710         |
| total_timesteps    | 13056       |
| value_loss         | 4.6577563   |
------------------------------------
--------------------------------------
| approxkl           | 0.008081196   |
| clipfrac           | 0.109375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | -0.0605       |
| fps                | 20            |
| n_updates          | 103           |
| policy_entropy     | -0.7391506    |
| policy_loss        | -0.0034793704 |
| serial_timesteps   | 13184         |
| time_elapsed       | 717           |
| total_timesteps    | 13184         |
| value_loss         | 4.418299      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0041436944 |
| clipfrac           | 0.044921875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.00758     |
| fps                | 20           |
| n_updates          | 104          |
| policy_entropy     | -0.74276197  |
| policy_loss        | 0.005685227  |
| serial_timesteps   | 13312        |
| time_elapsed       | 723          |
| total_timesteps    | 13312        |
| value_loss         | 2.5382328    |
-------------------------------------
-------------------------------------
| approxkl           | 0.016214196  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | -0.0259      |
| fps                | 18           |
| n_updates          | 105          |
| policy_entropy     | -0.74629176  |
| policy_loss        | -0.015598366 |
| serial_timesteps   | 13440        |
| time_elapsed       | 729          |
| total_timesteps    | 13440        |
| value_loss         | 3.5650616    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0054526813  |
| clipfrac           | 0.068359375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7e+03         |
| explained_variance | 0.0629        |
| fps                | 19            |
| n_updates          | 106           |
| policy_entropy     | -0.7481827    |
| policy_loss        | -0.0025001173 |
| serial_timesteps   | 13568         |
| time_elapsed       | 736           |
| total_timesteps    | 13568         |
| value_loss         | 44.430714     |
--------------------------------------
An average of 287.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.006730655  |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7e+03        |
| explained_variance | 0.131        |
| fps                | 19           |
| n_updates          | 107          |
| policy_entropy     | -0.74789596  |
| policy_loss        | 0.0026615008 |
| serial_timesteps   | 13696        |
| time_elapsed       | 743          |
| total_timesteps    | 13696        |
| value_loss         | 11.688168    |
-------------------------------------
------------------------------------
| approxkl           | 0.014547194 |
| clipfrac           | 0.21484375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7e+03       |
| explained_variance | 0.0966      |
| fps                | 19          |
| n_updates          | 108         |
| policy_entropy     | -0.7467416  |
| policy_loss        | 0.010878423 |
| serial_timesteps   | 13824       |
| time_elapsed       | 749         |
| total_timesteps    | 13824       |
| value_loss         | 5.2853103   |
------------------------------------
-------------------------------------
| approxkl           | 0.012197202  |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | 0.000308     |
| fps                | 19           |
| n_updates          | 109          |
| policy_entropy     | -0.7452784   |
| policy_loss        | -0.013264891 |
| serial_timesteps   | 13952        |
| time_elapsed       | 756          |
| total_timesteps    | 13952        |
| value_loss         | 6847.3804    |
-------------------------------------
------------------------------------
| approxkl           | 0.015143457 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -0.305      |
| fps                | 19          |
| n_updates          | 110         |
| policy_entropy     | -0.7443005  |
| policy_loss        | 0.00902264  |
| serial_timesteps   | 14080       |
| time_elapsed       | 762         |
| total_timesteps    | 14080       |
| value_loss         | 3.9616942   |
------------------------------------
-------------------------------------
| approxkl           | 0.037245687  |
| clipfrac           | 0.31835938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -1.56        |
| fps                | 18           |
| n_updates          | 111          |
| policy_entropy     | -0.7443292   |
| policy_loss        | -0.009215401 |
| serial_timesteps   | 14208        |
| time_elapsed       | 769          |
| total_timesteps    | 14208        |
| value_loss         | 1.8696338    |
-------------------------------------
-------------------------------------
| approxkl           | 0.022419     |
| clipfrac           | 0.27539062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -2.56        |
| fps                | 18           |
| n_updates          | 112          |
| policy_entropy     | -0.7447092   |
| policy_loss        | -0.014867272 |
| serial_timesteps   | 14336        |
| time_elapsed       | 776          |
| total_timesteps    | 14336        |
| value_loss         | 2.5777502    |
-------------------------------------
------------------------------------
| approxkl           | 0.014007015 |
| clipfrac           | 0.171875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | 0.0441      |
| fps                | 19          |
| n_updates          | 113         |
| policy_entropy     | -0.745503   |
| policy_loss        | 0.014303187 |
| serial_timesteps   | 14464       |
| time_elapsed       | 783         |
| total_timesteps    | 14464       |
| value_loss         | 1.4578817   |
------------------------------------
--------------------------------------
| approxkl           | 0.01159712    |
| clipfrac           | 0.1796875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 6.99e+03      |
| explained_variance | 0.0557        |
| fps                | 19            |
| n_updates          | 114           |
| policy_entropy     | -0.7449327    |
| policy_loss        | -0.0063123973 |
| serial_timesteps   | 14592         |
| time_elapsed       | 789           |
| total_timesteps    | 14592         |
| value_loss         | 1.9779793     |
--------------------------------------
An average of 288.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.010440597  |
| clipfrac           | 0.15039062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 6.99e+03     |
| explained_variance | -0.0352      |
| fps                | 19           |
| n_updates          | 115          |
| policy_entropy     | -0.7442329   |
| policy_loss        | 0.0025265017 |
| serial_timesteps   | 14720        |
| time_elapsed       | 796          |
| total_timesteps    | 14720        |
| value_loss         | 10.285437    |
-------------------------------------
------------------------------------
| approxkl           | 0.050061595 |
| clipfrac           | 0.31054688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -0.0157     |
| fps                | 19          |
| n_updates          | 116         |
| policy_entropy     | -0.74411047 |
| policy_loss        | -0.02167816 |
| serial_timesteps   | 14848       |
| time_elapsed       | 802         |
| total_timesteps    | 14848       |
| value_loss         | 1.3542887   |
------------------------------------
------------------------------------
| approxkl           | 0.015664289 |
| clipfrac           | 0.17578125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 6.99e+03    |
| explained_variance | -0.15       |
| fps                | 20          |
| n_updates          | 117         |
| policy_entropy     | -0.7451733  |
| policy_loss        | 0.010840747 |
| serial_timesteps   | 14976       |
| time_elapsed       | 809         |
| total_timesteps    | 14976       |
| value_loss         | 0.703875    |
------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b2cd3ef60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b2cd3ef60>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b2ca1eb00>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b2ca1eb00>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2349 samples, validate on 92 samples
Epoch 545/5000
 - 10s - loss: 0.1190 - val_loss: 0.0042
Epoch 546/5000
 - 1s - loss: 0.0188 - val_loss: 0.0051
Epoch 547/5000
 - 1s - loss: 0.0100 - val_loss: 0.0068
Epoch 548/5000
 - 1s - loss: 0.0072 - val_loss: 0.0075
Epoch 549/5000
 - 1s - loss: 0.0069 - val_loss: 0.0068
Epoch 550/5000
 - 1s - loss: 0.0069 - val_loss: 0.0061
Train on 1934 samples, validate on 92 samples
Epoch 409/5000
 - 10s - loss: 0.0119 - val_loss: 0.0303
Epoch 410/5000
 - 1s - loss: 0.0162 - val_loss: 0.0154
Epoch 411/5000
 - 1s - loss: 0.0084 - val_loss: 0.0228
Epoch 412/5000
 - 1s - loss: 0.0038 - val_loss: 0.0179
Epoch 413/5000
 - 1s - loss: 0.0021 - val_loss: 0.0181
Epoch 414/5000
 - 1s - loss: 0.0020 - val_loss: 0.0172
Epoch 415/5000
 - 1s - loss: 0.0020 - val_loss: 0.0172
Train on 2452 samples, validate on 92 samples
Epoch 1304/5000
 - 11s - loss: 0.6552 - val_loss: 0.5455
Epoch 1305/5000
 - 1s - loss: 0.5674 - val_loss: 0.3395
Epoch 1306/5000
 - 1s - loss: 0.5225 - val_loss: 0.2495
Epoch 1307/5000
 - 1s - loss: 0.5187 - val_loss: 0.2367
Epoch 1308/5000
 - 1s - loss: 0.5165 - val_loss: 0.2316
Epoch 1309/5000
 - 1s - loss: 0.5143 - val_loss: 0.2271
Epoch 1310/5000
 - 1s - loss: 0.5119 - val_loss: 0.2221
Epoch 1311/5000
 - 1s - loss: 0.5089 - val_loss: 0.2154
Epoch 1312/5000
 - 1s - loss: 0.5057 - val_loss: 0.2092
Epoch 1313/5000
 - 1s - loss: 0.5007 - val_loss: 0.2020
Epoch 1314/5000
 - 1s - loss: 0.4951 - val_loss: 0.1939
Epoch 1315/5000
 - 1s - loss: 0.4888 - val_loss: 0.1864
Epoch 1316/5000
 - 1s - loss: 0.4822 - val_loss: 0.1800
Epoch 1317/5000
 - 1s - loss: 0.4757 - val_loss: 0.1753
Epoch 1318/5000
 - 1s - loss: 0.4701 - val_loss: 0.1723
Epoch 1319/5000
 - 1s - loss: 0.4657 - val_loss: 0.1708
Epoch 1320/5000
 - 1s - loss: 0.4605 - val_loss: 0.1709
Epoch 1321/5000
 - 1s - loss: 0.4595 - val_loss: 0.1704
Epoch 1322/5000
 - 1s - loss: 0.4530 - val_loss: 0.1735
Epoch 1323/5000
 - 1s - loss: 0.4546 - val_loss: 0.1720
Epoch 1324/5000
 - 1s - loss: 0.4344 - val_loss: 0.1656
Epoch 1325/5000
 - 1s - loss: 0.4328 - val_loss: 0.1589
Epoch 1326/5000
 - 1s - loss: 0.4315 - val_loss: 0.1536
Epoch 1327/5000
 - 1s - loss: 0.4304 - val_loss: 0.1493
Epoch 1328/5000
 - 1s - loss: 0.4294 - val_loss: 0.1459
Epoch 1329/5000
 - 1s - loss: 0.4286 - val_loss: 0.1430
Epoch 1330/5000
 - 1s - loss: 0.4278 - val_loss: 0.1407
Epoch 1331/5000
 - 1s - loss: 0.4270 - val_loss: 0.1388
Epoch 1332/5000
 - 1s - loss: 0.4262 - val_loss: 0.1372
Epoch 1333/5000
 - 1s - loss: 0.4255 - val_loss: 0.1358
Epoch 1334/5000
 - 1s - loss: 0.4248 - val_loss: 0.1345
Epoch 1335/5000
 - 1s - loss: 0.4241 - val_loss: 0.1334
Epoch 1336/5000
 - 1s - loss: 0.4234 - val_loss: 0.1324
Epoch 1337/5000
 - 1s - loss: 0.4227 - val_loss: 0.1314
Epoch 1338/5000
 - 1s - loss: 0.4221 - val_loss: 0.1305
Epoch 1339/5000
 - 1s - loss: 0.4215 - val_loss: 0.1296
Epoch 1340/5000
 - 1s - loss: 0.4209 - val_loss: 0.1287
Epoch 1341/5000
 - 1s - loss: 0.4204 - val_loss: 0.1279
Epoch 1342/5000
 - 1s - loss: 0.4199 - val_loss: 0.1271
Epoch 1343/5000
 - 1s - loss: 0.4195 - val_loss: 0.1265
Epoch 1344/5000
 - 1s - loss: 0.4190 - val_loss: 0.1260
Epoch 1345/5000
 - 1s - loss: 0.4186 - val_loss: 0.1255
Epoch 1346/5000
 - 1s - loss: 0.4182 - val_loss: 0.1250
Epoch 1347/5000
 - 1s - loss: 0.4177 - val_loss: 0.1246
Epoch 1348/5000
 - 1s - loss: 0.4173 - val_loss: 0.1241
Epoch 1349/5000
 - 1s - loss: 0.4170 - val_loss: 0.1236
Epoch 1350/5000
 - 1s - loss: 0.4166 - val_loss: 0.1232
Epoch 1351/5000
 - 1s - loss: 0.4163 - val_loss: 0.1228
Epoch 1352/5000
 - 1s - loss: 0.4160 - val_loss: 0.1224
Epoch 1353/5000
 - 1s - loss: 0.4157 - val_loss: 0.1222
Epoch 1354/5000
 - 1s - loss: 0.4154 - val_loss: 0.1220
Epoch 1355/5000
 - 1s - loss: 0.4151 - val_loss: 0.1217
Epoch 1356/5000
 - 1s - loss: 0.4149 - val_loss: 0.1216
Epoch 1357/5000
 - 1s - loss: 0.4146 - val_loss: 0.1215
Epoch 1358/5000
 - 1s - loss: 0.4144 - val_loss: 0.1214
Epoch 1359/5000
 - 1s - loss: 0.4141 - val_loss: 0.1213
Epoch 1360/5000
 - 1s - loss: 0.4139 - val_loss: 0.1213
Epoch 1361/5000
 - 1s - loss: 0.4137 - val_loss: 0.1213
Epoch 1362/5000
 - 1s - loss: 0.4113 - val_loss: 0.1213
Epoch 1363/5000
 - 1s - loss: 0.4113 - val_loss: 0.1212
Epoch 1364/5000
 - 1s - loss: 0.4113 - val_loss: 0.1212
Epoch 1365/5000
 - 1s - loss: 0.4112 - val_loss: 0.1211
Epoch 1366/5000
 - 1s - loss: 0.4112 - val_loss: 0.1211
Epoch 1367/5000
 - 1s - loss: 0.4112 - val_loss: 0.1210
Epoch 1368/5000
 - 1s - loss: 0.4112 - val_loss: 0.1209
Epoch 1369/5000
 - 1s - loss: 0.4111 - val_loss: 0.1209
Epoch 1370/5000
 - 1s - loss: 0.4111 - val_loss: 0.1208
Epoch 1371/5000
 - 1s - loss: 0.4111 - val_loss: 0.1208
Epoch 1372/5000
 - 1s - loss: 0.4111 - val_loss: 0.1207
Epoch 1373/5000
 - 1s - loss: 0.4111 - val_loss: 0.1207
Epoch 1374/5000
 - 1s - loss: 0.4110 - val_loss: 0.1206
Epoch 1375/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1376/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1377/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1378/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1379/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1380/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1381/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1382/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1383/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1384/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1385/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1386/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
Epoch 1387/5000
 - 1s - loss: 0.4108 - val_loss: 0.1206
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.009416358  |
| clipfrac           | 0.12695312   |
| explained_variance | -0.00358     |
| fps                | 2            |
| n_updates          | 1            |
| policy_entropy     | -0.74657536  |
| policy_loss        | 0.0036844478 |
| serial_timesteps   | 128          |
| time_elapsed       | 2.31e-05     |
| total_timesteps    | 128          |
| value_loss         | 110.125      |
-------------------------------------
------------------------------------
| approxkl           | 0.013541745 |
| clipfrac           | 0.18164062  |
| explained_variance | 0.0316      |
| fps                | 20          |
| n_updates          | 2           |
| policy_entropy     | -0.7462715  |
| policy_loss        | 0.009715769 |
| serial_timesteps   | 256         |
| time_elapsed       | 51.2        |
| total_timesteps    | 256         |
| value_loss         | 91.7045     |
------------------------------------
------------------------------------
| approxkl           | 0.021020627 |
| clipfrac           | 0.25976562  |
| explained_variance | -1.39       |
| fps                | 21          |
| n_updates          | 3           |
| policy_entropy     | -0.74522394 |
| policy_loss        | 0.003435099 |
| serial_timesteps   | 384         |
| time_elapsed       | 57.6        |
| total_timesteps    | 384         |
| value_loss         | 335.68454   |
------------------------------------
-------------------------------------
| approxkl           | 0.019373339  |
| clipfrac           | 0.171875     |
| explained_variance | 0.0467       |
| fps                | 23           |
| n_updates          | 4            |
| policy_entropy     | -0.74449044  |
| policy_loss        | 0.0061031696 |
| serial_timesteps   | 512          |
| time_elapsed       | 63.5         |
| total_timesteps    | 512          |
| value_loss         | 154.6554     |
-------------------------------------
------------------------------------
| approxkl           | 0.007444522 |
| clipfrac           | 0.08203125  |
| explained_variance | -0.104      |
| fps                | 23          |
| n_updates          | 5           |
| policy_entropy     | -0.74367654 |
| policy_loss        | 0.004918362 |
| serial_timesteps   | 640         |
| time_elapsed       | 69          |
| total_timesteps    | 640         |
| value_loss         | 80.9826     |
------------------------------------
An average of 289.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0083188005 |
| clipfrac           | 0.111328125  |
| explained_variance | -0.0273      |
| fps                | 22           |
| n_updates          | 6            |
| policy_entropy     | -0.74301565  |
| policy_loss        | 0.0010118049 |
| serial_timesteps   | 768          |
| time_elapsed       | 74.5         |
| total_timesteps    | 768          |
| value_loss         | 261.172      |
-------------------------------------
--------------------------------------
| approxkl           | 0.011443634   |
| clipfrac           | 0.14648438    |
| explained_variance | 0.0755        |
| fps                | 21            |
| n_updates          | 7             |
| policy_entropy     | -0.74156785   |
| policy_loss        | -0.0005404176 |
| serial_timesteps   | 896           |
| time_elapsed       | 80.3          |
| total_timesteps    | 896           |
| value_loss         | 179.5379      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0052310145 |
| clipfrac           | 0.06640625   |
| explained_variance | -0.943       |
| fps                | 20           |
| n_updates          | 8            |
| policy_entropy     | -0.7412731   |
| policy_loss        | 0.0024870108 |
| serial_timesteps   | 1024         |
| time_elapsed       | 86.2         |
| total_timesteps    | 1024         |
| value_loss         | 10.521573    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014074599  |
| clipfrac           | 0.16796875   |
| explained_variance | 0.376        |
| fps                | 20           |
| n_updates          | 9            |
| policy_entropy     | -0.74179196  |
| policy_loss        | 0.0064535458 |
| serial_timesteps   | 1152         |
| time_elapsed       | 92.5         |
| total_timesteps    | 1152         |
| value_loss         | 5.798294     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0069108573  |
| clipfrac           | 0.091796875   |
| explained_variance | -0.404        |
| fps                | 22            |
| n_updates          | 10            |
| policy_entropy     | -0.74300504   |
| policy_loss        | -0.0059615686 |
| serial_timesteps   | 1280          |
| time_elapsed       | 98.6          |
| total_timesteps    | 1280          |
| value_loss         | 6.128827      |
--------------------------------------
--------------------------------------
| approxkl           | 0.008378865   |
| clipfrac           | 0.1171875     |
| explained_variance | -0.16         |
| fps                | 22            |
| n_updates          | 11            |
| policy_entropy     | -0.74505025   |
| policy_loss        | -0.0034003893 |
| serial_timesteps   | 1408          |
| time_elapsed       | 104           |
| total_timesteps    | 1408          |
| value_loss         | 140.91388     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0035102936 |
| clipfrac           | 0.0390625    |
| explained_variance | -0.716       |
| fps                | 20           |
| n_updates          | 12           |
| policy_entropy     | -0.74537206  |
| policy_loss        | 0.0067838538 |
| serial_timesteps   | 1536         |
| time_elapsed       | 110          |
| total_timesteps    | 1536         |
| value_loss         | 28.65617     |
-------------------------------------
------------------------------------
| approxkl           | 0.008835351 |
| clipfrac           | 0.13867188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.92e+03    |
| explained_variance | -0.00868    |
| fps                | 20          |
| n_updates          | 13          |
| policy_entropy     | -0.74474066 |
| policy_loss        | 0.007038014 |
| serial_timesteps   | 1664        |
| time_elapsed       | 116         |
| total_timesteps    | 1664        |
| value_loss         | 4216.7627   |
------------------------------------
An average of 290.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.011394592  |
| clipfrac           | 0.13671875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | -0.0373      |
| fps                | 20           |
| n_updates          | 14           |
| policy_entropy     | -0.7442583   |
| policy_loss        | 0.0053603947 |
| serial_timesteps   | 1792         |
| time_elapsed       | 123          |
| total_timesteps    | 1792         |
| value_loss         | 703.927      |
-------------------------------------
------------------------------------
| approxkl           | 0.008947078 |
| clipfrac           | 0.1171875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.92e+03    |
| explained_variance | -0.0229     |
| fps                | 18          |
| n_updates          | 15          |
| policy_entropy     | -0.74369097 |
| policy_loss        | 0.005525357 |
| serial_timesteps   | 1920        |
| time_elapsed       | 129         |
| total_timesteps    | 1920        |
| value_loss         | 172.22638   |
------------------------------------
-------------------------------------
| approxkl           | 0.0065854923 |
| clipfrac           | 0.072265625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | 0.0202       |
| fps                | 21           |
| n_updates          | 16           |
| policy_entropy     | -0.74465245  |
| policy_loss        | 0.0023530957 |
| serial_timesteps   | 2048         |
| time_elapsed       | 136          |
| total_timesteps    | 2048         |
| value_loss         | 155.21158    |
-------------------------------------
------------------------------------
| approxkl           | 0.008396791 |
| clipfrac           | 0.12695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.92e+03    |
| explained_variance | -0.0683     |
| fps                | 20          |
| n_updates          | 17          |
| policy_entropy     | -0.7470502  |
| policy_loss        | 0.002584851 |
| serial_timesteps   | 2176        |
| time_elapsed       | 142         |
| total_timesteps    | 2176        |
| value_loss         | 77.9716     |
------------------------------------
-------------------------------------
| approxkl           | 0.01560985   |
| clipfrac           | 0.171875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | -0.983       |
| fps                | 23           |
| n_updates          | 18           |
| policy_entropy     | -0.7480512   |
| policy_loss        | 0.0028559917 |
| serial_timesteps   | 2304         |
| time_elapsed       | 148          |
| total_timesteps    | 2304         |
| value_loss         | 255.46556    |
-------------------------------------
--------------------------------------
| approxkl           | 0.008698109   |
| clipfrac           | 0.09765625    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.92e+03      |
| explained_variance | 0.164         |
| fps                | 22            |
| n_updates          | 19            |
| policy_entropy     | -0.74862814   |
| policy_loss        | -0.0015524225 |
| serial_timesteps   | 2432          |
| time_elapsed       | 153           |
| total_timesteps    | 2432          |
| value_loss         | 118.73888     |
--------------------------------------
-------------------------------------
| approxkl           | 0.017121598  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | -0.193       |
| fps                | 23           |
| n_updates          | 20           |
| policy_entropy     | -0.7487766   |
| policy_loss        | -0.004149137 |
| serial_timesteps   | 2560         |
| time_elapsed       | 159          |
| total_timesteps    | 2560         |
| value_loss         | 133.31186    |
-------------------------------------
------------------------------------
| approxkl           | 0.005974538 |
| clipfrac           | 0.068359375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.92e+03    |
| explained_variance | -0.0709     |
| fps                | 22          |
| n_updates          | 21          |
| policy_entropy     | -0.74923134 |
| policy_loss        | 0.00541454  |
| serial_timesteps   | 2688        |
| time_elapsed       | 165         |
| total_timesteps    | 2688        |
| value_loss         | 200.91177   |
------------------------------------
An average of 290.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.004876073  |
| clipfrac           | 0.046875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | 0.184        |
| fps                | 20           |
| n_updates          | 22           |
| policy_entropy     | -0.7511993   |
| policy_loss        | 0.0034567872 |
| serial_timesteps   | 2816         |
| time_elapsed       | 170          |
| total_timesteps    | 2816         |
| value_loss         | 186.51416    |
-------------------------------------
-------------------------------------
| approxkl           | 0.009770581  |
| clipfrac           | 0.140625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | 0.0753       |
| fps                | 19           |
| n_updates          | 23           |
| policy_entropy     | -0.75153786  |
| policy_loss        | -0.009992864 |
| serial_timesteps   | 2944         |
| time_elapsed       | 177          |
| total_timesteps    | 2944         |
| value_loss         | 10.778533    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0051676254 |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.92e+03     |
| explained_variance | 0.258        |
| fps                | 20           |
| n_updates          | 24           |
| policy_entropy     | -0.75139195  |
| policy_loss        | 0.0032990251 |
| serial_timesteps   | 3072         |
| time_elapsed       | 183          |
| total_timesteps    | 3072         |
| value_loss         | 10.72754     |
-------------------------------------
--------------------------------------
| approxkl           | 0.013661351   |
| clipfrac           | 0.22070312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.75e+03      |
| explained_variance | 0.00674       |
| fps                | 22            |
| n_updates          | 25            |
| policy_entropy     | -0.7515694    |
| policy_loss        | -0.0028014346 |
| serial_timesteps   | 3200          |
| time_elapsed       | 189           |
| total_timesteps    | 3200          |
| value_loss         | 5495.3174     |
--------------------------------------
--------------------------------------
| approxkl           | 0.00060020084 |
| clipfrac           | 0.0           |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.75e+03      |
| explained_variance | -0.298        |
| fps                | 22            |
| n_updates          | 26            |
| policy_entropy     | -0.7515352    |
| policy_loss        | 0.0017110856  |
| serial_timesteps   | 3328          |
| time_elapsed       | 195           |
| total_timesteps    | 3328          |
| value_loss         | 130.50665     |
--------------------------------------
------------------------------------
| approxkl           | 0.008432475 |
| clipfrac           | 0.12695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.718      |
| fps                | 19          |
| n_updates          | 27          |
| policy_entropy     | -0.7510635  |
| policy_loss        | 0.004846948 |
| serial_timesteps   | 3456        |
| time_elapsed       | 201         |
| total_timesteps    | 3456        |
| value_loss         | 30.285898   |
------------------------------------
-------------------------------------
| approxkl           | 0.010351323  |
| clipfrac           | 0.14453125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | -0.028       |
| fps                | 19           |
| n_updates          | 28           |
| policy_entropy     | -0.7508171   |
| policy_loss        | -0.010573629 |
| serial_timesteps   | 3584         |
| time_elapsed       | 207          |
| total_timesteps    | 3584         |
| value_loss         | 40.396133    |
-------------------------------------
An average of 291.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.015598195 |
| clipfrac           | 0.16015625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.0758     |
| fps                | 20          |
| n_updates          | 29          |
| policy_entropy     | -0.751215   |
| policy_loss        | 0.009617043 |
| serial_timesteps   | 3712        |
| time_elapsed       | 214         |
| total_timesteps    | 3712        |
| value_loss         | 944.34143   |
------------------------------------
------------------------------------
| approxkl           | 0.023257883 |
| clipfrac           | 0.23632812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.277      |
| fps                | 21          |
| n_updates          | 30          |
| policy_entropy     | -0.751753   |
| policy_loss        | 0.018265104 |
| serial_timesteps   | 3840        |
| time_elapsed       | 220         |
| total_timesteps    | 3840        |
| value_loss         | 100.301445  |
------------------------------------
-------------------------------------
| approxkl           | 0.007965039  |
| clipfrac           | 0.087890625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | 0.0834       |
| fps                | 21           |
| n_updates          | 31           |
| policy_entropy     | -0.7518618   |
| policy_loss        | 0.0052939923 |
| serial_timesteps   | 3968         |
| time_elapsed       | 226          |
| total_timesteps    | 3968         |
| value_loss         | 103.500824   |
-------------------------------------
-------------------------------------
| approxkl           | 0.0045017344 |
| clipfrac           | 0.052734375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | 0.0903       |
| fps                | 22           |
| n_updates          | 32           |
| policy_entropy     | -0.75297695  |
| policy_loss        | 0.0043634735 |
| serial_timesteps   | 4096         |
| time_elapsed       | 232          |
| total_timesteps    | 4096         |
| value_loss         | 108.23062    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008313784  |
| clipfrac           | 0.09375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | -0.684       |
| fps                | 23           |
| n_updates          | 33           |
| policy_entropy     | -0.75412977  |
| policy_loss        | 0.0012897777 |
| serial_timesteps   | 4224         |
| time_elapsed       | 238          |
| total_timesteps    | 4224         |
| value_loss         | 219.14885    |
-------------------------------------
------------------------------------
| approxkl           | 0.019294597 |
| clipfrac           | 0.21875     |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.19        |
| fps                | 22          |
| n_updates          | 34          |
| policy_entropy     | -0.7546107  |
| policy_loss        | 0.017096767 |
| serial_timesteps   | 4352        |
| time_elapsed       | 243         |
| total_timesteps    | 4352        |
| value_loss         | 144.50731   |
------------------------------------
------------------------------------
| approxkl           | 0.05218579  |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.07        |
| fps                | 23          |
| n_updates          | 35          |
| policy_entropy     | -0.7535528  |
| policy_loss        | 0.004931953 |
| serial_timesteps   | 4480        |
| time_elapsed       | 249         |
| total_timesteps    | 4480        |
| value_loss         | 162.0174    |
------------------------------------
-------------------------------------
| approxkl           | 0.0077528455 |
| clipfrac           | 0.109375     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | -0.0838      |
| fps                | 23           |
| n_updates          | 36           |
| policy_entropy     | -0.75264984  |
| policy_loss        | 0.0042323717 |
| serial_timesteps   | 4608         |
| time_elapsed       | 255          |
| total_timesteps    | 4608         |
| value_loss         | 169.3779     |
-------------------------------------
An average of 292.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.018284988  |
| clipfrac           | 0.1953125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | 0.00939      |
| fps                | 21           |
| n_updates          | 37           |
| policy_entropy     | -0.75275475  |
| policy_loss        | 0.0009561328 |
| serial_timesteps   | 4736         |
| time_elapsed       | 260          |
| total_timesteps    | 4736         |
| value_loss         | 6109.061     |
-------------------------------------
---------------------------------------
| approxkl           | 0.002535049    |
| clipfrac           | 0.029296875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.67e+03       |
| explained_variance | -0.257         |
| fps                | 20             |
| n_updates          | 38             |
| policy_entropy     | -0.75316566    |
| policy_loss        | -0.00027762796 |
| serial_timesteps   | 4864           |
| time_elapsed       | 266            |
| total_timesteps    | 4864           |
| value_loss         | 9.525231       |
---------------------------------------
--------------------------------------
| approxkl           | 0.02342678    |
| clipfrac           | 0.2109375     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 0.101         |
| fps                | 22            |
| n_updates          | 39            |
| policy_entropy     | -0.7539828    |
| policy_loss        | -0.0057232436 |
| serial_timesteps   | 4992          |
| time_elapsed       | 272           |
| total_timesteps    | 4992          |
| value_loss         | 12.409727     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0100649735 |
| clipfrac           | 0.12890625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | 0.132        |
| fps                | 21           |
| n_updates          | 40           |
| policy_entropy     | -0.7534028   |
| policy_loss        | 0.0028193255 |
| serial_timesteps   | 5120         |
| time_elapsed       | 278          |
| total_timesteps    | 5120         |
| value_loss         | 4.5270586    |
-------------------------------------
--------------------------------------
| approxkl           | 0.010402996   |
| clipfrac           | 0.13476562    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | -0.181        |
| fps                | 21            |
| n_updates          | 41            |
| policy_entropy     | -0.75276667   |
| policy_loss        | 0.00027360558 |
| serial_timesteps   | 5248          |
| time_elapsed       | 284           |
| total_timesteps    | 5248          |
| value_loss         | 147.6245      |
--------------------------------------
--------------------------------------
| approxkl           | 0.008147628   |
| clipfrac           | 0.099609375   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | -0.644        |
| fps                | 18            |
| n_updates          | 42            |
| policy_entropy     | -0.752374     |
| policy_loss        | -0.0066939443 |
| serial_timesteps   | 5376          |
| time_elapsed       | 290           |
| total_timesteps    | 5376          |
| value_loss         | 14.133404     |
--------------------------------------
--------------------------------------
| approxkl           | 0.005427784   |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.67e+03      |
| explained_variance | 0.0134        |
| fps                | 18            |
| n_updates          | 43            |
| policy_entropy     | -0.75233155   |
| policy_loss        | -0.0020363957 |
| serial_timesteps   | 5504          |
| time_elapsed       | 297           |
| total_timesteps    | 5504          |
| value_loss         | 6.9032826     |
--------------------------------------
------------------------------------
| approxkl           | 0.015000933 |
| clipfrac           | 0.15234375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | -0.0322     |
| fps                | 20          |
| n_updates          | 44          |
| policy_entropy     | -0.7535974  |
| policy_loss        | 0.010317416 |
| serial_timesteps   | 5632        |
| time_elapsed       | 303         |
| total_timesteps    | 5632        |
| value_loss         | 890.9941    |
------------------------------------
An average of 292.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.008463792  |
| clipfrac           | 0.125        |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | 0.0478       |
| fps                | 20           |
| n_updates          | 45           |
| policy_entropy     | -0.7538619   |
| policy_loss        | 0.0034465492 |
| serial_timesteps   | 5760         |
| time_elapsed       | 310          |
| total_timesteps    | 5760         |
| value_loss         | 125.45576    |
-------------------------------------
------------------------------------
| approxkl           | 0.01186962  |
| clipfrac           | 0.1328125   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 0.0207      |
| fps                | 20          |
| n_updates          | 46          |
| policy_entropy     | -0.7556131  |
| policy_loss        | 0.005399963 |
| serial_timesteps   | 5888        |
| time_elapsed       | 316         |
| total_timesteps    | 5888        |
| value_loss         | 120.38927   |
------------------------------------
------------------------------------
| approxkl           | 0.025869295 |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.67e+03    |
| explained_variance | 0.11        |
| fps                | 21          |
| n_updates          | 47          |
| policy_entropy     | -0.7546247  |
| policy_loss        | 0.021543827 |
| serial_timesteps   | 6016        |
| time_elapsed       | 322         |
| total_timesteps    | 6016        |
| value_loss         | 97.82504    |
------------------------------------
-------------------------------------
| approxkl           | 0.021175424  |
| clipfrac           | 0.25         |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.67e+03     |
| explained_variance | -0.898       |
| fps                | 22           |
| n_updates          | 48           |
| policy_entropy     | -0.75397617  |
| policy_loss        | 0.0063516567 |
| serial_timesteps   | 6144         |
| time_elapsed       | 328          |
| total_timesteps    | 6144         |
| value_loss         | 263.37317    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0035231654 |
| clipfrac           | 0.05078125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 0.0586       |
| fps                | 22           |
| n_updates          | 49           |
| policy_entropy     | -0.75424564  |
| policy_loss        | 0.006068752  |
| serial_timesteps   | 6272         |
| time_elapsed       | 334          |
| total_timesteps    | 6272         |
| value_loss         | 5843.8213    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0076096486 |
| clipfrac           | 0.095703125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 0.0349       |
| fps                | 22           |
| n_updates          | 50           |
| policy_entropy     | -0.75569767  |
| policy_loss        | 0.0007677438 |
| serial_timesteps   | 6400         |
| time_elapsed       | 340          |
| total_timesteps    | 6400         |
| value_loss         | 171.93349    |
-------------------------------------
--------------------------------------
| approxkl           | 0.013346415   |
| clipfrac           | 0.1640625     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.71e+03      |
| explained_variance | -0.033        |
| fps                | 23            |
| n_updates          | 51            |
| policy_entropy     | -0.7548254    |
| policy_loss        | -0.0017225952 |
| serial_timesteps   | 6528          |
| time_elapsed       | 345           |
| total_timesteps    | 6528          |
| value_loss         | 153.05069     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0058657    |
| clipfrac           | 0.08203125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 0.0226       |
| fps                | 20           |
| n_updates          | 52           |
| policy_entropy     | -0.7525125   |
| policy_loss        | -0.000886071 |
| serial_timesteps   | 6656         |
| time_elapsed       | 351          |
| total_timesteps    | 6656         |
| value_loss         | 74.583984    |
-------------------------------------
An average of 293.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.021214696  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | -0.271       |
| fps                | 19           |
| n_updates          | 53           |
| policy_entropy     | -0.7516695   |
| policy_loss        | -0.016507102 |
| serial_timesteps   | 6784         |
| time_elapsed       | 357          |
| total_timesteps    | 6784         |
| value_loss         | 9.311519     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0055793375 |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 0.147        |
| fps                | 21           |
| n_updates          | 54           |
| policy_entropy     | -0.7515723   |
| policy_loss        | 0.002342103  |
| serial_timesteps   | 6912         |
| time_elapsed       | 363          |
| total_timesteps    | 6912         |
| value_loss         | 13.8806095   |
-------------------------------------
------------------------------------
| approxkl           | 0.015219105 |
| clipfrac           | 0.15039062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | -0.0327     |
| fps                | 21          |
| n_updates          | 55          |
| policy_entropy     | -0.75205296 |
| policy_loss        | 0.021803964 |
| serial_timesteps   | 7040        |
| time_elapsed       | 369         |
| total_timesteps    | 7040        |
| value_loss         | 8.774299    |
------------------------------------
-------------------------------------
| approxkl           | 0.0049293423 |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | -0.13        |
| fps                | 22           |
| n_updates          | 56           |
| policy_entropy     | -0.75333303  |
| policy_loss        | 0.0021568488 |
| serial_timesteps   | 7168         |
| time_elapsed       | 375          |
| total_timesteps    | 7168         |
| value_loss         | 103.5974     |
-------------------------------------
-------------------------------------
| approxkl           | 0.01805153   |
| clipfrac           | 0.21484375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | -0.539       |
| fps                | 19           |
| n_updates          | 57           |
| policy_entropy     | -0.75351566  |
| policy_loss        | -0.007896051 |
| serial_timesteps   | 7296         |
| time_elapsed       | 381          |
| total_timesteps    | 7296         |
| value_loss         | 15.338616    |
-------------------------------------
-------------------------------------
| approxkl           | 0.006671479  |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | 0.0302       |
| fps                | 19           |
| n_updates          | 58           |
| policy_entropy     | -0.75293523  |
| policy_loss        | -0.002477597 |
| serial_timesteps   | 7424         |
| time_elapsed       | 388          |
| total_timesteps    | 7424         |
| value_loss         | 16.754017    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0065250774 |
| clipfrac           | 0.080078125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.71e+03     |
| explained_variance | -0.000796    |
| fps                | 20           |
| n_updates          | 59           |
| policy_entropy     | -0.75253683  |
| policy_loss        | 0.0022066482 |
| serial_timesteps   | 7552         |
| time_elapsed       | 394          |
| total_timesteps    | 7552         |
| value_loss         | 856.4682     |
-------------------------------------
------------------------------------
| approxkl           | 0.035563547 |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.71e+03    |
| explained_variance | -0.15       |
| fps                | 20          |
| n_updates          | 60          |
| policy_entropy     | -0.7513191  |
| policy_loss        | 0.016591568 |
| serial_timesteps   | 7680        |
| time_elapsed       | 400         |
| total_timesteps    | 7680        |
| value_loss         | 70.407486   |
------------------------------------
An average of 293.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.022003017  |
| clipfrac           | 0.23828125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | 0.00281      |
| fps                | 21           |
| n_updates          | 61           |
| policy_entropy     | -0.75102293  |
| policy_loss        | 0.0106273675 |
| serial_timesteps   | 7808         |
| time_elapsed       | 407          |
| total_timesteps    | 7808         |
| value_loss         | 6623.7363    |
-------------------------------------
------------------------------------
| approxkl           | 0.015142825 |
| clipfrac           | 0.18359375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.0734      |
| fps                | 20          |
| n_updates          | 62          |
| policy_entropy     | -0.7507248  |
| policy_loss        | 0.011728531 |
| serial_timesteps   | 7936        |
| time_elapsed       | 413         |
| total_timesteps    | 7936        |
| value_loss         | 79.86046    |
------------------------------------
------------------------------------
| approxkl           | 0.018555952 |
| clipfrac           | 0.22265625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.549      |
| fps                | 22          |
| n_updates          | 63          |
| policy_entropy     | -0.7502621  |
| policy_loss        | 0.017661836 |
| serial_timesteps   | 8064        |
| time_elapsed       | 419         |
| total_timesteps    | 8064        |
| value_loss         | 205.69214   |
------------------------------------
------------------------------------
| approxkl           | 0.02750745  |
| clipfrac           | 0.23828125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.0769      |
| fps                | 23          |
| n_updates          | 64          |
| policy_entropy     | -0.7511321  |
| policy_loss        | 0.015602586 |
| serial_timesteps   | 8192        |
| time_elapsed       | 424         |
| total_timesteps    | 8192        |
| value_loss         | 54.61171    |
------------------------------------
------------------------------------
| approxkl           | 0.019356305 |
| clipfrac           | 0.22265625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.0125     |
| fps                | 22          |
| n_updates          | 65          |
| policy_entropy     | -0.7521261  |
| policy_loss        | 0.017530035 |
| serial_timesteps   | 8320        |
| time_elapsed       | 430         |
| total_timesteps    | 8320        |
| value_loss         | 148.61499   |
------------------------------------
--------------------------------------
| approxkl           | 0.0157159     |
| clipfrac           | 0.21289062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.75e+03      |
| explained_variance | 0.0438        |
| fps                | 23            |
| n_updates          | 66            |
| policy_entropy     | -0.75273466   |
| policy_loss        | -0.0043800515 |
| serial_timesteps   | 8448          |
| time_elapsed       | 436           |
| total_timesteps    | 8448          |
| value_loss         | 171.66748     |
--------------------------------------
------------------------------------
| approxkl           | 0.03367078  |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.00188     |
| fps                | 21          |
| n_updates          | 67          |
| policy_entropy     | -0.75183946 |
| policy_loss        | 0.035208862 |
| serial_timesteps   | 8576        |
| time_elapsed       | 441         |
| total_timesteps    | 8576        |
| value_loss         | 56.16353    |
------------------------------------
An average of 294.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.014591229   |
| clipfrac           | 0.18945312    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.75e+03      |
| explained_variance | 0.369         |
| fps                | 20            |
| n_updates          | 68            |
| policy_entropy     | -0.75165147   |
| policy_loss        | -0.0006596055 |
| serial_timesteps   | 8704          |
| time_elapsed       | 447           |
| total_timesteps    | 8704          |
| value_loss         | 5.329889      |
--------------------------------------
-------------------------------------
| approxkl           | 0.019036427  |
| clipfrac           | 0.21289062   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | 0.126        |
| fps                | 22           |
| n_updates          | 69           |
| policy_entropy     | -0.75220597  |
| policy_loss        | 0.0058508003 |
| serial_timesteps   | 8832         |
| time_elapsed       | 453          |
| total_timesteps    | 8832         |
| value_loss         | 14.267407    |
-------------------------------------
------------------------------------
| approxkl           | 0.019021932 |
| clipfrac           | 0.20507812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.312      |
| fps                | 22          |
| n_updates          | 70          |
| policy_entropy     | -0.7526081  |
| policy_loss        | 0.008969493 |
| serial_timesteps   | 8960        |
| time_elapsed       | 459         |
| total_timesteps    | 8960        |
| value_loss         | 8.27425     |
------------------------------------
------------------------------------
| approxkl           | 0.06513825  |
| clipfrac           | 0.40820312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.0448     |
| fps                | 20          |
| n_updates          | 71          |
| policy_entropy     | -0.75282615 |
| policy_loss        | 0.03319633  |
| serial_timesteps   | 9088        |
| time_elapsed       | 465         |
| total_timesteps    | 9088        |
| value_loss         | 173.98523   |
------------------------------------
-------------------------------------
| approxkl           | 0.0026579015 |
| clipfrac           | 0.017578125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | -0.29        |
| fps                | 19           |
| n_updates          | 72           |
| policy_entropy     | -0.7525617   |
| policy_loss        | 0.0036751397 |
| serial_timesteps   | 9216         |
| time_elapsed       | 471          |
| total_timesteps    | 9216         |
| value_loss         | 15.687139    |
-------------------------------------
------------------------------------
| approxkl           | 0.013433126 |
| clipfrac           | 0.16601562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | -0.00852    |
| fps                | 20          |
| n_updates          | 73          |
| policy_entropy     | -0.7523623  |
| policy_loss        | 0.009063722 |
| serial_timesteps   | 9344        |
| time_elapsed       | 477         |
| total_timesteps    | 9344        |
| value_loss         | 5943.053    |
------------------------------------
------------------------------------
| approxkl           | 0.03481953  |
| clipfrac           | 0.26757812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | -0.0232     |
| fps                | 20          |
| n_updates          | 74          |
| policy_entropy     | -0.7518602  |
| policy_loss        | 0.016746843 |
| serial_timesteps   | 9472        |
| time_elapsed       | 484         |
| total_timesteps    | 9472        |
| value_loss         | 875.45984   |
------------------------------------
------------------------------------
| approxkl           | 0.059926324 |
| clipfrac           | 0.4921875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | -0.0924     |
| fps                | 19          |
| n_updates          | 75          |
| policy_entropy     | -0.7502933  |
| policy_loss        | 0.05085453  |
| serial_timesteps   | 9600        |
| time_elapsed       | 490         |
| total_timesteps    | 9600        |
| value_loss         | 51.88179    |
------------------------------------
An average of 295.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.06375672  |
| clipfrac           | 0.43945312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 0.0715      |
| fps                | 21          |
| n_updates          | 76          |
| policy_entropy     | -0.75008404 |
| policy_loss        | 0.03547643  |
| serial_timesteps   | 9728        |
| time_elapsed       | 496         |
| total_timesteps    | 9728        |
| value_loss         | 93.64525    |
------------------------------------
------------------------------------
| approxkl           | 0.020504156 |
| clipfrac           | 0.21679688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 0.0323      |
| fps                | 21          |
| n_updates          | 77          |
| policy_entropy     | -0.7500699  |
| policy_loss        | 0.01406293  |
| serial_timesteps   | 9856        |
| time_elapsed       | 502         |
| total_timesteps    | 9856        |
| value_loss         | 46.843597   |
------------------------------------
-------------------------------------
| approxkl           | 0.0064124614 |
| clipfrac           | 0.087890625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.77e+03     |
| explained_variance | -0.632       |
| fps                | 21           |
| n_updates          | 78           |
| policy_entropy     | -0.7502669   |
| policy_loss        | 0.0050190915 |
| serial_timesteps   | 9984         |
| time_elapsed       | 508          |
| total_timesteps    | 9984         |
| value_loss         | 194.07597    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01170339   |
| clipfrac           | 0.13085938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.77e+03     |
| explained_variance | 0.243        |
| fps                | 21           |
| n_updates          | 79           |
| policy_entropy     | -0.75016767  |
| policy_loss        | 0.0065057566 |
| serial_timesteps   | 10112        |
| time_elapsed       | 514          |
| total_timesteps    | 10112        |
| value_loss         | 43.74831     |
-------------------------------------
---------------------------------------
| approxkl           | 0.043718357    |
| clipfrac           | 0.29296875     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.77e+03       |
| explained_variance | -0.0762        |
| fps                | 23             |
| n_updates          | 80             |
| policy_entropy     | -0.75035626    |
| policy_loss        | -0.00041735824 |
| serial_timesteps   | 10240          |
| time_elapsed       | 520            |
| total_timesteps    | 10240          |
| value_loss         | 134.37335      |
---------------------------------------
--------------------------------------
| approxkl           | 0.008722977   |
| clipfrac           | 0.119140625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.77e+03      |
| explained_variance | -0.0662       |
| fps                | 21            |
| n_updates          | 81            |
| policy_entropy     | -0.7502252    |
| policy_loss        | -0.0073677823 |
| serial_timesteps   | 10368         |
| time_elapsed       | 526           |
| total_timesteps    | 10368         |
| value_loss         | 150.13794     |
--------------------------------------
--------------------------------------
| approxkl           | 0.0026843008  |
| clipfrac           | 0.03125       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.77e+03      |
| explained_variance | -0.116        |
| fps                | 22            |
| n_updates          | 82            |
| policy_entropy     | -0.75041264   |
| policy_loss        | 0.00058479444 |
| serial_timesteps   | 10496         |
| time_elapsed       | 532           |
| total_timesteps    | 10496         |
| value_loss         | 27.453077     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0056887483 |
| clipfrac           | 0.07421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.77e+03     |
| explained_variance | 0.303        |
| fps                | 20           |
| n_updates          | 83           |
| policy_entropy     | -0.749436    |
| policy_loss        | 0.0029990475 |
| serial_timesteps   | 10624        |
| time_elapsed       | 537          |
| total_timesteps    | 10624        |
| value_loss         | 16.746298    |
-------------------------------------
An average of 295.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.009619331 |
| clipfrac           | 0.107421875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.77e+03    |
| explained_variance | 0.198       |
| fps                | 21          |
| n_updates          | 84          |
| policy_entropy     | -0.74862766 |
| policy_loss        | 0.008645225 |
| serial_timesteps   | 10752       |
| time_elapsed       | 544         |
| total_timesteps    | 10752       |
| value_loss         | 11.0381155  |
------------------------------------
--------------------------------------
| approxkl           | 0.0079853255  |
| clipfrac           | 0.111328125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.75e+03      |
| explained_variance | 0.0306        |
| fps                | 21            |
| n_updates          | 85            |
| policy_entropy     | -0.75053775   |
| policy_loss        | -0.0020809541 |
| serial_timesteps   | 10880         |
| time_elapsed       | 550           |
| total_timesteps    | 10880         |
| value_loss         | 5511.0405     |
--------------------------------------
---------------------------------------
| approxkl           | 0.0043265326   |
| clipfrac           | 0.060546875    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 5.75e+03       |
| explained_variance | -0.0247        |
| fps                | 20             |
| n_updates          | 86             |
| policy_entropy     | -0.7510459     |
| policy_loss        | -0.00031821313 |
| serial_timesteps   | 11008          |
| time_elapsed       | 556            |
| total_timesteps    | 11008          |
| value_loss         | 119.88661      |
---------------------------------------
------------------------------------
| approxkl           | 0.005529321 |
| clipfrac           | 0.060546875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.257      |
| fps                | 18          |
| n_updates          | 87          |
| policy_entropy     | -0.7507395  |
| policy_loss        | 0.005271745 |
| serial_timesteps   | 11136       |
| time_elapsed       | 562         |
| total_timesteps    | 11136       |
| value_loss         | 15.757317   |
------------------------------------
-------------------------------------
| approxkl           | 0.016408974  |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | 0.178        |
| fps                | 20           |
| n_updates          | 88           |
| policy_entropy     | -0.7497507   |
| policy_loss        | 0.0029601227 |
| serial_timesteps   | 11264        |
| time_elapsed       | 569          |
| total_timesteps    | 11264        |
| value_loss         | 10.940381    |
-------------------------------------
------------------------------------
| approxkl           | 0.036436204 |
| clipfrac           | 0.37695312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.0155     |
| fps                | 20          |
| n_updates          | 89          |
| policy_entropy     | -0.7482283  |
| policy_loss        | 0.029335203 |
| serial_timesteps   | 11392       |
| time_elapsed       | 575         |
| total_timesteps    | 11392       |
| value_loss         | 916.298     |
------------------------------------
------------------------------------
| approxkl           | 0.042939536 |
| clipfrac           | 0.3671875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.0556     |
| fps                | 20          |
| n_updates          | 90          |
| policy_entropy     | -0.74805224 |
| policy_loss        | 0.03482189  |
| serial_timesteps   | 11520       |
| time_elapsed       | 581         |
| total_timesteps    | 11520       |
| value_loss         | 61.475807   |
------------------------------------
------------------------------------
| approxkl           | 0.018395526 |
| clipfrac           | 0.17382812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.159       |
| fps                | 22          |
| n_updates          | 91          |
| policy_entropy     | -0.7481875  |
| policy_loss        | 0.018834686 |
| serial_timesteps   | 11648       |
| time_elapsed       | 587         |
| total_timesteps    | 11648       |
| value_loss         | 78.62842    |
------------------------------------
An average of 296.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.04780645  |
| clipfrac           | 0.30664062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.134       |
| fps                | 21          |
| n_updates          | 92          |
| policy_entropy     | -0.7492602  |
| policy_loss        | 0.009624996 |
| serial_timesteps   | 11776       |
| time_elapsed       | 593         |
| total_timesteps    | 11776       |
| value_loss         | 93.95235    |
------------------------------------
-------------------------------------
| approxkl           | 0.009280859  |
| clipfrac           | 0.12695312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.75e+03     |
| explained_variance | -1.11        |
| fps                | 21           |
| n_updates          | 93           |
| policy_entropy     | -0.7497636   |
| policy_loss        | -0.003799489 |
| serial_timesteps   | 11904        |
| time_elapsed       | 599          |
| total_timesteps    | 11904        |
| value_loss         | 130.19522    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0061176093  |
| clipfrac           | 0.076171875   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.75e+03      |
| explained_variance | 0.157         |
| fps                | 22            |
| n_updates          | 94            |
| policy_entropy     | -0.7495849    |
| policy_loss        | -8.670543e-05 |
| serial_timesteps   | 12032         |
| time_elapsed       | 605           |
| total_timesteps    | 12032         |
| value_loss         | 50.61964      |
--------------------------------------
------------------------------------
| approxkl           | 0.041556846 |
| clipfrac           | 0.29882812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | -0.109      |
| fps                | 22          |
| n_updates          | 95          |
| policy_entropy     | -0.74891406 |
| policy_loss        | 0.028080665 |
| serial_timesteps   | 12160       |
| time_elapsed       | 610         |
| total_timesteps    | 12160       |
| value_loss         | 165.07954   |
------------------------------------
------------------------------------
| approxkl           | 0.015370213 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.75e+03    |
| explained_variance | 0.0186      |
| fps                | 21          |
| n_updates          | 96          |
| policy_entropy     | -0.748757   |
| policy_loss        | 0.01276971  |
| serial_timesteps   | 12288       |
| time_elapsed       | 616         |
| total_timesteps    | 12288       |
| value_loss         | 105.18297   |
------------------------------------
------------------------------------
| approxkl           | 0.109658904 |
| clipfrac           | 0.48242188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -0.0121     |
| fps                | 20          |
| n_updates          | 97          |
| policy_entropy     | -0.74842465 |
| policy_loss        | 0.077259935 |
| serial_timesteps   | 12416       |
| time_elapsed       | 622         |
| total_timesteps    | 12416       |
| value_loss         | 5758.8433   |
------------------------------------
-------------------------------------
| approxkl           | 0.006067537  |
| clipfrac           | 0.05859375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | 0.37         |
| fps                | 21           |
| n_updates          | 98           |
| policy_entropy     | -0.7482353   |
| policy_loss        | 0.0022122958 |
| serial_timesteps   | 12544        |
| time_elapsed       | 628          |
| total_timesteps    | 12544        |
| value_loss         | 9.9533825    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0036540532 |
| clipfrac           | 0.04296875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | -0.105       |
| fps                | 22           |
| n_updates          | 99           |
| policy_entropy     | -0.74863285  |
| policy_loss        | 0.004224669  |
| serial_timesteps   | 12672        |
| time_elapsed       | 634          |
| total_timesteps    | 12672        |
| value_loss         | 20.491844    |
-------------------------------------
An average of 297.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.03404111  |
| clipfrac           | 0.265625    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -1.17       |
| fps                | 21          |
| n_updates          | 100         |
| policy_entropy     | -0.75032604 |
| policy_loss        | 0.02313473  |
| serial_timesteps   | 12800       |
| time_elapsed       | 640         |
| total_timesteps    | 12800       |
| value_loss         | 18.96989    |
------------------------------------
------------------------------------
| approxkl           | 0.046060927 |
| clipfrac           | 0.36328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 0.0272      |
| fps                | 21          |
| n_updates          | 101         |
| policy_entropy     | -0.7516559  |
| policy_loss        | 0.010679787 |
| serial_timesteps   | 12928       |
| time_elapsed       | 646         |
| total_timesteps    | 12928       |
| value_loss         | 107.68836   |
------------------------------------
------------------------------------
| approxkl           | 0.011176338 |
| clipfrac           | 0.11328125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | -0.0506     |
| fps                | 20          |
| n_updates          | 102         |
| policy_entropy     | -0.7519105  |
| policy_loss        | 0.00801364  |
| serial_timesteps   | 13056       |
| time_elapsed       | 652         |
| total_timesteps    | 13056       |
| value_loss         | 14.353466   |
------------------------------------
-------------------------------------
| approxkl           | 0.026994698  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | -0.206       |
| fps                | 19           |
| n_updates          | 103          |
| policy_entropy     | -0.7523864   |
| policy_loss        | -0.008541324 |
| serial_timesteps   | 13184        |
| time_elapsed       | 658          |
| total_timesteps    | 13184        |
| value_loss         | 37.56483     |
-------------------------------------
------------------------------------
| approxkl           | 0.02453056  |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 0.0303      |
| fps                | 20          |
| n_updates          | 104         |
| policy_entropy     | -0.7529674  |
| policy_loss        | 0.009086672 |
| serial_timesteps   | 13312       |
| time_elapsed       | 665         |
| total_timesteps    | 13312       |
| value_loss         | 494.27576   |
------------------------------------
------------------------------------
| approxkl           | 0.016189035 |
| clipfrac           | 0.22851562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 0.0629      |
| fps                | 21          |
| n_updates          | 105         |
| policy_entropy     | -0.7526517  |
| policy_loss        | 0.009246275 |
| serial_timesteps   | 13440       |
| time_elapsed       | 671         |
| total_timesteps    | 13440       |
| value_loss         | 74.8542     |
------------------------------------
-------------------------------------
| approxkl           | 0.01390214   |
| clipfrac           | 0.16601562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | 0.0414       |
| fps                | 21           |
| n_updates          | 106          |
| policy_entropy     | -0.75280756  |
| policy_loss        | -0.009110691 |
| serial_timesteps   | 13568        |
| time_elapsed       | 677          |
| total_timesteps    | 13568        |
| value_loss         | 93.40556     |
-------------------------------------
------------------------------------
| approxkl           | 0.022798017 |
| clipfrac           | 0.23828125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.72e+03    |
| explained_variance | 0.173       |
| fps                | 22          |
| n_updates          | 107         |
| policy_entropy     | -0.7522288  |
| policy_loss        | 0.014614794 |
| serial_timesteps   | 13696       |
| time_elapsed       | 683         |
| total_timesteps    | 13696       |
| value_loss         | 92.36761    |
------------------------------------
An average of 297.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0043327156 |
| clipfrac           | 0.044921875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.72e+03     |
| explained_variance | -0.523       |
| fps                | 22           |
| n_updates          | 108          |
| policy_entropy     | -0.75122505  |
| policy_loss        | 0.002043088  |
| serial_timesteps   | 13824        |
| time_elapsed       | 689          |
| total_timesteps    | 13824        |
| value_loss         | 91.20353     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0077543138  |
| clipfrac           | 0.09375       |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 5.74e+03      |
| explained_variance | -0.0104       |
| fps                | 22            |
| n_updates          | 109           |
| policy_entropy     | -0.75089145   |
| policy_loss        | -0.0033795866 |
| serial_timesteps   | 13952         |
| time_elapsed       | 694           |
| total_timesteps    | 13952         |
| value_loss         | 5656.465      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008559492  |
| clipfrac           | 0.111328125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.74e+03     |
| explained_variance | 0.0658       |
| fps                | 21           |
| n_updates          | 110          |
| policy_entropy     | -0.7513915   |
| policy_loss        | 0.0007037418 |
| serial_timesteps   | 14080        |
| time_elapsed       | 700          |
| total_timesteps    | 14080        |
| value_loss         | 185.02701    |
-------------------------------------
-------------------------------------
| approxkl           | 0.014044995  |
| clipfrac           | 0.15625      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.74e+03     |
| explained_variance | -0.147       |
| fps                | 22           |
| n_updates          | 111          |
| policy_entropy     | -0.75289524  |
| policy_loss        | 0.0042927656 |
| serial_timesteps   | 14208        |
| time_elapsed       | 706          |
| total_timesteps    | 14208        |
| value_loss         | 91.68863     |
-------------------------------------
-------------------------------------
| approxkl           | 0.007020586  |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.74e+03     |
| explained_variance | -2.35        |
| fps                | 19           |
| n_updates          | 112          |
| policy_entropy     | -0.7535087   |
| policy_loss        | 0.0026372313 |
| serial_timesteps   | 14336        |
| time_elapsed       | 712          |
| total_timesteps    | 14336        |
| value_loss         | 29.595148    |
-------------------------------------
-------------------------------------
| approxkl           | 0.044489257  |
| clipfrac           | 0.32421875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.74e+03     |
| explained_variance | 0.16         |
| fps                | 20           |
| n_updates          | 113          |
| policy_entropy     | -0.75463164  |
| policy_loss        | -0.010466748 |
| serial_timesteps   | 14464        |
| time_elapsed       | 718          |
| total_timesteps    | 14464        |
| value_loss         | 14.068586    |
-------------------------------------
-------------------------------------
| approxkl           | 0.029962225  |
| clipfrac           | 0.27148438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.74e+03     |
| explained_variance | 0.209        |
| fps                | 20           |
| n_updates          | 114          |
| policy_entropy     | -0.75517434  |
| policy_loss        | 0.0148623735 |
| serial_timesteps   | 14592        |
| time_elapsed       | 724          |
| total_timesteps    | 14592        |
| value_loss         | 23.276285    |
-------------------------------------
An average of 298.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.010826832 |
| clipfrac           | 0.111328125 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.74e+03    |
| explained_variance | -0.575      |
| fps                | 22          |
| n_updates          | 115         |
| policy_entropy     | -0.754582   |
| policy_loss        | 0.005997035 |
| serial_timesteps   | 14720       |
| time_elapsed       | 730         |
| total_timesteps    | 14720       |
| value_loss         | 27.001558   |
------------------------------------
-------------------------------------
| approxkl           | 0.01248084   |
| clipfrac           | 0.16210938   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 5.74e+03     |
| explained_variance | 0.0257       |
| fps                | 19           |
| n_updates          | 116          |
| policy_entropy     | -0.75418293  |
| policy_loss        | -0.018347815 |
| serial_timesteps   | 14848        |
| time_elapsed       | 736          |
| total_timesteps    | 14848        |
| value_loss         | 107.109856   |
-------------------------------------
------------------------------------
| approxkl           | 0.005532266 |
| clipfrac           | 0.0546875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 5.74e+03    |
| explained_variance | -0.113      |
| fps                | 19          |
| n_updates          | 117         |
| policy_entropy     | -0.7538447  |
| policy_loss        | 0.002134531 |
| serial_timesteps   | 14976       |
| time_elapsed       | 742         |
| total_timesteps    | 14976       |
| value_loss         | 15.913462   |
------------------------------------
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b2a44d908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b2a44d908>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b28be3668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b28be3668>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Train on 2386 samples, validate on 34 samples
Epoch 551/5000
 - 11s - loss: 0.2313 - val_loss: 0.0207
Epoch 552/5000
 - 1s - loss: 0.2313 - val_loss: 0.0207
Epoch 553/5000
 - 1s - loss: 0.2313 - val_loss: 0.0207
Epoch 554/5000
 - 1s - loss: 0.2313 - val_loss: 0.0207
Epoch 555/5000
 - 1s - loss: 0.2313 - val_loss: 0.0207
Epoch 556/5000
 - 1s - loss: 0.2313 - val_loss: 0.0207
Train on 1985 samples, validate on 34 samples
Epoch 416/5000
 - 11s - loss: 0.0125 - val_loss: 0.0379
Epoch 417/5000
 - 1s - loss: 0.0136 - val_loss: 0.0400
Epoch 418/5000
 - 1s - loss: 0.0119 - val_loss: 0.0311
Epoch 419/5000
 - 1s - loss: 0.0096 - val_loss: 0.0210
Epoch 420/5000
 - 1s - loss: 0.0076 - val_loss: 0.0155
Epoch 421/5000
 - 1s - loss: 0.0072 - val_loss: 0.0145
Epoch 422/5000
 - 1s - loss: 0.0070 - val_loss: 0.0150
Epoch 423/5000
 - 1s - loss: 0.0065 - val_loss: 0.0128
Epoch 424/5000
 - 1s - loss: 0.0061 - val_loss: 0.0130
Epoch 425/5000
 - 1s - loss: 0.0053 - val_loss: 0.0100
Epoch 426/5000
 - 0s - loss: 0.0052 - val_loss: 0.0107
Epoch 427/5000
 - 1s - loss: 0.0057 - val_loss: 0.0138
Epoch 428/5000
 - 1s - loss: 0.0055 - val_loss: 0.0078
Epoch 429/5000
 - 0s - loss: 0.0038 - val_loss: 0.0062
Epoch 430/5000
 - 1s - loss: 0.0034 - val_loss: 0.0055
Epoch 431/5000
 - 1s - loss: 0.0031 - val_loss: 0.0052
Epoch 432/5000
 - 1s - loss: 0.0030 - val_loss: 0.0050
Epoch 433/5000
 - 1s - loss: 0.0029 - val_loss: 0.0048
Epoch 434/5000
 - 1s - loss: 0.0029 - val_loss: 0.0046
Epoch 435/5000
 - 1s - loss: 0.0029 - val_loss: 0.0045
Epoch 436/5000
 - 1s - loss: 0.0028 - val_loss: 0.0045
Epoch 437/5000
 - 1s - loss: 0.0028 - val_loss: 0.0044
Epoch 438/5000
 - 1s - loss: 0.0028 - val_loss: 0.0044
Epoch 439/5000
 - 1s - loss: 0.0028 - val_loss: 0.0044
Epoch 440/5000
 - 1s - loss: 0.0027 - val_loss: 0.0043
Epoch 441/5000
 - 1s - loss: 0.0027 - val_loss: 0.0043
Epoch 442/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 443/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 444/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 445/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 446/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 447/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 448/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 449/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 450/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 451/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 452/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 453/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 454/5000
 - 0s - loss: 0.0027 - val_loss: 0.0042
Epoch 455/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 456/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 457/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 458/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 459/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 460/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 461/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 462/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 463/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Epoch 464/5000
 - 1s - loss: 0.0027 - val_loss: 0.0042
Train on 2504 samples, validate on 34 samples
Epoch 1388/5000
 - 12s - loss: 0.6763 - val_loss: 0.7268
Epoch 1389/5000
 - 1s - loss: 0.6456 - val_loss: 0.7596
Epoch 1390/5000
 - 1s - loss: 0.6203 - val_loss: 0.7922
Epoch 1391/5000
 - 1s - loss: 0.6070 - val_loss: 0.7954
Epoch 1392/5000
 - 1s - loss: 0.6049 - val_loss: 0.7986
Epoch 1393/5000
 - 1s - loss: 0.6029 - val_loss: 0.8019
setting environment to train mode..... 

Training Started... 

-------------------------------------
| approxkl           | 0.005281156  |
| clipfrac           | 0.064453125  |
| explained_variance | -1.61        |
| fps                | 2            |
| n_updates          | 1            |
| policy_entropy     | -0.7550426   |
| policy_loss        | -0.005093067 |
| serial_timesteps   | 128          |
| time_elapsed       | 2.38e-05     |
| total_timesteps    | 128          |
| value_loss         | 28.414349    |
-------------------------------------
------------------------------------
| approxkl           | 0.023975676 |
| clipfrac           | 0.26953125  |
| explained_variance | -0.0255     |
| fps                | 18          |
| n_updates          | 2           |
| policy_entropy     | -0.75536585 |
| policy_loss        | 0.019015022 |
| serial_timesteps   | 256         |
| time_elapsed       | 54.2        |
| total_timesteps    | 256         |
| value_loss         | 52.62677    |
------------------------------------
------------------------------------
| approxkl           | 0.008963238 |
| clipfrac           | 0.111328125 |
| explained_variance | -0.525      |
| fps                | 18          |
| n_updates          | 3           |
| policy_entropy     | -0.7552871  |
| policy_loss        | 0.005961804 |
| serial_timesteps   | 384         |
| time_elapsed       | 61.2        |
| total_timesteps    | 384         |
| value_loss         | 88.37887    |
------------------------------------
------------------------------------
| approxkl           | 0.012809149 |
| clipfrac           | 0.140625    |
| explained_variance | -0.845      |
| fps                | 18          |
| n_updates          | 4           |
| policy_entropy     | -0.7571101  |
| policy_loss        | 0.010279223 |
| serial_timesteps   | 512         |
| time_elapsed       | 68          |
| total_timesteps    | 512         |
| value_loss         | 89.36205    |
------------------------------------
--------------------------------------
| approxkl           | 0.018946694   |
| clipfrac           | 0.19921875    |
| explained_variance | -0.331        |
| fps                | 19            |
| n_updates          | 5             |
| policy_entropy     | -0.75745267   |
| policy_loss        | -0.0066446904 |
| serial_timesteps   | 640           |
| time_elapsed       | 75            |
| total_timesteps    | 640           |
| value_loss         | 63.028755     |
--------------------------------------
An average of 299.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.009909085  |
| clipfrac           | 0.123046875  |
| explained_variance | -0.309       |
| fps                | 18           |
| n_updates          | 6            |
| policy_entropy     | -0.7559693   |
| policy_loss        | 0.0048838686 |
| serial_timesteps   | 768          |
| time_elapsed       | 81.7         |
| total_timesteps    | 768          |
| value_loss         | 42.98891     |
-------------------------------------
--------------------------------------
| approxkl           | 0.012387647   |
| clipfrac           | 0.14648438    |
| explained_variance | -0.0994       |
| fps                | 18            |
| n_updates          | 7             |
| policy_entropy     | -0.75620955   |
| policy_loss        | -0.0057630395 |
| serial_timesteps   | 896           |
| time_elapsed       | 88.7          |
| total_timesteps    | 896           |
| value_loss         | 43.03134      |
--------------------------------------
------------------------------------
| approxkl           | 0.014414389 |
| clipfrac           | 0.20703125  |
| explained_variance | -0.2        |
| fps                | 18          |
| n_updates          | 8           |
| policy_entropy     | -0.7562215  |
| policy_loss        | 0.005729068 |
| serial_timesteps   | 1024        |
| time_elapsed       | 95.4        |
| total_timesteps    | 1024        |
| value_loss         | 37.95751    |
------------------------------------
------------------------------------
| approxkl           | 0.021781502 |
| clipfrac           | 0.21679688  |
| explained_variance | -0.216      |
| fps                | 18          |
| n_updates          | 9           |
| policy_entropy     | -0.7560093  |
| policy_loss        | 0.020324694 |
| serial_timesteps   | 1152        |
| time_elapsed       | 102         |
| total_timesteps    | 1152        |
| value_loss         | 43.661777   |
------------------------------------
-------------------------------------
| approxkl           | 0.005665108  |
| clipfrac           | 0.072265625  |
| explained_variance | 0.118        |
| fps                | 18           |
| n_updates          | 10           |
| policy_entropy     | -0.7551179   |
| policy_loss        | 0.0008730821 |
| serial_timesteps   | 1280         |
| time_elapsed       | 109          |
| total_timesteps    | 1280         |
| value_loss         | 60.126804    |
-------------------------------------
------------------------------------
| approxkl           | 0.014114305 |
| clipfrac           | 0.19140625  |
| explained_variance | 0.0921      |
| fps                | 18          |
| n_updates          | 11          |
| policy_entropy     | -0.75342125 |
| policy_loss        | 0.012686641 |
| serial_timesteps   | 1408        |
| time_elapsed       | 116         |
| total_timesteps    | 1408        |
| value_loss         | 38.87029    |
------------------------------------
------------------------------------
| approxkl           | 0.038232416 |
| clipfrac           | 0.28320312  |
| explained_variance | -0.017      |
| fps                | 18          |
| n_updates          | 12          |
| policy_entropy     | -0.75398606 |
| policy_loss        | 0.022139855 |
| serial_timesteps   | 1536        |
| time_elapsed       | 123         |
| total_timesteps    | 1536        |
| value_loss         | 84.99005    |
------------------------------------
-------------------------------------
| approxkl           | 0.009679283  |
| clipfrac           | 0.15429688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | 0.00802      |
| fps                | 18           |
| n_updates          | 13           |
| policy_entropy     | -0.75477153  |
| policy_loss        | 0.0022120685 |
| serial_timesteps   | 1664         |
| time_elapsed       | 130          |
| total_timesteps    | 1664         |
| value_loss         | 3727.236     |
-------------------------------------
An average of 300.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.023284955 |
| clipfrac           | 0.1796875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.0633     |
| fps                | 19          |
| n_updates          | 14          |
| policy_entropy     | -0.7550993  |
| policy_loss        | 0.019678356 |
| serial_timesteps   | 1792        |
| time_elapsed       | 137         |
| total_timesteps    | 1792        |
| value_loss         | 70.614044   |
------------------------------------
------------------------------------
| approxkl           | 0.017482823 |
| clipfrac           | 0.17578125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.163       |
| fps                | 18          |
| n_updates          | 15          |
| policy_entropy     | -0.75491726 |
| policy_loss        | 0.008297509 |
| serial_timesteps   | 1920        |
| time_elapsed       | 143         |
| total_timesteps    | 1920        |
| value_loss         | 53.78986    |
------------------------------------
------------------------------------
| approxkl           | 0.02032188  |
| clipfrac           | 0.26757812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.0576     |
| fps                | 18          |
| n_updates          | 16          |
| policy_entropy     | -0.75415015 |
| policy_loss        | 0.032286096 |
| serial_timesteps   | 2048        |
| time_elapsed       | 150         |
| total_timesteps    | 2048        |
| value_loss         | 3.9490256   |
------------------------------------
------------------------------------
| approxkl           | 0.10529738  |
| clipfrac           | 0.5234375   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.00298     |
| fps                | 19          |
| n_updates          | 17          |
| policy_entropy     | -0.7534278  |
| policy_loss        | 0.044938445 |
| serial_timesteps   | 2176        |
| time_elapsed       | 157         |
| total_timesteps    | 2176        |
| value_loss         | 53.908173   |
------------------------------------
------------------------------------
| approxkl           | 0.033799976 |
| clipfrac           | 0.34179688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.102       |
| fps                | 18          |
| n_updates          | 18          |
| policy_entropy     | -0.7525919  |
| policy_loss        | 0.035476737 |
| serial_timesteps   | 2304        |
| time_elapsed       | 164         |
| total_timesteps    | 2304        |
| value_loss         | 52.26645    |
------------------------------------
--------------------------------------
| approxkl           | 0.007816818   |
| clipfrac           | 0.109375      |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.44e+03      |
| explained_variance | -0.459        |
| fps                | 19            |
| n_updates          | 19            |
| policy_entropy     | -0.75274754   |
| policy_loss        | -0.0017987065 |
| serial_timesteps   | 2432          |
| time_elapsed       | 171           |
| total_timesteps    | 2432          |
| value_loss         | 71.78954      |
--------------------------------------
-------------------------------------
| approxkl           | 0.008269515  |
| clipfrac           | 0.09375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | 0.209        |
| fps                | 19           |
| n_updates          | 20           |
| policy_entropy     | -0.7530263   |
| policy_loss        | 0.0044117123 |
| serial_timesteps   | 2560         |
| time_elapsed       | 177          |
| total_timesteps    | 2560         |
| value_loss         | 36.85628     |
-------------------------------------
------------------------------------
| approxkl           | 0.060679346 |
| clipfrac           | 0.33984375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.0359      |
| fps                | 18          |
| n_updates          | 21          |
| policy_entropy     | -0.75184107 |
| policy_loss        | 0.020279532 |
| serial_timesteps   | 2688        |
| time_elapsed       | 184         |
| total_timesteps    | 2688        |
| value_loss         | 35.595726   |
------------------------------------
An average of 300.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.026909115 |
| clipfrac           | 0.27148438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.228      |
| fps                | 18          |
| n_updates          | 22          |
| policy_entropy     | -0.7515221  |
| policy_loss        | 0.02107516  |
| serial_timesteps   | 2816        |
| time_elapsed       | 191         |
| total_timesteps    | 2816        |
| value_loss         | 35.333492   |
------------------------------------
-------------------------------------
| approxkl           | 0.003969421  |
| clipfrac           | 0.0390625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | -0.603       |
| fps                | 19           |
| n_updates          | 23           |
| policy_entropy     | -0.7525659   |
| policy_loss        | -0.007513304 |
| serial_timesteps   | 2944         |
| time_elapsed       | 198          |
| total_timesteps    | 2944         |
| value_loss         | 19.022879    |
-------------------------------------
------------------------------------
| approxkl           | 0.045727797 |
| clipfrac           | 0.328125    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.294      |
| fps                | 18          |
| n_updates          | 24          |
| policy_entropy     | -0.7524601  |
| policy_loss        | 0.01923094  |
| serial_timesteps   | 3072        |
| time_elapsed       | 204         |
| total_timesteps    | 3072        |
| value_loss         | 17.210335   |
------------------------------------
------------------------------------
| approxkl           | 0.017859625 |
| clipfrac           | 0.23828125  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.0062     |
| fps                | 18          |
| n_updates          | 25          |
| policy_entropy     | -0.7511717  |
| policy_loss        | 0.004845136 |
| serial_timesteps   | 3200        |
| time_elapsed       | 211         |
| total_timesteps    | 3200        |
| value_loss         | 5273.3867   |
------------------------------------
------------------------------------
| approxkl           | 0.027045958 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.157       |
| fps                | 18          |
| n_updates          | 26          |
| policy_entropy     | -0.75067675 |
| policy_loss        | 0.011741034 |
| serial_timesteps   | 3328        |
| time_elapsed       | 218         |
| total_timesteps    | 3328        |
| value_loss         | 12.975309   |
------------------------------------
------------------------------------
| approxkl           | 0.03210812  |
| clipfrac           | 0.3125      |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.127       |
| fps                | 18          |
| n_updates          | 27          |
| policy_entropy     | -0.7502427  |
| policy_loss        | 0.019388285 |
| serial_timesteps   | 3456        |
| time_elapsed       | 225         |
| total_timesteps    | 3456        |
| value_loss         | 43.728592   |
------------------------------------
------------------------------------
| approxkl           | 0.016460318 |
| clipfrac           | 0.15820312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.218      |
| fps                | 18          |
| n_updates          | 28          |
| policy_entropy     | -0.74943966 |
| policy_loss        | 0.001780281 |
| serial_timesteps   | 3584        |
| time_elapsed       | 232         |
| total_timesteps    | 3584        |
| value_loss         | 30.404703   |
------------------------------------
-------------------------------------
| approxkl           | 0.0020671517 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | -0.115       |
| fps                | 18           |
| n_updates          | 29           |
| policy_entropy     | -0.7498202   |
| policy_loss        | 0.003752622  |
| serial_timesteps   | 3712         |
| time_elapsed       | 239          |
| total_timesteps    | 3712         |
| value_loss         | 51.10428     |
-------------------------------------
An average of 301.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.029332412 |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | 0.222       |
| fps                | 18          |
| n_updates          | 30          |
| policy_entropy     | -0.7506716  |
| policy_loss        | 0.02000383  |
| serial_timesteps   | 3840        |
| time_elapsed       | 246         |
| total_timesteps    | 3840        |
| value_loss         | 38.187443   |
------------------------------------
-------------------------------------
| approxkl           | 0.025361836  |
| clipfrac           | 0.296875     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | 0.103        |
| fps                | 19           |
| n_updates          | 31           |
| policy_entropy     | -0.75067383  |
| policy_loss        | 0.0110542495 |
| serial_timesteps   | 3968         |
| time_elapsed       | 252          |
| total_timesteps    | 3968         |
| value_loss         | 4.982544     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0018936116 |
| clipfrac           | 0.015625     |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | -0.0662      |
| fps                | 18           |
| n_updates          | 32           |
| policy_entropy     | -0.75098836  |
| policy_loss        | 0.004480632  |
| serial_timesteps   | 4096         |
| time_elapsed       | 259          |
| total_timesteps    | 4096         |
| value_loss         | 20.216463    |
-------------------------------------
------------------------------------
| approxkl           | 0.007832069 |
| clipfrac           | 0.107421875 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.26       |
| fps                | 18          |
| n_updates          | 33          |
| policy_entropy     | -0.753281   |
| policy_loss        | 0.003832237 |
| serial_timesteps   | 4224        |
| time_elapsed       | 266         |
| total_timesteps    | 4224        |
| value_loss         | 27.09252    |
------------------------------------
------------------------------------
| approxkl           | 0.008346019 |
| clipfrac           | 0.10546875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.44e+03    |
| explained_variance | -0.535      |
| fps                | 18          |
| n_updates          | 34          |
| policy_entropy     | -0.7559873  |
| policy_loss        | 0.004417993 |
| serial_timesteps   | 4352        |
| time_elapsed       | 273         |
| total_timesteps    | 4352        |
| value_loss         | 33.542866   |
------------------------------------
--------------------------------------
| approxkl           | 0.011392617   |
| clipfrac           | 0.16992188    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.44e+03      |
| explained_variance | 0.045         |
| fps                | 18            |
| n_updates          | 35            |
| policy_entropy     | -0.7563537    |
| policy_loss        | -0.0059987353 |
| serial_timesteps   | 4480          |
| time_elapsed       | 280           |
| total_timesteps    | 4480          |
| value_loss         | 25.29441      |
--------------------------------------
-------------------------------------
| approxkl           | 0.016928444  |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.44e+03     |
| explained_variance | -0.0384      |
| fps                | 19           |
| n_updates          | 36           |
| policy_entropy     | -0.7572235   |
| policy_loss        | 0.0059473664 |
| serial_timesteps   | 4608         |
| time_elapsed       | 287          |
| total_timesteps    | 4608         |
| value_loss         | 28.402788    |
-------------------------------------
An average of 302.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0147386985 |
| clipfrac           | 0.19726562   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.41e+03     |
| explained_variance | 0.00049      |
| fps                | 18           |
| n_updates          | 37           |
| policy_entropy     | -0.7579194   |
| policy_loss        | 0.0076282616 |
| serial_timesteps   | 4736         |
| time_elapsed       | 293          |
| total_timesteps    | 4736         |
| value_loss         | 5890.9434    |
-------------------------------------
--------------------------------------
| approxkl           | 0.0065348684  |
| clipfrac           | 0.095703125   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.41e+03      |
| explained_variance | -0.603        |
| fps                | 19            |
| n_updates          | 38            |
| policy_entropy     | -0.75822157   |
| policy_loss        | 0.00072771707 |
| serial_timesteps   | 4864          |
| time_elapsed       | 300           |
| total_timesteps    | 4864          |
| value_loss         | 21.164366     |
--------------------------------------
------------------------------------
| approxkl           | 0.015867313 |
| clipfrac           | 0.18554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.41e+03    |
| explained_variance | -0.945      |
| fps                | 19          |
| n_updates          | 39          |
| policy_entropy     | -0.7587505  |
| policy_loss        | 0.011780024 |
| serial_timesteps   | 4992        |
| time_elapsed       | 307         |
| total_timesteps    | 4992        |
| value_loss         | 11.870736   |
------------------------------------
-------------------------------------
| approxkl           | 0.016363084  |
| clipfrac           | 0.20117188   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.41e+03     |
| explained_variance | 0.268        |
| fps                | 18           |
| n_updates          | 40           |
| policy_entropy     | -0.75972885  |
| policy_loss        | -0.018086733 |
| serial_timesteps   | 5120         |
| time_elapsed       | 314          |
| total_timesteps    | 5120         |
| value_loss         | 9.410254     |
-------------------------------------
-------------------------------------
| approxkl           | 0.011470671  |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.41e+03     |
| explained_variance | 0.147        |
| fps                | 18           |
| n_updates          | 41           |
| policy_entropy     | -0.75912505  |
| policy_loss        | 0.0002323892 |
| serial_timesteps   | 5248         |
| time_elapsed       | 320          |
| total_timesteps    | 5248         |
| value_loss         | 10.13925     |
-------------------------------------
--------------------------------------
| approxkl           | 0.0041306047  |
| clipfrac           | 0.056640625   |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.41e+03      |
| explained_variance | 0.102         |
| fps                | 19            |
| n_updates          | 42            |
| policy_entropy     | -0.7587399    |
| policy_loss        | -0.0038430998 |
| serial_timesteps   | 5376          |
| time_elapsed       | 327           |
| total_timesteps    | 5376          |
| value_loss         | 20.153742     |
--------------------------------------
-------------------------------------
| approxkl           | 0.005379531  |
| clipfrac           | 0.060546875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.41e+03     |
| explained_variance | -0.0593      |
| fps                | 18           |
| n_updates          | 43           |
| policy_entropy     | -0.75956947  |
| policy_loss        | 0.0029848185 |
| serial_timesteps   | 5504         |
| time_elapsed       | 334          |
| total_timesteps    | 5504         |
| value_loss         | 17.39484     |
-------------------------------------
------------------------------------
| approxkl           | 0.01925699  |
| clipfrac           | 0.18164062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.41e+03    |
| explained_variance | 0.0971      |
| fps                | 19          |
| n_updates          | 44          |
| policy_entropy     | -0.75929105 |
| policy_loss        | 0.011473481 |
| serial_timesteps   | 5632        |
| time_elapsed       | 341         |
| total_timesteps    | 5632        |
| value_loss         | 41.513527   |
------------------------------------
An average of 302.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.013433611 |
| clipfrac           | 0.18554688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.41e+03    |
| explained_variance | 0.191       |
| fps                | 19          |
| n_updates          | 45          |
| policy_entropy     | -0.7584484  |
| policy_loss        | 0.010221955 |
| serial_timesteps   | 5760        |
| time_elapsed       | 347         |
| total_timesteps    | 5760        |
| value_loss         | 33.904316   |
------------------------------------
--------------------------------------
| approxkl           | 0.0091695115  |
| clipfrac           | 0.1328125     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.41e+03      |
| explained_variance | 0.355         |
| fps                | 18            |
| n_updates          | 46            |
| policy_entropy     | -0.7583554    |
| policy_loss        | -0.0034165473 |
| serial_timesteps   | 5888          |
| time_elapsed       | 354           |
| total_timesteps    | 5888          |
| value_loss         | 6.01192       |
--------------------------------------
-------------------------------------
| approxkl           | 0.017896837  |
| clipfrac           | 0.21875      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.41e+03     |
| explained_variance | 0.222        |
| fps                | 19           |
| n_updates          | 47           |
| policy_entropy     | -0.75876766  |
| policy_loss        | -0.015385868 |
| serial_timesteps   | 6016         |
| time_elapsed       | 360          |
| total_timesteps    | 6016         |
| value_loss         | 4.8298497    |
-------------------------------------
-------------------------------------
| approxkl           | 0.005233771  |
| clipfrac           | 0.0703125    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.41e+03     |
| explained_variance | -0.157       |
| fps                | 18           |
| n_updates          | 48           |
| policy_entropy     | -0.759645    |
| policy_loss        | -0.005569674 |
| serial_timesteps   | 6144         |
| time_elapsed       | 367          |
| total_timesteps    | 6144         |
| value_loss         | 14.39322     |
-------------------------------------
------------------------------------
| approxkl           | 0.04504644  |
| clipfrac           | 0.37109375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.37e+03    |
| explained_variance | 0.00556     |
| fps                | 18          |
| n_updates          | 49          |
| policy_entropy     | -0.75948876 |
| policy_loss        | 0.027993575 |
| serial_timesteps   | 6272        |
| time_elapsed       | 374         |
| total_timesteps    | 6272        |
| value_loss         | 6287.5825   |
------------------------------------
-------------------------------------
| approxkl           | 0.022063846  |
| clipfrac           | 0.25195312   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | 0.0365       |
| fps                | 19           |
| n_updates          | 50           |
| policy_entropy     | -0.75903183  |
| policy_loss        | -0.018504133 |
| serial_timesteps   | 6400         |
| time_elapsed       | 381          |
| total_timesteps    | 6400         |
| value_loss         | 0.72195864   |
-------------------------------------
------------------------------------
| approxkl           | 0.035982557 |
| clipfrac           | 0.30859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.37e+03    |
| explained_variance | -0.0045     |
| fps                | 18          |
| n_updates          | 51          |
| policy_entropy     | -0.7584558  |
| policy_loss        | 0.026017835 |
| serial_timesteps   | 6528        |
| time_elapsed       | 388         |
| total_timesteps    | 6528        |
| value_loss         | 10.708683   |
------------------------------------
------------------------------------
| approxkl           | 0.015611211 |
| clipfrac           | 0.22070312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.37e+03    |
| explained_variance | 0.11        |
| fps                | 19          |
| n_updates          | 52          |
| policy_entropy     | -0.7582493  |
| policy_loss        | 0.019967062 |
| serial_timesteps   | 6656        |
| time_elapsed       | 395         |
| total_timesteps    | 6656        |
| value_loss         | 4.0228653   |
------------------------------------
An average of 303.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.011493214  |
| clipfrac           | 0.14453125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | 0.15         |
| fps                | 18           |
| n_updates          | 53           |
| policy_entropy     | -0.7574128   |
| policy_loss        | 0.0024755509 |
| serial_timesteps   | 6784         |
| time_elapsed       | 401          |
| total_timesteps    | 6784         |
| value_loss         | 2.2944584    |
-------------------------------------
-------------------------------------
| approxkl           | 0.013514045  |
| clipfrac           | 0.1484375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | 0.164        |
| fps                | 18           |
| n_updates          | 54           |
| policy_entropy     | -0.75688934  |
| policy_loss        | -0.001505814 |
| serial_timesteps   | 6912         |
| time_elapsed       | 408          |
| total_timesteps    | 6912         |
| value_loss         | 3.093995     |
-------------------------------------
-------------------------------------
| approxkl           | 0.012745314  |
| clipfrac           | 0.1796875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | -0.461       |
| fps                | 17           |
| n_updates          | 55           |
| policy_entropy     | -0.75680006  |
| policy_loss        | 0.0021375595 |
| serial_timesteps   | 7040         |
| time_elapsed       | 415          |
| total_timesteps    | 7040         |
| value_loss         | 1.8740106    |
-------------------------------------
-------------------------------------
| approxkl           | 0.008207303  |
| clipfrac           | 0.09375      |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | 0.108        |
| fps                | 19           |
| n_updates          | 56           |
| policy_entropy     | -0.7559474   |
| policy_loss        | -0.003721748 |
| serial_timesteps   | 7168         |
| time_elapsed       | 423          |
| total_timesteps    | 7168         |
| value_loss         | 29.080132    |
-------------------------------------
------------------------------------
| approxkl           | 0.008854221 |
| clipfrac           | 0.09765625  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.37e+03    |
| explained_variance | -0.0764     |
| fps                | 18          |
| n_updates          | 57          |
| policy_entropy     | -0.7552151  |
| policy_loss        | 0.00500112  |
| serial_timesteps   | 7296        |
| time_elapsed       | 429         |
| total_timesteps    | 7296        |
| value_loss         | 8.073101    |
------------------------------------
-------------------------------------
| approxkl           | 0.0076800855 |
| clipfrac           | 0.099609375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | 0.00899      |
| fps                | 19           |
| n_updates          | 58           |
| policy_entropy     | -0.75462836  |
| policy_loss        | 0.007109476  |
| serial_timesteps   | 7424         |
| time_elapsed       | 436          |
| total_timesteps    | 7424         |
| value_loss         | 16.741772    |
-------------------------------------
------------------------------------
| approxkl           | 0.010776579 |
| clipfrac           | 0.16796875  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.37e+03    |
| explained_variance | 0.0269      |
| fps                | 18          |
| n_updates          | 59          |
| policy_entropy     | -0.7544696  |
| policy_loss        | 0.008795299 |
| serial_timesteps   | 7552        |
| time_elapsed       | 443         |
| total_timesteps    | 7552        |
| value_loss         | 14.395108   |
------------------------------------
-------------------------------------
| approxkl           | 0.0125691965 |
| clipfrac           | 0.14257812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.37e+03     |
| explained_variance | -0.204       |
| fps                | 19           |
| n_updates          | 60           |
| policy_entropy     | -0.7546155   |
| policy_loss        | 0.005643826  |
| serial_timesteps   | 7680         |
| time_elapsed       | 450          |
| total_timesteps    | 7680         |
| value_loss         | 37.918377    |
-------------------------------------
An average of 304.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.0078109703 |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | 0.0103       |
| fps                | 19           |
| n_updates          | 61           |
| policy_entropy     | -0.75435036  |
| policy_loss        | 0.0048001697 |
| serial_timesteps   | 7808         |
| time_elapsed       | 456          |
| total_timesteps    | 7808         |
| value_loss         | 6489.224     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0031816228 |
| clipfrac           | 0.033203125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | 0.267        |
| fps                | 18           |
| n_updates          | 62           |
| policy_entropy     | -0.7540849   |
| policy_loss        | 0.0015129382 |
| serial_timesteps   | 7936         |
| time_elapsed       | 463          |
| total_timesteps    | 7936         |
| value_loss         | 7.983748     |
-------------------------------------
------------------------------------
| approxkl           | 0.009162758 |
| clipfrac           | 0.115234375 |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.0455      |
| fps                | 18          |
| n_updates          | 63          |
| policy_entropy     | -0.754027   |
| policy_loss        | 0.005443117 |
| serial_timesteps   | 8064        |
| time_elapsed       | 470         |
| total_timesteps    | 8064        |
| value_loss         | 10.784339   |
------------------------------------
-------------------------------------
| approxkl           | 0.0061933678 |
| clipfrac           | 0.076171875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | -0.241       |
| fps                | 18           |
| n_updates          | 64           |
| policy_entropy     | -0.7557104   |
| policy_loss        | 0.0020503844 |
| serial_timesteps   | 8192         |
| time_elapsed       | 477          |
| total_timesteps    | 8192         |
| value_loss         | 8.319674     |
-------------------------------------
------------------------------------
| approxkl           | 0.029051885 |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | -0.0606     |
| fps                | 19          |
| n_updates          | 65          |
| policy_entropy     | -0.7562332  |
| policy_loss        | 0.006382378 |
| serial_timesteps   | 8320        |
| time_elapsed       | 484         |
| total_timesteps    | 8320        |
| value_loss         | 11.677348   |
------------------------------------
------------------------------------
| approxkl           | 0.021944785 |
| clipfrac           | 0.234375    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.0506      |
| fps                | 18          |
| n_updates          | 66          |
| policy_entropy     | -0.7566668  |
| policy_loss        | 0.014402522 |
| serial_timesteps   | 8448        |
| time_elapsed       | 490         |
| total_timesteps    | 8448        |
| value_loss         | 16.023941   |
------------------------------------
------------------------------------
| approxkl           | 0.009739655 |
| clipfrac           | 0.14648438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.117       |
| fps                | 18          |
| n_updates          | 67          |
| policy_entropy     | -0.757067   |
| policy_loss        | 0.011011487 |
| serial_timesteps   | 8576        |
| time_elapsed       | 497         |
| total_timesteps    | 8576        |
| value_loss         | 14.30233    |
------------------------------------
-------------------------------------
| approxkl           | 0.0071895164 |
| clipfrac           | 0.095703125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | -0.0314      |
| fps                | 18           |
| n_updates          | 68           |
| policy_entropy     | -0.75716037  |
| policy_loss        | 0.012769132  |
| serial_timesteps   | 8704         |
| time_elapsed       | 504          |
| total_timesteps    | 8704         |
| value_loss         | 1.278919     |
-------------------------------------
An average of 304.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.023638522 |
| clipfrac           | 0.2421875   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | -0.0709     |
| fps                | 18          |
| n_updates          | 69          |
| policy_entropy     | -0.75675744 |
| policy_loss        | 0.004591858 |
| serial_timesteps   | 8832        |
| time_elapsed       | 511         |
| total_timesteps    | 8832        |
| value_loss         | 1.7281374   |
------------------------------------
-------------------------------------
| approxkl           | 0.021085216  |
| clipfrac           | 0.23632812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | -0.0868      |
| fps                | 18           |
| n_updates          | 70           |
| policy_entropy     | -0.7567491   |
| policy_loss        | -0.010284626 |
| serial_timesteps   | 8960         |
| time_elapsed       | 518          |
| total_timesteps    | 8960         |
| value_loss         | 2.9674802    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0148549415 |
| clipfrac           | 0.16796875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | 0.0354       |
| fps                | 18           |
| n_updates          | 71           |
| policy_entropy     | -0.75660545  |
| policy_loss        | 0.010741586  |
| serial_timesteps   | 9088         |
| time_elapsed       | 525          |
| total_timesteps    | 9088         |
| value_loss         | 16.000992    |
-------------------------------------
------------------------------------
| approxkl           | 0.030565685 |
| clipfrac           | 0.33007812  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | -0.0176     |
| fps                | 18          |
| n_updates          | 72          |
| policy_entropy     | -0.75651455 |
| policy_loss        | 0.023617998 |
| serial_timesteps   | 9216        |
| time_elapsed       | 532         |
| total_timesteps    | 9216        |
| value_loss         | 13.5928335  |
------------------------------------
-----------------------------------
| approxkl           | 0.22109216 |
| clipfrac           | 0.5703125  |
| ep_len_mean        | 1.54e+03   |
| ep_reward_mean     | 7.26e+03   |
| explained_variance | 0.000497   |
| fps                | 18         |
| n_updates          | 73         |
| policy_entropy     | -0.7563266 |
| policy_loss        | 0.05264234 |
| serial_timesteps   | 9344       |
| time_elapsed       | 539        |
| total_timesteps    | 9344       |
| value_loss         | 6960.212   |
-----------------------------------
-------------------------------------
| approxkl           | 0.01103016   |
| clipfrac           | 0.15234375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.26e+03     |
| explained_variance | 0.0112       |
| fps                | 19           |
| n_updates          | 74           |
| policy_entropy     | -0.75578153  |
| policy_loss        | 0.0051587094 |
| serial_timesteps   | 9472         |
| time_elapsed       | 545          |
| total_timesteps    | 9472         |
| value_loss         | 28.51527     |
-------------------------------------
------------------------------------
| approxkl           | 0.005066671 |
| clipfrac           | 0.05859375  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.26e+03    |
| explained_variance | -0.196      |
| fps                | 19          |
| n_updates          | 75          |
| policy_entropy     | -0.7551334  |
| policy_loss        | 0.009048741 |
| serial_timesteps   | 9600        |
| time_elapsed       | 552         |
| total_timesteps    | 9600        |
| value_loss         | 27.118717   |
------------------------------------
An average of 305.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.007467143  |
| clipfrac           | 0.09765625   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.26e+03     |
| explained_variance | 0.227        |
| fps                | 18           |
| n_updates          | 76           |
| policy_entropy     | -0.7555641   |
| policy_loss        | 0.0009336199 |
| serial_timesteps   | 9728         |
| time_elapsed       | 559          |
| total_timesteps    | 9728         |
| value_loss         | 6.271705     |
-------------------------------------
------------------------------------
| approxkl           | 0.02984528  |
| clipfrac           | 0.29492188  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.26e+03    |
| explained_variance | 0.0687      |
| fps                | 19          |
| n_updates          | 77          |
| policy_entropy     | -0.75526685 |
| policy_loss        | 0.015818095 |
| serial_timesteps   | 9856        |
| time_elapsed       | 565         |
| total_timesteps    | 9856        |
| value_loss         | 6.1629043   |
------------------------------------
------------------------------------
| approxkl           | 0.027941313 |
| clipfrac           | 0.28710938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.26e+03    |
| explained_variance | -0.0434     |
| fps                | 18          |
| n_updates          | 78          |
| policy_entropy     | -0.7549128  |
| policy_loss        | 0.012275597 |
| serial_timesteps   | 9984        |
| time_elapsed       | 572         |
| total_timesteps    | 9984        |
| value_loss         | 14.502047   |
------------------------------------
-------------------------------------
| approxkl           | 0.0116085885 |
| clipfrac           | 0.119140625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.26e+03     |
| explained_variance | 0.0134       |
| fps                | 19           |
| n_updates          | 79           |
| policy_entropy     | -0.75478184  |
| policy_loss        | 0.0058730887 |
| serial_timesteps   | 10112        |
| time_elapsed       | 579          |
| total_timesteps    | 10112        |
| value_loss         | 19.595585    |
-------------------------------------
--------------------------------------
| approxkl           | 0.012059253   |
| clipfrac           | 0.15234375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.26e+03      |
| explained_variance | -0.00972      |
| fps                | 18            |
| n_updates          | 80            |
| policy_entropy     | -0.75432074   |
| policy_loss        | -0.0008495904 |
| serial_timesteps   | 10240         |
| time_elapsed       | 585           |
| total_timesteps    | 10240         |
| value_loss         | 15.0144825    |
--------------------------------------
-------------------------------------
| approxkl           | 0.008645847  |
| clipfrac           | 0.103515625  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.26e+03     |
| explained_variance | -0.0249      |
| fps                | 19           |
| n_updates          | 81           |
| policy_entropy     | -0.7526677   |
| policy_loss        | 0.0011528537 |
| serial_timesteps   | 10368        |
| time_elapsed       | 592          |
| total_timesteps    | 10368        |
| value_loss         | 15.613591    |
-------------------------------------
------------------------------------
| approxkl           | 0.041937873 |
| clipfrac           | 0.31054688  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.26e+03    |
| explained_variance | 0.0864      |
| fps                | 18          |
| n_updates          | 82          |
| policy_entropy     | -0.7520278  |
| policy_loss        | 0.018938223 |
| serial_timesteps   | 10496       |
| time_elapsed       | 599         |
| total_timesteps    | 10496       |
| value_loss         | 8.431186    |
------------------------------------
-------------------------------------
| approxkl           | 0.019467743  |
| clipfrac           | 0.2421875    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.26e+03     |
| explained_variance | 0.00472      |
| fps                | 18           |
| n_updates          | 83           |
| policy_entropy     | -0.75170815  |
| policy_loss        | -0.011082999 |
| serial_timesteps   | 10624        |
| time_elapsed       | 606          |
| total_timesteps    | 10624        |
| value_loss         | 1.8751916    |
-------------------------------------
An average of 305.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
-------------------------------------
| approxkl           | 0.031166447  |
| clipfrac           | 0.31054688   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.26e+03     |
| explained_variance | -0.0129      |
| fps                | 18           |
| n_updates          | 84           |
| policy_entropy     | -0.7514917   |
| policy_loss        | -0.006995583 |
| serial_timesteps   | 10752        |
| time_elapsed       | 613          |
| total_timesteps    | 10752        |
| value_loss         | 1.7459289    |
-------------------------------------
------------------------------------
| approxkl           | 0.013734582 |
| clipfrac           | 0.22460938  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | -0.000341   |
| fps                | 18          |
| n_updates          | 85          |
| policy_entropy     | -0.75169146 |
| policy_loss        | 0.011481587 |
| serial_timesteps   | 10880       |
| time_elapsed       | 619         |
| total_timesteps    | 10880       |
| value_loss         | 6765.0205   |
------------------------------------
-------------------------------------
| approxkl           | 0.0149157345 |
| clipfrac           | 0.18359375   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | -0.00807     |
| fps                | 19           |
| n_updates          | 86           |
| policy_entropy     | -0.7518253   |
| policy_loss        | 0.0024421653 |
| serial_timesteps   | 11008        |
| time_elapsed       | 626          |
| total_timesteps    | 11008        |
| value_loss         | 11.986922    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0037677104 |
| clipfrac           | 0.048828125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | -0.00426     |
| fps                | 18           |
| n_updates          | 87           |
| policy_entropy     | -0.751588    |
| policy_loss        | 0.008511441  |
| serial_timesteps   | 11136        |
| time_elapsed       | 633          |
| total_timesteps    | 11136        |
| value_loss         | 20.272264    |
-------------------------------------
---------------------------------------
| approxkl           | 0.0070604794   |
| clipfrac           | 0.111328125    |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 7.27e+03       |
| explained_variance | -0.00412       |
| fps                | 18             |
| n_updates          | 88             |
| policy_entropy     | -0.75131387    |
| policy_loss        | -0.00073146005 |
| serial_timesteps   | 11264          |
| time_elapsed       | 640            |
| total_timesteps    | 11264          |
| value_loss         | 16.485445      |
---------------------------------------
--------------------------------------
| approxkl           | 0.011712581   |
| clipfrac           | 0.13085938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.27e+03      |
| explained_variance | -0.000134     |
| fps                | 18            |
| n_updates          | 89            |
| policy_entropy     | -0.7506518    |
| policy_loss        | -0.0013218917 |
| serial_timesteps   | 11392         |
| time_elapsed       | 647           |
| total_timesteps    | 11392         |
| value_loss         | 32.67997      |
--------------------------------------
------------------------------------
| approxkl           | 0.013752748 |
| clipfrac           | 0.18164062  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.0748      |
| fps                | 17          |
| n_updates          | 90          |
| policy_entropy     | -0.75044763 |
| policy_loss        | 0.008017935 |
| serial_timesteps   | 11520       |
| time_elapsed       | 653         |
| total_timesteps    | 11520       |
| value_loss         | 18.079361   |
------------------------------------
------------------------------------
| approxkl           | 0.023743419 |
| clipfrac           | 0.2890625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.123       |
| fps                | 19          |
| n_updates          | 91          |
| policy_entropy     | -0.7501212  |
| policy_loss        | 0.018487934 |
| serial_timesteps   | 11648       |
| time_elapsed       | 660         |
| total_timesteps    | 11648       |
| value_loss         | 7.346444    |
------------------------------------
An average of 306.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.014322279 |
| clipfrac           | 0.13476562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.0347      |
| fps                | 18          |
| n_updates          | 92          |
| policy_entropy     | -0.74946237 |
| policy_loss        | 0.007951363 |
| serial_timesteps   | 11776       |
| time_elapsed       | 667         |
| total_timesteps    | 11776       |
| value_loss         | 7.2895355   |
------------------------------------
-------------------------------------
| approxkl           | 0.01674153   |
| clipfrac           | 0.20507812   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | -0.0465      |
| fps                | 18           |
| n_updates          | 93           |
| policy_entropy     | -0.74880457  |
| policy_loss        | -0.014879281 |
| serial_timesteps   | 11904        |
| time_elapsed       | 674          |
| total_timesteps    | 11904        |
| value_loss         | 8.871632     |
-------------------------------------
-------------------------------------
| approxkl           | 0.0067015947 |
| clipfrac           | 0.083984375  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.27e+03     |
| explained_variance | 0.0128       |
| fps                | 19           |
| n_updates          | 94           |
| policy_entropy     | -0.7494214   |
| policy_loss        | 0.007644618  |
| serial_timesteps   | 12032        |
| time_elapsed       | 681          |
| total_timesteps    | 12032        |
| value_loss         | 13.909976    |
-------------------------------------
------------------------------------
| approxkl           | 0.022370493 |
| clipfrac           | 0.28320312  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | 0.032       |
| fps                | 18          |
| n_updates          | 95          |
| policy_entropy     | -0.7503596  |
| policy_loss        | 0.020262998 |
| serial_timesteps   | 12160       |
| time_elapsed       | 687         |
| total_timesteps    | 12160       |
| value_loss         | 11.499365   |
------------------------------------
------------------------------------
| approxkl           | 0.014032764 |
| clipfrac           | 0.17773438  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.27e+03    |
| explained_variance | -0.0164     |
| fps                | 19          |
| n_updates          | 96          |
| policy_entropy     | -0.75054467 |
| policy_loss        | 0.008419846 |
| serial_timesteps   | 12288       |
| time_elapsed       | 694         |
| total_timesteps    | 12288       |
| value_loss         | 8.016083    |
------------------------------------
--------------------------------------
| approxkl           | 0.018949542   |
| clipfrac           | 0.24609375    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.28e+03      |
| explained_variance | 0.000438      |
| fps                | 18            |
| n_updates          | 97            |
| policy_entropy     | -0.7508596    |
| policy_loss        | -0.0015187175 |
| serial_timesteps   | 12416         |
| time_elapsed       | 701           |
| total_timesteps    | 12416         |
| value_loss         | 6769.0225     |
--------------------------------------
---------------------------------------
| approxkl           | 0.021116043    |
| clipfrac           | 0.22265625     |
| ep_len_mean        | 1.54e+03       |
| ep_reward_mean     | 7.28e+03       |
| explained_variance | -0.0272        |
| fps                | 18             |
| n_updates          | 98             |
| policy_entropy     | -0.750788      |
| policy_loss        | -0.00017900136 |
| serial_timesteps   | 12544          |
| time_elapsed       | 708            |
| total_timesteps    | 12544          |
| value_loss         | 11.109274      |
---------------------------------------
-------------------------------------
| approxkl           | 0.0076972097 |
| clipfrac           | 0.10546875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.28e+03     |
| explained_variance | -0.00198     |
| fps                | 18           |
| n_updates          | 99           |
| policy_entropy     | -0.7505568   |
| policy_loss        | 0.008408087  |
| serial_timesteps   | 12672        |
| time_elapsed       | 715          |
| total_timesteps    | 12672        |
| value_loss         | 20.150192    |
-------------------------------------
An average of 307.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.014741219 |
| clipfrac           | 0.171875    |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.28e+03    |
| explained_variance | -0.00387    |
| fps                | 18          |
| n_updates          | 100         |
| policy_entropy     | -0.75024366 |
| policy_loss        | 0.020769037 |
| serial_timesteps   | 12800       |
| time_elapsed       | 722         |
| total_timesteps    | 12800       |
| value_loss         | 7.573896    |
------------------------------------
-------------------------------------
| approxkl           | 0.008770533  |
| clipfrac           | 0.11328125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.28e+03     |
| explained_variance | -0.00595     |
| fps                | 17           |
| n_updates          | 101          |
| policy_entropy     | -0.75085163  |
| policy_loss        | 0.0014948205 |
| serial_timesteps   | 12928        |
| time_elapsed       | 729          |
| total_timesteps    | 12928        |
| value_loss         | 38.57131     |
-------------------------------------
--------------------------------------
| approxkl           | 0.01070053    |
| clipfrac           | 0.15039062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.28e+03      |
| explained_variance | 0.000726      |
| fps                | 18            |
| n_updates          | 102           |
| policy_entropy     | -0.7527185    |
| policy_loss        | -0.0054482273 |
| serial_timesteps   | 13056         |
| time_elapsed       | 736           |
| total_timesteps    | 13056         |
| value_loss         | 35.144276     |
--------------------------------------
-------------------------------------
| approxkl           | 0.0100265145 |
| clipfrac           | 0.107421875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.28e+03     |
| explained_variance | -0.00326     |
| fps                | 18           |
| n_updates          | 103          |
| policy_entropy     | -0.75369906  |
| policy_loss        | 0.011843141  |
| serial_timesteps   | 13184        |
| time_elapsed       | 743          |
| total_timesteps    | 13184        |
| value_loss         | 17.128078    |
-------------------------------------
-------------------------------------
| approxkl           | 0.0068225022 |
| clipfrac           | 0.0859375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.28e+03     |
| explained_variance | -0.000537    |
| fps                | 18           |
| n_updates          | 104          |
| policy_entropy     | -0.75449395  |
| policy_loss        | 0.0021429206 |
| serial_timesteps   | 13312        |
| time_elapsed       | 750          |
| total_timesteps    | 13312        |
| value_loss         | 19.872055    |
-------------------------------------
--------------------------------------
| approxkl           | 0.015977817   |
| clipfrac           | 0.22460938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.28e+03      |
| explained_variance | 0.0161        |
| fps                | 18            |
| n_updates          | 105           |
| policy_entropy     | -0.7541213    |
| policy_loss        | -0.0020457432 |
| serial_timesteps   | 13440         |
| time_elapsed       | 757           |
| total_timesteps    | 13440         |
| value_loss         | 9.267812      |
--------------------------------------
--------------------------------------
| approxkl           | 0.0043350304  |
| clipfrac           | 0.0546875     |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.28e+03      |
| explained_variance | 0.0215        |
| fps                | 19            |
| n_updates          | 106           |
| policy_entropy     | -0.75325054   |
| policy_loss        | -0.0006148843 |
| serial_timesteps   | 13568         |
| time_elapsed       | 763           |
| total_timesteps    | 13568         |
| value_loss         | 16.525618     |
--------------------------------------
------------------------------------
| approxkl           | 0.03064106  |
| clipfrac           | 0.29101562  |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.28e+03    |
| explained_variance | 0.00445     |
| fps                | 18          |
| n_updates          | 107         |
| policy_entropy     | -0.7529726  |
| policy_loss        | 0.021748278 |
| serial_timesteps   | 13696       |
| time_elapsed       | 770         |
| total_timesteps    | 13696       |
| value_loss         | 24.018032   |
------------------------------------
An average of 307.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
--------------------------------------
| approxkl           | 0.018286895   |
| clipfrac           | 0.21289062    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.28e+03      |
| explained_variance | -0.0304       |
| fps                | 18            |
| n_updates          | 108           |
| policy_entropy     | -0.75292426   |
| policy_loss        | -0.0026409181 |
| serial_timesteps   | 13824         |
| time_elapsed       | 777           |
| total_timesteps    | 13824         |
| value_loss         | 23.90842      |
--------------------------------------
-------------------------------------
| approxkl           | 0.0068835528 |
| clipfrac           | 0.091796875  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | -8.38e-05    |
| fps                | 19           |
| n_updates          | 109          |
| policy_entropy     | -0.7522204   |
| policy_loss        | -0.00813428  |
| serial_timesteps   | 13952        |
| time_elapsed       | 784          |
| total_timesteps    | 13952        |
| value_loss         | 6797.1377    |
-------------------------------------
-------------------------------------
| approxkl           | 0.033275455  |
| clipfrac           | 0.30273438   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | -0.0312      |
| fps                | 18           |
| n_updates          | 110          |
| policy_entropy     | -0.7516608   |
| policy_loss        | -0.022967404 |
| serial_timesteps   | 14080        |
| time_elapsed       | 790          |
| total_timesteps    | 14080        |
| value_loss         | 3.5829382    |
-------------------------------------
-------------------------------------
| approxkl           | 0.01805536   |
| clipfrac           | 0.2265625    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | -0.00936     |
| fps                | 18           |
| n_updates          | 111          |
| policy_entropy     | -0.75128293  |
| policy_loss        | -0.026402408 |
| serial_timesteps   | 14208        |
| time_elapsed       | 797          |
| total_timesteps    | 14208        |
| value_loss         | 3.1739852    |
-------------------------------------
-------------------------------------
| approxkl           | 0.018770855  |
| clipfrac           | 0.2109375    |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | 0.00727      |
| fps                | 18           |
| n_updates          | 112          |
| policy_entropy     | -0.7521817   |
| policy_loss        | -0.010014363 |
| serial_timesteps   | 14336        |
| time_elapsed       | 804          |
| total_timesteps    | 14336        |
| value_loss         | 6.484892     |
-------------------------------------
-------------------------------------
| approxkl           | 0.039678853  |
| clipfrac           | 0.23046875   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | -0.0357      |
| fps                | 18           |
| n_updates          | 113          |
| policy_entropy     | -0.75316924  |
| policy_loss        | -0.010748817 |
| serial_timesteps   | 14464        |
| time_elapsed       | 811          |
| total_timesteps    | 14464        |
| value_loss         | 6.456296     |
-------------------------------------
-------------------------------------
| approxkl           | 0.009905808  |
| clipfrac           | 0.14453125   |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | 0.00364      |
| fps                | 19           |
| n_updates          | 114          |
| policy_entropy     | -0.75517493  |
| policy_loss        | 0.0048381984 |
| serial_timesteps   | 14592        |
| time_elapsed       | 818          |
| total_timesteps    | 14592        |
| value_loss         | 10.6773205   |
-------------------------------------
-------------------------------------
| approxkl           | 0.00535505   |
| clipfrac           | 0.064453125  |
| ep_len_mean        | 1.54e+03     |
| ep_reward_mean     | 7.31e+03     |
| explained_variance | -0.000958    |
| fps                | 19           |
| n_updates          | 115          |
| policy_entropy     | -0.7560372   |
| policy_loss        | 0.0037173587 |
| serial_timesteps   | 14720        |
| time_elapsed       | 824          |
| total_timesteps    | 14720        |
| value_loss         | 6.4835277    |
-------------------------------------
An average of 308.0 episodes completed
Best mean reward: 4397.92 - Latest 5 sample mean reward per episode: 3117.93
------------------------------------
| approxkl           | 0.012113262 |
| clipfrac           | 0.1640625   |
| ep_len_mean        | 1.54e+03    |
| ep_reward_mean     | 7.31e+03    |
| explained_variance | -0.0108     |
| fps                | 19          |
| n_updates          | 116         |
| policy_entropy     | -0.75632876 |
| policy_loss        | 0.011786469 |
| serial_timesteps   | 14848       |
| time_elapsed       | 831         |
| total_timesteps    | 14848       |
| value_loss         | 27.431505   |
------------------------------------
--------------------------------------
| approxkl           | 0.010951259   |
| clipfrac           | 0.13085938    |
| ep_len_mean        | 1.54e+03      |
| ep_reward_mean     | 7.31e+03      |
| explained_variance | -0.00205      |
| fps                | 19            |
| n_updates          | 117           |
| policy_entropy     | -0.75719583   |
| policy_loss        | -0.0031835942 |
| serial_timesteps   | 14976         |
| time_elapsed       | 838           |
| total_timesteps    | 14976         |
| value_loss         | 21.281765     |
--------------------------------------
/data/nauga/SmartBuildings/venvs/sbvenv1/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b26bc2128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b26bc2128>>: AttributeError: module 'gast' has no attribute 'Num'
WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b24dad320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f8b24dad320>>: AttributeError: module 'gast' has no attribute 'Num'
setting environment to test mode..... 

Done!
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
