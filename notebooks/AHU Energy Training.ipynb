{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# including the project directory to the notebook level\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import warnings  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    from keras import backend as K\n",
    "    from nn_source import models as mp\n",
    "from dataprocess import dataprocessor as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pickled file for ahu data\n",
    "ahudata = dp.readfile('../data/processed/ahu1energy.pkl')\n",
    "\n",
    "# return pickled df\n",
    "ahu = ahudata.return_df(processmethods=['file2df'])\n",
    "\n",
    "# read the pickled file for ghi data\n",
    "ghidata = dp.readfile('../data/processed/ghi.pkl')\n",
    "\n",
    "# return pickled df\n",
    "ghi = ghidata.return_df(processmethods=['file2df'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only required columns and rearranging them\n",
    "ahu = ahu[[\n",
    "    'AHU_1 outdoorAirTemp', 'WeatherDataProfile humidity',\n",
    "    'AHU_1 supplyAirTemp', 'HW_BTU_METER currentKbtuDeltaReading',\n",
    "    'CHW_BTU_METER currentKbtuDeltaReading'\n",
    "]]\n",
    "\n",
    "# renaming columns\n",
    "ahu.columns = ['oat', 'orh', 'sat', 'hwe', 'cwe']\n",
    "\n",
    "# Total energy is sum of heating and coling\n",
    "ahu['totale'] = ahu['hwe'] + ahu['cwe']\n",
    "# dropping heating and cooling energy columns\n",
    "ahu = ahu.drop(columns=['hwe', 'cwe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging ahu and ghi data\n",
    "df = dp.merge_df_columns([ahu, ghi])\n",
    "\n",
    "# rearranging columns\n",
    "df = df[['oat', 'orh', 'sat', 'Ghi', 'totale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HourSine'] = np.sin(2*np.pi*df.index.hour/24.0)\n",
    "df['HourCos'] = np.cos(2*np.pi*df.index.hour/24.0)\n",
    "df['WeekSine'] = np.sin(2*np.pi*df.index.week/52.0)\n",
    "df['WeekCos'] = np.cos(2*np.pi*df.index.week/52.0)\n",
    "df['DayofWeekSine'] = np.sin(2*np.pi*df.index.dayofweek/7.0)\n",
    "df['DayofWeekCos'] = np.cos(2*np.pi*df.index.dayofweek/7.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    'oat', 'orh', 'sat', 'Ghi', 'HourSine', 'HourCos', 'WeekSine', 'WeekCos',\n",
    "    'DayofWeekSine', 'DayofWeekCos', 'totale'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of 7 day dataframes for training\n",
    "dflist = dp.df2dflist(df, subsequence=True, period=1, days=7, hours=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_scaler, y_scaler = dp.df2arrays(\n",
    "    dflist[1],\n",
    "    predictorcols=['oat', 'orh', 'sat', 'Ghi'],\n",
    "    outputcols=['totale'],\n",
    "    scaling=True,\n",
    "    feature_range=(0,1),\n",
    "    reshaping=True,\n",
    "    lag=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [X_train, X_test, y_train, y_test]:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../results/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the results directory\n",
    "try:\n",
    "    os.mkdir('../results/lstmtrain/')\n",
    "except FileExistsError:\n",
    "    files = os.listdir('../results/lstmtrain/')\n",
    "    for f in files:\n",
    "        os.remove('../results/lstmtrain/' + f)\n",
    "        \n",
    "os.mkdir('../results/lstmtrain/loginfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate learner model\n",
    "model = mp.lstm_model('../results/lstmtrain/',\n",
    "                      inputdim=X_train.shape[-1],\n",
    "                      outputdim=1,\n",
    "                      period=1)\n",
    "\n",
    "# Desing model architecture\n",
    "model.design_model(lstmhiddenlayers=[16] * 1,\n",
    "                   densehiddenlayers=[32] * 5,\n",
    "                   dropoutlist=[[], []],\n",
    "                   batchnormalizelist=[[], []])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.show_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating early sstopping, model checkpointing and learning reate changing callbacks\n",
    "model.model_callbacks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.train_model(X_train, y_train, X_test, y_test, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!tensorboard --logdir '../results/lstmtrain/loginfo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train, preds_test = model.evaluate_model(X_train,\n",
    "                                               y_train,\n",
    "                                               X_test,\n",
    "                                               y_test,\n",
    "                                               y_scaler,\n",
    "                                               scaling = True,\n",
    "                                               saveplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.dataframeplot(dflist[2], lazy=False, style='-', legend=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('sbvenv1': venv)",
   "language": "python",
   "name": "python36964bitsbvenv1venv1a534851ebbc4d609aad5dcf7b359ab5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
